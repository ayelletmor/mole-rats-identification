/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
[I 2023-09-23 18:44:22,189] A new study created in memory with name: no-name-a39762d5-6b82-4a85-becf-bc691984154a
I am process 1935276, running on amorgenstern-titanx8-25nlt: starting (Sat Sep 23 18:44:17 2023)
balanced sampler is not used
---------------the train dataloader---------------
now using following mask: 24 freq, 96 time
now using mix-up with rate 0.000000
now process ours
use dataset mean -0.023 and std 0.413 to normalize the input.
number of classes is 4
---------------the evaluation dataloader---------------
now using following mask: 0 freq, 0 time
now using mix-up with rate 0.000000
now process ours
use dataset mean -0.023 and std 0.413 to normalize the input.
number of classes is 4
Now train with ours with 1923 training samples, evaluate with 209 samples
now load a SSL pretrained models from SSAST-Base-Patch-400.pth
pretraining patch split stride: frequency=16, time=16
pretraining patch shape: frequency=16, time=16
pretraining patch array dimension: frequency=8, time=64
pretraining number of patches=512
fine-tuning patch split stride: frequncey=16, time=16
fine-tuning number of patches=256

Creating experiment directory: hyperparameter_search_sep_data
Now starting fine-tuning for 50 epochs
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcbe219e820>
The learning rate scheduler starts at 9 epoch with decay rate of 0.778 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 18:44:22.272474
current #epochs=1, #steps=0
[1695494677.017352] [amorgenstern-titanx8-25nlt:1935276:f]        vfs_fuse.c:281  UCX  ERROR inotify_add_watch(/tmp) failed: No space left on device
start validation
acc: 0.377990
AUC: 0.673962
Avg Precision: 0.338438
Avg Recall: 1.000000
d_prime: 0.637643
train_loss: 1.258547
valid_loss: 1.364345
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.001631335509464941
Epoch-1 lr: 0.004894006528394823
epoch 1 training time: 31.566
---------------
2023-09-23 18:44:53.839222
current #epochs=2, #steps=40
start validation
acc: 0.535885
AUC: 0.706332
Avg Precision: 0.327592
Avg Recall: 1.000000
d_prime: 0.767495
train_loss: 1.166015
valid_loss: 1.339852
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.001631335509464941
Epoch-2 lr: 0.004894006528394823
epoch 2 training time: 19.296
---------------
2023-09-23 18:45:13.135753
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00164	Per Sample DNN Time 0.00554	Train Loss 1.1166	
start validation
acc: 0.320574
AUC: 0.789092
Avg Precision: 0.332799
Avg Recall: 1.000000
d_prime: 1.136001
train_loss: 1.133847
valid_loss: 1.369754
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.001631335509464941
Epoch-3 lr: 0.004894006528394823
epoch 3 training time: 15.388
---------------
2023-09-23 18:45:28.523790
current #epochs=4, #steps=120
start validation
acc: 0.535885
AUC: 0.797934
Avg Precision: 0.371636
Avg Recall: 1.000000
d_prime: 1.179826
train_loss: 1.128937
valid_loss: 1.349385
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.001631335509464941
Epoch-4 lr: 0.004894006528394823
epoch 4 training time: 15.111
---------------
2023-09-23 18:45:43.634670
current #epochs=5, #steps=160
start validation
acc: 0.535885
AUC: 0.788565
Avg Precision: 0.405282
Avg Recall: 1.000000
d_prime: 1.133424
train_loss: 1.131383
valid_loss: 1.346208
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.001631335509464941
Epoch-5 lr: 0.004894006528394823
epoch 5 training time: 15.385
---------------
2023-09-23 18:45:59.019678
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03990	Per Sample Data Time 0.03026	Per Sample DNN Time 0.00965	Train Loss 0.9917	
start validation
acc: 0.320574
AUC: 0.690019
Avg Precision: 0.332816
Avg Recall: 1.000000
d_prime: 0.701315
train_loss: 1.104389
valid_loss: 1.364472
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.001631335509464941
Epoch-6 lr: 0.004894006528394823
epoch 6 training time: 15.596
---------------
2023-09-23 18:46:14.615495
current #epochs=7, #steps=240
start validation
acc: 0.535885
AUC: 0.750084
Avg Precision: 0.412607
Avg Recall: 1.000000
d_prime: 0.954248
train_loss: 1.105126
valid_loss: 1.351702
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.001631335509464941
Epoch-7 lr: 0.004894006528394823
epoch 7 training time: 15.437
---------------
2023-09-23 18:46:30.052831
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00564	Train Loss 1.1240	
start validation
acc: 0.535885
AUC: 0.474785
Avg Precision: 0.260227
Avg Recall: 1.000000
d_prime: -0.089445
train_loss: 1.096596
valid_loss: 1.348138
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.001631335509464941
Epoch-8 lr: 0.004894006528394823
epoch 8 training time: 15.239
---------------
2023-09-23 18:46:45.291299
current #epochs=9, #steps=320
start validation
acc: 0.851675
AUC: 0.788959
Avg Precision: 0.489699
Avg Recall: 1.000000
d_prime: 1.135351
train_loss: 1.103664
valid_loss: 1.355936
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0012692464948214465
Epoch-9 lr: 0.0038077394844643394
epoch 9 training time: 17.706
---------------
2023-09-23 18:47:02.997738
current #epochs=10, #steps=360
start validation
acc: 0.535885
AUC: 0.798246
Avg Precision: 0.332861
Avg Recall: 1.000000
d_prime: 1.181394
train_loss: 1.093858
valid_loss: 1.339751
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0012692464948214465
Epoch-10 lr: 0.0038077394844643394
epoch 10 training time: 15.400
---------------
2023-09-23 18:47:18.398012
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04050	Per Sample Data Time 0.03151	Per Sample DNN Time 0.00899	Train Loss 0.8919	
start validation
acc: 0.535885
AUC: 0.598968
Avg Precision: 0.423577
Avg Recall: 1.000000
d_prime: 0.354511
train_loss: 1.127586
valid_loss: 1.355765
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0012692464948214465
Epoch-11 lr: 0.0038077394844643394
epoch 11 training time: 15.248
---------------
2023-09-23 18:47:33.646500
current #epochs=12, #steps=440
start validation
acc: 0.535885
AUC: 0.717731
Avg Precision: 0.333539
Avg Recall: 1.000000
d_prime: 0.814749
train_loss: 1.101894
valid_loss: 1.355509
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0012692464948214465
Epoch-12 lr: 0.0038077394844643394
epoch 12 training time: 15.368
---------------
2023-09-23 18:47:49.014795
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00715	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00557	Train Loss 1.1049	
start validation
acc: 0.535885
AUC: 0.709863
Avg Precision: 0.418844
Avg Recall: 1.000000
d_prime: 0.782038
train_loss: 1.098752
valid_loss: 1.348152
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0012692464948214465
Epoch-13 lr: 0.0038077394844643394
epoch 13 training time: 15.326
---------------
2023-09-23 18:48:04.341136
current #epochs=14, #steps=520
start validation
acc: 0.535885
AUC: 0.693798
Avg Precision: 0.428311
Avg Recall: 1.000000
d_prime: 0.716505
train_loss: 1.100254
valid_loss: 1.352313
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0012692464948214465
Epoch-14 lr: 0.0038077394844643394
epoch 14 training time: 15.051
---------------
2023-09-23 18:48:19.391918
current #epochs=15, #steps=560
start validation
acc: 0.535885
AUC: 0.772378
Avg Precision: 0.398327
Avg Recall: 1.000000
d_prime: 1.055996
train_loss: 1.095052
valid_loss: 1.349493
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0012692464948214465
Epoch-15 lr: 0.0038077394844643394
epoch 15 training time: 15.964
---------------
2023-09-23 18:48:35.355859
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04093	Per Sample Data Time 0.03127	Per Sample DNN Time 0.00967	Train Loss 1.0838	
start validation
acc: 0.535885
AUC: 0.718697
Avg Precision: 0.331799
Avg Recall: 1.000000
d_prime: 0.818794
train_loss: 1.090631
valid_loss: 1.350833
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0012692464948214465
Epoch-16 lr: 0.0038077394844643394
epoch 16 training time: 15.345
---------------
2023-09-23 18:48:50.700961
current #epochs=17, #steps=640
start validation
acc: 0.535885
AUC: 0.704318
Avg Precision: 0.383919
Avg Recall: 1.000000
d_prime: 0.759235
train_loss: 1.088969
valid_loss: 1.352054
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0009875262662215408
Epoch-17 lr: 0.0029625787986646223
epoch 17 training time: 15.313
---------------
2023-09-23 18:49:06.013961
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00732	Per Sample Data Time 0.00170	Per Sample DNN Time 0.00562	Train Loss 1.0848	
start validation
acc: 0.535885
AUC: 0.804198
Avg Precision: 0.436676
Avg Recall: 1.000000
d_prime: 1.211574
train_loss: 1.088324
valid_loss: 1.345275
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0009875262662215408
Epoch-18 lr: 0.0029625787986646223
epoch 18 training time: 15.408
---------------
2023-09-23 18:49:21.421931
current #epochs=19, #steps=720
start validation
acc: 0.574163
AUC: 0.801302
Avg Precision: 0.357471
Avg Recall: 1.000000
d_prime: 1.196823
train_loss: 1.080576
valid_loss: 1.322207
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0009875262662215408
Epoch-19 lr: 0.0029625787986646223
epoch 19 training time: 15.324
---------------
2023-09-23 18:49:36.746082
current #epochs=20, #steps=760
start validation
acc: 0.535885
AUC: 0.796830
Avg Precision: 0.387117
Avg Recall: 1.000000
d_prime: 1.174296
train_loss: 1.078543
valid_loss: 1.340221
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0009875262662215408
Epoch-20 lr: 0.0029625787986646223
epoch 20 training time: 15.295
---------------
2023-09-23 18:49:52.041002
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03982	Per Sample Data Time 0.02977	Per Sample DNN Time 0.01005	Train Loss 1.0697	
start validation
acc: 0.851675
AUC: 0.803520
Avg Precision: 0.475277
Avg Recall: 1.000000
d_prime: 1.208109
train_loss: 1.061327
valid_loss: 1.242365
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0009875262662215408
Epoch-21 lr: 0.0029625787986646223
epoch 21 training time: 15.271
---------------
2023-09-23 18:50:07.312016
current #epochs=22, #steps=840
start validation
acc: 0.846890
AUC: 0.816877
Avg Precision: 0.474073
Avg Recall: 1.000000
d_prime: 1.277783
train_loss: 0.999593
valid_loss: 1.257139
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0009875262662215408
Epoch-22 lr: 0.0029625787986646223
epoch 22 training time: 15.257
---------------
2023-09-23 18:50:22.569373
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00564	Train Loss 0.9856	
start validation
acc: 0.679426
AUC: 0.805562
Avg Precision: 0.475290
Avg Recall: 1.000000
d_prime: 1.218570
train_loss: 0.987548
valid_loss: 1.292462
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0009875262662215408
Epoch-23 lr: 0.0029625787986646223
epoch 23 training time: 15.290
---------------
2023-09-23 18:50:37.858810
current #epochs=24, #steps=920
start validation
acc: 0.808612
AUC: 0.819219
Avg Precision: 0.460782
Avg Recall: 1.000000
d_prime: 1.290320
train_loss: 0.934909
valid_loss: 1.251359
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0009875262662215408
Epoch-24 lr: 0.0029625787986646223
epoch 24 training time: 15.383
---------------
2023-09-23 18:50:53.242075
current #epochs=25, #steps=960
start validation
acc: 0.765550
AUC: 0.804520
Avg Precision: 0.462956
Avg Recall: 1.000000
d_prime: 1.213221
train_loss: 0.990355
valid_loss: 1.275635
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.0007683362770402188
Epoch-25 lr: 0.002305008831120656
epoch 25 training time: 15.843
---------------
2023-09-23 18:51:09.085060
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.03983	Per Sample Data Time 0.02976	Per Sample DNN Time 0.01006	Train Loss 0.9484	
start validation
acc: 0.703349
AUC: 0.808435
Avg Precision: 0.455626
Avg Recall: 1.000000
d_prime: 1.233398
train_loss: 0.983172
valid_loss: 1.298631
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.0007683362770402188
Epoch-26 lr: 0.002305008831120656
epoch 26 training time: 15.292
---------------
2023-09-23 18:51:24.377184
current #epochs=27, #steps=1040
start validation
acc: 0.837321
AUC: 0.807990
Avg Precision: 0.490465
Avg Recall: 1.000000
d_prime: 1.231091
train_loss: 0.941234
valid_loss: 1.260477
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.0007683362770402188
Epoch-27 lr: 0.002305008831120656
epoch 27 training time: 15.286
---------------
2023-09-23 18:51:39.663943
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00565	Train Loss 0.9944	
start validation
acc: 0.842105
AUC: 0.800227
Avg Precision: 0.465468
Avg Recall: 1.000000
d_prime: 1.191379
train_loss: 0.944139
valid_loss: 1.232766
validation finished
normal learning rate scheduler step
Epoch-28 lr: 0.0007683362770402188
Epoch-28 lr: 0.002305008831120656
epoch 28 training time: 15.321
---------------
2023-09-23 18:51:54.984716
current #epochs=29, #steps=1120
start validation
acc: 0.717703
AUC: 0.802510
Avg Precision: 0.439438
Avg Recall: 1.000000
d_prime: 1.202961
train_loss: 0.933042
valid_loss: 1.279407
validation finished
normal learning rate scheduler step
Epoch-29 lr: 0.0007683362770402188
Epoch-29 lr: 0.002305008831120656
epoch 29 training time: 15.383
---------------
2023-09-23 18:52:10.367509
current #epochs=30, #steps=1160
start validation
acc: 0.803828
AUC: 0.797456
Avg Precision: 0.412404
Avg Recall: 1.000000
d_prime: 1.177430
train_loss: 0.880978
valid_loss: 1.234604
validation finished
normal learning rate scheduler step
Epoch-30 lr: 0.0007683362770402188
Epoch-30 lr: 0.002305008831120656
epoch 30 training time: 15.332
---------------
2023-09-23 18:52:25.699187
current #epochs=31, #steps=1200
Epoch: [31][0/40]	Per Sample Total Time 0.03996	Per Sample Data Time 0.02999	Per Sample DNN Time 0.00998	Train Loss 0.8013	
start validation
acc: 0.669856
AUC: 0.797661
Avg Precision: 0.419826
Avg Recall: 1.000000
d_prime: 1.178456
train_loss: 0.915454
valid_loss: 1.271935
validation finished
normal learning rate scheduler step
Epoch-31 lr: 0.0007683362770402188
Epoch-31 lr: 0.002305008831120656
epoch 31 training time: 15.287
---------------
2023-09-23 18:52:40.986187
current #epochs=32, #steps=1240
start validation
acc: 0.784689
AUC: 0.808078
Avg Precision: 0.431851
Avg Recall: 1.000000
d_prime: 1.231548
train_loss: 0.906842
valid_loss: 1.227374
validation finished
normal learning rate scheduler step
Epoch-32 lr: 0.0007683362770402188
Epoch-32 lr: 0.002305008831120656
epoch 32 training time: 15.279
---------------
2023-09-23 18:52:56.265031
current #epochs=33, #steps=1280
Epoch: [33][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00563	Train Loss 0.8799	
start validation
acc: 0.760766
AUC: 0.808973
Avg Precision: 0.444597
Avg Recall: 1.000000
d_prime: 1.236191
train_loss: 0.871954
valid_loss: 1.221777
validation finished
normal learning rate scheduler step
Epoch-33 lr: 0.0005977974002400735
Epoch-33 lr: 0.0017933922007202204
epoch 33 training time: 15.335
---------------
2023-09-23 18:53:11.599619
current #epochs=34, #steps=1320
start validation
acc: 0.765550
AUC: 0.805091
Avg Precision: 0.452022
Avg Recall: 1.000000
d_prime: 1.216150
train_loss: 0.878188
valid_loss: 1.232286
validation finished
normal learning rate scheduler step
Epoch-34 lr: 0.0005977974002400735
Epoch-34 lr: 0.0017933922007202204
epoch 34 training time: 15.376
---------------
2023-09-23 18:53:26.975404
current #epochs=35, #steps=1360
start validation
[I 2023-09-23 18:53:42,258] Trial 0 finished with value: 0.44491567769157475 and parameters: {'warmup': 'True', 'num_epochs': 35, 'batch_size': 11, 'lr-adaptschedule': 'False', 'lr': 0.001631335509464941, 'head-lr': 3, 'lr-scheduler-start': 9, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.7780413578061233}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.751196
AUC: 0.826673
Avg Precision: 0.444916
Avg Recall: 1.000000
d_prime: 1.330914
train_loss: 0.860501
valid_loss: 1.232693
validation finished
normal learning rate scheduler step
Epoch-35 lr: 0.0005977974002400735
Epoch-35 lr: 0.0017933922007202204
epoch 35 training time: 15.279
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 5 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcbd1e737c0>
The learning rate scheduler starts at 7 epoch with decay rate of 0.755 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 18:53:42.264424
current #epochs=1, #steps=0
start validation
acc: 0.382775
AUC: 0.779828
Avg Precision: 0.327837
Avg Recall: 1.000000
d_prime: 1.091225
train_loss: 1.422625
valid_loss: 1.365791
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0032143835447243133
Epoch-1 lr: 0.016071917723621567
epoch 1 training time: 17.903
---------------
2023-09-23 18:54:00.167291
current #epochs=2, #steps=40
start validation
acc: 0.535885
AUC: 0.501638
Avg Precision: 0.270292
Avg Recall: 1.000000
d_prime: 0.005807
train_loss: 1.180928
valid_loss: 1.350459
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0032143835447243133
Epoch-2 lr: 0.016071917723621567
epoch 2 training time: 17.584
---------------
2023-09-23 18:54:17.751152
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00555	Train Loss 1.2393	
start validation
acc: 0.425837
AUC: 0.656118
Avg Precision: 0.309281
Avg Recall: 1.000000
d_prime: 0.568361
train_loss: 1.201153
valid_loss: 1.357015
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0032143835447243133
Epoch-3 lr: 0.016071917723621567
epoch 3 training time: 15.262
---------------
2023-09-23 18:54:33.012950
current #epochs=4, #steps=120
start validation
acc: 0.488038
AUC: 0.618431
Avg Precision: 0.272826
Avg Recall: 1.000000
d_prime: 0.426189
train_loss: 1.107989
valid_loss: 1.355436
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0032143835447243133
Epoch-4 lr: 0.016071917723621567
epoch 4 training time: 15.270
---------------
2023-09-23 18:54:48.282881
current #epochs=5, #steps=160
start validation
acc: 0.535885
AUC: 0.708637
Avg Precision: 0.341087
Avg Recall: 1.000000
d_prime: 0.776981
train_loss: 1.128053
valid_loss: 1.357145
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0032143835447243133
Epoch-5 lr: 0.016071917723621567
epoch 5 training time: 15.317
---------------
2023-09-23 18:55:03.600007
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03987	Per Sample Data Time 0.02955	Per Sample DNN Time 0.01033	Train Loss 0.9714	
start validation
acc: 0.535885
AUC: 0.674385
Avg Precision: 0.302940
Avg Recall: 1.000000
d_prime: 0.639302
train_loss: 1.107668
valid_loss: 1.347432
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0032143835447243133
Epoch-6 lr: 0.016071917723621567
epoch 6 training time: 15.353
---------------
2023-09-23 18:55:18.953590
current #epochs=7, #steps=240
start validation
acc: 0.540670
AUC: 0.662397
Avg Precision: 0.292440
Avg Recall: 1.000000
d_prime: 0.592575
train_loss: 1.076182
valid_loss: 1.345861
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.002428012883179209
Epoch-7 lr: 0.012140064415896044
epoch 7 training time: 17.861
---------------
2023-09-23 18:55:36.814909
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00715	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00557	Train Loss 1.0460	
start validation
acc: 0.559809
AUC: 0.699381
Avg Precision: 0.334048
Avg Recall: 1.000000
d_prime: 0.739098
train_loss: 1.024553
valid_loss: 1.334105
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.002428012883179209
Epoch-8 lr: 0.012140064415896044
epoch 8 training time: 18.096
---------------
2023-09-23 18:55:54.909806
current #epochs=9, #steps=320
start validation
acc: 0.636364
AUC: 0.655277
Avg Precision: 0.291747
Avg Recall: 1.000000
d_prime: 0.565130
train_loss: 0.994762
valid_loss: 1.297026
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.002428012883179209
Epoch-9 lr: 0.012140064415896044
epoch 9 training time: 17.926
---------------
2023-09-23 18:56:12.835334
current #epochs=10, #steps=360
start validation
acc: 0.569378
AUC: 0.733687
Avg Precision: 0.286831
Avg Recall: 1.000000
d_prime: 0.882474
train_loss: 1.010655
valid_loss: 1.328654
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.002428012883179209
Epoch-10 lr: 0.012140064415896044
epoch 10 training time: 15.341
---------------
2023-09-23 18:56:28.176594
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03913	Per Sample Data Time 0.03254	Per Sample DNN Time 0.00659	Train Loss 0.9138	
start validation
acc: 0.669856
AUC: 0.646598
Avg Precision: 0.306138
Avg Recall: 1.000000
d_prime: 0.531960
train_loss: 0.987985
valid_loss: 1.318480
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.002428012883179209
Epoch-11 lr: 0.012140064415896044
epoch 11 training time: 17.728
---------------
2023-09-23 18:56:45.905117
current #epochs=12, #steps=440
start validation
acc: 0.516746
AUC: 0.658743
Avg Precision: 0.279753
Avg Recall: 1.000000
d_prime: 0.578463
train_loss: 1.000161
valid_loss: 1.316709
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.002428012883179209
Epoch-12 lr: 0.012140064415896044
epoch 12 training time: 15.280
---------------
2023-09-23 18:57:01.184997
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00714	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00553	Train Loss 0.9915	
start validation
acc: 0.502392
AUC: 0.624190
Avg Precision: 0.267358
Avg Recall: 1.000000
d_prime: 0.447603
train_loss: 0.998904
valid_loss: 1.331398
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.002428012883179209
Epoch-13 lr: 0.012140064415896044
epoch 13 training time: 15.163
---------------
2023-09-23 18:57:16.347781
current #epochs=14, #steps=520
start validation
[I 2023-09-23 18:57:32,449] Trial 1 finished with value: 0.2724114090990992 and parameters: {'warmup': 'False', 'num_epochs': 14, 'batch_size': 57, 'lr-adaptschedule': 'True', 'lr': 0.0032143835447243133, 'head-lr': 5, 'lr-scheduler-start': 7, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.7553587956746}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.607656
AUC: 0.682428
Avg Precision: 0.272411
Avg Recall: 1.000000
d_prime: 0.671044
train_loss: 0.943355
valid_loss: 1.306892
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.002428012883179209
Epoch-14 lr: 0.012140064415896044
epoch 14 training time: 16.098
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcbd2c7fac0>
The learning rate scheduler starts at 9 epoch with decay rate of 0.661 every 6 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 18:57:32.455975
current #epochs=1, #steps=0
start validation
acc: 0.732057
AUC: 0.716207
Avg Precision: 0.278429
Avg Recall: 1.000000
d_prime: 0.808380
train_loss: 0.952314
valid_loss: 1.306541
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.001324222257542119
Epoch-1 lr: 0.003972666772626357
epoch 1 training time: 18.847
---------------
2023-09-23 18:57:51.303122
current #epochs=2, #steps=40
start validation
acc: 0.688995
AUC: 0.719038
Avg Precision: 0.272985
Avg Recall: 1.000000
d_prime: 0.820225
train_loss: 0.919065
valid_loss: 1.297059
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.001324222257542119
Epoch-2 lr: 0.003972666772626357
epoch 2 training time: 15.315
---------------
2023-09-23 18:58:06.617516
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00712	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00558	Train Loss 0.8734	
start validation
acc: 0.669856
AUC: 0.748855
Avg Precision: 0.282059
Avg Recall: 1.000000
d_prime: 0.948785
train_loss: 0.904584
valid_loss: 1.288280
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.001324222257542119
Epoch-3 lr: 0.003972666772626357
epoch 3 training time: 15.352
---------------
2023-09-23 18:58:21.969610
current #epochs=4, #steps=120
start validation
acc: 0.698565
AUC: 0.738094
Avg Precision: 0.290564
Avg Recall: 1.000000
d_prime: 0.901535
train_loss: 0.927174
valid_loss: 1.289515
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.001324222257542119
Epoch-4 lr: 0.003972666772626357
epoch 4 training time: 15.211
---------------
2023-09-23 18:58:37.180568
current #epochs=5, #steps=160
start validation
acc: 0.655502
AUC: 0.746862
Avg Precision: 0.283916
Avg Recall: 1.000000
d_prime: 0.939951
train_loss: 0.899284
valid_loss: 1.292328
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.001324222257542119
Epoch-5 lr: 0.003972666772626357
epoch 5 training time: 15.373
---------------
2023-09-23 18:58:52.553891
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04046	Per Sample Data Time 0.03178	Per Sample DNN Time 0.00868	Train Loss 0.8473	
start validation
acc: 0.684211
AUC: 0.732035
Avg Precision: 0.286178
Avg Recall: 1.000000
d_prime: 0.875369
train_loss: 0.888327
valid_loss: 1.284585
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.001324222257542119
Epoch-6 lr: 0.003972666772626357
epoch 6 training time: 15.382
---------------
2023-09-23 18:59:07.935509
current #epochs=7, #steps=240
start validation
acc: 0.708134
AUC: 0.757219
Avg Precision: 0.281214
Avg Recall: 1.000000
d_prime: 0.986253
train_loss: 0.896318
valid_loss: 1.265025
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.001324222257542119
Epoch-7 lr: 0.003972666772626357
epoch 7 training time: 15.397
---------------
2023-09-23 18:59:23.332418
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00563	Train Loss 0.8739	
start validation
acc: 0.732057
AUC: 0.750797
Avg Precision: 0.284347
Avg Recall: 1.000000
d_prime: 0.957424
train_loss: 0.892330
valid_loss: 1.290938
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.001324222257542119
Epoch-8 lr: 0.003972666772626357
epoch 8 training time: 15.349
---------------
2023-09-23 18:59:38.681577
current #epochs=9, #steps=320
start validation
acc: 0.626794
AUC: 0.744333
Avg Precision: 0.284303
Avg Recall: 1.000000
d_prime: 0.928802
train_loss: 0.886838
valid_loss: 1.290750
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0008759692051572698
Epoch-9 lr: 0.0026279076154718094
epoch 9 training time: 15.456
---------------
2023-09-23 18:59:54.137644
current #epochs=10, #steps=360
start validation
acc: 0.669856
AUC: 0.725588
Avg Precision: 0.286706
Avg Recall: 1.000000
d_prime: 0.847855
train_loss: 0.868701
valid_loss: 1.274996
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0008759692051572698
Epoch-10 lr: 0.0026279076154718094
epoch 10 training time: 15.320
---------------
2023-09-23 19:00:09.457675
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03952	Per Sample Data Time 0.02933	Per Sample DNN Time 0.01019	Train Loss 0.9388	
start validation
acc: 0.636364
AUC: 0.735150
Avg Precision: 0.293246
Avg Recall: 1.000000
d_prime: 0.888781
train_loss: 0.853654
valid_loss: 1.280105
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0008759692051572698
Epoch-11 lr: 0.0026279076154718094
epoch 11 training time: 15.328
---------------
2023-09-23 19:00:24.785918
current #epochs=12, #steps=440
start validation
acc: 0.679426
AUC: 0.745944
Avg Precision: 0.291032
Avg Recall: 1.000000
d_prime: 0.935900
train_loss: 0.871820
valid_loss: 1.276369
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0008759692051572698
Epoch-12 lr: 0.0026279076154718094
epoch 12 training time: 15.448
---------------
2023-09-23 19:00:40.234113
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00563	Train Loss 0.8442	
start validation
acc: 0.645933
AUC: 0.750196
Avg Precision: 0.291101
Avg Recall: 1.000000
d_prime: 0.954747
train_loss: 0.864037
valid_loss: 1.279637
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0008759692051572698
Epoch-13 lr: 0.0026279076154718094
epoch 13 training time: 16.111
---------------
2023-09-23 19:00:56.345215
current #epochs=14, #steps=520
start validation
acc: 0.669856
AUC: 0.748494
Avg Precision: 0.294397
Avg Recall: 1.000000
d_prime: 0.947183
train_loss: 0.873323
valid_loss: 1.266299
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0008759692051572698
Epoch-14 lr: 0.0026279076154718094
epoch 14 training time: 15.964
---------------
2023-09-23 19:01:12.309723
current #epochs=15, #steps=560
start validation
acc: 0.631579
AUC: 0.731400
Avg Precision: 0.288047
Avg Recall: 1.000000
d_prime: 0.872646
train_loss: 0.896018
valid_loss: 1.289168
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0005794511034787174
Epoch-15 lr: 0.001738353310436152
epoch 15 training time: 16.173
---------------
2023-09-23 19:01:28.482728
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04057	Per Sample Data Time 0.03025	Per Sample DNN Time 0.01031	Train Loss 0.8048	
start validation
acc: 0.674641
AUC: 0.741563
Avg Precision: 0.293030
Avg Recall: 1.000000
d_prime: 0.916653
train_loss: 0.851182
valid_loss: 1.279242
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0005794511034787174
Epoch-16 lr: 0.001738353310436152
epoch 16 training time: 15.384
---------------
2023-09-23 19:01:43.866366
current #epochs=17, #steps=640
start validation
acc: 0.722488
AUC: 0.752203
Avg Precision: 0.298607
Avg Recall: 1.000000
d_prime: 0.963701
train_loss: 0.845744
valid_loss: 1.265707
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0005794511034787174
Epoch-17 lr: 0.001738353310436152
epoch 17 training time: 15.393
---------------
2023-09-23 19:01:59.259832
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00727	Per Sample Data Time 0.00164	Per Sample DNN Time 0.00562	Train Loss 0.8440	
start validation
acc: 0.669856
AUC: 0.725944
Avg Precision: 0.273465
Avg Recall: 1.000000
d_prime: 0.849365
train_loss: 0.838757
valid_loss: 1.279999
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0005794511034787174
Epoch-18 lr: 0.001738353310436152
epoch 18 training time: 15.396
---------------
2023-09-23 19:02:14.656221
current #epochs=19, #steps=720
start validation
acc: 0.641148
AUC: 0.730615
Avg Precision: 0.298825
Avg Recall: 1.000000
d_prime: 0.869282
train_loss: 0.845710
valid_loss: 1.276419
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0005794511034787174
Epoch-19 lr: 0.001738353310436152
epoch 19 training time: 15.322
---------------
2023-09-23 19:02:29.978278
current #epochs=20, #steps=760
start validation
acc: 0.669856
AUC: 0.740433
Avg Precision: 0.304726
Avg Recall: 1.000000
d_prime: 0.911715
train_loss: 0.858228
valid_loss: 1.267275
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0005794511034787174
Epoch-20 lr: 0.001738353310436152
epoch 20 training time: 15.337
---------------
2023-09-23 19:02:45.315802
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04111	Per Sample Data Time 0.03113	Per Sample DNN Time 0.00997	Train Loss 0.8017	
start validation
acc: 0.679426
AUC: 0.731668
Avg Precision: 0.303575
Avg Recall: 1.000000
d_prime: 0.873793
train_loss: 0.845778
valid_loss: 1.264057
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0003833052341861959
Epoch-21 lr: 0.0011499157025585877
epoch 21 training time: 15.416
---------------
2023-09-23 19:03:00.731352
current #epochs=22, #steps=840
start validation
acc: 0.660287
AUC: 0.742756
Avg Precision: 0.304308
Avg Recall: 1.000000
d_prime: 0.921877
train_loss: 0.823791
valid_loss: 1.272573
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0003833052341861959
Epoch-22 lr: 0.0011499157025585877
epoch 22 training time: 15.307
---------------
2023-09-23 19:03:16.038540
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00726	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00564	Train Loss 0.8315	
start validation
acc: 0.660287
AUC: 0.744474
Avg Precision: 0.309845
Avg Recall: 1.000000
d_prime: 0.929422
train_loss: 0.835709
valid_loss: 1.263978
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0003833052341861959
Epoch-23 lr: 0.0011499157025585877
epoch 23 training time: 15.378
---------------
2023-09-23 19:03:31.416532
current #epochs=24, #steps=920
start validation
acc: 0.674641
AUC: 0.737566
Avg Precision: 0.309979
Avg Recall: 1.000000
d_prime: 0.899242
train_loss: 0.810916
valid_loss: 1.265701
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0003833052341861959
Epoch-24 lr: 0.0011499157025585877
epoch 24 training time: 15.335
---------------
2023-09-23 19:03:46.751764
current #epochs=25, #steps=960
start validation
acc: 0.684211
AUC: 0.740169
Avg Precision: 0.315346
Avg Recall: 1.000000
d_prime: 0.910563
train_loss: 0.814126
valid_loss: 1.251330
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.0003833052341861959
Epoch-25 lr: 0.0011499157025585877
epoch 25 training time: 15.429
---------------
2023-09-23 19:04:02.181064
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.04156	Per Sample Data Time 0.03170	Per Sample DNN Time 0.00986	Train Loss 0.8416	
start validation
acc: 0.650718
AUC: 0.763117
Avg Precision: 0.303021
Avg Recall: 1.000000
d_prime: 1.013094
train_loss: 0.826005
valid_loss: 1.259409
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.0003833052341861959
Epoch-26 lr: 0.0011499157025585877
epoch 26 training time: 15.445
---------------
2023-09-23 19:04:17.625974
current #epochs=27, #steps=1040
start validation
acc: 0.598086
AUC: 0.702627
Avg Precision: 0.308167
Avg Recall: 1.000000
d_prime: 0.752321
train_loss: 0.817624
valid_loss: 1.267555
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.00025355530720795464
Epoch-27 lr: 0.0007606659216238639
epoch 27 training time: 15.360
---------------
2023-09-23 19:04:32.985985
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00723	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00565	Train Loss 0.7936	
start validation
acc: 0.622010
AUC: 0.741192
Avg Precision: 0.302060
Avg Recall: 1.000000
d_prime: 0.915032
train_loss: 0.813550
valid_loss: 1.266112
validation finished
normal learning rate scheduler step
Epoch-28 lr: 0.00025355530720795464
Epoch-28 lr: 0.0007606659216238639
epoch 28 training time: 15.464
---------------
2023-09-23 19:04:48.449949
current #epochs=29, #steps=1120
start validation
acc: 0.617225
AUC: 0.764001
Avg Precision: 0.294238
Avg Recall: 1.000000
d_prime: 1.017148
train_loss: 0.810238
valid_loss: 1.262862
validation finished
normal learning rate scheduler step
Epoch-29 lr: 0.00025355530720795464
Epoch-29 lr: 0.0007606659216238639
epoch 29 training time: 15.280
---------------
2023-09-23 19:05:03.730312
current #epochs=30, #steps=1160
start validation
[I 2023-09-23 19:05:19,015] Trial 2 finished with value: 0.2932250283256475 and parameters: {'warmup': 'False', 'num_epochs': 30, 'batch_size': 41, 'lr-adaptschedule': 'True', 'lr': 0.001324222257542119, 'head-lr': 3, 'lr-scheduler-start': 9, 'lr-scheduler-step': 6, 'lr-scheduler-decay': 0.6614971166419986}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.607656
AUC: 0.738474
Avg Precision: 0.293225
Avg Recall: 1.000000
d_prime: 0.903183
train_loss: 0.828096
valid_loss: 1.271723
validation finished
normal learning rate scheduler step
Epoch-30 lr: 0.00025355530720795464
Epoch-30 lr: 0.0007606659216238639
epoch 30 training time: 15.281
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcbd1e73a30>
The learning rate scheduler starts at 8 epoch with decay rate of 0.923 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 19:05:19.020988
current #epochs=1, #steps=0
start validation
[I 2023-09-23 19:05:37,726] Trial 3 finished with value: 0.27902217289068587 and parameters: {'warmup': 'True', 'num_epochs': 1, 'batch_size': 11, 'lr-adaptschedule': 'False', 'lr': 0.0025664427371825042, 'head-lr': 4, 'lr-scheduler-start': 8, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.9229572973859728}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.626794
AUC: 0.699135
Avg Precision: 0.279022
Avg Recall: 1.000000
d_prime: 0.738098
train_loss: 0.931700
valid_loss: 1.293834
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0025664427371825042
Epoch-1 lr: 0.010265770948730017
epoch 1 training time: 18.701
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 2 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0a736520>
The learning rate scheduler starts at 7 epoch with decay rate of 0.827 every 1 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 19:05:37.732154
current #epochs=1, #steps=0
start validation
[I 2023-09-23 19:05:55,448] Trial 4 finished with value: 0.2689720627220627 and parameters: {'warmup': 'True', 'num_epochs': 1, 'batch_size': 35, 'lr-adaptschedule': 'True', 'lr': 0.0012247368731727055, 'head-lr': 2, 'lr-scheduler-start': 7, 'lr-scheduler-step': 1, 'lr-scheduler-decay': 0.8270822953918904}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.622010
AUC: 0.784459
Avg Precision: 0.268972
Avg Recall: 1.000000
d_prime: 1.113471
train_loss: 0.873153
valid_loss: 1.296952
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0012247368731727055
Epoch-1 lr: 0.002449473746345411
epoch 1 training time: 17.712
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc5263e6a0>
The learning rate scheduler starts at 10 epoch with decay rate of 0.946 every 10 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 19:05:55.454364
current #epochs=1, #steps=0
start validation
acc: 0.717703
AUC: 0.754660
Avg Precision: 0.333312
Avg Recall: 1.000000
d_prime: 0.974715
train_loss: 1.016213
valid_loss: 1.282471
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.004248663037854506
Epoch-1 lr: 0.016994652151418023
epoch 1 training time: 17.770
---------------
2023-09-23 19:06:13.224748
current #epochs=2, #steps=40
start validation
acc: 0.574163
AUC: 0.635665
Avg Precision: 0.288155
Avg Recall: 1.000000
d_prime: 0.490583
train_loss: 0.920953
valid_loss: 1.335180
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.004248663037854506
Epoch-2 lr: 0.016994652151418023
epoch 2 training time: 15.339
---------------
2023-09-23 19:06:28.563802
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00557	Train Loss 0.9504	
start validation
acc: 0.636364
AUC: 0.720254
Avg Precision: 0.294339
Avg Recall: 1.000000
d_prime: 0.825329
train_loss: 0.960524
valid_loss: 1.302706
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.004248663037854506
Epoch-3 lr: 0.016994652151418023
epoch 3 training time: 15.306
---------------
2023-09-23 19:06:43.870073
current #epochs=4, #steps=120
start validation
acc: 0.583732
AUC: 0.699451
Avg Precision: 0.291323
Avg Recall: 1.000000
d_prime: 0.739382
train_loss: 0.939962
valid_loss: 1.315636
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.004248663037854506
Epoch-4 lr: 0.016994652151418023
epoch 4 training time: 15.315
---------------
2023-09-23 19:06:59.185611
current #epochs=5, #steps=160
start validation
acc: 0.650718
AUC: 0.731212
Avg Precision: 0.278590
Avg Recall: 1.000000
d_prime: 0.871840
train_loss: 0.936552
valid_loss: 1.295795
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.004248663037854506
Epoch-5 lr: 0.016994652151418023
epoch 5 training time: 15.325
---------------
2023-09-23 19:07:14.510477
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03927	Per Sample Data Time 0.03116	Per Sample DNN Time 0.00811	Train Loss 0.8618	
start validation
acc: 0.765550
AUC: 0.761506
Avg Precision: 0.276283
Avg Recall: 1.000000
d_prime: 1.005727
train_loss: 0.953047
valid_loss: 1.296616
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.004248663037854506
Epoch-6 lr: 0.016994652151418023
epoch 6 training time: 18.131
---------------
2023-09-23 19:07:32.641529
current #epochs=7, #steps=240
start validation
acc: 0.612440
AUC: 0.686577
Avg Precision: 0.276203
Avg Recall: 1.000000
d_prime: 0.687549
train_loss: 0.950695
valid_loss: 1.311599
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.004248663037854506
Epoch-7 lr: 0.016994652151418023
epoch 7 training time: 15.415
---------------
2023-09-23 19:07:48.056553
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00563	Train Loss 0.8973	
start validation
acc: 0.722488
AUC: 0.760323
Avg Precision: 0.297767
Avg Recall: 1.000000
d_prime: 1.000331
train_loss: 0.887299
valid_loss: 1.257010
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.004248663037854506
Epoch-8 lr: 0.016994652151418023
epoch 8 training time: 15.353
---------------
2023-09-23 19:08:03.409358
current #epochs=9, #steps=320
start validation
acc: 0.660287
AUC: 0.729167
Avg Precision: 0.280872
Avg Recall: 1.000000
d_prime: 0.863087
train_loss: 0.876449
valid_loss: 1.277243
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.004248663037854506
Epoch-9 lr: 0.016994652151418023
epoch 9 training time: 16.598
---------------
2023-09-23 19:08:20.006897
current #epochs=10, #steps=360
start validation
acc: 0.669856
AUC: 0.767549
Avg Precision: 0.280650
Avg Recall: 1.000000
d_prime: 1.033506
train_loss: 0.866009
valid_loss: 1.270784
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.004018670976101885
Epoch-10 lr: 0.01607468390440754
epoch 10 training time: 15.255
---------------
2023-09-23 19:08:35.261451
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03917	Per Sample Data Time 0.03231	Per Sample DNN Time 0.00686	Train Loss 0.6594	
start validation
acc: 0.669856
AUC: 0.763084
Avg Precision: 0.283495
Avg Recall: 1.000000
d_prime: 1.012941
train_loss: 0.880149
valid_loss: 1.268837
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.004018670976101885
Epoch-11 lr: 0.01607468390440754
epoch 11 training time: 15.473
---------------
2023-09-23 19:08:50.733923
current #epochs=12, #steps=440
start validation
acc: 0.593301
AUC: 0.769477
Avg Precision: 0.300317
Avg Recall: 1.000000
d_prime: 1.042453
train_loss: 0.845051
valid_loss: 1.270946
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.004018670976101885
Epoch-12 lr: 0.01607468390440754
epoch 12 training time: 15.526
---------------
2023-09-23 19:09:06.260030
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00566	Train Loss 0.8448	
start validation
acc: 0.746411
AUC: 0.765481
Avg Precision: 0.290353
Avg Recall: 1.000000
d_prime: 1.023953
train_loss: 0.854891
valid_loss: 1.251121
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.004018670976101885
Epoch-13 lr: 0.01607468390440754
epoch 13 training time: 15.364
---------------
2023-09-23 19:09:21.624158
current #epochs=14, #steps=520
start validation
acc: 0.660287
AUC: 0.774196
Avg Precision: 0.291190
Avg Recall: 1.000000
d_prime: 1.064531
train_loss: 0.835826
valid_loss: 1.250078
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.004018670976101885
Epoch-14 lr: 0.01607468390440754
epoch 14 training time: 15.333
---------------
2023-09-23 19:09:36.956936
current #epochs=15, #steps=560
start validation
acc: 0.727273
AUC: 0.799643
Avg Precision: 0.289745
Avg Recall: 1.000000
d_prime: 1.188428
train_loss: 0.841986
valid_loss: 1.241168
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.004018670976101885
Epoch-15 lr: 0.01607468390440754
epoch 15 training time: 16.191
---------------
2023-09-23 19:09:53.148137
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03941	Per Sample Data Time 0.02907	Per Sample DNN Time 0.01034	Train Loss 0.6727	
start validation
acc: 0.736842
AUC: 0.783328
Avg Precision: 0.298816
Avg Recall: 1.000000
d_prime: 1.108011
train_loss: 0.840626
valid_loss: 1.239169
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.004018670976101885
Epoch-16 lr: 0.01607468390440754
epoch 16 training time: 15.325
---------------
2023-09-23 19:10:08.473728
current #epochs=17, #steps=640
start validation
acc: 0.760766
AUC: 0.778004
Avg Precision: 0.274630
Avg Recall: 1.000000
d_prime: 1.082538
train_loss: 0.863734
valid_loss: 1.234280
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.004018670976101885
Epoch-17 lr: 0.01607468390440754
epoch 17 training time: 15.395
---------------
2023-09-23 19:10:23.868316
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00561	Train Loss 0.8566	
start validation
acc: 0.674641
AUC: 0.791848
Avg Precision: 0.293959
Avg Recall: 1.000000
d_prime: 1.149543
train_loss: 0.838970
valid_loss: 1.226557
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.004018670976101885
Epoch-18 lr: 0.01607468390440754
epoch 18 training time: 15.305
---------------
2023-09-23 19:10:39.172877
current #epochs=19, #steps=720
start validation
acc: 0.679426
AUC: 0.798587
Avg Precision: 0.271299
Avg Recall: 1.000000
d_prime: 1.183109
train_loss: 0.844510
valid_loss: 1.256969
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.004018670976101885
Epoch-19 lr: 0.01607468390440754
epoch 19 training time: 15.299
---------------
2023-09-23 19:10:54.472315
current #epochs=20, #steps=760
start validation
acc: 0.665072
AUC: 0.782059
Avg Precision: 0.268331
Avg Recall: 1.000000
d_prime: 1.101905
train_loss: 0.830288
valid_loss: 1.264928
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.00380112903053827
Epoch-20 lr: 0.01520451612215308
epoch 20 training time: 15.904
---------------
2023-09-23 19:11:10.375891
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04061	Per Sample Data Time 0.03084	Per Sample DNN Time 0.00977	Train Loss 0.8633	
start validation
acc: 0.703349
AUC: 0.811434
Avg Precision: 0.302362
Avg Recall: 1.000000
d_prime: 1.249021
train_loss: 0.855980
valid_loss: 1.226768
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.00380112903053827
Epoch-21 lr: 0.01520451612215308
epoch 21 training time: 15.414
---------------
2023-09-23 19:11:25.789898
current #epochs=22, #steps=840
start validation
acc: 0.665072
AUC: 0.769849
Avg Precision: 0.285244
Avg Recall: 1.000000
d_prime: 1.044184
train_loss: 0.827319
valid_loss: 1.242416
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.00380112903053827
Epoch-22 lr: 0.01520451612215308
epoch 22 training time: 15.433
---------------
2023-09-23 19:11:41.223051
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00723	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00565	Train Loss 0.8057	
start validation
acc: 0.712919
AUC: 0.817702
Avg Precision: 0.317542
Avg Recall: 1.000000
d_prime: 1.282183
train_loss: 0.821699
valid_loss: 1.227245
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.00380112903053827
Epoch-23 lr: 0.01520451612215308
epoch 23 training time: 15.368
---------------
2023-09-23 19:11:56.590633
current #epochs=24, #steps=920
start validation
acc: 0.746411
AUC: 0.822931
Avg Precision: 0.290752
Avg Recall: 1.000000
d_prime: 1.310401
train_loss: 0.824983
valid_loss: 1.218051
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.00380112903053827
Epoch-24 lr: 0.01520451612215308
epoch 24 training time: 15.319
---------------
2023-09-23 19:12:11.909638
current #epochs=25, #steps=960
start validation
acc: 0.669856
AUC: 0.826845
Avg Precision: 0.264461
Avg Recall: 1.000000
d_prime: 1.331864
train_loss: 0.839309
valid_loss: 1.251270
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.00380112903053827
Epoch-25 lr: 0.01520451612215308
epoch 25 training time: 15.380
---------------
2023-09-23 19:12:27.290062
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.04034	Per Sample Data Time 0.03138	Per Sample DNN Time 0.00896	Train Loss 0.7146	
start validation
acc: 0.641148
AUC: 0.796467
Avg Precision: 0.281379
Avg Recall: 1.000000
d_prime: 1.172477
train_loss: 0.812512
valid_loss: 1.275308
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.00380112903053827
Epoch-26 lr: 0.01520451612215308
epoch 26 training time: 15.316
---------------
2023-09-23 19:12:42.606073
current #epochs=27, #steps=1040
start validation
acc: 0.688995
AUC: 0.761899
Avg Precision: 0.284499
Avg Recall: 1.000000
d_prime: 1.007519
train_loss: 0.788858
valid_loss: 1.259128
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.00380112903053827
Epoch-27 lr: 0.01520451612215308
epoch 27 training time: 15.338
---------------
2023-09-23 19:12:57.944122
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00729	Per Sample Data Time 0.00165	Per Sample DNN Time 0.00563	Train Loss 0.7561	
start validation
acc: 0.712919
AUC: 0.840883
Avg Precision: 0.288736
Avg Recall: 1.000000
d_prime: 1.411518
train_loss: 0.764069
valid_loss: 1.223682
validation finished
normal learning rate scheduler step
Epoch-28 lr: 0.00380112903053827
Epoch-28 lr: 0.01520451612215308
epoch 28 training time: 15.487
---------------
2023-09-23 19:13:13.431331
current #epochs=29, #steps=1120
start validation
[I 2023-09-23 19:13:28,695] Trial 5 finished with value: 0.2651479919251828 and parameters: {'warmup': 'True', 'num_epochs': 29, 'batch_size': 15, 'lr-adaptschedule': 'False', 'lr': 0.004248663037854506, 'head-lr': 4, 'lr-scheduler-start': 10, 'lr-scheduler-step': 10, 'lr-scheduler-decay': 0.945867191701613}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.535885
AUC: 0.796747
Avg Precision: 0.265148
Avg Recall: 1.000000
d_prime: 1.173877
train_loss: 0.803548
valid_loss: 1.271797
validation finished
normal learning rate scheduler step
Epoch-29 lr: 0.00380112903053827
Epoch-29 lr: 0.01520451612215308
epoch 29 training time: 15.260
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 1 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcbd1e73100>
The learning rate scheduler starts at 8 epoch with decay rate of 0.895 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 19:13:28.701125
current #epochs=1, #steps=0
start validation
acc: 0.717703
AUC: 0.782660
Avg Precision: 0.267188
Avg Recall: 1.000000
d_prime: 1.104795
train_loss: 0.882240
valid_loss: 1.262713
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0008827941200082735
Epoch-1 lr: 0.0008827941200082735
epoch 1 training time: 17.784
---------------
2023-09-23 19:13:46.485290
current #epochs=2, #steps=40
start validation
acc: 0.674641
AUC: 0.803056
Avg Precision: 0.295060
Avg Recall: 1.000000
d_prime: 1.205740
train_loss: 0.795606
valid_loss: 1.261267
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0008827941200082735
Epoch-2 lr: 0.0008827941200082735
epoch 2 training time: 15.249
---------------
2023-09-23 19:14:01.734156
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00557	Train Loss 0.7237	
start validation
acc: 0.703349
AUC: 0.788445
Avg Precision: 0.272495
Avg Recall: 1.000000
d_prime: 1.132838
train_loss: 0.732823
valid_loss: 1.246326
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0008827941200082735
Epoch-3 lr: 0.0008827941200082735
epoch 3 training time: 15.388
---------------
2023-09-23 19:14:17.122091
current #epochs=4, #steps=120
start validation
acc: 0.703349
AUC: 0.824835
Avg Precision: 0.287212
Avg Recall: 1.000000
d_prime: 1.320805
train_loss: 0.748646
valid_loss: 1.234696
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0008827941200082735
Epoch-4 lr: 0.0008827941200082735
epoch 4 training time: 15.273
---------------
2023-09-23 19:14:32.395300
current #epochs=5, #steps=160
start validation
acc: 0.698565
AUC: 0.808874
Avg Precision: 0.276972
Avg Recall: 1.000000
d_prime: 1.235674
train_loss: 0.727271
valid_loss: 1.235382
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0008827941200082735
Epoch-5 lr: 0.0008827941200082735
epoch 5 training time: 15.406
---------------
2023-09-23 19:14:47.801482
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03991	Per Sample Data Time 0.03002	Per Sample DNN Time 0.00989	Train Loss 0.9050	
start validation
acc: 0.708134
AUC: 0.810412
Avg Precision: 0.288259
Avg Recall: 1.000000
d_prime: 1.243682
train_loss: 0.726666
valid_loss: 1.242908
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0008827941200082735
Epoch-6 lr: 0.0008827941200082735
epoch 6 training time: 15.307
---------------
2023-09-23 19:15:03.108586
current #epochs=7, #steps=240
start validation
acc: 0.741627
AUC: 0.814373
Avg Precision: 0.287376
Avg Recall: 1.000000
d_prime: 1.264487
train_loss: 0.700559
valid_loss: 1.229456
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0008827941200082735
Epoch-7 lr: 0.0008827941200082735
epoch 7 training time: 19.079
---------------
2023-09-23 19:15:22.187109
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00154	Per Sample DNN Time 0.00565	Train Loss 0.6982	
start validation
acc: 0.741627
AUC: 0.819922
Avg Precision: 0.283742
Avg Recall: 1.000000
d_prime: 1.294104
train_loss: 0.697346
valid_loss: 1.229926
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0007901745896496213
Epoch-8 lr: 0.0007901745896496213
epoch 8 training time: 15.670
---------------
2023-09-23 19:15:37.856636
current #epochs=9, #steps=320
start validation
acc: 0.669856
AUC: 0.796416
Avg Precision: 0.289683
Avg Recall: 1.000000
d_prime: 1.172226
train_loss: 0.722254
valid_loss: 1.256918
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0007901745896496213
Epoch-9 lr: 0.0007901745896496213
epoch 9 training time: 15.359
---------------
2023-09-23 19:15:53.215379
current #epochs=10, #steps=360
start validation
acc: 0.684211
AUC: 0.800152
Avg Precision: 0.293740
Avg Recall: 1.000000
d_prime: 1.191000
train_loss: 0.716896
valid_loss: 1.249136
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0007901745896496213
Epoch-10 lr: 0.0007901745896496213
epoch 10 training time: 15.299
---------------
2023-09-23 19:16:08.514735
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03825	Per Sample Data Time 0.03098	Per Sample DNN Time 0.00727	Train Loss 0.7826	
start validation
acc: 0.703349
AUC: 0.830367
Avg Precision: 0.292224
Avg Recall: 1.000000
d_prime: 1.351447
train_loss: 0.691981
valid_loss: 1.231752
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0007901745896496213
Epoch-11 lr: 0.0007901745896496213
epoch 11 training time: 15.314
---------------
2023-09-23 19:16:23.828480
current #epochs=12, #steps=440
start validation
acc: 0.760766
AUC: 0.818010
Avg Precision: 0.291320
Avg Recall: 1.000000
d_prime: 1.283836
train_loss: 0.696281
valid_loss: 1.248800
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0007901745896496213
Epoch-12 lr: 0.0007901745896496213
epoch 12 training time: 17.638
---------------
2023-09-23 19:16:41.466036
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00560	Train Loss 0.6834	
start validation
acc: 0.688995
AUC: 0.816603
Avg Precision: 0.306896
Avg Recall: 1.000000
d_prime: 1.276321
train_loss: 0.678914
valid_loss: 1.226483
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0007901745896496213
Epoch-13 lr: 0.0007901745896496213
epoch 13 training time: 15.298
---------------
2023-09-23 19:16:56.764047
current #epochs=14, #steps=520
start validation
acc: 0.593301
AUC: 0.786493
Avg Precision: 0.303961
Avg Recall: 1.000000
d_prime: 1.123325
train_loss: 0.661691
valid_loss: 1.237591
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0007901745896496213
Epoch-14 lr: 0.0007901745896496213
epoch 14 training time: 15.313
---------------
2023-09-23 19:17:12.077542
current #epochs=15, #steps=560
start validation
[I 2023-09-23 19:17:30,566] Trial 6 finished with value: 0.32225571964867544 and parameters: {'warmup': 'True', 'num_epochs': 15, 'batch_size': 46, 'lr-adaptschedule': 'False', 'lr': 0.0008827941200082735, 'head-lr': 1, 'lr-scheduler-start': 8, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.895083657378932}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.789474
AUC: 0.867645
Avg Precision: 0.322256
Avg Recall: 1.000000
d_prime: 1.577313
train_loss: 0.679897
valid_loss: 1.198691
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0007901745896496213
Epoch-15 lr: 0.0007901745896496213
epoch 15 training time: 18.485
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 2 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc097d9e20>
The learning rate scheduler starts at 5 epoch with decay rate of 0.620 every 7 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 19:17:30.574947
current #epochs=1, #steps=0
start validation
acc: 0.760766
AUC: 0.831961
Avg Precision: 0.315553
Avg Recall: 1.000000
d_prime: 1.360391
train_loss: 0.685867
valid_loss: 1.215663
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0017253298380382773
Epoch-1 lr: 0.0034506596760765546
epoch 1 training time: 18.656
---------------
2023-09-23 19:17:49.230706
current #epochs=2, #steps=40
start validation
acc: 0.794258
AUC: 0.856112
Avg Precision: 0.298931
Avg Recall: 1.000000
d_prime: 1.503326
train_loss: 0.702941
valid_loss: 1.196588
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0017253298380382773
Epoch-2 lr: 0.0034506596760765546
epoch 2 training time: 18.483
---------------
2023-09-23 19:18:07.713496
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00166	Per Sample DNN Time 0.00554	Train Loss 0.6930	
start validation
acc: 0.645933
AUC: 0.803892
Avg Precision: 0.309389
Avg Recall: 1.000000
d_prime: 1.210007
train_loss: 0.698791
valid_loss: 1.228519
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0017253298380382773
Epoch-3 lr: 0.0034506596760765546
epoch 3 training time: 15.372
---------------
2023-09-23 19:18:23.085083
current #epochs=4, #steps=120
start validation
acc: 0.722488
AUC: 0.792054
Avg Precision: 0.294277
Avg Recall: 1.000000
d_prime: 1.150559
train_loss: 0.709628
valid_loss: 1.250452
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0017253298380382773
Epoch-4 lr: 0.0034506596760765546
epoch 4 training time: 15.253
---------------
2023-09-23 19:18:38.337731
current #epochs=5, #steps=160
start validation
[I 2023-09-23 19:18:53,715] Trial 7 finished with value: 0.36523253450049026 and parameters: {'warmup': 'True', 'num_epochs': 5, 'batch_size': 53, 'lr-adaptschedule': 'False', 'lr': 0.0017253298380382773, 'head-lr': 2, 'lr-scheduler-start': 5, 'lr-scheduler-step': 7, 'lr-scheduler-decay': 0.6196661973014606}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.746411
AUC: 0.868966
Avg Precision: 0.365233
Avg Recall: 1.000000
d_prime: 1.586062
train_loss: 0.684789
valid_loss: 1.202327
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.001069128579827924
Epoch-5 lr: 0.002138257159655848
epoch 5 training time: 15.373
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0a667460>
The learning rate scheduler starts at 3 epoch with decay rate of 0.923 every 1 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 19:18:53.722001
current #epochs=1, #steps=0
start validation
acc: 0.679426
AUC: 0.833325
Avg Precision: 0.280616
Avg Recall: 1.000000
d_prime: 1.368094
train_loss: 0.710295
valid_loss: 1.222331
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0023103608323862047
Epoch-1 lr: 0.009241443329544819
epoch 1 training time: 18.933
---------------
2023-09-23 19:19:12.655592
current #epochs=2, #steps=40
start validation
acc: 0.717703
AUC: 0.870313
Avg Precision: 0.318117
Avg Recall: 1.000000
d_prime: 1.595054
train_loss: 0.684741
valid_loss: 1.223913
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0023103608323862047
Epoch-2 lr: 0.009241443329544819
epoch 2 training time: 18.511
---------------
2023-09-23 19:19:31.166652
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00559	Train Loss 0.6301	
start validation
acc: 0.755981
AUC: 0.846010
Avg Precision: 0.312852
Avg Recall: 1.000000
d_prime: 1.441749
train_loss: 0.658024
valid_loss: 1.217161
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.002133080431008491
Epoch-3 lr: 0.008532321724033964
epoch 3 training time: 17.703
---------------
2023-09-23 19:19:48.869945
current #epochs=4, #steps=120
start validation
acc: 0.727273
AUC: 0.862180
Avg Precision: 0.325591
Avg Recall: 1.000000
d_prime: 1.541730
train_loss: 0.672095
valid_loss: 1.196895
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0019694032470468996
Epoch-4 lr: 0.007877612988187599
epoch 4 training time: 15.360
---------------
2023-09-23 19:20:04.229635
current #epochs=5, #steps=160
start validation
acc: 0.736842
AUC: 0.845446
Avg Precision: 0.292886
Avg Recall: 1.000000
d_prime: 1.438393
train_loss: 0.652797
valid_loss: 1.202925
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0018182854678598064
Epoch-5 lr: 0.007273141871439226
epoch 5 training time: 15.299
---------------
2023-09-23 19:20:19.528278
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03922	Per Sample Data Time 0.02969	Per Sample DNN Time 0.00952	Train Loss 0.6142	
start validation
acc: 0.712919
AUC: 0.820075
Avg Precision: 0.307993
Avg Recall: 1.000000
d_prime: 1.294927
train_loss: 0.663380
valid_loss: 1.228020
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.001678763375447721
Epoch-6 lr: 0.006715053501790884
epoch 6 training time: 15.242
---------------
2023-09-23 19:20:34.770818
current #epochs=7, #steps=240
start validation
acc: 0.755981
AUC: 0.864131
Avg Precision: 0.293889
Avg Recall: 1.000000
d_prime: 1.554316
train_loss: 0.683472
valid_loss: 1.249070
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0015499472005690135
Epoch-7 lr: 0.006199788802276054
epoch 7 training time: 15.345
---------------
2023-09-23 19:20:50.115875
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00713	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00554	Train Loss 0.6716	
start validation
acc: 0.722488
AUC: 0.822982
Avg Precision: 0.281773
Avg Recall: 1.000000
d_prime: 1.310677
train_loss: 0.668068
valid_loss: 1.215453
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0014310154484464056
Epoch-8 lr: 0.005724061793785622
epoch 8 training time: 15.347
---------------
2023-09-23 19:21:05.462640
current #epochs=9, #steps=320
start validation
acc: 0.732057
AUC: 0.826520
Avg Precision: 0.286724
Avg Recall: 1.000000
d_prime: 1.330074
train_loss: 0.631080
valid_loss: 1.229508
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0013212096598777564
Epoch-9 lr: 0.005284838639511026
epoch 9 training time: 18.199
---------------
2023-09-23 19:21:23.661391
current #epochs=10, #steps=360
start validation
acc: 0.712919
AUC: 0.876912
Avg Precision: 0.316194
Avg Recall: 1.000000
d_prime: 1.640046
train_loss: 0.628828
valid_loss: 1.208066
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0012198295743413652
Epoch-10 lr: 0.004879318297365461
epoch 10 training time: 15.424
---------------
2023-09-23 19:21:39.085393
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03954	Per Sample Data Time 0.02956	Per Sample DNN Time 0.00998	Train Loss 0.8345	
start validation
acc: 0.612440
AUC: 0.784134
Avg Precision: 0.287949
Avg Recall: 1.000000
d_prime: 1.111900
train_loss: 0.665504
valid_loss: 1.246037
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.001126228664249632
Epoch-11 lr: 0.004504914656998528
epoch 11 training time: 15.410
---------------
2023-09-23 19:21:54.495521
current #epochs=12, #steps=440
start validation
acc: 0.722488
AUC: 0.863634
Avg Precision: 0.291772
Avg Recall: 1.000000
d_prime: 1.551097
train_loss: 0.629572
valid_loss: 1.210692
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.001039810011871835
Epoch-12 lr: 0.00415924004748734
epoch 12 training time: 15.354
---------------
2023-09-23 19:22:09.848973
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00562	Train Loss 0.6324	
start validation
acc: 0.727273
AUC: 0.860133
Avg Precision: 0.330765
Avg Recall: 1.000000
d_prime: 1.528645
train_loss: 0.601002
valid_loss: 1.206088
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0009600225026320706
Epoch-13 lr: 0.0038400900105282822
epoch 13 training time: 15.500
---------------
2023-09-23 19:22:25.349371
current #epochs=14, #steps=520
start validation
acc: 0.722488
AUC: 0.878727
Avg Precision: 0.290120
Avg Recall: 1.000000
d_prime: 1.652717
train_loss: 0.591779
valid_loss: 1.203739
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0008863573105060118
Epoch-14 lr: 0.003545429242024047
epoch 14 training time: 16.612
---------------
2023-09-23 19:22:41.961679
current #epochs=15, #steps=560
start validation
acc: 0.722488
AUC: 0.860388
Avg Precision: 0.294577
Avg Recall: 1.000000
d_prime: 1.530267
train_loss: 0.631994
valid_loss: 1.204457
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0008183446531029322
Epoch-15 lr: 0.003273378612411729
epoch 15 training time: 15.348
---------------
2023-09-23 19:22:57.309680
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04264	Per Sample Data Time 0.03328	Per Sample DNN Time 0.00936	Train Loss 0.7802	
start validation
acc: 0.693780
AUC: 0.836952
Avg Precision: 0.295980
Avg Recall: 1.000000
d_prime: 1.388767
train_loss: 0.598326
valid_loss: 1.215222
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0007555507957392949
Epoch-16 lr: 0.0030222031829571796
epoch 16 training time: 15.448
---------------
2023-09-23 19:23:12.757972
current #epochs=17, #steps=640
start validation
acc: 0.746411
AUC: 0.866923
Avg Precision: 0.310913
Avg Recall: 1.000000
d_prime: 1.572550
train_loss: 0.590529
valid_loss: 1.192469
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0006975752853980935
Epoch-17 lr: 0.002790301141592374
epoch 17 training time: 15.371
---------------
2023-09-23 19:23:28.128847
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00727	Per Sample Data Time 0.00164	Per Sample DNN Time 0.00563	Train Loss 0.5747	
start validation
acc: 0.727273
AUC: 0.852838
Avg Precision: 0.301077
Avg Recall: 1.000000
d_prime: 1.483065
train_loss: 0.579721
valid_loss: 1.193467
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0006440483969341729
Epoch-18 lr: 0.0025761935877366914
epoch 18 training time: 15.378
---------------
2023-09-23 19:23:43.506731
current #epochs=19, #steps=720
start validation
acc: 0.755981
AUC: 0.852794
Avg Precision: 0.305859
Avg Recall: 1.000000
d_prime: 1.482792
train_loss: 0.577789
valid_loss: 1.194494
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0005946287752393063
Epoch-19 lr: 0.002378515100957225
epoch 19 training time: 16.289
---------------
2023-09-23 19:23:59.795935
current #epochs=20, #steps=760
start validation
acc: 0.483254
AUC: 0.729039
Avg Precision: 0.282140
Avg Recall: 1.000000
d_prime: 0.862541
train_loss: 0.616834
valid_loss: 1.266115
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0005490012583304925
Epoch-20 lr: 0.00219600503332197
epoch 20 training time: 15.283
---------------
2023-09-23 19:24:15.078598
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04024	Per Sample Data Time 0.03120	Per Sample DNN Time 0.00904	Train Loss 0.7054	
start validation
acc: 0.741627
AUC: 0.858133
Avg Precision: 0.304064
Avg Recall: 1.000000
d_prime: 1.515992
train_loss: 0.656577
valid_loss: 1.198903
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0005068748674787322
Epoch-21 lr: 0.002027499469914929
epoch 21 training time: 15.362
---------------
2023-09-23 19:24:30.440685
current #epochs=22, #steps=840
start validation
acc: 0.736842
AUC: 0.854404
Avg Precision: 0.301571
Avg Recall: 1.000000
d_prime: 1.492719
train_loss: 0.588502
valid_loss: 1.188088
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0004679809515608034
Epoch-22 lr: 0.0018719238062432136
epoch 22 training time: 15.347
---------------
2023-09-23 19:24:45.787418
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00733	Per Sample Data Time 0.00166	Per Sample DNN Time 0.00567	Train Loss 0.5883	
start validation
acc: 0.760766
AUC: 0.882950
Avg Precision: 0.295242
Avg Recall: 1.000000
d_prime: 1.682722
train_loss: 0.569058
valid_loss: 1.176442
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0004320714738000779
Epoch-23 lr: 0.0017282858952003116
epoch 23 training time: 17.818
---------------
2023-09-23 19:25:03.605313
current #epochs=24, #steps=920
start validation
[I 2023-09-23 19:25:18,975] Trial 8 finished with value: 0.3052680543328744 and parameters: {'warmup': 'False', 'num_epochs': 24, 'batch_size': 47, 'lr-adaptschedule': 'True', 'lr': 0.0023103608323862047, 'head-lr': 4, 'lr-scheduler-start': 3, 'lr-scheduler-step': 1, 'lr-scheduler-decay': 0.9232672235035193}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.741627
AUC: 0.881250
Avg Precision: 0.305268
Avg Recall: 1.000000
d_prime: 1.670552
train_loss: 0.562324
valid_loss: 1.172110
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.00039891742997047154
Epoch-24 lr: 0.0015956697198818862
epoch 24 training time: 15.366
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 2 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcbe21918b0>
The learning rate scheduler starts at 3 epoch with decay rate of 0.869 every 1 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 19:25:18.982046
current #epochs=1, #steps=0
start validation
acc: 0.698565
AUC: 0.815400
Avg Precision: 0.301544
Avg Recall: 1.000000
d_prime: 1.269924
train_loss: 0.778578
valid_loss: 1.249911
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.004133372287800764
Epoch-1 lr: 0.008266744575601528
epoch 1 training time: 18.209
---------------
2023-09-23 19:25:37.191545
current #epochs=2, #steps=40
start validation
acc: 0.775120
AUC: 0.837112
Avg Precision: 0.281406
Avg Recall: 1.000000
d_prime: 1.389688
train_loss: 0.680619
valid_loss: 1.217581
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.004133372287800764
Epoch-2 lr: 0.008266744575601528
epoch 2 training time: 17.874
---------------
2023-09-23 19:25:55.065480
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00164	Per Sample DNN Time 0.00557	Train Loss 0.6760	
start validation
acc: 0.794258
AUC: 0.856675
Avg Precision: 0.300975
Avg Recall: 1.000000
d_prime: 1.506841
train_loss: 0.680529
valid_loss: 1.218935
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0035923617949117272
Epoch-3 lr: 0.0071847235898234545
epoch 3 training time: 18.085
---------------
2023-09-23 19:26:13.150577
current #epochs=4, #steps=120
start validation
acc: 0.727273
AUC: 0.782969
Avg Precision: 0.318882
Avg Recall: 1.000000
d_prime: 1.106280
train_loss: 0.689363
valid_loss: 1.249542
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0031221633008063207
Epoch-4 lr: 0.006244326601612641
epoch 4 training time: 15.264
---------------
2023-09-23 19:26:28.414200
current #epochs=5, #steps=160
start validation
acc: 0.688995
AUC: 0.788899
Avg Precision: 0.296240
Avg Recall: 1.000000
d_prime: 1.135057
train_loss: 0.652561
valid_loss: 1.244603
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0027135083361338745
Epoch-5 lr: 0.005427016672267749
epoch 5 training time: 15.159
---------------
2023-09-23 19:26:43.573801
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04031	Per Sample Data Time 0.03016	Per Sample DNN Time 0.01015	Train Loss 0.6844	
start validation
acc: 0.559809
AUC: 0.741100
Avg Precision: 0.287891
Avg Recall: 1.000000
d_prime: 0.914628
train_loss: 0.623542
valid_loss: 1.259687
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0023583415666843716
Epoch-6 lr: 0.004716683133368743
epoch 6 training time: 16.833
---------------
2023-09-23 19:27:00.406542
current #epochs=7, #steps=240
start validation
acc: 0.760766
AUC: 0.862982
Avg Precision: 0.327762
Avg Recall: 1.000000
d_prime: 1.546885
train_loss: 0.615626
valid_loss: 1.205847
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0020496620080686936
Epoch-7 lr: 0.004099324016137387
epoch 7 training time: 15.374
---------------
2023-09-23 19:27:15.780611
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00726	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00565	Train Loss 0.5556	
start validation
[I 2023-09-23 19:27:32,045] Trial 9 finished with value: 0.31855476636254676 and parameters: {'warmup': 'False', 'num_epochs': 8, 'batch_size': 44, 'lr-adaptschedule': 'False', 'lr': 0.004133372287800764, 'head-lr': 2, 'lr-scheduler-start': 3, 'lr-scheduler-step': 1, 'lr-scheduler-decay': 0.8691115981771651}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.760766
AUC: 0.838043
Avg Precision: 0.318555
Avg Recall: 1.000000
d_prime: 1.395046
train_loss: 0.585155
valid_loss: 1.210173
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0017813850235555997
Epoch-8 lr: 0.0035627700471111993
epoch 8 training time: 16.261
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcbe219eac0>
The learning rate scheduler starts at 5 epoch with decay rate of 0.751 every 4 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 19:27:32.075671
current #epochs=1, #steps=0
start validation
acc: 0.755981
AUC: 0.837446
Avg Precision: 0.313688
Avg Recall: 1.000000
d_prime: 1.391608
train_loss: 0.595265
valid_loss: 1.213807
validation finished
normal learning rate scheduler step
Epoch-1 lr: 7.191378593262329e-05
Epoch-1 lr: 0.00021574135779786987
epoch 1 training time: 18.937
---------------
2023-09-23 19:27:51.012856
current #epochs=2, #steps=40
start validation
acc: 0.765550
AUC: 0.843686
Avg Precision: 0.321277
Avg Recall: 1.000000
d_prime: 1.427966
train_loss: 0.567605
valid_loss: 1.209942
validation finished
normal learning rate scheduler step
Epoch-2 lr: 7.191378593262329e-05
Epoch-2 lr: 0.00021574135779786987
epoch 2 training time: 18.757
---------------
2023-09-23 19:28:09.770251
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00712	Per Sample Data Time 0.00164	Per Sample DNN Time 0.00548	Train Loss 0.5553	
start validation
acc: 0.779904
AUC: 0.848397
Avg Precision: 0.324590
Avg Recall: 1.000000
d_prime: 1.456050
train_loss: 0.553002
valid_loss: 1.206605
validation finished
normal learning rate scheduler step
Epoch-3 lr: 7.191378593262329e-05
Epoch-3 lr: 0.00021574135779786987
epoch 3 training time: 17.703
---------------
2023-09-23 19:28:27.472971
current #epochs=4, #steps=120
start validation
acc: 0.765550
AUC: 0.846103
Avg Precision: 0.324979
Avg Recall: 1.000000
d_prime: 1.442303
train_loss: 0.562414
valid_loss: 1.207442
validation finished
normal learning rate scheduler step
Epoch-4 lr: 7.191378593262329e-05
Epoch-4 lr: 0.00021574135779786987
epoch 4 training time: 15.345
---------------
2023-09-23 19:28:42.817813
current #epochs=5, #steps=160
start validation
acc: 0.770335
AUC: 0.845655
Avg Precision: 0.325326
Avg Recall: 1.000000
d_prime: 1.439633
train_loss: 0.563520
valid_loss: 1.207005
validation finished
normal learning rate scheduler step
Epoch-5 lr: 5.403366456418536e-05
Epoch-5 lr: 0.0001621009936925561
epoch 5 training time: 15.247
---------------
2023-09-23 19:28:58.064968
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03721	Per Sample Data Time 0.03059	Per Sample DNN Time 0.00662	Train Loss 0.6867	
start validation
acc: 0.765550
AUC: 0.844669
Avg Precision: 0.323976
Avg Recall: 1.000000
d_prime: 1.433779
train_loss: 0.551324
valid_loss: 1.206209
validation finished
normal learning rate scheduler step
Epoch-6 lr: 5.403366456418536e-05
Epoch-6 lr: 0.0001621009936925561
epoch 6 training time: 15.290
---------------
2023-09-23 19:29:13.354803
current #epochs=7, #steps=240
start validation
acc: 0.765550
AUC: 0.847071
Avg Precision: 0.328811
Avg Recall: 1.000000
d_prime: 1.448086
train_loss: 0.547916
valid_loss: 1.205795
validation finished
normal learning rate scheduler step
Epoch-7 lr: 5.403366456418536e-05
Epoch-7 lr: 0.0001621009936925561
epoch 7 training time: 15.307
---------------
2023-09-23 19:29:28.661993
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00706	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00551	Train Loss 0.5761	
start validation
acc: 0.775120
AUC: 0.849276
Avg Precision: 0.329969
Avg Recall: 1.000000
d_prime: 1.461355
train_loss: 0.563330
valid_loss: 1.203678
validation finished
normal learning rate scheduler step
Epoch-8 lr: 5.403366456418536e-05
Epoch-8 lr: 0.0001621009936925561
epoch 8 training time: 15.251
---------------
2023-09-23 19:29:43.913541
current #epochs=9, #steps=320
start validation
acc: 0.775120
AUC: 0.847886
Avg Precision: 0.331449
Avg Recall: 1.000000
d_prime: 1.452978
train_loss: 0.552185
valid_loss: 1.203325
validation finished
normal learning rate scheduler step
Epoch-9 lr: 4.059912669554537e-05
Epoch-9 lr: 0.0001217973800866361
epoch 9 training time: 15.307
---------------
2023-09-23 19:29:59.220731
current #epochs=10, #steps=360
start validation
acc: 0.770335
AUC: 0.855472
Avg Precision: 0.331008
Avg Recall: 1.000000
d_prime: 1.499343
train_loss: 0.559765
valid_loss: 1.200323
validation finished
normal learning rate scheduler step
Epoch-10 lr: 4.059912669554537e-05
Epoch-10 lr: 0.0001217973800866361
epoch 10 training time: 15.351
---------------
2023-09-23 19:30:14.572025
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03845	Per Sample Data Time 0.03170	Per Sample DNN Time 0.00675	Train Loss 0.4757	
start validation
acc: 0.775120
AUC: 0.857482
Avg Precision: 0.331502
Avg Recall: 1.000000
d_prime: 1.511900
train_loss: 0.546299
valid_loss: 1.199344
validation finished
normal learning rate scheduler step
Epoch-11 lr: 4.059912669554537e-05
Epoch-11 lr: 0.0001217973800866361
epoch 11 training time: 15.316
---------------
2023-09-23 19:30:29.887898
current #epochs=12, #steps=440
start validation
acc: 0.775120
AUC: 0.856128
Avg Precision: 0.331135
Avg Recall: 1.000000
d_prime: 1.503428
train_loss: 0.558361
valid_loss: 1.199545
validation finished
normal learning rate scheduler step
Epoch-12 lr: 4.059912669554537e-05
Epoch-12 lr: 0.0001217973800866361
epoch 12 training time: 15.345
---------------
2023-09-23 19:30:45.233509
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00710	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00554	Train Loss 0.5409	
start validation
acc: 0.775120
AUC: 0.855938
Avg Precision: 0.329678
Avg Recall: 1.000000
d_prime: 1.502244
train_loss: 0.550553
valid_loss: 1.198437
validation finished
normal learning rate scheduler step
Epoch-13 lr: 3.05048547370497e-05
Epoch-13 lr: 9.15145642111491e-05
epoch 13 training time: 16.465
---------------
2023-09-23 19:31:01.698282
current #epochs=14, #steps=520
start validation
acc: 0.775120
AUC: 0.856886
Avg Precision: 0.331162
Avg Recall: 1.000000
d_prime: 1.508165
train_loss: 0.569572
valid_loss: 1.198958
validation finished
normal learning rate scheduler step
Epoch-14 lr: 3.05048547370497e-05
Epoch-14 lr: 9.15145642111491e-05
epoch 14 training time: 15.374
---------------
2023-09-23 19:31:17.072602
current #epochs=15, #steps=560
start validation
acc: 0.775120
AUC: 0.855640
Avg Precision: 0.330422
Avg Recall: 1.000000
d_prime: 1.500387
train_loss: 0.556446
valid_loss: 1.200251
validation finished
normal learning rate scheduler step
Epoch-15 lr: 3.05048547370497e-05
Epoch-15 lr: 9.15145642111491e-05
epoch 15 training time: 16.148
---------------
2023-09-23 19:31:33.220747
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03773	Per Sample Data Time 0.03076	Per Sample DNN Time 0.00697	Train Loss 0.5796	
start validation
acc: 0.775120
AUC: 0.854038
Avg Precision: 0.330619
Avg Recall: 1.000000
d_prime: 1.490457
train_loss: 0.569937
valid_loss: 1.201524
validation finished
normal learning rate scheduler step
Epoch-16 lr: 3.05048547370497e-05
Epoch-16 lr: 9.15145642111491e-05
epoch 16 training time: 15.344
---------------
2023-09-23 19:31:48.565094
current #epochs=17, #steps=640
start validation
acc: 0.770335
AUC: 0.849121
Avg Precision: 0.329910
Avg Recall: 1.000000
d_prime: 1.460415
train_loss: 0.548627
valid_loss: 1.202840
validation finished
normal learning rate scheduler step
Epoch-17 lr: 2.292034923575352e-05
Epoch-17 lr: 6.876104770726056e-05
epoch 17 training time: 15.275
---------------
2023-09-23 19:32:03.840442
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00710	Per Sample Data Time 0.00153	Per Sample DNN Time 0.00557	Train Loss 0.5458	
start validation
acc: 0.770335
AUC: 0.847856
Avg Precision: 0.329234
Avg Recall: 1.000000
d_prime: 1.452795
train_loss: 0.542425
valid_loss: 1.203761
validation finished
normal learning rate scheduler step
Epoch-18 lr: 2.292034923575352e-05
Epoch-18 lr: 6.876104770726056e-05
epoch 18 training time: 15.246
---------------
2023-09-23 19:32:19.086895
current #epochs=19, #steps=720
start validation
acc: 0.770335
AUC: 0.849430
Avg Precision: 0.329234
Avg Recall: 1.000000
d_prime: 1.462286
train_loss: 0.549293
valid_loss: 1.202345
validation finished
normal learning rate scheduler step
Epoch-19 lr: 2.292034923575352e-05
Epoch-19 lr: 6.876104770726056e-05
epoch 19 training time: 15.264
---------------
2023-09-23 19:32:34.351472
current #epochs=20, #steps=760
start validation
acc: 0.775120
AUC: 0.852567
Avg Precision: 0.329234
Avg Recall: 1.000000
d_prime: 1.481396
train_loss: 0.532174
valid_loss: 1.200969
validation finished
normal learning rate scheduler step
Epoch-20 lr: 2.292034923575352e-05
Epoch-20 lr: 6.876104770726056e-05
epoch 20 training time: 15.247
---------------
2023-09-23 19:32:49.598551
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03813	Per Sample Data Time 0.03084	Per Sample DNN Time 0.00729	Train Loss 0.6269	
start validation
acc: 0.770335
AUC: 0.854915
Avg Precision: 0.330619
Avg Recall: 1.000000
d_prime: 1.495881
train_loss: 0.561659
valid_loss: 1.199181
validation finished
normal learning rate scheduler step
Epoch-21 lr: 1.722160009012768e-05
Epoch-21 lr: 5.166480027038305e-05
epoch 21 training time: 15.259
---------------
2023-09-23 19:33:04.857918
current #epochs=22, #steps=840
start validation
acc: 0.775120
AUC: 0.854691
Avg Precision: 0.330064
Avg Recall: 1.000000
d_prime: 1.494491
train_loss: 0.543799
valid_loss: 1.199918
validation finished
normal learning rate scheduler step
Epoch-22 lr: 1.722160009012768e-05
Epoch-22 lr: 5.166480027038305e-05
epoch 22 training time: 15.357
---------------
2023-09-23 19:33:20.215489
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00712	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00556	Train Loss 0.5715	
start validation
acc: 0.770335
AUC: 0.853939
Avg Precision: 0.329910
Avg Recall: 1.000000
d_prime: 1.489840
train_loss: 0.550964
valid_loss: 1.198947
validation finished
normal learning rate scheduler step
Epoch-23 lr: 1.722160009012768e-05
Epoch-23 lr: 5.166480027038305e-05
epoch 23 training time: 15.281
---------------
2023-09-23 19:33:35.496510
current #epochs=24, #steps=920
start validation
acc: 0.770335
AUC: 0.854215
Avg Precision: 0.329372
Avg Recall: 1.000000
d_prime: 1.491550
train_loss: 0.523421
valid_loss: 1.198309
validation finished
normal learning rate scheduler step
Epoch-24 lr: 1.722160009012768e-05
Epoch-24 lr: 5.166480027038305e-05
epoch 24 training time: 15.378
---------------
2023-09-23 19:33:50.874976
current #epochs=25, #steps=960
start validation
acc: 0.770335
AUC: 0.854646
Avg Precision: 0.329372
Avg Recall: 1.000000
d_prime: 1.494214
train_loss: 0.532463
valid_loss: 1.198317
validation finished
normal learning rate scheduler step
Epoch-25 lr: 1.2939746537615766e-05
Epoch-25 lr: 3.88192396128473e-05
epoch 25 training time: 15.467
---------------
2023-09-23 19:34:06.341502
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.03787	Per Sample Data Time 0.03014	Per Sample DNN Time 0.00772	Train Loss 0.4738	
start validation
acc: 0.770335
AUC: 0.854560
Avg Precision: 0.329038
Avg Recall: 1.000000
d_prime: 1.493685
train_loss: 0.548688
valid_loss: 1.197939
validation finished
normal learning rate scheduler step
Epoch-26 lr: 1.2939746537615766e-05
Epoch-26 lr: 3.88192396128473e-05
epoch 26 training time: 15.269
---------------
2023-09-23 19:34:21.610229
current #epochs=27, #steps=1040
start validation
acc: 0.770335
AUC: 0.854145
Avg Precision: 0.327957
Avg Recall: 1.000000
d_prime: 1.491115
train_loss: 0.539270
valid_loss: 1.197961
validation finished
normal learning rate scheduler step
Epoch-27 lr: 1.2939746537615766e-05
Epoch-27 lr: 3.88192396128473e-05
epoch 27 training time: 15.363
---------------
2023-09-23 19:34:36.972846
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00714	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00552	Train Loss 0.5262	
start validation
acc: 0.770335
AUC: 0.854454
Avg Precision: 0.327957
Avg Recall: 1.000000
d_prime: 1.493024
train_loss: 0.537975
valid_loss: 1.197497
validation finished
normal learning rate scheduler step
Epoch-28 lr: 1.2939746537615766e-05
Epoch-28 lr: 3.88192396128473e-05
epoch 28 training time: 15.355
---------------
2023-09-23 19:34:52.328185
current #epochs=29, #steps=1120
start validation
acc: 0.770335
AUC: 0.853420
Avg Precision: 0.328711
Avg Recall: 1.000000
d_prime: 1.486639
train_loss: 0.552976
valid_loss: 1.197594
validation finished
normal learning rate scheduler step
Epoch-29 lr: 9.722501949962409e-06
Epoch-29 lr: 2.916750584988723e-05
epoch 29 training time: 15.353
---------------
2023-09-23 19:35:07.680996
current #epochs=30, #steps=1160
start validation
acc: 0.770335
AUC: 0.854337
Avg Precision: 0.328711
Avg Recall: 1.000000
d_prime: 1.492305
train_loss: 0.528779
valid_loss: 1.197345
validation finished
normal learning rate scheduler step
Epoch-30 lr: 9.722501949962409e-06
Epoch-30 lr: 2.916750584988723e-05
epoch 30 training time: 15.622
---------------
2023-09-23 19:35:23.302526
current #epochs=31, #steps=1200
Epoch: [31][0/40]	Per Sample Total Time 0.03865	Per Sample Data Time 0.03069	Per Sample DNN Time 0.00796	Train Loss 0.6360	
start validation
acc: 0.770335
AUC: 0.853497
Avg Precision: 0.328711
Avg Recall: 1.000000
d_prime: 1.487115
train_loss: 0.550684
valid_loss: 1.197989
validation finished
normal learning rate scheduler step
Epoch-31 lr: 9.722501949962409e-06
Epoch-31 lr: 2.916750584988723e-05
epoch 31 training time: 15.344
---------------
2023-09-23 19:35:38.647143
current #epochs=32, #steps=1240
start validation
acc: 0.770335
AUC: 0.853200
Avg Precision: 0.328711
Avg Recall: 1.000000
d_prime: 1.485286
train_loss: 0.541022
valid_loss: 1.198292
validation finished
normal learning rate scheduler step
Epoch-32 lr: 9.722501949962409e-06
Epoch-32 lr: 2.916750584988723e-05
epoch 32 training time: 15.127
---------------
2023-09-23 19:35:53.773497
current #epochs=33, #steps=1280
Epoch: [33][20/40]	Per Sample Total Time 0.00710	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00555	Train Loss 0.5546	
start validation
acc: 0.770335
AUC: 0.854096
Avg Precision: 0.328711
Avg Recall: 1.000000
d_prime: 1.490815
train_loss: 0.546340
valid_loss: 1.197644
validation finished
normal learning rate scheduler step
Epoch-33 lr: 7.305169687229444e-06
Epoch-33 lr: 2.1915509061688337e-05
epoch 33 training time: 15.274
---------------
2023-09-23 19:36:09.047394
current #epochs=34, #steps=1320
start validation
acc: 0.770335
AUC: 0.853938
Avg Precision: 0.328711
Avg Recall: 1.000000
d_prime: 1.489838
train_loss: 0.541537
valid_loss: 1.197821
validation finished
normal learning rate scheduler step
Epoch-34 lr: 7.305169687229444e-06
Epoch-34 lr: 2.1915509061688337e-05
epoch 34 training time: 15.284
---------------
2023-09-23 19:36:24.331033
current #epochs=35, #steps=1360
start validation
acc: 0.770335
AUC: 0.853466
Avg Precision: 0.328711
Avg Recall: 1.000000
d_prime: 1.486928
train_loss: 0.558379
valid_loss: 1.197818
validation finished
normal learning rate scheduler step
Epoch-35 lr: 7.305169687229444e-06
Epoch-35 lr: 2.1915509061688337e-05
epoch 35 training time: 16.147
---------------
2023-09-23 19:36:40.478215
current #epochs=36, #steps=1400
Epoch: [36][0/40]	Per Sample Total Time 0.03698	Per Sample Data Time 0.02928	Per Sample DNN Time 0.00771	Train Loss 0.5567	
start validation
acc: 0.770335
AUC: 0.853845
Avg Precision: 0.327630
Avg Recall: 1.000000
d_prime: 1.489262
train_loss: 0.551046
valid_loss: 1.197446
validation finished
normal learning rate scheduler step
Epoch-36 lr: 7.305169687229444e-06
Epoch-36 lr: 2.1915509061688337e-05
epoch 36 training time: 15.178
---------------
2023-09-23 19:36:55.655767
current #epochs=37, #steps=1440
start validation
acc: 0.770335
AUC: 0.853594
Avg Precision: 0.327630
Avg Recall: 1.000000
d_prime: 1.487715
train_loss: 0.527342
valid_loss: 1.197562
validation finished
normal learning rate scheduler step
Epoch-37 lr: 5.488865359335029e-06
Epoch-37 lr: 1.6466596078005092e-05
epoch 37 training time: 15.392
---------------
2023-09-23 19:37:11.048421
current #epochs=38, #steps=1480
Epoch: [38][20/40]	Per Sample Total Time 0.00710	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00555	Train Loss 0.5497	
start validation
acc: 0.770335
AUC: 0.853173
Avg Precision: 0.327630
Avg Recall: 1.000000
d_prime: 1.485123
train_loss: 0.533553
valid_loss: 1.197841
validation finished
normal learning rate scheduler step
Epoch-38 lr: 5.488865359335029e-06
Epoch-38 lr: 1.6466596078005092e-05
epoch 38 training time: 15.265
---------------
2023-09-23 19:37:26.313323
current #epochs=39, #steps=1520
start validation
acc: 0.770335
AUC: 0.853108
Avg Precision: 0.327630
Avg Recall: 1.000000
d_prime: 1.484719
train_loss: 0.552258
valid_loss: 1.197896
validation finished
normal learning rate scheduler step
Epoch-39 lr: 5.488865359335029e-06
Epoch-39 lr: 1.6466596078005092e-05
epoch 39 training time: 15.643
---------------
2023-09-23 19:37:41.956517
current #epochs=40, #steps=1560
start validation
acc: 0.770335
AUC: 0.853361
Avg Precision: 0.327630
Avg Recall: 1.000000
d_prime: 1.486277
train_loss: 0.527803
valid_loss: 1.197830
validation finished
normal learning rate scheduler step
Epoch-40 lr: 5.488865359335029e-06
Epoch-40 lr: 1.6466596078005092e-05
epoch 40 training time: 15.206
---------------
2023-09-23 19:37:57.162708
current #epochs=41, #steps=1600
Epoch: [41][0/40]	Per Sample Total Time 0.03718	Per Sample Data Time 0.02948	Per Sample DNN Time 0.00771	Train Loss 0.5708	
start validation
acc: 0.770335
AUC: 0.854030
Avg Precision: 0.327957
Avg Recall: 1.000000
d_prime: 1.490405
train_loss: 0.545902
valid_loss: 1.197616
validation finished
normal learning rate scheduler step
Epoch-41 lr: 4.12415374629501e-06
Epoch-41 lr: 1.2372461238885033e-05
epoch 41 training time: 15.386
---------------
2023-09-23 19:38:12.548998
current #epochs=42, #steps=1640
start validation
acc: 0.770335
AUC: 0.853928
Avg Precision: 0.327957
Avg Recall: 1.000000
d_prime: 1.489774
train_loss: 0.548876
valid_loss: 1.197540
validation finished
normal learning rate scheduler step
Epoch-42 lr: 4.12415374629501e-06
Epoch-42 lr: 1.2372461238885033e-05
epoch 42 training time: 15.161
---------------
2023-09-23 19:38:27.710011
current #epochs=43, #steps=1680
Epoch: [43][20/40]	Per Sample Total Time 0.00706	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00550	Train Loss 0.5199	
start validation
acc: 0.770335
AUC: 0.853988
Avg Precision: 0.327957
Avg Recall: 1.000000
d_prime: 1.490144
train_loss: 0.540637
valid_loss: 1.197526
validation finished
normal learning rate scheduler step
Epoch-43 lr: 4.12415374629501e-06
Epoch-43 lr: 1.2372461238885033e-05
epoch 43 training time: 15.162
---------------
2023-09-23 19:38:42.872534
current #epochs=44, #steps=1720
start validation
acc: 0.770335
AUC: 0.853810
Avg Precision: 0.327630
Avg Recall: 1.000000
d_prime: 1.489044
train_loss: 0.541147
valid_loss: 1.197605
validation finished
normal learning rate scheduler step
Epoch-44 lr: 4.12415374629501e-06
Epoch-44 lr: 1.2372461238885033e-05
epoch 44 training time: 15.248
---------------
2023-09-23 19:38:58.120643
current #epochs=45, #steps=1760
start validation
acc: 0.770335
AUC: 0.853358
Avg Precision: 0.327630
Avg Recall: 1.000000
d_prime: 1.486260
train_loss: 0.546736
valid_loss: 1.197679
validation finished
normal learning rate scheduler step
Epoch-45 lr: 3.0987541157576773e-06
Epoch-45 lr: 9.296262347273034e-06
epoch 45 training time: 15.239
---------------
2023-09-23 19:39:13.359287
current #epochs=46, #steps=1800
Epoch: [46][0/40]	Per Sample Total Time 0.03833	Per Sample Data Time 0.03120	Per Sample DNN Time 0.00713	Train Loss 0.5798	
start validation
acc: 0.770335
AUC: 0.853536
Avg Precision: 0.327630
Avg Recall: 1.000000
d_prime: 1.487358
train_loss: 0.531905
valid_loss: 1.197622
validation finished
normal learning rate scheduler step
Epoch-46 lr: 3.0987541157576773e-06
Epoch-46 lr: 9.296262347273034e-06
epoch 46 training time: 15.277
---------------
2023-09-23 19:39:28.635941
current #epochs=47, #steps=1840
start validation
acc: 0.770335
AUC: 0.853404
Avg Precision: 0.327630
Avg Recall: 1.000000
d_prime: 1.486543
train_loss: 0.542057
valid_loss: 1.197739
validation finished
normal learning rate scheduler step
Epoch-47 lr: 3.0987541157576773e-06
Epoch-47 lr: 9.296262347273034e-06
epoch 47 training time: 15.346
---------------
2023-09-23 19:39:43.981771
current #epochs=48, #steps=1880
Epoch: [48][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00556	Train Loss 0.5452	
start validation
acc: 0.770335
AUC: 0.853378
Avg Precision: 0.327630
Avg Recall: 1.000000
d_prime: 1.486382
train_loss: 0.541149
valid_loss: 1.197779
validation finished
normal learning rate scheduler step
Epoch-48 lr: 3.0987541157576773e-06
Epoch-48 lr: 9.296262347273034e-06
epoch 48 training time: 15.314
---------------
2023-09-23 19:39:59.295873
current #epochs=49, #steps=1920
start validation
[I 2023-09-23 19:40:14,598] Trial 10 finished with value: 0.32763038277511963 and parameters: {'warmup': 'True', 'num_epochs': 49, 'batch_size': 26, 'lr-adaptschedule': 'False', 'lr': 7.191378593262329e-05, 'head-lr': 3, 'lr-scheduler-start': 5, 'lr-scheduler-step': 4, 'lr-scheduler-decay': 0.7513672637790203}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.770335
AUC: 0.853358
Avg Precision: 0.327630
Avg Recall: 1.000000
d_prime: 1.486260
train_loss: 0.534030
valid_loss: 1.197794
validation finished
normal learning rate scheduler step
Epoch-49 lr: 2.3283024010808234e-06
Epoch-49 lr: 6.984907203242472e-06
epoch 49 training time: 15.298
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 2 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcbe219e520>
The learning rate scheduler starts at 5 epoch with decay rate of 0.628 every 6 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 19:40:14.630871
current #epochs=1, #steps=0
start validation
acc: 0.799043
AUC: 0.856256
Avg Precision: 0.317125
Avg Recall: 1.000000
d_prime: 1.504224
train_loss: 0.612703
valid_loss: 1.235101
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0018294230052939957
Epoch-1 lr: 0.0036588460105879913
epoch 1 training time: 17.668
---------------
2023-09-23 19:40:32.299145
current #epochs=2, #steps=40
start validation
acc: 0.755981
AUC: 0.832638
Avg Precision: 0.326580
Avg Recall: 1.000000
d_prime: 1.364208
train_loss: 0.623536
valid_loss: 1.208395
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0018294230052939957
Epoch-2 lr: 0.0036588460105879913
epoch 2 training time: 15.219
---------------
2023-09-23 19:40:47.518016
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00712	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00552	Train Loss 0.6041	
start validation
acc: 0.770335
AUC: 0.870040
Avg Precision: 0.334542
Avg Recall: 1.000000
d_prime: 1.593226
train_loss: 0.584570
valid_loss: 1.198218
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0018294230052939957
Epoch-3 lr: 0.0036588460105879913
epoch 3 training time: 15.316
---------------
2023-09-23 19:41:02.834264
current #epochs=4, #steps=120
start validation
acc: 0.679426
AUC: 0.799842
Avg Precision: 0.293843
Avg Recall: 1.000000
d_prime: 1.189433
train_loss: 0.578617
valid_loss: 1.228732
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0018294230052939957
Epoch-4 lr: 0.0036588460105879913
epoch 4 training time: 15.287
---------------
2023-09-23 19:41:18.121256
current #epochs=5, #steps=160
start validation
acc: 0.751196
AUC: 0.839619
Avg Precision: 0.292940
Avg Recall: 1.000000
d_prime: 1.404162
train_loss: 0.580048
valid_loss: 1.205215
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0011479729480790412
Epoch-5 lr: 0.0022959458961580824
epoch 5 training time: 15.200
---------------
2023-09-23 19:41:33.320954
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03830	Per Sample Data Time 0.03227	Per Sample DNN Time 0.00604	Train Loss 0.4681	
start validation
acc: 0.789474
AUC: 0.865540
Avg Precision: 0.277873
Avg Recall: 1.000000
d_prime: 1.563490
train_loss: 0.565422
valid_loss: 1.184255
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0011479729480790412
Epoch-6 lr: 0.0022959458961580824
epoch 6 training time: 15.338
---------------
2023-09-23 19:41:48.659260
current #epochs=7, #steps=240
start validation
acc: 0.684211
AUC: 0.855405
Avg Precision: 0.307440
Avg Recall: 1.000000
d_prime: 1.498923
train_loss: 0.570287
valid_loss: 1.210467
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0011479729480790412
Epoch-7 lr: 0.0022959458961580824
epoch 7 training time: 15.603
---------------
2023-09-23 19:42:04.261708
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00714	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00558	Train Loss 0.5639	
start validation
acc: 0.674641
AUC: 0.839027
Avg Precision: 0.316762
Avg Recall: 1.000000
d_prime: 1.400731
train_loss: 0.559935
valid_loss: 1.213427
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0011479729480790412
Epoch-8 lr: 0.0022959458961580824
epoch 8 training time: 15.249
---------------
2023-09-23 19:42:19.511400
current #epochs=9, #steps=320
start validation
acc: 0.794258
AUC: 0.869683
Avg Precision: 0.327345
Avg Recall: 1.000000
d_prime: 1.590842
train_loss: 0.558984
valid_loss: 1.196098
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0011479729480790412
Epoch-9 lr: 0.0022959458961580824
epoch 9 training time: 15.225
---------------
2023-09-23 19:42:34.735859
current #epochs=10, #steps=360
start validation
acc: 0.775120
AUC: 0.834915
Avg Precision: 0.316700
Avg Recall: 1.000000
d_prime: 1.377121
train_loss: 0.534824
valid_loss: 1.213064
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0011479729480790412
Epoch-10 lr: 0.0022959458961580824
epoch 10 training time: 15.335
---------------
2023-09-23 19:42:50.071420
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03844	Per Sample Data Time 0.03133	Per Sample DNN Time 0.00711	Train Loss 0.5678	
start validation
acc: 0.746411
AUC: 0.862926
Avg Precision: 0.303995
Avg Recall: 1.000000
d_prime: 1.546526
train_loss: 0.543417
valid_loss: 1.193024
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0007203593076656989
Epoch-11 lr: 0.0014407186153313977
epoch 11 training time: 15.308
---------------
2023-09-23 19:43:05.378939
current #epochs=12, #steps=440
start validation
acc: 0.741627
AUC: 0.867592
Avg Precision: 0.312360
Avg Recall: 1.000000
d_prime: 1.576962
train_loss: 0.515822
valid_loss: 1.188474
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0007203593076656989
Epoch-12 lr: 0.0014407186153313977
epoch 12 training time: 15.334
---------------
2023-09-23 19:43:20.712672
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00710	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00555	Train Loss 0.5214	
start validation
acc: 0.760766
AUC: 0.883532
Avg Precision: 0.361644
Avg Recall: 1.000000
d_prime: 1.686914
train_loss: 0.524959
valid_loss: 1.188759
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0007203593076656989
Epoch-13 lr: 0.0014407186153313977
epoch 13 training time: 15.189
---------------
2023-09-23 19:43:35.901894
current #epochs=14, #steps=520
start validation
acc: 0.760766
AUC: 0.858469
Avg Precision: 0.322163
Avg Recall: 1.000000
d_prime: 1.518107
train_loss: 0.545110
valid_loss: 1.189428
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0007203593076656989
Epoch-14 lr: 0.0014407186153313977
epoch 14 training time: 15.330
---------------
2023-09-23 19:43:51.231752
current #epochs=15, #steps=560
start validation
acc: 0.794258
AUC: 0.873049
Avg Precision: 0.334498
Avg Recall: 1.000000
d_prime: 1.613507
train_loss: 0.540135
valid_loss: 1.182704
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0007203593076656989
Epoch-15 lr: 0.0014407186153313977
epoch 15 training time: 15.321
---------------
2023-09-23 19:44:06.553408
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03757	Per Sample Data Time 0.03023	Per Sample DNN Time 0.00734	Train Loss 0.5716	
start validation
acc: 0.765550
AUC: 0.873260
Avg Precision: 0.341079
Avg Recall: 1.000000
d_prime: 1.614945
train_loss: 0.503368
valid_loss: 1.185861
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0007203593076656989
Epoch-16 lr: 0.0014407186153313977
epoch 16 training time: 15.308
---------------
2023-09-23 19:44:21.861038
current #epochs=17, #steps=640
start validation
acc: 0.727273
AUC: 0.874169
Avg Precision: 0.316517
Avg Recall: 1.000000
d_prime: 1.621146
train_loss: 0.533835
valid_loss: 1.186973
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.000452029408017789
Epoch-17 lr: 0.000904058816035578
epoch 17 training time: 15.312
---------------
2023-09-23 19:44:37.172714
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00706	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00552	Train Loss 0.5469	
start validation
acc: 0.794258
AUC: 0.885588
Avg Precision: 0.307848
Avg Recall: 1.000000
d_prime: 1.701857
train_loss: 0.524731
valid_loss: 1.172243
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.000452029408017789
Epoch-18 lr: 0.000904058816035578
epoch 18 training time: 15.161
---------------
2023-09-23 19:44:52.333627
current #epochs=19, #steps=720
start validation
acc: 0.799043
AUC: 0.882334
Avg Precision: 0.317788
Avg Recall: 1.000000
d_prime: 1.678301
train_loss: 0.499380
valid_loss: 1.170244
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.000452029408017789
Epoch-19 lr: 0.000904058816035578
epoch 19 training time: 15.245
---------------
2023-09-23 19:45:07.578710
current #epochs=20, #steps=760
start validation
acc: 0.784689
AUC: 0.862026
Avg Precision: 0.300100
Avg Recall: 1.000000
d_prime: 1.540739
train_loss: 0.496772
valid_loss: 1.186148
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.000452029408017789
Epoch-20 lr: 0.000904058816035578
epoch 20 training time: 15.430
---------------
2023-09-23 19:45:23.008754
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03748	Per Sample Data Time 0.03037	Per Sample DNN Time 0.00711	Train Loss 0.3862	
start validation
acc: 0.751196
AUC: 0.867815
Avg Precision: 0.308515
Avg Recall: 1.000000
d_prime: 1.578434
train_loss: 0.512344
valid_loss: 1.178347
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.000452029408017789
Epoch-21 lr: 0.000904058816035578
epoch 21 training time: 16.485
---------------
2023-09-23 19:45:39.493339
current #epochs=22, #steps=840
start validation
acc: 0.784689
AUC: 0.884987
Avg Precision: 0.318878
Avg Recall: 1.000000
d_prime: 1.697469
train_loss: 0.502319
valid_loss: 1.169590
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.000452029408017789
Epoch-22 lr: 0.000904058816035578
epoch 22 training time: 15.276
---------------
2023-09-23 19:45:54.769815
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00710	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00553	Train Loss 0.5122	
start validation
acc: 0.765550
AUC: 0.871036
Avg Precision: 0.310237
Avg Recall: 1.000000
d_prime: 1.599903
train_loss: 0.489334
valid_loss: 1.174098
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.00028365092744486004
Epoch-23 lr: 0.0005673018548897201
epoch 23 training time: 15.284
---------------
2023-09-23 19:46:10.053619
current #epochs=24, #steps=920
start validation
acc: 0.784689
AUC: 0.879644
Avg Precision: 0.329783
Avg Recall: 1.000000
d_prime: 1.659169
train_loss: 0.500792
valid_loss: 1.169448
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.00028365092744486004
Epoch-24 lr: 0.0005673018548897201
epoch 24 training time: 15.217
---------------
2023-09-23 19:46:25.270542
current #epochs=25, #steps=960
start validation
acc: 0.770335
AUC: 0.880519
Avg Precision: 0.331360
Avg Recall: 1.000000
d_prime: 1.665358
train_loss: 0.486484
valid_loss: 1.172201
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.00028365092744486004
Epoch-25 lr: 0.0005673018548897201
epoch 25 training time: 15.244
---------------
2023-09-23 19:46:40.514538
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.03788	Per Sample Data Time 0.03078	Per Sample DNN Time 0.00710	Train Loss 0.4935	
start validation
acc: 0.784689
AUC: 0.880647
Avg Precision: 0.332003
Avg Recall: 1.000000
d_prime: 1.666265
train_loss: 0.481400
valid_loss: 1.163557
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.00028365092744486004
Epoch-26 lr: 0.0005673018548897201
epoch 26 training time: 15.228
---------------
2023-09-23 19:46:55.742407
current #epochs=27, #steps=1040
start validation
acc: 0.794258
AUC: 0.883331
Avg Precision: 0.355848
Avg Recall: 1.000000
d_prime: 1.685469
train_loss: 0.475010
valid_loss: 1.170151
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.00028365092744486004
Epoch-27 lr: 0.0005673018548897201
epoch 27 training time: 16.391
---------------
2023-09-23 19:47:12.133601
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00557	Train Loss 0.5009	
start validation
acc: 0.770335
AUC: 0.883807
Avg Precision: 0.348567
Avg Recall: 1.000000
d_prime: 1.688901
train_loss: 0.486907
valid_loss: 1.174046
validation finished
normal learning rate scheduler step
Epoch-28 lr: 0.00028365092744486004
Epoch-28 lr: 0.0005673018548897201
epoch 28 training time: 15.698
---------------
2023-09-23 19:47:27.831996
current #epochs=29, #steps=1120
start validation
acc: 0.784689
AUC: 0.876744
Avg Precision: 0.355649
Avg Recall: 1.000000
d_prime: 1.638879
train_loss: 0.485968
valid_loss: 1.168611
validation finished
normal learning rate scheduler step
Epoch-29 lr: 0.00017799250936603432
Epoch-29 lr: 0.00035598501873206865
epoch 29 training time: 15.217
---------------
2023-09-23 19:47:43.049397
current #epochs=30, #steps=1160
start validation
acc: 0.784689
AUC: 0.872429
Avg Precision: 0.339854
Avg Recall: 1.000000
d_prime: 1.609301
train_loss: 0.489713
valid_loss: 1.180463
validation finished
normal learning rate scheduler step
Epoch-30 lr: 0.00017799250936603432
Epoch-30 lr: 0.00035598501873206865
epoch 30 training time: 15.322
---------------
2023-09-23 19:47:58.371434
current #epochs=31, #steps=1200
Epoch: [31][0/40]	Per Sample Total Time 0.03805	Per Sample Data Time 0.03079	Per Sample DNN Time 0.00726	Train Loss 0.5659	
start validation
acc: 0.794258
AUC: 0.874414
Avg Precision: 0.333547
Avg Recall: 1.000000
d_prime: 1.622820
train_loss: 0.464161
valid_loss: 1.173824
validation finished
normal learning rate scheduler step
Epoch-31 lr: 0.00017799250936603432
Epoch-31 lr: 0.00035598501873206865
epoch 31 training time: 15.325
---------------
2023-09-23 19:48:13.696482
current #epochs=32, #steps=1240
start validation
acc: 0.789474
AUC: 0.873916
Avg Precision: 0.340356
Avg Recall: 1.000000
d_prime: 1.619414
train_loss: 0.481056
valid_loss: 1.172702
validation finished
normal learning rate scheduler step
Epoch-32 lr: 0.00017799250936603432
Epoch-32 lr: 0.00035598501873206865
epoch 32 training time: 15.289
---------------
2023-09-23 19:48:28.985022
current #epochs=33, #steps=1280
Epoch: [33][20/40]	Per Sample Total Time 0.00711	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00551	Train Loss 0.4784	
start validation
acc: 0.784689
AUC: 0.868797
Avg Precision: 0.332844
Avg Recall: 1.000000
d_prime: 1.584940
train_loss: 0.460584
valid_loss: 1.173959
validation finished
normal learning rate scheduler step
Epoch-33 lr: 0.00017799250936603432
Epoch-33 lr: 0.00035598501873206865
epoch 33 training time: 15.282
---------------
2023-09-23 19:48:44.267473
current #epochs=34, #steps=1320
start validation
acc: 0.789474
AUC: 0.877770
Avg Precision: 0.341839
Avg Recall: 1.000000
d_prime: 1.646019
train_loss: 0.474608
valid_loss: 1.177084
validation finished
normal learning rate scheduler step
Epoch-34 lr: 0.00017799250936603432
Epoch-34 lr: 0.00035598501873206865
epoch 34 training time: 15.284
---------------
2023-09-23 19:48:59.551290
current #epochs=35, #steps=1360
start validation
acc: 0.799043
AUC: 0.880641
Avg Precision: 0.334146
Avg Recall: 1.000000
d_prime: 1.666222
train_loss: 0.483089
valid_loss: 1.169528
validation finished
normal learning rate scheduler step
Epoch-35 lr: 0.000111691273763159
Epoch-35 lr: 0.000223382547526318
epoch 35 training time: 15.766
---------------
2023-09-23 19:49:15.316646
current #epochs=36, #steps=1400
Epoch: [36][0/40]	Per Sample Total Time 0.03971	Per Sample Data Time 0.03223	Per Sample DNN Time 0.00747	Train Loss 0.3394	
start validation
acc: 0.784689
AUC: 0.876804
Avg Precision: 0.329732
Avg Recall: 1.000000
d_prime: 1.639296
train_loss: 0.473468
valid_loss: 1.174634
validation finished
normal learning rate scheduler step
Epoch-36 lr: 0.000111691273763159
Epoch-36 lr: 0.000223382547526318
epoch 36 training time: 15.341
---------------
2023-09-23 19:49:30.657985
current #epochs=37, #steps=1440
start validation
acc: 0.779904
AUC: 0.876496
Avg Precision: 0.333176
Avg Recall: 1.000000
d_prime: 1.637157
train_loss: 0.462348
valid_loss: 1.168954
validation finished
normal learning rate scheduler step
Epoch-37 lr: 0.000111691273763159
Epoch-37 lr: 0.000223382547526318
epoch 37 training time: 15.275
---------------
2023-09-23 19:49:45.933138
current #epochs=38, #steps=1480
Epoch: [38][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00165	Per Sample DNN Time 0.00555	Train Loss 0.4541	
start validation
acc: 0.799043
AUC: 0.881065
Avg Precision: 0.338259
Avg Recall: 1.000000
d_prime: 1.669237
train_loss: 0.454389
valid_loss: 1.167712
validation finished
normal learning rate scheduler step
Epoch-38 lr: 0.000111691273763159
Epoch-38 lr: 0.000223382547526318
epoch 38 training time: 16.949
---------------
2023-09-23 19:50:02.882882
current #epochs=39, #steps=1520
start validation
acc: 0.789474
AUC: 0.876470
Avg Precision: 0.336406
Avg Recall: 1.000000
d_prime: 1.636977
train_loss: 0.465488
valid_loss: 1.175124
validation finished
normal learning rate scheduler step
Epoch-39 lr: 0.000111691273763159
Epoch-39 lr: 0.000223382547526318
epoch 39 training time: 15.335
---------------
2023-09-23 19:50:18.217834
current #epochs=40, #steps=1560
start validation
acc: 0.784689
AUC: 0.876341
Avg Precision: 0.334166
Avg Recall: 1.000000
d_prime: 1.636086
train_loss: 0.473831
valid_loss: 1.175191
validation finished
normal learning rate scheduler step
Epoch-40 lr: 0.000111691273763159
Epoch-40 lr: 0.000223382547526318
epoch 40 training time: 15.415
---------------
2023-09-23 19:50:33.633124
current #epochs=41, #steps=1600
Epoch: [41][0/40]	Per Sample Total Time 0.03786	Per Sample Data Time 0.03010	Per Sample DNN Time 0.00775	Train Loss 0.4428	
start validation
[I 2023-09-23 19:50:48,957] Trial 11 finished with value: 0.3364886877828054 and parameters: {'warmup': 'True', 'num_epochs': 41, 'batch_size': 60, 'lr-adaptschedule': 'False', 'lr': 0.0018294230052939957, 'head-lr': 2, 'lr-scheduler-start': 5, 'lr-scheduler-step': 6, 'lr-scheduler-decay': 0.6275054729043146}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.789474
AUC: 0.873992
Avg Precision: 0.336489
Avg Recall: 1.000000
d_prime: 1.619934
train_loss: 0.456106
valid_loss: 1.172891
validation finished
normal learning rate scheduler step
Epoch-41 lr: 7.008688556203636e-05
Epoch-41 lr: 0.00014017377112407272
epoch 41 training time: 15.320
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 1 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc52638490>
The learning rate scheduler starts at 5 epoch with decay rate of 0.710 every 4 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 19:50:48.987607
current #epochs=1, #steps=0
start validation
acc: 0.693780
AUC: 0.858954
Avg Precision: 0.293474
Avg Recall: 1.000000
d_prime: 1.521173
train_loss: 0.616275
valid_loss: 1.213273
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0028539780433622223
Epoch-1 lr: 0.0028539780433622223
epoch 1 training time: 17.723
---------------
2023-09-23 19:51:06.711192
current #epochs=2, #steps=40
start validation
acc: 0.746411
AUC: 0.867511
Avg Precision: 0.315771
Avg Recall: 1.000000
d_prime: 1.576428
train_loss: 0.572029
valid_loss: 1.200369
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0028539780433622223
Epoch-2 lr: 0.0028539780433622223
epoch 2 training time: 17.706
---------------
2023-09-23 19:51:24.417223
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00556	Train Loss 0.5338	
start validation
acc: 0.760766
AUC: 0.868568
Avg Precision: 0.353950
Avg Recall: 1.000000
d_prime: 1.583423
train_loss: 0.550381
valid_loss: 1.196631
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0028539780433622223
Epoch-3 lr: 0.0028539780433622223
epoch 3 training time: 17.725
---------------
2023-09-23 19:51:42.142610
current #epochs=4, #steps=120
start validation
acc: 0.693780
AUC: 0.827827
Avg Precision: 0.294484
Avg Recall: 1.000000
d_prime: 1.337297
train_loss: 0.602404
valid_loss: 1.209996
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0028539780433622223
Epoch-4 lr: 0.0028539780433622223
epoch 4 training time: 15.392
---------------
2023-09-23 19:51:57.534795
current #epochs=5, #steps=160
start validation
acc: 0.755981
AUC: 0.843888
Avg Precision: 0.306289
Avg Recall: 1.000000
d_prime: 1.429156
train_loss: 0.537820
valid_loss: 1.197737
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.002026766630802414
Epoch-5 lr: 0.002026766630802414
epoch 5 training time: 15.617
---------------
2023-09-23 19:52:13.151187
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03687	Per Sample Data Time 0.02948	Per Sample DNN Time 0.00739	Train Loss 0.6841	
start validation
acc: 0.693780
AUC: 0.805740
Avg Precision: 0.294334
Avg Recall: 1.000000
d_prime: 1.219485
train_loss: 0.538870
valid_loss: 1.223245
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.002026766630802414
Epoch-6 lr: 0.002026766630802414
epoch 6 training time: 15.341
---------------
2023-09-23 19:52:28.492722
current #epochs=7, #steps=240
start validation
acc: 0.760766
AUC: 0.827334
Avg Precision: 0.289056
Avg Recall: 1.000000
d_prime: 1.334570
train_loss: 0.512482
valid_loss: 1.215575
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.002026766630802414
Epoch-7 lr: 0.002026766630802414
epoch 7 training time: 15.376
---------------
2023-09-23 19:52:43.868599
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00704	Per Sample Data Time 0.00152	Per Sample DNN Time 0.00552	Train Loss 0.5314	
start validation
acc: 0.760766
AUC: 0.842967
Avg Precision: 0.314856
Avg Recall: 1.000000
d_prime: 1.423728
train_loss: 0.529270
valid_loss: 1.188353
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.002026766630802414
Epoch-8 lr: 0.002026766630802414
epoch 8 training time: 15.221
---------------
2023-09-23 19:52:59.090161
current #epochs=9, #steps=320
start validation
acc: 0.770335
AUC: 0.837614
Avg Precision: 0.306905
Avg Recall: 1.000000
d_prime: 1.392575
train_loss: 0.528670
valid_loss: 1.178657
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0014393183526019212
Epoch-9 lr: 0.0014393183526019212
epoch 9 training time: 18.704
---------------
2023-09-23 19:53:17.794159
current #epochs=10, #steps=360
start validation
acc: 0.722488
AUC: 0.790258
Avg Precision: 0.287783
Avg Recall: 1.000000
d_prime: 1.141720
train_loss: 0.547331
valid_loss: 1.225196
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0014393183526019212
Epoch-10 lr: 0.0014393183526019212
epoch 10 training time: 15.336
---------------
2023-09-23 19:53:33.130530
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03738	Per Sample Data Time 0.02990	Per Sample DNN Time 0.00748	Train Loss 0.4331	
start validation
acc: 0.779904
AUC: 0.844687
Avg Precision: 0.286934
Avg Recall: 1.000000
d_prime: 1.433883
train_loss: 0.545243
valid_loss: 1.202043
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0014393183526019212
Epoch-11 lr: 0.0014393183526019212
epoch 11 training time: 18.414
---------------
2023-09-23 19:53:51.544430
current #epochs=12, #steps=440
start validation
acc: 0.770335
AUC: 0.844765
Avg Precision: 0.296213
Avg Recall: 1.000000
d_prime: 1.434348
train_loss: 0.535936
valid_loss: 1.196460
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0014393183526019212
Epoch-12 lr: 0.0014393183526019212
epoch 12 training time: 15.320
---------------
2023-09-23 19:54:06.864270
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00561	Train Loss 0.4896	
start validation
acc: 0.794258
AUC: 0.860241
Avg Precision: 0.327360
Avg Recall: 1.000000
d_prime: 1.529338
train_loss: 0.505363
valid_loss: 1.190185
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0010221390507680352
Epoch-13 lr: 0.0010221390507680352
epoch 13 training time: 17.786
---------------
2023-09-23 19:54:24.650050
current #epochs=14, #steps=520
start validation
acc: 0.760766
AUC: 0.873139
Avg Precision: 0.355549
Avg Recall: 1.000000
d_prime: 1.614121
train_loss: 0.503336
valid_loss: 1.183818
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0010221390507680352
Epoch-14 lr: 0.0010221390507680352
epoch 14 training time: 15.322
---------------
2023-09-23 19:54:39.972453
current #epochs=15, #steps=560
start validation
acc: 0.770335
AUC: 0.862839
Avg Precision: 0.363011
Avg Recall: 1.000000
d_prime: 1.545966
train_loss: 0.490907
valid_loss: 1.179008
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0010221390507680352
Epoch-15 lr: 0.0010221390507680352
epoch 15 training time: 15.170
---------------
2023-09-23 19:54:55.142848
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04166	Per Sample Data Time 0.03222	Per Sample DNN Time 0.00944	Train Loss 0.4516	
start validation
acc: 0.708134
AUC: 0.852074
Avg Precision: 0.345398
Avg Recall: 1.000000
d_prime: 1.478377
train_loss: 0.485059
valid_loss: 1.195929
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0010221390507680352
Epoch-16 lr: 0.0010221390507680352
epoch 16 training time: 15.418
---------------
2023-09-23 19:55:10.560659
current #epochs=17, #steps=640
start validation
acc: 0.717703
AUC: 0.848235
Avg Precision: 0.294881
Avg Recall: 1.000000
d_prime: 1.455072
train_loss: 0.483625
valid_loss: 1.193309
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0007258771051006924
Epoch-17 lr: 0.0007258771051006924
epoch 17 training time: 15.322
---------------
2023-09-23 19:55:25.882581
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00557	Train Loss 0.4503	
start validation
acc: 0.775120
AUC: 0.881883
Avg Precision: 0.345256
Avg Recall: 1.000000
d_prime: 1.675072
train_loss: 0.460359
valid_loss: 1.166938
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0007258771051006924
Epoch-18 lr: 0.0007258771051006924
epoch 18 training time: 15.273
---------------
2023-09-23 19:55:41.155842
current #epochs=19, #steps=720
start validation
acc: 0.779904
AUC: 0.879718
Avg Precision: 0.343752
Avg Recall: 1.000000
d_prime: 1.659692
train_loss: 0.472554
valid_loss: 1.157022
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0007258771051006924
Epoch-19 lr: 0.0007258771051006924
epoch 19 training time: 15.326
---------------
2023-09-23 19:55:56.481594
current #epochs=20, #steps=760
start validation
acc: 0.775120
AUC: 0.862776
Avg Precision: 0.339432
Avg Recall: 1.000000
d_prime: 1.545560
train_loss: 0.460171
valid_loss: 1.179257
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0007258771051006924
Epoch-20 lr: 0.0007258771051006924
epoch 20 training time: 15.251
---------------
2023-09-23 19:56:11.732986
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04182	Per Sample Data Time 0.03225	Per Sample DNN Time 0.00957	Train Loss 0.5114	
start validation
acc: 0.794258
AUC: 0.849467
Avg Precision: 0.294144
Avg Recall: 1.000000
d_prime: 1.462507
train_loss: 0.446678
valid_loss: 1.177374
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0005154852182914358
Epoch-21 lr: 0.0005154852182914358
epoch 21 training time: 16.312
---------------
2023-09-23 19:56:28.044490
current #epochs=22, #steps=840
start validation
acc: 0.784689
AUC: 0.884030
Avg Precision: 0.339721
Avg Recall: 1.000000
d_prime: 1.690517
train_loss: 0.442086
valid_loss: 1.169048
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0005154852182914358
Epoch-22 lr: 0.0005154852182914358
epoch 22 training time: 15.479
---------------
2023-09-23 19:56:43.523790
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00154	Per Sample DNN Time 0.00568	Train Loss 0.4705	
start validation
acc: 0.775120
AUC: 0.878226
Avg Precision: 0.333930
Avg Recall: 1.000000
d_prime: 1.649207
train_loss: 0.458661
valid_loss: 1.167352
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0005154852182914358
Epoch-23 lr: 0.0005154852182914358
epoch 23 training time: 16.212
---------------
2023-09-23 19:56:59.735674
current #epochs=24, #steps=920
start validation
acc: 0.803828
AUC: 0.882883
Avg Precision: 0.358923
Avg Recall: 1.000000
d_prime: 1.682237
train_loss: 0.445789
valid_loss: 1.166749
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0005154852182914358
Epoch-24 lr: 0.0005154852182914358
epoch 24 training time: 17.777
---------------
2023-09-23 19:57:17.512515
current #epochs=25, #steps=960
start validation
acc: 0.794258
AUC: 0.880637
Avg Precision: 0.325364
Avg Recall: 1.000000
d_prime: 1.666197
train_loss: 0.440247
valid_loss: 1.159581
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.00036607437872022194
Epoch-25 lr: 0.00036607437872022194
epoch 25 training time: 15.261
---------------
2023-09-23 19:57:32.773644
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.04006	Per Sample Data Time 0.03130	Per Sample DNN Time 0.00877	Train Loss 0.4532	
start validation
acc: 0.784689
AUC: 0.870235
Avg Precision: 0.325250
Avg Recall: 1.000000
d_prime: 1.594530
train_loss: 0.432844
valid_loss: 1.163340
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.00036607437872022194
Epoch-26 lr: 0.00036607437872022194
epoch 26 training time: 15.346
---------------
2023-09-23 19:57:48.119837
current #epochs=27, #steps=1040
start validation
acc: 0.789474
AUC: 0.884391
Avg Precision: 0.334176
Avg Recall: 1.000000
d_prime: 1.693137
train_loss: 0.444437
valid_loss: 1.153213
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.00036607437872022194
Epoch-27 lr: 0.00036607437872022194
epoch 27 training time: 16.010
---------------
2023-09-23 19:58:04.130414
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00714	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00555	Train Loss 0.4387	
start validation
acc: 0.760766
AUC: 0.882193
Avg Precision: 0.349403
Avg Recall: 1.000000
d_prime: 1.677288
train_loss: 0.451797
valid_loss: 1.161371
validation finished
normal learning rate scheduler step
Epoch-28 lr: 0.00036607437872022194
Epoch-28 lr: 0.00036607437872022194
epoch 28 training time: 15.297
---------------
2023-09-23 19:58:19.427357
current #epochs=29, #steps=1120
start validation
acc: 0.736842
AUC: 0.874945
Avg Precision: 0.342695
Avg Recall: 1.000000
d_prime: 1.626465
train_loss: 0.467382
valid_loss: 1.161421
validation finished
normal learning rate scheduler step
Epoch-29 lr: 0.0002599695316183287
Epoch-29 lr: 0.0002599695316183287
epoch 29 training time: 15.216
---------------
2023-09-23 19:58:34.643175
current #epochs=30, #steps=1160
start validation
acc: 0.755981
AUC: 0.874907
Avg Precision: 0.345439
Avg Recall: 1.000000
d_prime: 1.626201
train_loss: 0.438851
valid_loss: 1.164350
validation finished
normal learning rate scheduler step
Epoch-30 lr: 0.0002599695316183287
Epoch-30 lr: 0.0002599695316183287
epoch 30 training time: 15.461
---------------
2023-09-23 19:58:50.104262
current #epochs=31, #steps=1200
Epoch: [31][0/40]	Per Sample Total Time 0.04081	Per Sample Data Time 0.03033	Per Sample DNN Time 0.01048	Train Loss 0.6416	
start validation
acc: 0.765550
AUC: 0.871024
Avg Precision: 0.320886
Avg Recall: 1.000000
d_prime: 1.599822
train_loss: 0.470269
valid_loss: 1.169007
validation finished
normal learning rate scheduler step
Epoch-31 lr: 0.0002599695316183287
Epoch-31 lr: 0.0002599695316183287
epoch 31 training time: 15.387
---------------
2023-09-23 19:59:05.490821
current #epochs=32, #steps=1240
start validation
acc: 0.732057
AUC: 0.869146
Avg Precision: 0.322614
Avg Recall: 1.000000
d_prime: 1.587261
train_loss: 0.448879
valid_loss: 1.174327
validation finished
normal learning rate scheduler step
Epoch-32 lr: 0.0002599695316183287
Epoch-32 lr: 0.0002599695316183287
epoch 32 training time: 15.436
---------------
2023-09-23 19:59:20.926920
current #epochs=33, #steps=1280
Epoch: [33][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00568	Train Loss 0.4232	
start validation
acc: 0.727273
AUC: 0.875106
Avg Precision: 0.339205
Avg Recall: 1.000000
d_prime: 1.627569
train_loss: 0.439180
valid_loss: 1.171052
validation finished
normal learning rate scheduler step
Epoch-33 lr: 0.00018461864937427224
Epoch-33 lr: 0.00018461864937427224
epoch 33 training time: 15.366
---------------
2023-09-23 19:59:36.292870
current #epochs=34, #steps=1320
start validation
acc: 0.755981
AUC: 0.883344
Avg Precision: 0.351138
Avg Recall: 1.000000
d_prime: 1.685562
train_loss: 0.436306
valid_loss: 1.165874
validation finished
normal learning rate scheduler step
Epoch-34 lr: 0.00018461864937427224
Epoch-34 lr: 0.00018461864937427224
epoch 34 training time: 15.308
---------------
2023-09-23 19:59:51.600589
current #epochs=35, #steps=1360
start validation
acc: 0.751196
AUC: 0.875848
Avg Precision: 0.345808
Avg Recall: 1.000000
d_prime: 1.632682
train_loss: 0.447672
valid_loss: 1.161630
validation finished
normal learning rate scheduler step
Epoch-35 lr: 0.00018461864937427224
Epoch-35 lr: 0.00018461864937427224
epoch 35 training time: 15.397
---------------
2023-09-23 20:00:06.997509
current #epochs=36, #steps=1400
Epoch: [36][0/40]	Per Sample Total Time 0.03998	Per Sample Data Time 0.03052	Per Sample DNN Time 0.00946	Train Loss 0.4283	
start validation
acc: 0.746411
AUC: 0.881845
Avg Precision: 0.356526
Avg Recall: 1.000000
d_prime: 1.674794
train_loss: 0.431357
valid_loss: 1.154766
validation finished
normal learning rate scheduler step
Epoch-36 lr: 0.00018461864937427224
Epoch-36 lr: 0.00018461864937427224
epoch 36 training time: 15.307
---------------
2023-09-23 20:00:22.303940
current #epochs=37, #steps=1440
start validation
acc: 0.751196
AUC: 0.887300
Avg Precision: 0.367610
Avg Recall: 1.000000
d_prime: 1.714443
train_loss: 0.420177
valid_loss: 1.154606
validation finished
normal learning rate scheduler step
Epoch-37 lr: 0.0001311078474642966
Epoch-37 lr: 0.0001311078474642966
epoch 37 training time: 15.362
---------------
2023-09-23 20:00:37.665665
current #epochs=38, #steps=1480
Epoch: [38][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00563	Train Loss 0.4169	
start validation
[I 2023-09-23 20:00:52,949] Trial 12 finished with value: 0.36635438111168295 and parameters: {'warmup': 'True', 'num_epochs': 38, 'batch_size': 25, 'lr-adaptschedule': 'False', 'lr': 0.0028539780433622223, 'head-lr': 1, 'lr-scheduler-start': 5, 'lr-scheduler-step': 4, 'lr-scheduler-decay': 0.7101549486395891}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.760766
AUC: 0.886486
Avg Precision: 0.366354
Avg Recall: 1.000000
d_prime: 1.708437
train_loss: 0.426959
valid_loss: 1.150224
validation finished
normal learning rate scheduler step
Epoch-38 lr: 0.0001311078474642966
Epoch-38 lr: 0.0001311078474642966
epoch 38 training time: 15.280
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 1 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0a698610>
The learning rate scheduler starts at 10 epoch with decay rate of 0.712 every 4 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 20:00:52.981176
current #epochs=1, #steps=0
start validation
acc: 0.775120
AUC: 0.852704
Avg Precision: 0.291587
Avg Recall: 1.000000
d_prime: 1.482237
train_loss: 0.697810
valid_loss: 1.195279
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0035040717742924185
Epoch-1 lr: 0.0035040717742924185
epoch 1 training time: 18.757
---------------
2023-09-23 20:01:11.738422
current #epochs=2, #steps=40
start validation
acc: 0.789474
AUC: 0.864834
Avg Precision: 0.336235
Avg Recall: 1.000000
d_prime: 1.558886
train_loss: 0.597930
valid_loss: 1.199506
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0035040717742924185
Epoch-2 lr: 0.0035040717742924185
epoch 2 training time: 17.564
---------------
2023-09-23 20:01:29.302639
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00557	Train Loss 0.4993	
start validation
acc: 0.746411
AUC: 0.854821
Avg Precision: 0.298965
Avg Recall: 1.000000
d_prime: 1.495298
train_loss: 0.492121
valid_loss: 1.180137
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0035040717742924185
Epoch-3 lr: 0.0035040717742924185
epoch 3 training time: 15.351
---------------
2023-09-23 20:01:44.653525
current #epochs=4, #steps=120
start validation
acc: 0.799043
AUC: 0.854782
Avg Precision: 0.359415
Avg Recall: 1.000000
d_prime: 1.495058
train_loss: 0.563378
valid_loss: 1.199160
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0035040717742924185
Epoch-4 lr: 0.0035040717742924185
epoch 4 training time: 17.908
---------------
2023-09-23 20:02:02.562192
current #epochs=5, #steps=160
start validation
acc: 0.760766
AUC: 0.821743
Avg Precision: 0.283470
Avg Recall: 1.000000
d_prime: 1.303947
train_loss: 0.580441
valid_loss: 1.203959
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0035040717742924185
Epoch-5 lr: 0.0035040717742924185
epoch 5 training time: 15.297
---------------
2023-09-23 20:02:17.859223
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04100	Per Sample Data Time 0.03054	Per Sample DNN Time 0.01045	Train Loss 0.5421	
start validation
acc: 0.779904
AUC: 0.855172
Avg Precision: 0.349021
Avg Recall: 1.000000
d_prime: 1.497476
train_loss: 0.573651
valid_loss: 1.192929
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0035040717742924185
Epoch-6 lr: 0.0035040717742924185
epoch 6 training time: 15.320
---------------
2023-09-23 20:02:33.179805
current #epochs=7, #steps=240
start validation
acc: 0.770335
AUC: 0.844856
Avg Precision: 0.287576
Avg Recall: 1.000000
d_prime: 1.434887
train_loss: 0.564172
valid_loss: 1.199587
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0035040717742924185
Epoch-7 lr: 0.0035040717742924185
epoch 7 training time: 15.370
---------------
2023-09-23 20:02:48.549312
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00712	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00557	Train Loss 0.5533	
start validation
acc: 0.760766
AUC: 0.843382
Avg Precision: 0.329025
Avg Recall: 1.000000
d_prime: 1.426174
train_loss: 0.557486
valid_loss: 1.196603
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0035040717742924185
Epoch-8 lr: 0.0035040717742924185
epoch 8 training time: 15.255
---------------
2023-09-23 20:03:03.804175
current #epochs=9, #steps=320
start validation
acc: 0.665072
AUC: 0.817112
Avg Precision: 0.302620
Avg Recall: 1.000000
d_prime: 1.279035
train_loss: 0.547125
valid_loss: 1.233259
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0035040717742924185
Epoch-9 lr: 0.0035040717742924185
epoch 9 training time: 15.205
---------------
2023-09-23 20:03:19.009490
current #epochs=10, #steps=360
start validation
acc: 0.755981
AUC: 0.885756
Avg Precision: 0.325297
Avg Recall: 1.000000
d_prime: 1.703083
train_loss: 0.560022
valid_loss: 1.172594
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0024937215854541122
Epoch-10 lr: 0.0024937215854541122
epoch 10 training time: 15.320
---------------
2023-09-23 20:03:34.329991
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03915	Per Sample Data Time 0.02903	Per Sample DNN Time 0.01012	Train Loss 0.6579	
start validation
acc: 0.765550
AUC: 0.849421
Avg Precision: 0.303668
Avg Recall: 1.000000
d_prime: 1.462228
train_loss: 0.515491
valid_loss: 1.174770
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0024937215854541122
Epoch-11 lr: 0.0024937215854541122
epoch 11 training time: 15.347
---------------
2023-09-23 20:03:49.676924
current #epochs=12, #steps=440
start validation
acc: 0.684211
AUC: 0.836044
Avg Precision: 0.294397
Avg Recall: 1.000000
d_prime: 1.383564
train_loss: 0.516294
valid_loss: 1.186033
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0024937215854541122
Epoch-12 lr: 0.0024937215854541122
epoch 12 training time: 15.417
---------------
2023-09-23 20:04:05.093583
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00726	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00566	Train Loss 0.5481	
start validation
acc: 0.751196
AUC: 0.882563
Avg Precision: 0.319345
Avg Recall: 1.000000
d_prime: 1.679941
train_loss: 0.514371
valid_loss: 1.172794
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0024937215854541122
Epoch-13 lr: 0.0024937215854541122
epoch 13 training time: 15.448
---------------
2023-09-23 20:04:20.541587
current #epochs=14, #steps=520
start validation
acc: 0.751196
AUC: 0.879462
Avg Precision: 0.369491
Avg Recall: 1.000000
d_prime: 1.657884
train_loss: 0.530918
valid_loss: 1.166530
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0017746917718360693
Epoch-14 lr: 0.0017746917718360693
epoch 14 training time: 15.308
---------------
2023-09-23 20:04:35.850240
current #epochs=15, #steps=560
start validation
acc: 0.727273
AUC: 0.872614
Avg Precision: 0.339795
Avg Recall: 1.000000
d_prime: 1.610558
train_loss: 0.529537
valid_loss: 1.182472
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0017746917718360693
Epoch-15 lr: 0.0017746917718360693
epoch 15 training time: 16.461
---------------
2023-09-23 20:04:52.310647
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04012	Per Sample Data Time 0.03029	Per Sample DNN Time 0.00983	Train Loss 0.7547	
start validation
acc: 0.775120
AUC: 0.848917
Avg Precision: 0.314273
Avg Recall: 1.000000
d_prime: 1.459187
train_loss: 0.484816
valid_loss: 1.176234
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0017746917718360693
Epoch-16 lr: 0.0017746917718360693
epoch 16 training time: 15.287
---------------
2023-09-23 20:05:07.598105
current #epochs=17, #steps=640
start validation
acc: 0.736842
AUC: 0.853678
Avg Precision: 0.304331
Avg Recall: 1.000000
d_prime: 1.488232
train_loss: 0.503061
valid_loss: 1.191018
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0017746917718360693
Epoch-17 lr: 0.0017746917718360693
epoch 17 training time: 15.331
---------------
2023-09-23 20:05:22.929386
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00727	Per Sample Data Time 0.00167	Per Sample DNN Time 0.00560	Train Loss 0.4994	
start validation
acc: 0.755981
AUC: 0.882537
Avg Precision: 0.306338
Avg Recall: 1.000000
d_prime: 1.679752
train_loss: 0.502805
valid_loss: 1.180942
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0012629841692809146
Epoch-18 lr: 0.0012629841692809146
epoch 18 training time: 16.050
---------------
2023-09-23 20:05:38.979288
current #epochs=19, #steps=720
start validation
acc: 0.717703
AUC: 0.884311
Avg Precision: 0.380745
Avg Recall: 1.000000
d_prime: 1.692555
train_loss: 0.518925
valid_loss: 1.185346
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0012629841692809146
Epoch-19 lr: 0.0012629841692809146
epoch 19 training time: 15.413
---------------
2023-09-23 20:05:54.391818
current #epochs=20, #steps=760
start validation
acc: 0.732057
AUC: 0.872473
Avg Precision: 0.305227
Avg Recall: 1.000000
d_prime: 1.609600
train_loss: 0.490241
valid_loss: 1.162163
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0012629841692809146
Epoch-20 lr: 0.0012629841692809146
epoch 20 training time: 15.274
---------------
2023-09-23 20:06:09.665684
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04146	Per Sample Data Time 0.03216	Per Sample DNN Time 0.00930	Train Loss 0.6815	
start validation
acc: 0.789474
AUC: 0.880923
Avg Precision: 0.307049
Avg Recall: 1.000000
d_prime: 1.668224
train_loss: 0.477205
valid_loss: 1.153160
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0012629841692809146
Epoch-21 lr: 0.0012629841692809146
epoch 21 training time: 15.429
---------------
2023-09-23 20:06:25.094379
current #epochs=22, #steps=840
start validation
acc: 0.760766
AUC: 0.839725
Avg Precision: 0.274186
Avg Recall: 1.000000
d_prime: 1.404777
train_loss: 0.452702
valid_loss: 1.173939
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0008988203118809221
Epoch-22 lr: 0.0008988203118809221
epoch 22 training time: 16.658
---------------
2023-09-23 20:06:41.752282
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00729	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00566	Train Loss 0.4478	
start validation
acc: 0.775120
AUC: 0.873139
Avg Precision: 0.312500
Avg Recall: 1.000000
d_prime: 1.614120
train_loss: 0.442145
valid_loss: 1.161459
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0008988203118809221
Epoch-23 lr: 0.0008988203118809221
epoch 23 training time: 15.403
---------------
2023-09-23 20:06:57.155530
current #epochs=24, #steps=920
start validation
acc: 0.765550
AUC: 0.868494
Avg Precision: 0.337648
Avg Recall: 1.000000
d_prime: 1.582931
train_loss: 0.411965
valid_loss: 1.170797
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0008988203118809221
Epoch-24 lr: 0.0008988203118809221
epoch 24 training time: 15.335
---------------
2023-09-23 20:07:12.490531
current #epochs=25, #steps=960
start validation
acc: 0.789474
AUC: 0.877777
Avg Precision: 0.311428
Avg Recall: 1.000000
d_prime: 1.646071
train_loss: 0.431520
valid_loss: 1.162905
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.0008988203118809221
Epoch-25 lr: 0.0008988203118809221
epoch 25 training time: 15.592
---------------
2023-09-23 20:07:28.083033
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.04159	Per Sample Data Time 0.03159	Per Sample DNN Time 0.01000	Train Loss 0.4403	
start validation
acc: 0.770335
AUC: 0.868806
Avg Precision: 0.305744
Avg Recall: 1.000000
d_prime: 1.585002
train_loss: 0.426958
valid_loss: 1.165080
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.0006396580200286174
Epoch-26 lr: 0.0006396580200286174
epoch 26 training time: 15.432
---------------
2023-09-23 20:07:43.514694
current #epochs=27, #steps=1040
start validation
acc: 0.755981
AUC: 0.879084
Avg Precision: 0.314693
Avg Recall: 1.000000
d_prime: 1.655225
train_loss: 0.431959
valid_loss: 1.159976
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.0006396580200286174
Epoch-27 lr: 0.0006396580200286174
epoch 27 training time: 15.349
---------------
2023-09-23 20:07:58.863671
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00564	Train Loss 0.4035	
start validation
acc: 0.789474
AUC: 0.885379
Avg Precision: 0.348605
Avg Recall: 1.000000
d_prime: 1.700326
train_loss: 0.415961
valid_loss: 1.151593
validation finished
normal learning rate scheduler step
Epoch-28 lr: 0.0006396580200286174
Epoch-28 lr: 0.0006396580200286174
epoch 28 training time: 15.385
---------------
2023-09-23 20:08:14.248398
current #epochs=29, #steps=1120
start validation
acc: 0.808612
AUC: 0.886926
Avg Precision: 0.324816
Avg Recall: 1.000000
d_prime: 1.711678
train_loss: 0.411547
valid_loss: 1.146105
validation finished
normal learning rate scheduler step
Epoch-29 lr: 0.0006396580200286174
Epoch-29 lr: 0.0006396580200286174
epoch 29 training time: 17.748
---------------
2023-09-23 20:08:31.996977
current #epochs=30, #steps=1160
start validation
acc: 0.784689
AUC: 0.850688
Avg Precision: 0.313227
Avg Recall: 1.000000
d_prime: 1.469918
train_loss: 0.449899
valid_loss: 1.171551
validation finished
normal learning rate scheduler step
Epoch-30 lr: 0.0004552215578336173
Epoch-30 lr: 0.0004552215578336173
epoch 30 training time: 17.464
---------------
2023-09-23 20:08:49.461288
current #epochs=31, #steps=1200
Epoch: [31][0/40]	Per Sample Total Time 0.04100	Per Sample Data Time 0.03089	Per Sample DNN Time 0.01011	Train Loss 0.3820	
start validation
acc: 0.775120
AUC: 0.867048
Avg Precision: 0.321589
Avg Recall: 1.000000
d_prime: 1.573373
train_loss: 0.412713
valid_loss: 1.154441
validation finished
normal learning rate scheduler step
Epoch-31 lr: 0.0004552215578336173
Epoch-31 lr: 0.0004552215578336173
epoch 31 training time: 15.304
---------------
2023-09-23 20:09:04.765498
current #epochs=32, #steps=1240
start validation
acc: 0.794258
AUC: 0.869572
Avg Precision: 0.308368
Avg Recall: 1.000000
d_prime: 1.590097
train_loss: 0.414760
valid_loss: 1.153298
validation finished
normal learning rate scheduler step
Epoch-32 lr: 0.0004552215578336173
Epoch-32 lr: 0.0004552215578336173
epoch 32 training time: 15.343
---------------
2023-09-23 20:09:20.108094
current #epochs=33, #steps=1280
Epoch: [33][20/40]	Per Sample Total Time 0.00714	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00556	Train Loss 0.3926	
start validation
acc: 0.765550
AUC: 0.870121
Avg Precision: 0.325118
Avg Recall: 1.000000
d_prime: 1.593767
train_loss: 0.393450
valid_loss: 1.164865
validation finished
normal learning rate scheduler step
Epoch-33 lr: 0.0004552215578336173
Epoch-33 lr: 0.0004552215578336173
epoch 33 training time: 15.319
---------------
2023-09-23 20:09:35.427032
current #epochs=34, #steps=1320
start validation
acc: 0.770335
AUC: 0.883169
Avg Precision: 0.317543
Avg Recall: 1.000000
d_prime: 1.684300
train_loss: 0.407448
valid_loss: 1.153768
validation finished
normal learning rate scheduler step
Epoch-34 lr: 0.0003239647752828837
Epoch-34 lr: 0.0003239647752828837
epoch 34 training time: 15.301
---------------
2023-09-23 20:09:50.727573
current #epochs=35, #steps=1360
start validation
acc: 0.775120
AUC: 0.884975
Avg Precision: 0.327153
Avg Recall: 1.000000
d_prime: 1.697384
train_loss: 0.387465
valid_loss: 1.146825
validation finished
normal learning rate scheduler step
Epoch-35 lr: 0.0003239647752828837
Epoch-35 lr: 0.0003239647752828837
epoch 35 training time: 15.533
---------------
2023-09-23 20:10:06.260802
current #epochs=36, #steps=1400
Epoch: [36][0/40]	Per Sample Total Time 0.03863	Per Sample Data Time 0.02906	Per Sample DNN Time 0.00958	Train Loss 0.3941	
start validation
acc: 0.770335
AUC: 0.883381
Avg Precision: 0.320304
Avg Recall: 1.000000
d_prime: 1.685826
train_loss: 0.386149
valid_loss: 1.144814
validation finished
normal learning rate scheduler step
Epoch-36 lr: 0.0003239647752828837
Epoch-36 lr: 0.0003239647752828837
epoch 36 training time: 15.213
---------------
2023-09-23 20:10:21.474408
current #epochs=37, #steps=1440
start validation
[I 2023-09-23 20:10:36,843] Trial 13 finished with value: 0.324818837085667 and parameters: {'warmup': 'True', 'num_epochs': 37, 'batch_size': 22, 'lr-adaptschedule': 'False', 'lr': 0.0035040717742924185, 'head-lr': 1, 'lr-scheduler-start': 10, 'lr-scheduler-step': 4, 'lr-scheduler-decay': 0.7116639572708732}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.775120
AUC: 0.878770
Avg Precision: 0.324819
Avg Recall: 1.000000
d_prime: 1.653016
train_loss: 0.400982
valid_loss: 1.146669
validation finished
normal learning rate scheduler step
Epoch-37 lr: 0.0003239647752828837
Epoch-37 lr: 0.0003239647752828837
epoch 37 training time: 15.365
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 1 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc52638ac0>
The learning rate scheduler starts at 6 epoch with decay rate of 0.809 every 4 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 20:10:36.875395
current #epochs=1, #steps=0
start validation
acc: 0.674641
AUC: 0.838498
Avg Precision: 0.295328
Avg Recall: 1.000000
d_prime: 1.397675
train_loss: 0.642417
valid_loss: 1.233475
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.004888778413304687
Epoch-1 lr: 0.004888778413304687
epoch 1 training time: 17.838
---------------
2023-09-23 20:10:54.713916
current #epochs=2, #steps=40
start validation
acc: 0.684211
AUC: 0.788357
Avg Precision: 0.266573
Avg Recall: 1.000000
d_prime: 1.132408
train_loss: 0.638592
valid_loss: 1.229592
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.004888778413304687
Epoch-2 lr: 0.004888778413304687
epoch 2 training time: 17.738
---------------
2023-09-23 20:11:12.452254
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00165	Per Sample DNN Time 0.00556	Train Loss 0.5812	
start validation
acc: 0.746411
AUC: 0.822388
Avg Precision: 0.295930
Avg Recall: 1.000000
d_prime: 1.307444
train_loss: 0.585894
valid_loss: 1.235238
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.004888778413304687
Epoch-3 lr: 0.004888778413304687
epoch 3 training time: 17.977
---------------
2023-09-23 20:11:30.428923
current #epochs=4, #steps=120
start validation
acc: 0.755981
AUC: 0.836248
Avg Precision: 0.278998
Avg Recall: 1.000000
d_prime: 1.384732
train_loss: 0.534693
valid_loss: 1.196322
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.004888778413304687
Epoch-4 lr: 0.004888778413304687
epoch 4 training time: 17.712
---------------
2023-09-23 20:11:48.140686
current #epochs=5, #steps=160
start validation
acc: 0.784689
AUC: 0.883107
Avg Precision: 0.304571
Avg Recall: 1.000000
d_prime: 1.683852
train_loss: 0.540753
valid_loss: 1.186419
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.004888778413304687
Epoch-5 lr: 0.004888778413304687
epoch 5 training time: 17.865
---------------
2023-09-23 20:12:06.005352
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03981	Per Sample Data Time 0.03243	Per Sample DNN Time 0.00738	Train Loss 0.5090	
start validation
acc: 0.741627
AUC: 0.854414
Avg Precision: 0.294213
Avg Recall: 1.000000
d_prime: 1.492780
train_loss: 0.547519
valid_loss: 1.206361
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.003955500544887539
Epoch-6 lr: 0.003955500544887539
epoch 6 training time: 16.073
---------------
2023-09-23 20:12:22.078624
current #epochs=7, #steps=240
start validation
acc: 0.708134
AUC: 0.837393
Avg Precision: 0.283181
Avg Recall: 1.000000
d_prime: 1.391306
train_loss: 0.527918
valid_loss: 1.199517
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.003955500544887539
Epoch-7 lr: 0.003955500544887539
epoch 7 training time: 15.278
---------------
2023-09-23 20:12:37.356956
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00713	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00553	Train Loss 0.5509	
start validation
acc: 0.684211
AUC: 0.872224
Avg Precision: 0.314592
Avg Recall: 1.000000
d_prime: 1.607918
train_loss: 0.541392
valid_loss: 1.217263
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.003955500544887539
Epoch-8 lr: 0.003955500544887539
epoch 8 training time: 15.221
---------------
2023-09-23 20:12:52.578482
current #epochs=9, #steps=320
start validation
acc: 0.784689
AUC: 0.874045
Avg Precision: 0.358080
Avg Recall: 1.000000
d_prime: 1.620297
train_loss: 0.542125
valid_loss: 1.169927
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.003955500544887539
Epoch-9 lr: 0.003955500544887539
epoch 9 training time: 15.411
---------------
2023-09-23 20:13:07.988859
current #epochs=10, #steps=360
start validation
acc: 0.755981
AUC: 0.848003
Avg Precision: 0.327165
Avg Recall: 1.000000
d_prime: 1.453681
train_loss: 0.586647
valid_loss: 1.202495
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0032003873438046344
Epoch-10 lr: 0.0032003873438046344
epoch 10 training time: 15.361
---------------
2023-09-23 20:13:23.350267
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03713	Per Sample Data Time 0.02954	Per Sample DNN Time 0.00758	Train Loss 0.6107	
start validation
acc: 0.775120
AUC: 0.858241
Avg Precision: 0.344711
Avg Recall: 1.000000
d_prime: 1.516672
train_loss: 0.496569
valid_loss: 1.176538
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0032003873438046344
Epoch-11 lr: 0.0032003873438046344
epoch 11 training time: 15.264
---------------
2023-09-23 20:13:38.614087
current #epochs=12, #steps=440
start validation
acc: 0.822967
AUC: 0.868350
Avg Precision: 0.318602
Avg Recall: 1.000000
d_prime: 1.581973
train_loss: 0.505341
valid_loss: 1.168442
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0032003873438046344
Epoch-12 lr: 0.0032003873438046344
epoch 12 training time: 17.825
---------------
2023-09-23 20:13:56.439205
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00563	Train Loss 0.4624	
start validation
acc: 0.813397
AUC: 0.869977
Avg Precision: 0.316159
Avg Recall: 1.000000
d_prime: 1.592807
train_loss: 0.496164
valid_loss: 1.172712
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0032003873438046344
Epoch-13 lr: 0.0032003873438046344
epoch 13 training time: 15.296
---------------
2023-09-23 20:14:11.735806
current #epochs=14, #steps=520
start validation
acc: 0.760766
AUC: 0.890080
Avg Precision: 0.343767
Avg Recall: 1.000000
d_prime: 1.735171
train_loss: 0.515296
valid_loss: 1.148955
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0025894268080997296
Epoch-14 lr: 0.0025894268080997296
epoch 14 training time: 15.417
---------------
2023-09-23 20:14:27.152506
current #epochs=15, #steps=560
start validation
acc: 0.779904
AUC: 0.873470
Avg Precision: 0.346806
Avg Recall: 1.000000
d_prime: 1.616374
train_loss: 0.474703
valid_loss: 1.161766
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0025894268080997296
Epoch-15 lr: 0.0025894268080997296
epoch 15 training time: 15.960
---------------
2023-09-23 20:14:43.112733
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03755	Per Sample Data Time 0.02989	Per Sample DNN Time 0.00766	Train Loss 0.3824	
start validation
acc: 0.799043
AUC: 0.883440
Avg Precision: 0.350938
Avg Recall: 1.000000
d_prime: 1.686253
train_loss: 0.496517
valid_loss: 1.147071
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0025894268080997296
Epoch-16 lr: 0.0025894268080997296
epoch 16 training time: 15.298
---------------
2023-09-23 20:14:58.410488
current #epochs=17, #steps=640
start validation
acc: 0.842105
AUC: 0.883312
Avg Precision: 0.355244
Avg Recall: 1.000000
d_prime: 1.685327
train_loss: 0.460748
valid_loss: 1.160390
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0025894268080997296
Epoch-17 lr: 0.0025894268080997296
epoch 17 training time: 18.701
---------------
2023-09-23 20:15:17.111364
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00563	Train Loss 0.4303	
start validation
acc: 0.818182
AUC: 0.871718
Avg Precision: 0.324515
Avg Recall: 1.000000
d_prime: 1.604495
train_loss: 0.457435
valid_loss: 1.151952
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0020950998970438576
Epoch-18 lr: 0.0020950998970438576
epoch 18 training time: 15.372
---------------
2023-09-23 20:15:32.483934
current #epochs=19, #steps=720
start validation
acc: 0.779904
AUC: 0.862567
Avg Precision: 0.307646
Avg Recall: 1.000000
d_prime: 1.544216
train_loss: 0.432358
valid_loss: 1.160378
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0020950998970438576
Epoch-19 lr: 0.0020950998970438576
epoch 19 training time: 15.289
---------------
2023-09-23 20:15:47.773020
current #epochs=20, #steps=760
start validation
acc: 0.765550
AUC: 0.882602
Avg Precision: 0.334204
Avg Recall: 1.000000
d_prime: 1.680221
train_loss: 0.436019
valid_loss: 1.166782
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0020950998970438576
Epoch-20 lr: 0.0020950998970438576
epoch 20 training time: 15.259
---------------
2023-09-23 20:16:03.031990
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03736	Per Sample Data Time 0.02978	Per Sample DNN Time 0.00758	Train Loss 0.3341	
start validation
acc: 0.794258
AUC: 0.884160
Avg Precision: 0.370704
Avg Recall: 1.000000
d_prime: 1.691458
train_loss: 0.441776
valid_loss: 1.154303
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0020950998970438576
Epoch-21 lr: 0.0020950998970438576
epoch 21 training time: 15.349
---------------
2023-09-23 20:16:18.381202
current #epochs=22, #steps=840
start validation
acc: 0.827751
AUC: 0.884627
Avg Precision: 0.310806
Avg Recall: 1.000000
d_prime: 1.694851
train_loss: 0.411985
valid_loss: 1.142755
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0016951410114636177
Epoch-22 lr: 0.0016951410114636177
epoch 22 training time: 15.058
---------------
2023-09-23 20:16:33.439146
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00153	Per Sample DNN Time 0.00564	Train Loss 0.4011	
start validation
acc: 0.818182
AUC: 0.878676
Avg Precision: 0.347135
Avg Recall: 1.000000
d_prime: 1.652361
train_loss: 0.424499
valid_loss: 1.154831
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0016951410114636177
Epoch-23 lr: 0.0016951410114636177
epoch 23 training time: 15.267
---------------
2023-09-23 20:16:48.705727
current #epochs=24, #steps=920
start validation
acc: 0.794258
AUC: 0.876050
Avg Precision: 0.312870
Avg Recall: 1.000000
d_prime: 1.634076
train_loss: 0.404891
valid_loss: 1.138718
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0016951410114636177
Epoch-24 lr: 0.0016951410114636177
epoch 24 training time: 15.372
---------------
2023-09-23 20:17:04.077501
current #epochs=25, #steps=960
start validation
acc: 0.789474
AUC: 0.851142
Avg Precision: 0.373429
Avg Recall: 1.000000
d_prime: 1.472683
train_loss: 0.407922
valid_loss: 1.159466
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.0016951410114636177
Epoch-25 lr: 0.0016951410114636177
epoch 25 training time: 15.353
---------------
2023-09-23 20:17:19.430610
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.04125	Per Sample Data Time 0.03105	Per Sample DNN Time 0.01020	Train Loss 0.4168	
start validation
acc: 0.813397
AUC: 0.868292
Avg Precision: 0.348102
Avg Recall: 1.000000
d_prime: 1.581591
train_loss: 0.410021
valid_loss: 1.143471
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.0013715351009278124
Epoch-26 lr: 0.0013715351009278124
epoch 26 training time: 16.566
---------------
2023-09-23 20:17:35.996323
current #epochs=27, #steps=1040
start validation
acc: 0.755981
AUC: 0.847823
Avg Precision: 0.313882
Avg Recall: 1.000000
d_prime: 1.452595
train_loss: 0.413964
valid_loss: 1.173911
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.0013715351009278124
Epoch-27 lr: 0.0013715351009278124
epoch 27 training time: 15.314
---------------
2023-09-23 20:17:51.310862
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00562	Train Loss 0.3737	
start validation
acc: 0.808612
AUC: 0.889876
Avg Precision: 0.347192
Avg Recall: 1.000000
d_prime: 1.733637
train_loss: 0.392011
valid_loss: 1.142444
validation finished
normal learning rate scheduler step
Epoch-28 lr: 0.0013715351009278124
Epoch-28 lr: 0.0013715351009278124
epoch 28 training time: 16.228
---------------
2023-09-23 20:18:07.539437
current #epochs=29, #steps=1120
start validation
acc: 0.808612
AUC: 0.887279
Avg Precision: 0.307899
Avg Recall: 1.000000
d_prime: 1.714287
train_loss: 0.396029
valid_loss: 1.143660
validation finished
normal learning rate scheduler step
Epoch-29 lr: 0.0013715351009278124
Epoch-29 lr: 0.0013715351009278124
epoch 29 training time: 15.249
---------------
2023-09-23 20:18:22.787995
current #epochs=30, #steps=1160
start validation
acc: 0.765550
AUC: 0.859521
Avg Precision: 0.304319
Avg Recall: 1.000000
d_prime: 1.524761
train_loss: 0.379308
valid_loss: 1.178326
validation finished
normal learning rate scheduler step
Epoch-30 lr: 0.0011097062252377924
Epoch-30 lr: 0.0011097062252377924
epoch 30 training time: 15.320
---------------
2023-09-23 20:18:38.107774
current #epochs=31, #steps=1200
Epoch: [31][0/40]	Per Sample Total Time 0.03976	Per Sample Data Time 0.03012	Per Sample DNN Time 0.00965	Train Loss 0.2899	
start validation
acc: 0.813397
AUC: 0.881219
Avg Precision: 0.331040
Avg Recall: 1.000000
d_prime: 1.670335
train_loss: 0.398633
valid_loss: 1.151986
validation finished
normal learning rate scheduler step
Epoch-31 lr: 0.0011097062252377924
Epoch-31 lr: 0.0011097062252377924
epoch 31 training time: 15.313
---------------
2023-09-23 20:18:53.420943
current #epochs=32, #steps=1240
start validation
acc: 0.808612
AUC: 0.867995
Avg Precision: 0.343775
Avg Recall: 1.000000
d_prime: 1.579622
train_loss: 0.356215
valid_loss: 1.148808
validation finished
normal learning rate scheduler step
Epoch-32 lr: 0.0011097062252377924
Epoch-32 lr: 0.0011097062252377924
epoch 32 training time: 15.438
---------------
2023-09-23 20:19:08.859188
current #epochs=33, #steps=1280
Epoch: [33][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00561	Train Loss 0.3778	
start validation
acc: 0.818182
AUC: 0.889104
Avg Precision: 0.360463
Avg Recall: 1.000000
d_prime: 1.727854
train_loss: 0.381184
valid_loss: 1.149268
validation finished
normal learning rate scheduler step
Epoch-33 lr: 0.0011097062252377924
Epoch-33 lr: 0.0011097062252377924
epoch 33 training time: 15.342
---------------
2023-09-23 20:19:24.201427
current #epochs=34, #steps=1320
start validation
acc: 0.808612
AUC: 0.866209
Avg Precision: 0.326879
Avg Recall: 1.000000
d_prime: 1.567868
train_loss: 0.380854
valid_loss: 1.158230
validation finished
normal learning rate scheduler step
Epoch-34 lr: 0.0008978610212005974
Epoch-34 lr: 0.0008978610212005974
epoch 34 training time: 15.370
---------------
2023-09-23 20:19:39.571044
current #epochs=35, #steps=1360
start validation
acc: 0.803828
AUC: 0.887589
Avg Precision: 0.332309
Avg Recall: 1.000000
d_prime: 1.716583
train_loss: 0.353865
valid_loss: 1.136416
validation finished
normal learning rate scheduler step
Epoch-35 lr: 0.0008978610212005974
Epoch-35 lr: 0.0008978610212005974
epoch 35 training time: 15.322
---------------
2023-09-23 20:19:54.893003
current #epochs=36, #steps=1400
Epoch: [36][0/40]	Per Sample Total Time 0.04045	Per Sample Data Time 0.03069	Per Sample DNN Time 0.00976	Train Loss 0.3712	
start validation
acc: 0.784689
AUC: 0.878657
Avg Precision: 0.326710
Avg Recall: 1.000000
d_prime: 1.652224
train_loss: 0.359140
valid_loss: 1.152114
validation finished
normal learning rate scheduler step
Epoch-36 lr: 0.0008978610212005974
Epoch-36 lr: 0.0008978610212005974
epoch 36 training time: 15.449
---------------
2023-09-23 20:20:10.342001
current #epochs=37, #steps=1440
start validation
acc: 0.822967
AUC: 0.874132
Avg Precision: 0.362797
Avg Recall: 1.000000
d_prime: 1.620894
train_loss: 0.354289
valid_loss: 1.150313
validation finished
normal learning rate scheduler step
Epoch-37 lr: 0.0008978610212005974
Epoch-37 lr: 0.0008978610212005974
epoch 37 training time: 15.798
---------------
2023-09-23 20:20:26.140330
current #epochs=38, #steps=1480
Epoch: [38][20/40]	Per Sample Total Time 0.00727	Per Sample Data Time 0.00164	Per Sample DNN Time 0.00563	Train Loss 0.3463	
start validation
acc: 0.818182
AUC: 0.861118
Avg Precision: 0.292854
Avg Recall: 1.000000
d_prime: 1.534927
train_loss: 0.363552
valid_loss: 1.142452
validation finished
normal learning rate scheduler step
Epoch-38 lr: 0.000726457502947353
Epoch-38 lr: 0.000726457502947353
epoch 38 training time: 15.397
---------------
2023-09-23 20:20:41.536741
current #epochs=39, #steps=1520
start validation
acc: 0.822967
AUC: 0.870060
Avg Precision: 0.311400
Avg Recall: 1.000000
d_prime: 1.593360
train_loss: 0.359727
valid_loss: 1.146865
validation finished
normal learning rate scheduler step
Epoch-39 lr: 0.000726457502947353
Epoch-39 lr: 0.000726457502947353
epoch 39 training time: 15.279
---------------
2023-09-23 20:20:56.815458
current #epochs=40, #steps=1560
start validation
[I 2023-09-23 20:21:12,242] Trial 14 finished with value: 0.31627343698422133 and parameters: {'warmup': 'True', 'num_epochs': 40, 'batch_size': 26, 'lr-adaptschedule': 'False', 'lr': 0.004888778413304687, 'head-lr': 1, 'lr-scheduler-start': 6, 'lr-scheduler-step': 4, 'lr-scheduler-decay': 0.8090979403203763}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.808612
AUC: 0.869917
Avg Precision: 0.316273
Avg Recall: 1.000000
d_prime: 1.592403
train_loss: 0.395044
valid_loss: 1.157390
validation finished
normal learning rate scheduler step
Epoch-40 lr: 0.000726457502947353
Epoch-40 lr: 0.000726457502947353
epoch 40 training time: 15.422
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 5 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0a698df0>
The learning rate scheduler starts at 4 epoch with decay rate of 0.708 every 5 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 20:21:12.275467
current #epochs=1, #steps=0
start validation
acc: 0.760766
AUC: 0.858232
Avg Precision: 0.315252
Avg Recall: 1.000000
d_prime: 1.516615
train_loss: 0.457894
valid_loss: 1.185534
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0026971118208677174
Epoch-1 lr: 0.013485559104338588
epoch 1 training time: 17.714
---------------
2023-09-23 20:21:29.989841
current #epochs=2, #steps=40
start validation
acc: 0.770335
AUC: 0.865894
Avg Precision: 0.316170
Avg Recall: 1.000000
d_prime: 1.565803
train_loss: 0.410834
valid_loss: 1.153125
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0026971118208677174
Epoch-2 lr: 0.013485559104338588
epoch 2 training time: 17.836
---------------
2023-09-23 20:21:47.825536
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00167	Per Sample DNN Time 0.00553	Train Loss 0.3851	
start validation
acc: 0.842105
AUC: 0.863899
Avg Precision: 0.341664
Avg Recall: 1.000000
d_prime: 1.552816
train_loss: 0.398359
valid_loss: 1.150239
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0026971118208677174
Epoch-3 lr: 0.013485559104338588
epoch 3 training time: 17.833
---------------
2023-09-23 20:22:05.658550
current #epochs=4, #steps=120
start validation
acc: 0.775120
AUC: 0.871376
Avg Precision: 0.367246
Avg Recall: 1.000000
d_prime: 1.602192
train_loss: 0.408859
valid_loss: 1.163508
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0019093449168116144
Epoch-4 lr: 0.009546724584058072
epoch 4 training time: 15.274
---------------
2023-09-23 20:22:20.932396
current #epochs=5, #steps=160
start validation
acc: 0.779904
AUC: 0.864565
Avg Precision: 0.330113
Avg Recall: 1.000000
d_prime: 1.557137
train_loss: 0.435644
valid_loss: 1.152719
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0019093449168116144
Epoch-5 lr: 0.009546724584058072
epoch 5 training time: 16.042
---------------
2023-09-23 20:22:36.975005
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04201	Per Sample Data Time 0.03219	Per Sample DNN Time 0.00982	Train Loss 0.3764	
start validation
acc: 0.837321
AUC: 0.858908
Avg Precision: 0.371347
Avg Recall: 1.000000
d_prime: 1.520881
train_loss: 0.393125
valid_loss: 1.144955
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0019093449168116144
Epoch-6 lr: 0.009546724584058072
epoch 6 training time: 15.378
---------------
2023-09-23 20:22:52.352817
current #epochs=7, #steps=240
start validation
acc: 0.794258
AUC: 0.862490
Avg Precision: 0.344086
Avg Recall: 1.000000
d_prime: 1.543719
train_loss: 0.374252
valid_loss: 1.155569
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0019093449168116144
Epoch-7 lr: 0.009546724584058072
epoch 7 training time: 15.343
---------------
2023-09-23 20:23:07.695992
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00711	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00553	Train Loss 0.3727	
start validation
acc: 0.837321
AUC: 0.855556
Avg Precision: 0.305909
Avg Recall: 1.000000
d_prime: 1.499862
train_loss: 0.370075
valid_loss: 1.160774
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0019093449168116144
Epoch-8 lr: 0.009546724584058072
epoch 8 training time: 15.232
---------------
2023-09-23 20:23:22.927578
current #epochs=9, #steps=320
start validation
acc: 0.794258
AUC: 0.872739
Avg Precision: 0.331760
Avg Recall: 1.000000
d_prime: 1.611404
train_loss: 0.344367
valid_loss: 1.139753
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0013516673588199564
Epoch-9 lr: 0.006758336794099782
epoch 9 training time: 15.403
---------------
2023-09-23 20:23:38.330908
current #epochs=10, #steps=360
start validation
acc: 0.832536
AUC: 0.865764
Avg Precision: 0.330875
Avg Recall: 1.000000
d_prime: 1.564953
train_loss: 0.362229
valid_loss: 1.151442
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0013516673588199564
Epoch-10 lr: 0.006758336794099782
epoch 10 training time: 15.321
---------------
2023-09-23 20:23:53.652023
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03913	Per Sample Data Time 0.02903	Per Sample DNN Time 0.01010	Train Loss 0.4401	
start validation
acc: 0.808612
AUC: 0.866388
Avg Precision: 0.326990
Avg Recall: 1.000000
d_prime: 1.569042
train_loss: 0.381534
valid_loss: 1.152661
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0013516673588199564
Epoch-11 lr: 0.006758336794099782
epoch 11 training time: 15.306
---------------
2023-09-23 20:24:08.958201
current #epochs=12, #steps=440
start validation
acc: 0.803828
AUC: 0.855072
Avg Precision: 0.323870
Avg Recall: 1.000000
d_prime: 1.496855
train_loss: 0.345340
valid_loss: 1.151299
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0013516673588199564
Epoch-12 lr: 0.006758336794099782
epoch 12 training time: 15.927
---------------
2023-09-23 20:24:24.884974
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00727	Per Sample Data Time 0.00164	Per Sample DNN Time 0.00563	Train Loss 0.3044	
start validation
acc: 0.803828
AUC: 0.880786
Avg Precision: 0.318804
Avg Recall: 1.000000
d_prime: 1.667249
train_loss: 0.331367
valid_loss: 1.130071
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0013516673588199564
Epoch-13 lr: 0.006758336794099782
epoch 13 training time: 15.452
---------------
2023-09-23 20:24:40.336591
current #epochs=14, #steps=520
start validation
acc: 0.808612
AUC: 0.859947
Avg Precision: 0.300733
Avg Recall: 1.000000
d_prime: 1.527465
train_loss: 0.320909
valid_loss: 1.153354
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0009568751213113466
Epoch-14 lr: 0.004784375606556733
epoch 14 training time: 15.282
---------------
2023-09-23 20:24:55.618460
current #epochs=15, #steps=560
start validation
acc: 0.832536
AUC: 0.872902
Avg Precision: 0.321934
Avg Recall: 1.000000
d_prime: 1.612512
train_loss: 0.354871
valid_loss: 1.145035
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0009568751213113466
Epoch-15 lr: 0.004784375606556733
epoch 15 training time: 15.475
---------------
2023-09-23 20:25:11.093814
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04100	Per Sample Data Time 0.03107	Per Sample DNN Time 0.00994	Train Loss 0.2682	
start validation
acc: 0.846890
AUC: 0.877484
Avg Precision: 0.341555
Avg Recall: 1.000000
d_prime: 1.644023
train_loss: 0.332514
valid_loss: 1.119339
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0009568751213113466
Epoch-16 lr: 0.004784375606556733
epoch 16 training time: 17.888
---------------
2023-09-23 20:25:28.981717
current #epochs=17, #steps=640
start validation
acc: 0.856459
AUC: 0.864889
Avg Precision: 0.334306
Avg Recall: 1.000000
d_prime: 1.559245
train_loss: 0.330046
valid_loss: 1.144165
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0009568751213113466
Epoch-17 lr: 0.004784375606556733
epoch 17 training time: 17.730
---------------
2023-09-23 20:25:46.711643
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00556	Train Loss 0.3261	
start validation
acc: 0.837321
AUC: 0.864823
Avg Precision: 0.336039
Avg Recall: 1.000000
d_prime: 1.558815
train_loss: 0.330842
valid_loss: 1.146649
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0009568751213113466
Epoch-18 lr: 0.004784375606556733
epoch 18 training time: 15.375
---------------
2023-09-23 20:26:02.086776
current #epochs=19, #steps=720
start validation
acc: 0.827751
AUC: 0.850230
Avg Precision: 0.311606
Avg Recall: 1.000000
d_prime: 1.467134
train_loss: 0.313184
valid_loss: 1.151136
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0006773929930393212
Epoch-19 lr: 0.003386964965196606
epoch 19 training time: 15.238
---------------
2023-09-23 20:26:17.324701
current #epochs=20, #steps=760
start validation
acc: 0.851675
AUC: 0.861011
Avg Precision: 0.331871
Avg Recall: 1.000000
d_prime: 1.534243
train_loss: 0.307347
valid_loss: 1.135141
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0006773929930393212
Epoch-20 lr: 0.003386964965196606
epoch 20 training time: 15.339
---------------
2023-09-23 20:26:32.663600
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04064	Per Sample Data Time 0.03099	Per Sample DNN Time 0.00965	Train Loss 0.2519	
start validation
acc: 0.837321
AUC: 0.852959
Avg Precision: 0.310185
Avg Recall: 1.000000
d_prime: 1.483804
train_loss: 0.311372
valid_loss: 1.149928
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0006773929930393212
Epoch-21 lr: 0.003386964965196606
epoch 21 training time: 15.384
---------------
2023-09-23 20:26:48.047398
current #epochs=22, #steps=840
start validation
acc: 0.837321
AUC: 0.856943
Avg Precision: 0.328207
Avg Recall: 1.000000
d_prime: 1.508521
train_loss: 0.288760
valid_loss: 1.146323
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0006773929930393212
Epoch-22 lr: 0.003386964965196606
epoch 22 training time: 15.378
---------------
2023-09-23 20:27:03.425809
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00561	Train Loss 0.3140	
start validation
acc: 0.842105
AUC: 0.856824
Avg Precision: 0.340110
Avg Recall: 1.000000
d_prime: 1.507778
train_loss: 0.292775
valid_loss: 1.129633
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0006773929930393212
Epoch-23 lr: 0.003386964965196606
epoch 23 training time: 15.246
---------------
2023-09-23 20:27:18.671771
current #epochs=24, #steps=920
start validation
acc: 0.822967
AUC: 0.855692
Avg Precision: 0.333694
Avg Recall: 1.000000
d_prime: 1.500708
train_loss: 0.307123
valid_loss: 1.145579
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.00047954143314952617
Epoch-24 lr: 0.0023977071657476307
epoch 24 training time: 15.306
---------------
2023-09-23 20:27:33.977948
current #epochs=25, #steps=960
start validation
acc: 0.818182
AUC: 0.840490
Avg Precision: 0.297671
Avg Recall: 1.000000
d_prime: 1.409228
train_loss: 0.306710
valid_loss: 1.168390
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.00047954143314952617
Epoch-25 lr: 0.0023977071657476307
epoch 25 training time: 15.510
---------------
2023-09-23 20:27:49.487691
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.04132	Per Sample Data Time 0.03108	Per Sample DNN Time 0.01024	Train Loss 0.2416	
start validation
acc: 0.861244
AUC: 0.855761
Avg Precision: 0.314080
Avg Recall: 1.000000
d_prime: 1.501142
train_loss: 0.293782
valid_loss: 1.149586
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.00047954143314952617
Epoch-26 lr: 0.0023977071657476307
epoch 26 training time: 18.478
---------------
2023-09-23 20:28:07.965445
current #epochs=27, #steps=1040
start validation
acc: 0.813397
AUC: 0.856711
Avg Precision: 0.300635
Avg Recall: 1.000000
d_prime: 1.507072
train_loss: 0.294320
valid_loss: 1.161217
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.00047954143314952617
Epoch-27 lr: 0.0023977071657476307
epoch 27 training time: 15.412
---------------
2023-09-23 20:28:23.377174
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00559	Train Loss 0.2773	
start validation
acc: 0.842105
AUC: 0.850124
Avg Precision: 0.303137
Avg Recall: 1.000000
d_prime: 1.466493
train_loss: 0.296406
valid_loss: 1.159089
validation finished
normal learning rate scheduler step
Epoch-28 lr: 0.00047954143314952617
Epoch-28 lr: 0.0023977071657476307
epoch 28 training time: 15.289
---------------
2023-09-23 20:28:38.666395
current #epochs=29, #steps=1120
start validation
acc: 0.827751
AUC: 0.850876
Avg Precision: 0.310512
Avg Recall: 1.000000
d_prime: 1.471063
train_loss: 0.270656
valid_loss: 1.150599
validation finished
normal learning rate scheduler step
Epoch-29 lr: 0.00033947795219333305
Epoch-29 lr: 0.0016973897609666652
epoch 29 training time: 15.404
---------------
2023-09-23 20:28:54.070250
current #epochs=30, #steps=1160
start validation
acc: 0.842105
AUC: 0.857629
Avg Precision: 0.314582
Avg Recall: 1.000000
d_prime: 1.512824
train_loss: 0.248363
valid_loss: 1.145200
validation finished
normal learning rate scheduler step
Epoch-30 lr: 0.00033947795219333305
Epoch-30 lr: 0.0016973897609666652
epoch 30 training time: 15.246
---------------
2023-09-23 20:29:09.316024
current #epochs=31, #steps=1200
Epoch: [31][0/40]	Per Sample Total Time 0.03727	Per Sample Data Time 0.02967	Per Sample DNN Time 0.00760	Train Loss 0.2400	
start validation
acc: 0.846890
AUC: 0.857052
Avg Precision: 0.309496
Avg Recall: 1.000000
d_prime: 1.509206
train_loss: 0.260670
valid_loss: 1.148540
validation finished
normal learning rate scheduler step
Epoch-31 lr: 0.00033947795219333305
Epoch-31 lr: 0.0016973897609666652
epoch 31 training time: 15.211
---------------
2023-09-23 20:29:24.527107
current #epochs=32, #steps=1240
start validation
acc: 0.832536
AUC: 0.855953
Avg Precision: 0.305392
Avg Recall: 1.000000
d_prime: 1.502334
train_loss: 0.293686
valid_loss: 1.155694
validation finished
normal learning rate scheduler step
Epoch-32 lr: 0.00033947795219333305
Epoch-32 lr: 0.0016973897609666652
epoch 32 training time: 15.341
---------------
2023-09-23 20:29:39.868042
current #epochs=33, #steps=1280
Epoch: [33][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00564	Train Loss 0.2571	
start validation
acc: 0.837321
AUC: 0.859695
Avg Precision: 0.305880
Avg Recall: 1.000000
d_prime: 1.525865
train_loss: 0.265004
valid_loss: 1.151138
validation finished
normal learning rate scheduler step
Epoch-33 lr: 0.00033947795219333305
Epoch-33 lr: 0.0016973897609666652
epoch 33 training time: 15.406
---------------
2023-09-23 20:29:55.274163
current #epochs=34, #steps=1320
start validation
acc: 0.842105
AUC: 0.866851
Avg Precision: 0.312894
Avg Recall: 1.000000
d_prime: 1.572077
train_loss: 0.256833
valid_loss: 1.147131
validation finished
normal learning rate scheduler step
Epoch-34 lr: 0.00024032392627363277
Epoch-34 lr: 0.0012016196313681638
epoch 34 training time: 15.330
---------------
2023-09-23 20:30:10.603987
current #epochs=35, #steps=1360
start validation
acc: 0.846890
AUC: 0.857381
Avg Precision: 0.315054
Avg Recall: 1.000000
d_prime: 1.511265
train_loss: 0.278847
valid_loss: 1.141812
validation finished
normal learning rate scheduler step
Epoch-35 lr: 0.00024032392627363277
Epoch-35 lr: 0.0012016196313681638
epoch 35 training time: 15.301
---------------
2023-09-23 20:30:25.904617
current #epochs=36, #steps=1400
Epoch: [36][0/40]	Per Sample Total Time 0.04173	Per Sample Data Time 0.03227	Per Sample DNN Time 0.00946	Train Loss 0.5685	
start validation
acc: 0.842105
AUC: 0.847781
Avg Precision: 0.310770
Avg Recall: 1.000000
d_prime: 1.452342
train_loss: 0.258426
valid_loss: 1.151498
validation finished
normal learning rate scheduler step
Epoch-36 lr: 0.00024032392627363277
Epoch-36 lr: 0.0012016196313681638
epoch 36 training time: 15.430
---------------
2023-09-23 20:30:41.334518
current #epochs=37, #steps=1440
start validation
acc: 0.832536
AUC: 0.846495
Avg Precision: 0.309894
Avg Recall: 1.000000
d_prime: 1.444644
train_loss: 0.254876
valid_loss: 1.150294
validation finished
normal learning rate scheduler step
Epoch-37 lr: 0.00024032392627363277
Epoch-37 lr: 0.0012016196313681638
epoch 37 training time: 15.443
---------------
2023-09-23 20:30:56.777808
current #epochs=38, #steps=1480
Epoch: [38][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00562	Train Loss 0.2654	
start validation
acc: 0.837321
AUC: 0.859044
Avg Precision: 0.311885
Avg Recall: 1.000000
d_prime: 1.521739
train_loss: 0.262069
valid_loss: 1.142953
validation finished
normal learning rate scheduler step
Epoch-38 lr: 0.00024032392627363277
Epoch-38 lr: 0.0012016196313681638
epoch 38 training time: 15.367
---------------
2023-09-23 20:31:12.144772
current #epochs=39, #steps=1520
start validation
acc: 0.842105
AUC: 0.860428
Avg Precision: 0.320485
Avg Recall: 1.000000
d_prime: 1.530523
train_loss: 0.250321
valid_loss: 1.134841
validation finished
normal learning rate scheduler step
Epoch-39 lr: 0.0001701306054382071
Epoch-39 lr: 0.0008506530271910355
epoch 39 training time: 15.316
---------------
2023-09-23 20:31:27.460875
current #epochs=40, #steps=1560
start validation
acc: 0.846890
AUC: 0.853557
Avg Precision: 0.317788
Avg Recall: 1.000000
d_prime: 1.487487
train_loss: 0.229942
valid_loss: 1.142095
validation finished
normal learning rate scheduler step
Epoch-40 lr: 0.0001701306054382071
Epoch-40 lr: 0.0008506530271910355
epoch 40 training time: 15.342
---------------
2023-09-23 20:31:42.802325
current #epochs=41, #steps=1600
Epoch: [41][0/40]	Per Sample Total Time 0.03996	Per Sample Data Time 0.03030	Per Sample DNN Time 0.00966	Train Loss 0.4139	
start validation
acc: 0.846890
AUC: 0.854860
Avg Precision: 0.309957
Avg Recall: 1.000000
d_prime: 1.495542
train_loss: 0.229441
valid_loss: 1.145946
validation finished
normal learning rate scheduler step
Epoch-41 lr: 0.0001701306054382071
Epoch-41 lr: 0.0008506530271910355
epoch 41 training time: 15.856
---------------
2023-09-23 20:31:58.658772
current #epochs=42, #steps=1640
start validation
acc: 0.837321
AUC: 0.850608
Avg Precision: 0.310547
Avg Recall: 1.000000
d_prime: 1.469432
train_loss: 0.245738
valid_loss: 1.149853
validation finished
normal learning rate scheduler step
Epoch-42 lr: 0.0001701306054382071
Epoch-42 lr: 0.0008506530271910355
epoch 42 training time: 15.968
---------------
2023-09-23 20:32:14.626951
current #epochs=43, #steps=1680
Epoch: [43][20/40]	Per Sample Total Time 0.00727	Per Sample Data Time 0.00169	Per Sample DNN Time 0.00558	Train Loss 0.2284	
start validation
acc: 0.837321
AUC: 0.849399
Avg Precision: 0.307480
Avg Recall: 1.000000
d_prime: 1.462096
train_loss: 0.249226
valid_loss: 1.151042
validation finished
normal learning rate scheduler step
Epoch-43 lr: 0.0001701306054382071
Epoch-43 lr: 0.0008506530271910355
epoch 43 training time: 15.380
---------------
2023-09-23 20:32:30.006863
current #epochs=44, #steps=1720
start validation
acc: 0.837321
AUC: 0.858027
Avg Precision: 0.318648
Avg Recall: 1.000000
d_prime: 1.515328
train_loss: 0.237258
valid_loss: 1.138715
validation finished
normal learning rate scheduler step
Epoch-44 lr: 0.00012043920618130544
Epoch-44 lr: 0.0006021960309065272
epoch 44 training time: 15.266
---------------
2023-09-23 20:32:45.273041
current #epochs=45, #steps=1760
start validation
acc: 0.832536
AUC: 0.849872
Avg Precision: 0.313170
Avg Recall: 1.000000
d_prime: 1.464960
train_loss: 0.240806
valid_loss: 1.148283
validation finished
normal learning rate scheduler step
Epoch-45 lr: 0.00012043920618130544
Epoch-45 lr: 0.0006021960309065272
epoch 45 training time: 15.277
---------------
2023-09-23 20:33:00.550225
current #epochs=46, #steps=1800
Epoch: [46][0/40]	Per Sample Total Time 0.04079	Per Sample Data Time 0.03045	Per Sample DNN Time 0.01034	Train Loss 0.2459	
start validation
acc: 0.842105
AUC: 0.857882
Avg Precision: 0.320649
Avg Recall: 1.000000
d_prime: 1.514413
train_loss: 0.243026
valid_loss: 1.140504
validation finished
normal learning rate scheduler step
Epoch-46 lr: 0.00012043920618130544
Epoch-46 lr: 0.0006021960309065272
epoch 46 training time: 15.290
---------------
2023-09-23 20:33:15.840406
current #epochs=47, #steps=1840
start validation
[I 2023-09-23 20:33:31,183] Trial 15 finished with value: 0.31308138837942484 and parameters: {'warmup': 'True', 'num_epochs': 47, 'batch_size': 18, 'lr-adaptschedule': 'False', 'lr': 0.0026971118208677174, 'head-lr': 5, 'lr-scheduler-start': 4, 'lr-scheduler-step': 5, 'lr-scheduler-decay': 0.7079220453667873}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.832536
AUC: 0.853777
Avg Precision: 0.313081
Avg Recall: 1.000000
d_prime: 1.488846
train_loss: 0.242511
valid_loss: 1.146923
validation finished
normal learning rate scheduler step
Epoch-47 lr: 0.00012043920618130544
Epoch-47 lr: 0.0006021960309065272
epoch 47 training time: 15.338
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51dcdc70>
The learning rate scheduler starts at 6 epoch with decay rate of 0.815 every 3 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 20:33:31.215077
current #epochs=1, #steps=0
start validation
acc: 0.751196
AUC: 0.831662
Avg Precision: 0.309052
Avg Recall: 1.000000
d_prime: 1.358709
train_loss: 0.430012
valid_loss: 1.193174
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0021504165290479396
Epoch-1 lr: 0.006451249587143819
epoch 1 training time: 17.787
---------------
2023-09-23 20:33:49.002598
current #epochs=2, #steps=40
start validation
acc: 0.789474
AUC: 0.871413
Avg Precision: 0.374269
Avg Recall: 1.000000
d_prime: 1.602441
train_loss: 0.414759
valid_loss: 1.154188
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0021504165290479396
Epoch-2 lr: 0.006451249587143819
epoch 2 training time: 17.681
---------------
2023-09-23 20:34:06.683281
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00708	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00553	Train Loss 0.3608	
start validation
acc: 0.799043
AUC: 0.845076
Avg Precision: 0.326361
Avg Recall: 1.000000
d_prime: 1.436191
train_loss: 0.350218
valid_loss: 1.170839
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0021504165290479396
Epoch-3 lr: 0.006451249587143819
epoch 3 training time: 17.537
---------------
2023-09-23 20:34:24.220719
current #epochs=4, #steps=120
start validation
acc: 0.789474
AUC: 0.862009
Avg Precision: 0.381753
Avg Recall: 1.000000
d_prime: 1.540630
train_loss: 0.356793
valid_loss: 1.152490
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0021504165290479396
Epoch-4 lr: 0.006451249587143819
epoch 4 training time: 15.283
---------------
2023-09-23 20:34:39.503657
current #epochs=5, #steps=160
start validation
acc: 0.775120
AUC: 0.859309
Avg Precision: 0.281142
Avg Recall: 1.000000
d_prime: 1.523421
train_loss: 0.370190
valid_loss: 1.158961
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0021504165290479396
Epoch-5 lr: 0.006451249587143819
epoch 5 training time: 15.298
---------------
2023-09-23 20:34:54.801271
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03995	Per Sample Data Time 0.03013	Per Sample DNN Time 0.00982	Train Loss 0.3395	
start validation
acc: 0.784689
AUC: 0.857570
Avg Precision: 0.308136
Avg Recall: 1.000000
d_prime: 1.512450
train_loss: 0.333183
valid_loss: 1.153140
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.001752024880813187
Epoch-6 lr: 0.00525607464243956
epoch 6 training time: 15.283
---------------
2023-09-23 20:35:10.084879
current #epochs=7, #steps=240
start validation
acc: 0.837321
AUC: 0.882643
Avg Precision: 0.327743
Avg Recall: 1.000000
d_prime: 1.680517
train_loss: 0.319071
valid_loss: 1.144124
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.001752024880813187
Epoch-7 lr: 0.00525607464243956
epoch 7 training time: 17.756
---------------
2023-09-23 20:35:27.840484
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00714	Per Sample Data Time 0.00166	Per Sample DNN Time 0.00548	Train Loss 0.3274	
start validation
acc: 0.813397
AUC: 0.865492
Avg Precision: 0.304550
Avg Recall: 1.000000
d_prime: 1.563173
train_loss: 0.347827
valid_loss: 1.151418
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.001752024880813187
Epoch-8 lr: 0.00525607464243956
epoch 8 training time: 15.276
---------------
2023-09-23 20:35:43.116234
current #epochs=9, #steps=320
start validation
acc: 0.808612
AUC: 0.844213
Avg Precision: 0.300058
Avg Recall: 1.000000
d_prime: 1.431079
train_loss: 0.314438
valid_loss: 1.160653
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0014274402849514328
Epoch-9 lr: 0.004282320854854298
epoch 9 training time: 15.239
---------------
2023-09-23 20:35:58.354994
current #epochs=10, #steps=360
start validation
acc: 0.813397
AUC: 0.841343
Avg Precision: 0.294775
Avg Recall: 1.000000
d_prime: 1.414202
train_loss: 0.324924
valid_loss: 1.162068
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0014274402849514328
Epoch-10 lr: 0.004282320854854298
epoch 10 training time: 15.224
---------------
2023-09-23 20:36:13.578434
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03952	Per Sample Data Time 0.02986	Per Sample DNN Time 0.00966	Train Loss 0.2469	
start validation
acc: 0.803828
AUC: 0.866276
Avg Precision: 0.351247
Avg Recall: 1.000000
d_prime: 1.568307
train_loss: 0.306497
valid_loss: 1.153318
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0014274402849514328
Epoch-11 lr: 0.004282320854854298
epoch 11 training time: 15.242
---------------
2023-09-23 20:36:28.820207
current #epochs=12, #steps=440
start validation
acc: 0.837321
AUC: 0.849257
Avg Precision: 0.332092
Avg Recall: 1.000000
d_prime: 1.461237
train_loss: 0.273187
valid_loss: 1.141952
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0011629890587835144
Epoch-12 lr: 0.003488967176350543
epoch 12 training time: 15.381
---------------
2023-09-23 20:36:44.200515
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00708	Per Sample Data Time 0.00154	Per Sample DNN Time 0.00554	Train Loss 0.2745	
start validation
acc: 0.818182
AUC: 0.844475
Avg Precision: 0.312861
Avg Recall: 1.000000
d_prime: 1.432629
train_loss: 0.294955
valid_loss: 1.153138
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0011629890587835144
Epoch-13 lr: 0.003488967176350543
epoch 13 training time: 15.069
---------------
2023-09-23 20:36:59.269088
current #epochs=14, #steps=520
start validation
acc: 0.784689
AUC: 0.849128
Avg Precision: 0.313840
Avg Recall: 1.000000
d_prime: 1.460460
train_loss: 0.264337
valid_loss: 1.156997
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0011629890587835144
Epoch-14 lr: 0.003488967176350543
epoch 14 training time: 15.443
---------------
2023-09-23 20:37:14.712513
current #epochs=15, #steps=560
start validation
acc: 0.827751
AUC: 0.853656
Avg Precision: 0.301150
Avg Recall: 1.000000
d_prime: 1.488098
train_loss: 0.269101
valid_loss: 1.147183
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0009475307409417717
Epoch-15 lr: 0.002842592222825315
epoch 15 training time: 15.510
---------------
2023-09-23 20:37:30.222785
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03940	Per Sample Data Time 0.02937	Per Sample DNN Time 0.01004	Train Loss 0.1425	
start validation
acc: 0.818182
AUC: 0.840229
Avg Precision: 0.310512
Avg Recall: 1.000000
d_prime: 1.407710
train_loss: 0.269438
valid_loss: 1.155668
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0009475307409417717
Epoch-16 lr: 0.002842592222825315
epoch 16 training time: 15.266
---------------
2023-09-23 20:37:45.488613
current #epochs=17, #steps=640
start validation
acc: 0.822967
AUC: 0.859693
Avg Precision: 0.345284
Avg Recall: 1.000000
d_prime: 1.525851
train_loss: 0.269148
valid_loss: 1.134350
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0009475307409417717
Epoch-17 lr: 0.002842592222825315
epoch 17 training time: 15.397
---------------
2023-09-23 20:38:00.885943
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00563	Train Loss 0.3067	
start validation
acc: 0.818182
AUC: 0.851862
Avg Precision: 0.325486
Avg Recall: 1.000000
d_prime: 1.477078
train_loss: 0.288066
valid_loss: 1.152036
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0007719887803319287
Epoch-18 lr: 0.002315966340995786
epoch 18 training time: 15.351
---------------
2023-09-23 20:38:16.236836
current #epochs=19, #steps=720
start validation
acc: 0.799043
AUC: 0.867231
Avg Precision: 0.331675
Avg Recall: 1.000000
d_prime: 1.574579
train_loss: 0.272012
valid_loss: 1.145626
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0007719887803319287
Epoch-19 lr: 0.002315966340995786
epoch 19 training time: 15.393
---------------
2023-09-23 20:38:31.630560
current #epochs=20, #steps=760
start validation
acc: 0.799043
AUC: 0.853122
Avg Precision: 0.303429
Avg Recall: 1.000000
d_prime: 1.484808
train_loss: 0.278408
valid_loss: 1.155844
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0007719887803319287
Epoch-20 lr: 0.002315966340995786
epoch 20 training time: 15.320
---------------
2023-09-23 20:38:46.950780
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04106	Per Sample Data Time 0.03150	Per Sample DNN Time 0.00956	Train Loss 0.2435	
start validation
acc: 0.818182
AUC: 0.856193
Avg Precision: 0.331100
Avg Recall: 1.000000
d_prime: 1.503832
train_loss: 0.246624
valid_loss: 1.140672
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0006289681708543137
Epoch-21 lr: 0.001886904512562941
epoch 21 training time: 15.423
---------------
2023-09-23 20:39:02.373954
current #epochs=22, #steps=840
start validation
acc: 0.822967
AUC: 0.856047
Avg Precision: 0.325809
Avg Recall: 1.000000
d_prime: 1.502920
train_loss: 0.269155
valid_loss: 1.141195
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0006289681708543137
Epoch-22 lr: 0.001886904512562941
epoch 22 training time: 15.400
---------------
2023-09-23 20:39:17.773697
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00723	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00564	Train Loss 0.2216	
start validation
acc: 0.846890
AUC: 0.857631
Avg Precision: 0.329169
Avg Recall: 1.000000
d_prime: 1.512838
train_loss: 0.235988
valid_loss: 1.149347
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0006289681708543137
Epoch-23 lr: 0.001886904512562941
epoch 23 training time: 17.797
---------------
2023-09-23 20:39:35.571132
current #epochs=24, #steps=920
start validation
acc: 0.818182
AUC: 0.852716
Avg Precision: 0.325812
Avg Recall: 1.000000
d_prime: 1.482311
train_loss: 0.231995
valid_loss: 1.151101
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0005124439240913921
Epoch-24 lr: 0.001537331772274176
epoch 24 training time: 15.334
---------------
2023-09-23 20:39:50.905259
current #epochs=25, #steps=960
start validation
acc: 0.808612
AUC: 0.853152
Avg Precision: 0.309623
Avg Recall: 1.000000
d_prime: 1.484995
train_loss: 0.252643
valid_loss: 1.155396
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.0005124439240913921
Epoch-25 lr: 0.001537331772274176
epoch 25 training time: 15.385
---------------
2023-09-23 20:40:06.290700
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.04016	Per Sample Data Time 0.02990	Per Sample DNN Time 0.01025	Train Loss 0.3431	
start validation
acc: 0.794258
AUC: 0.855878
Avg Precision: 0.325208
Avg Recall: 1.000000
d_prime: 1.501872
train_loss: 0.237651
valid_loss: 1.159304
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.0005124439240913921
Epoch-26 lr: 0.001537331772274176
epoch 26 training time: 15.311
---------------
2023-09-23 20:40:21.601168
current #epochs=27, #steps=1040
start validation
acc: 0.813397
AUC: 0.854764
Avg Precision: 0.334253
Avg Recall: 1.000000
d_prime: 1.494946
train_loss: 0.215972
valid_loss: 1.150977
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.00041750725633938235
Epoch-27 lr: 0.001252521769018147
epoch 27 training time: 15.271
---------------
2023-09-23 20:40:36.872179
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00555	Train Loss 0.2334	
start validation
acc: 0.803828
AUC: 0.851861
Avg Precision: 0.322639
Avg Recall: 1.000000
d_prime: 1.477071
train_loss: 0.236801
valid_loss: 1.163108
validation finished
normal learning rate scheduler step
Epoch-28 lr: 0.00041750725633938235
Epoch-28 lr: 0.001252521769018147
epoch 28 training time: 16.536
---------------
2023-09-23 20:40:53.408174
current #epochs=29, #steps=1120
start validation
acc: 0.799043
AUC: 0.855229
Avg Precision: 0.318753
Avg Recall: 1.000000
d_prime: 1.497833
train_loss: 0.248490
valid_loss: 1.153047
validation finished
normal learning rate scheduler step
Epoch-29 lr: 0.00041750725633938235
Epoch-29 lr: 0.001252521769018147
epoch 29 training time: 15.293
---------------
2023-09-23 20:41:08.702032
current #epochs=30, #steps=1160
start validation
acc: 0.832536
AUC: 0.854048
Avg Precision: 0.322125
Avg Recall: 1.000000
d_prime: 1.490515
train_loss: 0.216113
valid_loss: 1.142668
validation finished
normal learning rate scheduler step
Epoch-30 lr: 0.00034015879767744283
Epoch-30 lr: 0.0010204763930323287
epoch 30 training time: 15.356
---------------
2023-09-23 20:41:24.057536
current #epochs=31, #steps=1200
Epoch: [31][0/40]	Per Sample Total Time 0.04068	Per Sample Data Time 0.03018	Per Sample DNN Time 0.01050	Train Loss 0.1330	
start validation
acc: 0.822967
AUC: 0.853901
Avg Precision: 0.324168
Avg Recall: 1.000000
d_prime: 1.489605
train_loss: 0.211686
valid_loss: 1.137018
validation finished
normal learning rate scheduler step
Epoch-31 lr: 0.00034015879767744283
Epoch-31 lr: 0.0010204763930323287
epoch 31 training time: 15.476
---------------
2023-09-23 20:41:39.533211
current #epochs=32, #steps=1240
start validation
acc: 0.846890
AUC: 0.861930
Avg Precision: 0.332671
Avg Recall: 1.000000
d_prime: 1.540121
train_loss: 0.206936
valid_loss: 1.128252
validation finished
normal learning rate scheduler step
Epoch-32 lr: 0.00034015879767744283
Epoch-32 lr: 0.0010204763930323287
epoch 32 training time: 15.379
---------------
2023-09-23 20:41:54.912072
current #epochs=33, #steps=1280
Epoch: [33][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00563	Train Loss 0.2412	
start validation
acc: 0.837321
AUC: 0.855125
Avg Precision: 0.324054
Avg Recall: 1.000000
d_prime: 1.497185
train_loss: 0.211662
valid_loss: 1.139328
validation finished
normal learning rate scheduler step
Epoch-33 lr: 0.0002771401116518728
Epoch-33 lr: 0.0008314203349556185
epoch 33 training time: 17.090
---------------
2023-09-23 20:42:12.002311
current #epochs=34, #steps=1320
start validation
[I 2023-09-23 20:42:27,374] Trial 16 finished with value: 0.315185527637389 and parameters: {'warmup': 'True', 'num_epochs': 34, 'batch_size': 9, 'lr-adaptschedule': 'False', 'lr': 0.0021504165290479396, 'head-lr': 3, 'lr-scheduler-start': 6, 'lr-scheduler-step': 3, 'lr-scheduler-decay': 0.8147374506969894}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.832536
AUC: 0.855773
Avg Precision: 0.315186
Avg Recall: 1.000000
d_prime: 1.501216
train_loss: 0.222910
valid_loss: 1.144338
validation finished
normal learning rate scheduler step
Epoch-34 lr: 0.0002771401116518728
Epoch-34 lr: 0.0008314203349556185
epoch 34 training time: 15.367
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 1 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0a6857c0>
The learning rate scheduler starts at 8 epoch with decay rate of 0.706 every 10 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 20:42:27.406640
current #epochs=1, #steps=0
start validation
acc: 0.803828
AUC: 0.858479
Avg Precision: 0.331503
Avg Recall: 1.000000
d_prime: 1.518172
train_loss: 0.416377
valid_loss: 1.162402
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0031495450839328963
Epoch-1 lr: 0.0031495450839328963
epoch 1 training time: 17.821
---------------
2023-09-23 20:42:45.227843
current #epochs=2, #steps=40
start validation
acc: 0.822967
AUC: 0.862446
Avg Precision: 0.301094
Avg Recall: 1.000000
d_prime: 1.543436
train_loss: 0.330688
valid_loss: 1.145436
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0031495450839328963
Epoch-2 lr: 0.0031495450839328963
epoch 2 training time: 17.733
---------------
2023-09-23 20:43:02.961189
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00714	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00557	Train Loss 0.3225	
start validation
acc: 0.794258
AUC: 0.853655
Avg Precision: 0.311205
Avg Recall: 1.000000
d_prime: 1.488092
train_loss: 0.318911
valid_loss: 1.157813
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0031495450839328963
Epoch-3 lr: 0.0031495450839328963
epoch 3 training time: 15.330
---------------
2023-09-23 20:43:18.291486
current #epochs=4, #steps=120
start validation
acc: 0.822967
AUC: 0.867558
Avg Precision: 0.348315
Avg Recall: 1.000000
d_prime: 1.576738
train_loss: 0.359394
valid_loss: 1.141630
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0031495450839328963
Epoch-4 lr: 0.0031495450839328963
epoch 4 training time: 15.315
---------------
2023-09-23 20:43:33.606720
current #epochs=5, #steps=160
start validation
acc: 0.822967
AUC: 0.852553
Avg Precision: 0.305275
Avg Recall: 1.000000
d_prime: 1.481309
train_loss: 0.402723
valid_loss: 1.172589
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0031495450839328963
Epoch-5 lr: 0.0031495450839328963
epoch 5 training time: 15.334
---------------
2023-09-23 20:43:48.941016
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04012	Per Sample Data Time 0.03041	Per Sample DNN Time 0.00970	Train Loss 0.3684	
start validation
acc: 0.803828
AUC: 0.870134
Avg Precision: 0.289470
Avg Recall: 1.000000
d_prime: 1.593855
train_loss: 0.332467
valid_loss: 1.164232
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0031495450839328963
Epoch-6 lr: 0.0031495450839328963
epoch 6 training time: 15.371
---------------
2023-09-23 20:44:04.312427
current #epochs=7, #steps=240
start validation
acc: 0.851675
AUC: 0.862339
Avg Precision: 0.353722
Avg Recall: 1.000000
d_prime: 1.542748
train_loss: 0.368546
valid_loss: 1.151667
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0031495450839328963
Epoch-7 lr: 0.0031495450839328963
epoch 7 training time: 17.690
---------------
2023-09-23 20:44:22.002365
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00725	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00564	Train Loss 0.3345	
start validation
acc: 0.775120
AUC: 0.840240
Avg Precision: 0.299222
Avg Recall: 1.000000
d_prime: 1.407770
train_loss: 0.361680
valid_loss: 1.169939
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0022223324322613066
Epoch-8 lr: 0.0022223324322613066
epoch 8 training time: 15.731
---------------
2023-09-23 20:44:37.733554
current #epochs=9, #steps=320
start validation
acc: 0.818182
AUC: 0.896016
Avg Precision: 0.330717
Avg Recall: 1.000000
d_prime: 1.780735
train_loss: 0.330805
valid_loss: 1.125627
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0022223324322613066
Epoch-9 lr: 0.0022223324322613066
epoch 9 training time: 15.272
---------------
2023-09-23 20:44:53.005624
current #epochs=10, #steps=360
start validation
acc: 0.803828
AUC: 0.860790
Avg Precision: 0.313065
Avg Recall: 1.000000
d_prime: 1.532833
train_loss: 0.294895
valid_loss: 1.149425
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0022223324322613066
Epoch-10 lr: 0.0022223324322613066
epoch 10 training time: 15.388
---------------
2023-09-23 20:45:08.393443
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03798	Per Sample Data Time 0.03057	Per Sample DNN Time 0.00741	Train Loss 0.2570	
start validation
acc: 0.813397
AUC: 0.858210
Avg Precision: 0.344648
Avg Recall: 1.000000
d_prime: 1.516479
train_loss: 0.291731
valid_loss: 1.175567
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0022223324322613066
Epoch-11 lr: 0.0022223324322613066
epoch 11 training time: 15.305
---------------
2023-09-23 20:45:23.698652
current #epochs=12, #steps=440
start validation
acc: 0.837321
AUC: 0.852579
Avg Precision: 0.341530
Avg Recall: 1.000000
d_prime: 1.481470
train_loss: 0.315046
valid_loss: 1.149035
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0022223324322613066
Epoch-12 lr: 0.0022223324322613066
epoch 12 training time: 15.241
---------------
2023-09-23 20:45:38.939235
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00561	Train Loss 0.2906	
start validation
acc: 0.803828
AUC: 0.832931
Avg Precision: 0.343475
Avg Recall: 1.000000
d_prime: 1.365863
train_loss: 0.311661
valid_loss: 1.165661
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0022223324322613066
Epoch-13 lr: 0.0022223324322613066
epoch 13 training time: 15.360
---------------
2023-09-23 20:45:54.299480
current #epochs=14, #steps=520
start validation
acc: 0.808612
AUC: 0.841263
Avg Precision: 0.318273
Avg Recall: 1.000000
d_prime: 1.413735
train_loss: 0.334898
valid_loss: 1.164269
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0022223324322613066
Epoch-14 lr: 0.0022223324322613066
epoch 14 training time: 15.308
---------------
2023-09-23 20:46:09.607466
current #epochs=15, #steps=560
start validation
acc: 0.808612
AUC: 0.879249
Avg Precision: 0.366256
Avg Recall: 1.000000
d_prime: 1.656383
train_loss: 0.302726
valid_loss: 1.149327
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0022223324322613066
Epoch-15 lr: 0.0022223324322613066
epoch 15 training time: 15.405
---------------
2023-09-23 20:46:25.012013
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04049	Per Sample Data Time 0.03131	Per Sample DNN Time 0.00918	Train Loss 0.4332	
start validation
acc: 0.818182
AUC: 0.839255
Avg Precision: 0.320610
Avg Recall: 1.000000
d_prime: 1.402050
train_loss: 0.348586
valid_loss: 1.160533
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0022223324322613066
Epoch-16 lr: 0.0022223324322613066
epoch 16 training time: 15.356
---------------
2023-09-23 20:46:40.367966
current #epochs=17, #steps=640
start validation
acc: 0.832536
AUC: 0.839491
Avg Precision: 0.321410
Avg Recall: 1.000000
d_prime: 1.403420
train_loss: 0.283358
valid_loss: 1.160612
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0022223324322613066
Epoch-17 lr: 0.0022223324322613066
epoch 17 training time: 16.052
---------------
2023-09-23 20:46:56.419995
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00725	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00563	Train Loss 0.2829	
start validation
acc: 0.822967
AUC: 0.845145
Avg Precision: 0.345744
Avg Recall: 1.000000
d_prime: 1.436604
train_loss: 0.271129
valid_loss: 1.162133
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0015680872341453612
Epoch-18 lr: 0.0015680872341453612
epoch 18 training time: 15.361
---------------
2023-09-23 20:47:11.781287
current #epochs=19, #steps=720
start validation
acc: 0.818182
AUC: 0.869191
Avg Precision: 0.322946
Avg Recall: 1.000000
d_prime: 1.587561
train_loss: 0.279263
valid_loss: 1.164737
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0015680872341453612
Epoch-19 lr: 0.0015680872341453612
epoch 19 training time: 15.351
---------------
2023-09-23 20:47:27.131910
current #epochs=20, #steps=760
start validation
acc: 0.784689
AUC: 0.844187
Avg Precision: 0.313352
Avg Recall: 1.000000
d_prime: 1.430922
train_loss: 0.272181
valid_loss: 1.176955
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0015680872341453612
Epoch-20 lr: 0.0015680872341453612
epoch 20 training time: 15.238
---------------
2023-09-23 20:47:42.369974
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04098	Per Sample Data Time 0.03104	Per Sample DNN Time 0.00994	Train Loss 0.3265	
start validation
acc: 0.822967
AUC: 0.872278
Avg Precision: 0.332840
Avg Recall: 1.000000
d_prime: 1.608277
train_loss: 0.263973
valid_loss: 1.139792
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0015680872341453612
Epoch-21 lr: 0.0015680872341453612
epoch 21 training time: 15.355
---------------
2023-09-23 20:47:57.724731
current #epochs=22, #steps=840
start validation
acc: 0.832536
AUC: 0.846480
Avg Precision: 0.309898
Avg Recall: 1.000000
d_prime: 1.444551
train_loss: 0.276083
valid_loss: 1.146235
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0015680872341453612
Epoch-22 lr: 0.0015680872341453612
epoch 22 training time: 15.319
---------------
2023-09-23 20:48:13.043950
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00564	Train Loss 0.2547	
start validation
[I 2023-09-23 20:48:28,327] Trial 17 finished with value: 0.3193437441198429 and parameters: {'warmup': 'True', 'num_epochs': 23, 'batch_size': 32, 'lr-adaptschedule': 'False', 'lr': 0.0031495450839328963, 'head-lr': 1, 'lr-scheduler-start': 8, 'lr-scheduler-step': 10, 'lr-scheduler-decay': 0.7056042612624672}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.832536
AUC: 0.868888
Avg Precision: 0.319344
Avg Recall: 1.000000
d_prime: 1.585548
train_loss: 0.263026
valid_loss: 1.137699
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0015680872341453612
Epoch-23 lr: 0.0015680872341453612
epoch 23 training time: 15.279
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51da2700>
The learning rate scheduler starts at 9 epoch with decay rate of 0.779 every 7 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 20:48:28.360079
current #epochs=1, #steps=0
start validation
acc: 0.818182
AUC: 0.834153
Avg Precision: 0.287030
Avg Recall: 1.000000
d_prime: 1.372790
train_loss: 0.373397
valid_loss: 1.164109
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0028783665524668195
Epoch-1 lr: 0.008635099657400459
epoch 1 training time: 18.408
---------------
2023-09-23 20:48:46.768549
current #epochs=2, #steps=40
start validation
acc: 0.808612
AUC: 0.850032
Avg Precision: 0.312653
Avg Recall: 1.000000
d_prime: 1.465934
train_loss: 0.324098
valid_loss: 1.154469
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0028783665524668195
Epoch-2 lr: 0.008635099657400459
epoch 2 training time: 15.264
---------------
2023-09-23 20:49:02.032652
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00712	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00552	Train Loss 0.2939	
start validation
acc: 0.784689
AUC: 0.861329
Avg Precision: 0.319092
Avg Recall: 1.000000
d_prime: 1.536275
train_loss: 0.289914
valid_loss: 1.160953
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0028783665524668195
Epoch-3 lr: 0.008635099657400459
epoch 3 training time: 15.368
---------------
2023-09-23 20:49:17.399944
current #epochs=4, #steps=120
start validation
acc: 0.799043
AUC: 0.851139
Avg Precision: 0.312446
Avg Recall: 1.000000
d_prime: 1.472663
train_loss: 0.349740
valid_loss: 1.166792
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0028783665524668195
Epoch-4 lr: 0.008635099657400459
epoch 4 training time: 15.252
---------------
2023-09-23 20:49:32.651752
current #epochs=5, #steps=160
start validation
acc: 0.751196
AUC: 0.869175
Avg Precision: 0.310307
Avg Recall: 1.000000
d_prime: 1.587455
train_loss: 0.319912
valid_loss: 1.172711
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0028783665524668195
Epoch-5 lr: 0.008635099657400459
epoch 5 training time: 15.324
---------------
2023-09-23 20:49:47.976317
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04049	Per Sample Data Time 0.03070	Per Sample DNN Time 0.00979	Train Loss 0.2342	
start validation
acc: 0.837321
AUC: 0.854244
Avg Precision: 0.325467
Avg Recall: 1.000000
d_prime: 1.491728
train_loss: 0.341132
valid_loss: 1.149370
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0028783665524668195
Epoch-6 lr: 0.008635099657400459
epoch 6 training time: 17.780
---------------
2023-09-23 20:50:05.755713
current #epochs=7, #steps=240
start validation
acc: 0.832536
AUC: 0.828757
Avg Precision: 0.293375
Avg Recall: 1.000000
d_prime: 1.342466
train_loss: 0.333790
valid_loss: 1.174218
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0028783665524668195
Epoch-7 lr: 0.008635099657400459
epoch 7 training time: 15.294
---------------
2023-09-23 20:50:21.049425
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00165	Per Sample DNN Time 0.00559	Train Loss 0.3090	
start validation
acc: 0.794258
AUC: 0.882835
Avg Precision: 0.334006
Avg Recall: 1.000000
d_prime: 1.681895
train_loss: 0.293724
valid_loss: 1.154880
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0028783665524668195
Epoch-8 lr: 0.008635099657400459
epoch 8 training time: 16.024
---------------
2023-09-23 20:50:37.073042
current #epochs=9, #steps=320
start validation
acc: 0.842105
AUC: 0.862928
Avg Precision: 0.329828
Avg Recall: 1.000000
d_prime: 1.546539
train_loss: 0.308967
valid_loss: 1.137419
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.002243479231051563
Epoch-9 lr: 0.00673043769315469
epoch 9 training time: 17.693
---------------
2023-09-23 20:50:54.766734
current #epochs=10, #steps=360
start validation
acc: 0.842105
AUC: 0.862064
Avg Precision: 0.371410
Avg Recall: 1.000000
d_prime: 1.540985
train_loss: 0.277779
valid_loss: 1.146768
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.002243479231051563
Epoch-10 lr: 0.00673043769315469
epoch 10 training time: 15.203
---------------
2023-09-23 20:51:09.969062
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04115	Per Sample Data Time 0.03182	Per Sample DNN Time 0.00932	Train Loss 0.2620	
start validation
acc: 0.856459
AUC: 0.865052
Avg Precision: 0.337582
Avg Recall: 1.000000
d_prime: 1.560307
train_loss: 0.282373
valid_loss: 1.158702
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.002243479231051563
Epoch-11 lr: 0.00673043769315469
epoch 11 training time: 17.738
---------------
2023-09-23 20:51:27.706695
current #epochs=12, #steps=440
start validation
acc: 0.779904
AUC: 0.864206
Avg Precision: 0.304010
Avg Recall: 1.000000
d_prime: 1.554805
train_loss: 0.279731
valid_loss: 1.159839
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.002243479231051563
Epoch-12 lr: 0.00673043769315469
epoch 12 training time: 15.905
---------------
2023-09-23 20:51:43.611602
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00563	Train Loss 0.2641	
start validation
acc: 0.827751
AUC: 0.883172
Avg Precision: 0.357858
Avg Recall: 1.000000
d_prime: 1.684321
train_loss: 0.279670
valid_loss: 1.151388
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.002243479231051563
Epoch-13 lr: 0.00673043769315469
epoch 13 training time: 15.373
---------------
2023-09-23 20:51:58.984772
current #epochs=14, #steps=520
start validation
acc: 0.832536
AUC: 0.853668
Avg Precision: 0.311272
Avg Recall: 1.000000
d_prime: 1.488170
train_loss: 0.282343
valid_loss: 1.135709
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.002243479231051563
Epoch-14 lr: 0.00673043769315469
epoch 14 training time: 15.343
---------------
2023-09-23 20:52:14.327725
current #epochs=15, #steps=560
start validation
acc: 0.779904
AUC: 0.850400
Avg Precision: 0.318611
Avg Recall: 1.000000
d_prime: 1.468168
train_loss: 0.270353
valid_loss: 1.144251
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.002243479231051563
Epoch-15 lr: 0.00673043769315469
epoch 15 training time: 15.348
---------------
2023-09-23 20:52:29.676055
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03705	Per Sample Data Time 0.02941	Per Sample DNN Time 0.00763	Train Loss 0.2298	
start validation
acc: 0.856459
AUC: 0.866232
Avg Precision: 0.402533
Avg Recall: 1.000000
d_prime: 1.568018
train_loss: 0.322010
valid_loss: 1.127973
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0017486303319659397
Epoch-16 lr: 0.0052458909958978195
epoch 16 training time: 15.437
---------------
2023-09-23 20:52:45.113302
current #epochs=17, #steps=640
start validation
acc: 0.784689
AUC: 0.847664
Avg Precision: 0.316614
Avg Recall: 1.000000
d_prime: 1.451644
train_loss: 0.289182
valid_loss: 1.148892
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0017486303319659397
Epoch-17 lr: 0.0052458909958978195
epoch 17 training time: 15.429
---------------
2023-09-23 20:53:00.542458
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00715	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00560	Train Loss 0.2150	
start validation
acc: 0.818182
AUC: 0.842571
Avg Precision: 0.307913
Avg Recall: 1.000000
d_prime: 1.421400
train_loss: 0.248644
valid_loss: 1.168156
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0017486303319659397
Epoch-18 lr: 0.0052458909958978195
epoch 18 training time: 15.243
---------------
2023-09-23 20:53:15.785087
current #epochs=19, #steps=720
start validation
acc: 0.837321
AUC: 0.861492
Avg Precision: 0.341320
Avg Recall: 1.000000
d_prime: 1.537316
train_loss: 0.234542
valid_loss: 1.155335
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0017486303319659397
Epoch-19 lr: 0.0052458909958978195
epoch 19 training time: 15.447
---------------
2023-09-23 20:53:31.232700
current #epochs=20, #steps=760
start validation
acc: 0.784689
AUC: 0.848419
Avg Precision: 0.298275
Avg Recall: 1.000000
d_prime: 1.456184
train_loss: 0.266448
valid_loss: 1.170236
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0017486303319659397
Epoch-20 lr: 0.0052458909958978195
epoch 20 training time: 15.470
---------------
2023-09-23 20:53:46.702283
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03964	Per Sample Data Time 0.03072	Per Sample DNN Time 0.00892	Train Loss 0.2683	
start validation
acc: 0.837321
AUC: 0.869918
Avg Precision: 0.344737
Avg Recall: 1.000000
d_prime: 1.592412
train_loss: 0.255301
valid_loss: 1.130335
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0017486303319659397
Epoch-21 lr: 0.0052458909958978195
epoch 21 training time: 15.331
---------------
2023-09-23 20:54:02.033174
current #epochs=22, #steps=840
start validation
acc: 0.803828
AUC: 0.855042
Avg Precision: 0.319731
Avg Recall: 1.000000
d_prime: 1.496670
train_loss: 0.224372
valid_loss: 1.149625
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0017486303319659397
Epoch-22 lr: 0.0052458909958978195
epoch 22 training time: 15.406
---------------
2023-09-23 20:54:17.439330
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00726	Per Sample Data Time 0.00165	Per Sample DNN Time 0.00561	Train Loss 0.2436	
start validation
acc: 0.818182
AUC: 0.865166
Avg Precision: 0.319008
Avg Recall: 1.000000
d_prime: 1.561050
train_loss: 0.225017
valid_loss: 1.165184
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0013629312879522867
Epoch-23 lr: 0.0040887938638568605
epoch 23 training time: 15.382
---------------
2023-09-23 20:54:32.821732
current #epochs=24, #steps=920
start validation
acc: 0.755981
AUC: 0.834191
Avg Precision: 0.311311
Avg Recall: 1.000000
d_prime: 1.373006
train_loss: 0.212768
valid_loss: 1.171481
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0013629312879522867
Epoch-24 lr: 0.0040887938638568605
epoch 24 training time: 15.264
---------------
2023-09-23 20:54:48.085906
current #epochs=25, #steps=960
start validation
acc: 0.775120
AUC: 0.850604
Avg Precision: 0.305934
Avg Recall: 1.000000
d_prime: 1.469404
train_loss: 0.217161
valid_loss: 1.169372
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.0013629312879522867
Epoch-25 lr: 0.0040887938638568605
epoch 25 training time: 15.367
---------------
2023-09-23 20:55:03.453588
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.04147	Per Sample Data Time 0.03106	Per Sample DNN Time 0.01041	Train Loss 0.3130	
start validation
acc: 0.818182
AUC: 0.862594
Avg Precision: 0.317930
Avg Recall: 1.000000
d_prime: 1.544387
train_loss: 0.216158
valid_loss: 1.165139
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.0013629312879522867
Epoch-26 lr: 0.0040887938638568605
epoch 26 training time: 15.829
---------------
2023-09-23 20:55:19.282545
current #epochs=27, #steps=1040
start validation
acc: 0.813397
AUC: 0.870899
Avg Precision: 0.322744
Avg Recall: 1.000000
d_prime: 1.598983
train_loss: 0.208519
valid_loss: 1.149417
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.0013629312879522867
Epoch-27 lr: 0.0040887938638568605
epoch 27 training time: 15.450
---------------
2023-09-23 20:55:34.732769
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00559	Train Loss 0.2366	
start validation
acc: 0.822967
AUC: 0.860614
Avg Precision: 0.328062
Avg Recall: 1.000000
d_prime: 1.531712
train_loss: 0.226750
valid_loss: 1.146692
validation finished
normal learning rate scheduler step
Epoch-28 lr: 0.0013629312879522867
Epoch-28 lr: 0.0040887938638568605
epoch 28 training time: 15.332
---------------
2023-09-23 20:55:50.064382
current #epochs=29, #steps=1120
start validation
acc: 0.794258
AUC: 0.844878
Avg Precision: 0.296758
Avg Recall: 1.000000
d_prime: 1.435017
train_loss: 0.209394
valid_loss: 1.172831
validation finished
normal learning rate scheduler step
Epoch-29 lr: 0.0013629312879522867
Epoch-29 lr: 0.0040887938638568605
epoch 29 training time: 15.345
---------------
2023-09-23 20:56:05.409513
current #epochs=30, #steps=1160
start validation
acc: 0.827751
AUC: 0.846277
Avg Precision: 0.312373
Avg Recall: 1.000000
d_prime: 1.443340
train_loss: 0.229554
valid_loss: 1.152884
validation finished
normal learning rate scheduler step
Epoch-30 lr: 0.0010623066875380391
Epoch-30 lr: 0.0031869200626141177
epoch 30 training time: 15.401
---------------
2023-09-23 20:56:20.811048
current #epochs=31, #steps=1200
Epoch: [31][0/40]	Per Sample Total Time 0.04066	Per Sample Data Time 0.03060	Per Sample DNN Time 0.01006	Train Loss 0.1011	
start validation
acc: 0.789474
AUC: 0.851167
Avg Precision: 0.305035
Avg Recall: 1.000000
d_prime: 1.472836
train_loss: 0.182030
valid_loss: 1.162047
validation finished
normal learning rate scheduler step
Epoch-31 lr: 0.0010623066875380391
Epoch-31 lr: 0.0031869200626141177
epoch 31 training time: 15.363
---------------
2023-09-23 20:56:36.174013
current #epochs=32, #steps=1240
start validation
acc: 0.822967
AUC: 0.838107
Avg Precision: 0.310178
Avg Recall: 1.000000
d_prime: 1.395413
train_loss: 0.186606
valid_loss: 1.155958
validation finished
normal learning rate scheduler step
Epoch-32 lr: 0.0010623066875380391
Epoch-32 lr: 0.0031869200626141177
epoch 32 training time: 15.405
---------------
2023-09-23 20:56:51.579424
current #epochs=33, #steps=1280
Epoch: [33][20/40]	Per Sample Total Time 0.00725	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00564	Train Loss 0.1842	
start validation
acc: 0.827751
AUC: 0.835299
Avg Precision: 0.329783
Avg Recall: 1.000000
d_prime: 1.379311
train_loss: 0.182681
valid_loss: 1.150030
validation finished
normal learning rate scheduler step
Epoch-33 lr: 0.0010623066875380391
Epoch-33 lr: 0.0031869200626141177
epoch 33 training time: 15.380
---------------
2023-09-23 20:57:06.959494
current #epochs=34, #steps=1320
start validation
acc: 0.827751
AUC: 0.850781
Avg Precision: 0.322271
Avg Recall: 1.000000
d_prime: 1.470481
train_loss: 0.189613
valid_loss: 1.145560
validation finished
normal learning rate scheduler step
Epoch-34 lr: 0.0010623066875380391
Epoch-34 lr: 0.0031869200626141177
epoch 34 training time: 15.331
---------------
2023-09-23 20:57:22.290157
current #epochs=35, #steps=1360
start validation
acc: 0.789474
AUC: 0.853940
Avg Precision: 0.320887
Avg Recall: 1.000000
d_prime: 1.489851
train_loss: 0.210514
valid_loss: 1.158423
validation finished
normal learning rate scheduler step
Epoch-35 lr: 0.0010623066875380391
Epoch-35 lr: 0.0031869200626141177
epoch 35 training time: 15.440
---------------
2023-09-23 20:57:37.730161
current #epochs=36, #steps=1400
Epoch: [36][0/40]	Per Sample Total Time 0.04013	Per Sample Data Time 0.02953	Per Sample DNN Time 0.01060	Train Loss 0.1852	
start validation
acc: 0.827751
AUC: 0.844359
Avg Precision: 0.314154
Avg Recall: 1.000000
d_prime: 1.431944
train_loss: 0.170724
valid_loss: 1.157856
validation finished
normal learning rate scheduler step
Epoch-36 lr: 0.0010623066875380391
Epoch-36 lr: 0.0031869200626141177
epoch 36 training time: 15.321
---------------
2023-09-23 20:57:53.051888
current #epochs=37, #steps=1440
start validation
acc: 0.813397
AUC: 0.837709
Avg Precision: 0.312859
Avg Recall: 1.000000
d_prime: 1.393123
train_loss: 0.163742
valid_loss: 1.167464
validation finished
normal learning rate scheduler step
Epoch-37 lr: 0.000827991483036192
Epoch-37 lr: 0.002483974449108576
epoch 37 training time: 15.679
---------------
2023-09-23 20:58:08.730790
current #epochs=38, #steps=1480
Epoch: [38][20/40]	Per Sample Total Time 0.00726	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00565	Train Loss 0.2462	
start validation
acc: 0.822967
AUC: 0.854689
Avg Precision: 0.316858
Avg Recall: 1.000000
d_prime: 1.494485
train_loss: 0.208076
valid_loss: 1.155966
validation finished
normal learning rate scheduler step
Epoch-38 lr: 0.000827991483036192
Epoch-38 lr: 0.002483974449108576
epoch 38 training time: 15.347
---------------
2023-09-23 20:58:24.077595
current #epochs=39, #steps=1520
start validation
acc: 0.827751
AUC: 0.854174
Avg Precision: 0.328689
Avg Recall: 1.000000
d_prime: 1.491295
train_loss: 0.161922
valid_loss: 1.151037
validation finished
normal learning rate scheduler step
Epoch-39 lr: 0.000827991483036192
Epoch-39 lr: 0.002483974449108576
epoch 39 training time: 15.362
---------------
2023-09-23 20:58:39.439766
current #epochs=40, #steps=1560
start validation
acc: 0.808612
AUC: 0.854586
Avg Precision: 0.300974
Avg Recall: 1.000000
d_prime: 1.493843
train_loss: 0.170784
valid_loss: 1.155699
validation finished
normal learning rate scheduler step
Epoch-40 lr: 0.000827991483036192
Epoch-40 lr: 0.002483974449108576
epoch 40 training time: 15.304
---------------
2023-09-23 20:58:54.743150
current #epochs=41, #steps=1600
Epoch: [41][0/40]	Per Sample Total Time 0.04068	Per Sample Data Time 0.03070	Per Sample DNN Time 0.00999	Train Loss 0.2436	
start validation
acc: 0.818182
AUC: 0.842982
Avg Precision: 0.324543
Avg Recall: 1.000000
d_prime: 1.423814
train_loss: 0.155625
valid_loss: 1.157494
validation finished
normal learning rate scheduler step
Epoch-41 lr: 0.000827991483036192
Epoch-41 lr: 0.002483974449108576
epoch 41 training time: 15.369
---------------
2023-09-23 20:59:10.112046
current #epochs=42, #steps=1640
start validation
acc: 0.813397
AUC: 0.862785
Avg Precision: 0.302511
Avg Recall: 1.000000
d_prime: 1.545618
train_loss: 0.151730
valid_loss: 1.171631
validation finished
normal learning rate scheduler step
Epoch-42 lr: 0.000827991483036192
Epoch-42 lr: 0.002483974449108576
epoch 42 training time: 15.446
---------------
2023-09-23 20:59:25.557732
current #epochs=43, #steps=1680
Epoch: [43][20/40]	Per Sample Total Time 0.00730	Per Sample Data Time 0.00168	Per Sample DNN Time 0.00562	Train Loss 0.1119	
start validation
acc: 0.789474
AUC: 0.854804
Avg Precision: 0.305478
Avg Recall: 1.000000
d_prime: 1.495196
train_loss: 0.144503
valid_loss: 1.168911
validation finished
normal learning rate scheduler step
Epoch-43 lr: 0.000827991483036192
Epoch-43 lr: 0.002483974449108576
epoch 43 training time: 15.485
---------------
2023-09-23 20:59:41.043101
current #epochs=44, #steps=1720
start validation
acc: 0.822967
AUC: 0.873828
Avg Precision: 0.310732
Avg Recall: 1.000000
d_prime: 1.618817
train_loss: 0.146679
valid_loss: 1.138084
validation finished
normal learning rate scheduler step
Epoch-44 lr: 0.0006453596725154041
Epoch-44 lr: 0.0019360790175462124
epoch 44 training time: 15.428
---------------
2023-09-23 20:59:56.471734
current #epochs=45, #steps=1760
start validation
[I 2023-09-23 21:00:13,184] Trial 18 finished with value: 0.3322170570160504 and parameters: {'warmup': 'False', 'num_epochs': 45, 'batch_size': 30, 'lr-adaptschedule': 'True', 'lr': 0.0028783665524668195, 'head-lr': 3, 'lr-scheduler-start': 9, 'lr-scheduler-step': 7, 'lr-scheduler-decay': 0.779427911684443}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.827751
AUC: 0.848017
Avg Precision: 0.332217
Avg Recall: 1.000000
d_prime: 1.453765
train_loss: 0.150476
valid_loss: 1.155022
validation finished
normal learning rate scheduler step
Epoch-45 lr: 0.0006453596725154041
Epoch-45 lr: 0.0019360790175462124
epoch 45 training time: 16.708
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 2 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0a6f3280>
The learning rate scheduler starts at 4 epoch with decay rate of 0.671 every 2 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 21:00:13.217007
current #epochs=1, #steps=0
start validation
acc: 0.832536
AUC: 0.846271
Avg Precision: 0.301841
Avg Recall: 1.000000
d_prime: 1.443307
train_loss: 0.279467
valid_loss: 1.143353
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.002436558107355169
Epoch-1 lr: 0.004873116214710338
epoch 1 training time: 18.192
---------------
2023-09-23 21:00:31.409591
current #epochs=2, #steps=40
start validation
acc: 0.822967
AUC: 0.850032
Avg Precision: 0.294044
Avg Recall: 1.000000
d_prime: 1.465930
train_loss: 0.225802
valid_loss: 1.171162
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.002436558107355169
Epoch-2 lr: 0.004873116214710338
epoch 2 training time: 15.399
---------------
2023-09-23 21:00:46.807980
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00711	Per Sample Data Time 0.00152	Per Sample DNN Time 0.00560	Train Loss 0.2174	
start validation
acc: 0.808612
AUC: 0.853626
Avg Precision: 0.303589
Avg Recall: 1.000000
d_prime: 1.487913
train_loss: 0.232252
valid_loss: 1.162156
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.002436558107355169
Epoch-3 lr: 0.004873116214710338
epoch 3 training time: 15.516
---------------
2023-09-23 21:01:02.323847
current #epochs=4, #steps=120
start validation
acc: 0.832536
AUC: 0.854878
Avg Precision: 0.342760
Avg Recall: 1.000000
d_prime: 1.495653
train_loss: 0.227954
valid_loss: 1.151676
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0016350209857530352
Epoch-4 lr: 0.0032700419715060705
epoch 4 training time: 15.251
---------------
2023-09-23 21:01:17.574952
current #epochs=5, #steps=160
start validation
acc: 0.818182
AUC: 0.847921
Avg Precision: 0.313105
Avg Recall: 1.000000
d_prime: 1.453188
train_loss: 0.280129
valid_loss: 1.153627
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0016350209857530352
Epoch-5 lr: 0.0032700419715060705
epoch 5 training time: 15.357
---------------
2023-09-23 21:01:32.932648
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04085	Per Sample Data Time 0.03159	Per Sample DNN Time 0.00926	Train Loss 0.2224	
start validation
acc: 0.832536
AUC: 0.854282
Avg Precision: 0.305832
Avg Recall: 1.000000
d_prime: 1.491963
train_loss: 0.244852
valid_loss: 1.132782
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.001097159807427958
Epoch-6 lr: 0.002194319614855916
epoch 6 training time: 15.380
---------------
2023-09-23 21:01:48.312503
current #epochs=7, #steps=240
start validation
acc: 0.837321
AUC: 0.862258
Avg Precision: 0.300771
Avg Recall: 1.000000
d_prime: 1.542230
train_loss: 0.224701
valid_loss: 1.148136
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.001097159807427958
Epoch-7 lr: 0.002194319614855916
epoch 7 training time: 18.093
---------------
2023-09-23 21:02:06.405097
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00564	Train Loss 0.1733	
start validation
acc: 0.842105
AUC: 0.862125
Avg Precision: 0.328309
Avg Recall: 1.000000
d_prime: 1.541377
train_loss: 0.167869
valid_loss: 1.136161
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0007362349801772989
Epoch-8 lr: 0.0014724699603545978
epoch 8 training time: 17.819
---------------
2023-09-23 21:02:24.223762
current #epochs=9, #steps=320
start validation
acc: 0.827751
AUC: 0.876094
Avg Precision: 0.308323
Avg Recall: 1.000000
d_prime: 1.634380
train_loss: 0.169926
valid_loss: 1.144204
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0007362349801772989
Epoch-9 lr: 0.0014724699603545978
epoch 9 training time: 16.383
---------------
2023-09-23 21:02:40.606674
current #epochs=10, #steps=360
start validation
acc: 0.846890
AUC: 0.866936
Avg Precision: 0.325556
Avg Recall: 1.000000
d_prime: 1.572640
train_loss: 0.162877
valid_loss: 1.140226
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0004940410160552291
Epoch-10 lr: 0.0009880820321104581
epoch 10 training time: 17.812
---------------
2023-09-23 21:02:58.418183
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04220	Per Sample Data Time 0.03158	Per Sample DNN Time 0.01061	Train Loss 0.0515	
start validation
acc: 0.827751
AUC: 0.865527
Avg Precision: 0.330412
Avg Recall: 1.000000
d_prime: 1.563404
train_loss: 0.158876
valid_loss: 1.142278
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0004940410160552291
Epoch-11 lr: 0.0009880820321104581
epoch 11 training time: 15.363
---------------
2023-09-23 21:03:13.780918
current #epochs=12, #steps=440
start validation
acc: 0.827751
AUC: 0.863846
Avg Precision: 0.307285
Avg Recall: 1.000000
d_prime: 1.552469
train_loss: 0.176469
valid_loss: 1.148692
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0003315198708517014
Epoch-12 lr: 0.0006630397417034028
epoch 12 training time: 16.460
---------------
2023-09-23 21:03:30.241104
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00569	Train Loss 0.1412	
start validation
acc: 0.832536
AUC: 0.866406
Avg Precision: 0.316962
Avg Recall: 1.000000
d_prime: 1.569160
train_loss: 0.153812
valid_loss: 1.139253
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0003315198708517014
Epoch-13 lr: 0.0006630397417034028
epoch 13 training time: 15.337
---------------
2023-09-23 21:03:45.578474
current #epochs=14, #steps=520
start validation
acc: 0.832536
AUC: 0.867193
Avg Precision: 0.311277
Avg Recall: 1.000000
d_prime: 1.574333
train_loss: 0.125815
valid_loss: 1.149530
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.00022246214625476038
Epoch-14 lr: 0.00044492429250952075
epoch 14 training time: 15.438
---------------
2023-09-23 21:04:01.016933
current #epochs=15, #steps=560
start validation
acc: 0.822967
AUC: 0.868618
Avg Precision: 0.316452
Avg Recall: 1.000000
d_prime: 1.583752
train_loss: 0.124437
valid_loss: 1.149964
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.00022246214625476038
Epoch-15 lr: 0.00044492429250952075
epoch 15 training time: 15.258
---------------
2023-09-23 21:04:16.274942
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03884	Per Sample Data Time 0.02942	Per Sample DNN Time 0.00941	Train Loss 0.1518	
start validation
acc: 0.832536
AUC: 0.862808
Avg Precision: 0.321300
Avg Recall: 1.000000
d_prime: 1.545765
train_loss: 0.137228
valid_loss: 1.136293
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.00014928036255905898
Epoch-16 lr: 0.00029856072511811796
epoch 16 training time: 15.251
---------------
2023-09-23 21:04:31.526244
current #epochs=17, #steps=640
start validation
acc: 0.832536
AUC: 0.861573
Avg Precision: 0.308089
Avg Recall: 1.000000
d_prime: 1.537832
train_loss: 0.108742
valid_loss: 1.150290
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.00014928036255905898
Epoch-17 lr: 0.00029856072511811796
epoch 17 training time: 15.411
---------------
2023-09-23 21:04:46.937894
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00563	Train Loss 0.1351	
start validation
acc: 0.837321
AUC: 0.859747
Avg Precision: 0.310086
Avg Recall: 1.000000
d_prime: 1.526193
train_loss: 0.144405
valid_loss: 1.151347
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.00010017266766924055
Epoch-18 lr: 0.0002003453353384811
epoch 18 training time: 16.320
---------------
2023-09-23 21:05:03.258024
current #epochs=19, #steps=720
start validation
acc: 0.827751
AUC: 0.860001
Avg Precision: 0.306803
Avg Recall: 1.000000
d_prime: 1.527810
train_loss: 0.145177
valid_loss: 1.147285
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.00010017266766924055
Epoch-19 lr: 0.0002003453353384811
epoch 19 training time: 15.344
---------------
2023-09-23 21:05:18.602079
current #epochs=20, #steps=760
start validation
acc: 0.832536
AUC: 0.862477
Avg Precision: 0.314390
Avg Recall: 1.000000
d_prime: 1.543636
train_loss: 0.132332
valid_loss: 1.143910
validation finished
normal learning rate scheduler step
Epoch-20 lr: 6.72195804990907e-05
Epoch-20 lr: 0.0001344391609981814
epoch 20 training time: 15.402
---------------
2023-09-23 21:05:34.004453
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03951	Per Sample Data Time 0.02950	Per Sample DNN Time 0.01001	Train Loss 0.1045	
start validation
acc: 0.837321
AUC: 0.863631
Avg Precision: 0.318594
Avg Recall: 1.000000
d_prime: 1.551081
train_loss: 0.144414
valid_loss: 1.143780
validation finished
normal learning rate scheduler step
Epoch-21 lr: 6.72195804990907e-05
Epoch-21 lr: 0.0001344391609981814
epoch 21 training time: 15.414
---------------
2023-09-23 21:05:49.418774
current #epochs=22, #steps=840
start validation
acc: 0.837321
AUC: 0.864088
Avg Precision: 0.314584
Avg Recall: 1.000000
d_prime: 1.554037
train_loss: 0.127628
valid_loss: 1.147609
validation finished
normal learning rate scheduler step
Epoch-22 lr: 4.5106835103895275e-05
Epoch-22 lr: 9.021367020779055e-05
epoch 22 training time: 15.519
---------------
2023-09-23 21:06:04.937570
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00725	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00562	Train Loss 0.1270	
start validation
acc: 0.832536
AUC: 0.863462
Avg Precision: 0.317409
Avg Recall: 1.000000
d_prime: 1.549985
train_loss: 0.146348
valid_loss: 1.147466
validation finished
normal learning rate scheduler step
Epoch-23 lr: 4.5106835103895275e-05
Epoch-23 lr: 9.021367020779055e-05
epoch 23 training time: 15.431
---------------
2023-09-23 21:06:20.369047
current #epochs=24, #steps=920
start validation
acc: 0.827751
AUC: 0.862590
Avg Precision: 0.313880
Avg Recall: 1.000000
d_prime: 1.544362
train_loss: 0.137015
valid_loss: 1.150484
validation finished
normal learning rate scheduler step
Epoch-24 lr: 3.0268361658661676e-05
Epoch-24 lr: 6.053672331732335e-05
epoch 24 training time: 15.339
---------------
2023-09-23 21:06:35.708564
current #epochs=25, #steps=960
start validation
acc: 0.832536
AUC: 0.863327
Avg Precision: 0.313996
Avg Recall: 1.000000
d_prime: 1.549115
train_loss: 0.147201
valid_loss: 1.148816
validation finished
normal learning rate scheduler step
Epoch-25 lr: 3.0268361658661676e-05
Epoch-25 lr: 6.053672331732335e-05
epoch 25 training time: 15.368
---------------
2023-09-23 21:06:51.076887
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.04079	Per Sample Data Time 0.03130	Per Sample DNN Time 0.00948	Train Loss 0.1482	
start validation
acc: 0.832536
AUC: 0.863824
Avg Precision: 0.314744
Avg Recall: 1.000000
d_prime: 1.552331
train_loss: 0.129097
valid_loss: 1.148319
validation finished
normal learning rate scheduler step
Epoch-26 lr: 2.0311194864133187e-05
Epoch-26 lr: 4.0622389728266374e-05
epoch 26 training time: 16.437
---------------
2023-09-23 21:07:07.514273
current #epochs=27, #steps=1040
start validation
acc: 0.832536
AUC: 0.864383
Avg Precision: 0.312878
Avg Recall: 1.000000
d_prime: 1.555952
train_loss: 0.119542
valid_loss: 1.149083
validation finished
normal learning rate scheduler step
Epoch-27 lr: 2.0311194864133187e-05
Epoch-27 lr: 4.0622389728266374e-05
epoch 27 training time: 15.363
---------------
2023-09-23 21:07:22.877608
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00723	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00560	Train Loss 0.1128	
start validation
acc: 0.832536
AUC: 0.864765
Avg Precision: 0.313177
Avg Recall: 1.000000
d_prime: 1.558439
train_loss: 0.111867
valid_loss: 1.148455
validation finished
normal learning rate scheduler step
Epoch-28 lr: 1.3629566127862604e-05
Epoch-28 lr: 2.725913225572521e-05
epoch 28 training time: 15.382
---------------
2023-09-23 21:07:38.260303
current #epochs=29, #steps=1120
start validation
acc: 0.837321
AUC: 0.865224
Avg Precision: 0.315414
Avg Recall: 1.000000
d_prime: 1.561428
train_loss: 0.132438
valid_loss: 1.147706
validation finished
normal learning rate scheduler step
Epoch-29 lr: 1.3629566127862604e-05
Epoch-29 lr: 2.725913225572521e-05
epoch 29 training time: 15.380
---------------
2023-09-23 21:07:53.640513
current #epochs=30, #steps=1160
start validation
acc: 0.837321
AUC: 0.865165
Avg Precision: 0.314351
Avg Recall: 1.000000
d_prime: 1.561039
train_loss: 0.128537
valid_loss: 1.147393
validation finished
normal learning rate scheduler step
Epoch-30 lr: 9.14594508478748e-06
Epoch-30 lr: 1.829189016957496e-05
epoch 30 training time: 15.394
---------------
2023-09-23 21:08:09.034333
current #epochs=31, #steps=1200
Epoch: [31][0/40]	Per Sample Total Time 0.04059	Per Sample Data Time 0.03060	Per Sample DNN Time 0.01000	Train Loss 0.0606	
start validation
[I 2023-09-23 21:08:24,512] Trial 19 finished with value: 0.3146095406480902 and parameters: {'warmup': 'True', 'num_epochs': 31, 'batch_size': 17, 'lr-adaptschedule': 'False', 'lr': 0.002436558107355169, 'head-lr': 2, 'lr-scheduler-start': 4, 'lr-scheduler-step': 2, 'lr-scheduler-decay': 0.671037140800149}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.837321
AUC: 0.865343
Avg Precision: 0.314610
Avg Recall: 1.000000
d_prime: 1.562203
train_loss: 0.130627
valid_loss: 1.147607
validation finished
normal learning rate scheduler step
Epoch-31 lr: 9.14594508478748e-06
Epoch-31 lr: 1.829189016957496e-05
epoch 31 training time: 15.473
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc52660910>
The learning rate scheduler starts at 9 epoch with decay rate of 0.745 every 5 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 21:08:24.545036
current #epochs=1, #steps=0
start validation
acc: 0.803828
AUC: 0.830634
Avg Precision: 0.303459
Avg Recall: 1.000000
d_prime: 1.352941
train_loss: 0.249440
valid_loss: 1.151846
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.002062499425742736
Epoch-1 lr: 0.008249997702970944
epoch 1 training time: 17.782
---------------
2023-09-23 21:08:42.326911
current #epochs=2, #steps=40
start validation
acc: 0.832536
AUC: 0.864117
Avg Precision: 0.320004
Avg Recall: 1.000000
d_prime: 1.554229
train_loss: 0.244268
valid_loss: 1.159525
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.002062499425742736
Epoch-2 lr: 0.008249997702970944
epoch 2 training time: 19.150
---------------
2023-09-23 21:09:01.477327
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00554	Train Loss 0.2267	
start validation
acc: 0.818182
AUC: 0.863930
Avg Precision: 0.343646
Avg Recall: 1.000000
d_prime: 1.553017
train_loss: 0.210605
valid_loss: 1.143959
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.002062499425742736
Epoch-3 lr: 0.008249997702970944
epoch 3 training time: 15.260
---------------
2023-09-23 21:09:16.737009
current #epochs=4, #steps=120
start validation
acc: 0.818182
AUC: 0.837800
Avg Precision: 0.314135
Avg Recall: 1.000000
d_prime: 1.393644
train_loss: 0.205452
valid_loss: 1.166806
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.002062499425742736
Epoch-4 lr: 0.008249997702970944
epoch 4 training time: 15.314
---------------
2023-09-23 21:09:32.050806
current #epochs=5, #steps=160
start validation
acc: 0.808612
AUC: 0.871471
Avg Precision: 0.332858
Avg Recall: 1.000000
d_prime: 1.602828
train_loss: 0.292258
valid_loss: 1.130820
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.002062499425742736
Epoch-5 lr: 0.008249997702970944
epoch 5 training time: 15.435
---------------
2023-09-23 21:09:47.485072
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04226	Per Sample Data Time 0.03224	Per Sample DNN Time 0.01002	Train Loss 0.3137	
start validation
acc: 0.770335
AUC: 0.823266
Avg Precision: 0.295927
Avg Recall: 1.000000
d_prime: 1.312226
train_loss: 0.258853
valid_loss: 1.160682
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.002062499425742736
Epoch-6 lr: 0.008249997702970944
epoch 6 training time: 16.224
---------------
2023-09-23 21:10:03.708900
current #epochs=7, #steps=240
start validation
acc: 0.827751
AUC: 0.851865
Avg Precision: 0.333178
Avg Recall: 1.000000
d_prime: 1.477098
train_loss: 0.202168
valid_loss: 1.134099
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.002062499425742736
Epoch-7 lr: 0.008249997702970944
epoch 7 training time: 15.561
---------------
2023-09-23 21:10:19.269805
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00725	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00564	Train Loss 0.2170	
start validation
acc: 0.842105
AUC: 0.847495
Avg Precision: 0.336673
Avg Recall: 1.000000
d_prime: 1.450629
train_loss: 0.211057
valid_loss: 1.137460
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.002062499425742736
Epoch-8 lr: 0.008249997702970944
epoch 8 training time: 18.874
---------------
2023-09-23 21:10:38.144058
current #epochs=9, #steps=320
start validation
acc: 0.779904
AUC: 0.856989
Avg Precision: 0.323538
Avg Recall: 1.000000
d_prime: 1.508808
train_loss: 0.195136
valid_loss: 1.163531
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0015369734948127954
Epoch-9 lr: 0.006147893979251182
epoch 9 training time: 15.601
---------------
2023-09-23 21:10:53.745261
current #epochs=10, #steps=360
start validation
acc: 0.799043
AUC: 0.854055
Avg Precision: 0.323974
Avg Recall: 1.000000
d_prime: 1.490558
train_loss: 0.197893
valid_loss: 1.145018
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0015369734948127954
Epoch-10 lr: 0.006147893979251182
epoch 10 training time: 15.459
---------------
2023-09-23 21:11:09.203854
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03964	Per Sample Data Time 0.03055	Per Sample DNN Time 0.00910	Train Loss 0.0495	
start validation
acc: 0.770335
AUC: 0.849372
Avg Precision: 0.311572
Avg Recall: 1.000000
d_prime: 1.461937
train_loss: 0.170840
valid_loss: 1.133476
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0015369734948127954
Epoch-11 lr: 0.006147893979251182
epoch 11 training time: 15.399
---------------
2023-09-23 21:11:24.603266
current #epochs=12, #steps=440
start validation
acc: 0.822967
AUC: 0.858527
Avg Precision: 0.333720
Avg Recall: 1.000000
d_prime: 1.518473
train_loss: 0.172455
valid_loss: 1.130582
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0015369734948127954
Epoch-12 lr: 0.006147893979251182
epoch 12 training time: 15.496
---------------
2023-09-23 21:11:40.099738
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00559	Train Loss 0.1913	
start validation
acc: 0.827751
AUC: 0.872369
Avg Precision: 0.341548
Avg Recall: 1.000000
d_prime: 1.608897
train_loss: 0.187526
valid_loss: 1.127960
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0015369734948127954
Epoch-13 lr: 0.006147893979251182
epoch 13 training time: 15.437
---------------
2023-09-23 21:11:55.536692
current #epochs=14, #steps=520
start validation
acc: 0.803828
AUC: 0.877517
Avg Precision: 0.357639
Avg Recall: 1.000000
d_prime: 1.644256
train_loss: 0.157182
valid_loss: 1.152815
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0011453518455678427
Epoch-14 lr: 0.004581407382271371
epoch 14 training time: 15.397
---------------
2023-09-23 21:12:10.933801
current #epochs=15, #steps=560
start validation
acc: 0.842105
AUC: 0.886639
Avg Precision: 0.372774
Avg Recall: 1.000000
d_prime: 1.709569
train_loss: 0.213038
valid_loss: 1.143621
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0011453518455678427
Epoch-15 lr: 0.004581407382271371
epoch 15 training time: 15.383
---------------
2023-09-23 21:12:26.316936
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04019	Per Sample Data Time 0.03070	Per Sample DNN Time 0.00950	Train Loss 0.1866	
start validation
acc: 0.842105
AUC: 0.878975
Avg Precision: 0.302082
Avg Recall: 1.000000
d_prime: 1.654454
train_loss: 0.170271
valid_loss: 1.134459
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0011453518455678427
Epoch-16 lr: 0.004581407382271371
epoch 16 training time: 15.435
---------------
2023-09-23 21:12:41.752060
current #epochs=17, #steps=640
start validation
acc: 0.837321
AUC: 0.863738
Avg Precision: 0.332619
Avg Recall: 1.000000
d_prime: 1.551774
train_loss: 0.176067
valid_loss: 1.153281
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0011453518455678427
Epoch-17 lr: 0.004581407382271371
epoch 17 training time: 15.329
---------------
2023-09-23 21:12:57.080722
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00723	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00565	Train Loss 0.1456	
start validation
acc: 0.827751
AUC: 0.852291
Avg Precision: 0.319368
Avg Recall: 1.000000
d_prime: 1.479708
train_loss: 0.157951
valid_loss: 1.151997
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0011453518455678427
Epoch-18 lr: 0.004581407382271371
epoch 18 training time: 15.412
---------------
2023-09-23 21:13:12.492932
current #epochs=19, #steps=720
start validation
acc: 0.789474
AUC: 0.867294
Avg Precision: 0.304893
Avg Recall: 1.000000
d_prime: 1.574998
train_loss: 0.179665
valid_loss: 1.170568
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0008535155970958662
Epoch-19 lr: 0.003414062388383465
epoch 19 training time: 15.441
---------------
2023-09-23 21:13:27.933861
current #epochs=20, #steps=760
start validation
[I 2023-09-23 21:13:43,360] Trial 20 finished with value: 0.3193134666494691 and parameters: {'warmup': 'True', 'num_epochs': 20, 'batch_size': 8, 'lr-adaptschedule': 'False', 'lr': 0.002062499425742736, 'head-lr': 4, 'lr-scheduler-start': 9, 'lr-scheduler-step': 5, 'lr-scheduler-decay': 0.7451994776964891}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.827751
AUC: 0.877071
Avg Precision: 0.319313
Avg Recall: 1.000000
d_prime: 1.641152
train_loss: 0.159441
valid_loss: 1.137723
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0008535155970958662
Epoch-20 lr: 0.003414062388383465
epoch 20 training time: 15.421
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 2 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51dd3dc0>
The learning rate scheduler starts at 5 epoch with decay rate of 0.609 every 7 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 21:13:43.392107
current #epochs=1, #steps=0
start validation
acc: 0.784689
AUC: 0.869842
Avg Precision: 0.314883
Avg Recall: 1.000000
d_prime: 1.591903
train_loss: 0.201967
valid_loss: 1.131917
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0016819591499791422
Epoch-1 lr: 0.0033639182999582844
epoch 1 training time: 18.639
---------------
2023-09-23 21:14:02.031196
current #epochs=2, #steps=40
start validation
acc: 0.784689
AUC: 0.836330
Avg Precision: 0.328972
Avg Recall: 1.000000
d_prime: 1.385200
train_loss: 0.213664
valid_loss: 1.157888
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0016819591499791422
Epoch-2 lr: 0.0033639182999582844
epoch 2 training time: 15.385
---------------
2023-09-23 21:14:17.416438
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00554	Train Loss 0.2939	
start validation
acc: 0.813397
AUC: 0.860500
Avg Precision: 0.318916
Avg Recall: 1.000000
d_prime: 1.530983
train_loss: 0.257574
valid_loss: 1.140695
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0016819591499791422
Epoch-3 lr: 0.0033639182999582844
epoch 3 training time: 19.398
---------------
2023-09-23 21:14:36.814121
current #epochs=4, #steps=120
start validation
acc: 0.818182
AUC: 0.871238
Avg Precision: 0.317594
Avg Recall: 1.000000
d_prime: 1.601260
train_loss: 0.204914
valid_loss: 1.145836
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0016819591499791422
Epoch-4 lr: 0.0033639182999582844
epoch 4 training time: 17.641
---------------
2023-09-23 21:14:54.454942
current #epochs=5, #steps=160
start validation
acc: 0.789474
AUC: 0.850954
Avg Precision: 0.297344
Avg Recall: 1.000000
d_prime: 1.471536
train_loss: 0.178320
valid_loss: 1.165078
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.001024519957997696
Epoch-5 lr: 0.002049039915995392
epoch 5 training time: 16.121
---------------
2023-09-23 21:15:10.575663
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03856	Per Sample Data Time 0.03140	Per Sample DNN Time 0.00717	Train Loss 0.1386	
start validation
acc: 0.832536
AUC: 0.859501
Avg Precision: 0.312370
Avg Recall: 1.000000
d_prime: 1.524633
train_loss: 0.178277
valid_loss: 1.152352
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.001024519957997696
Epoch-6 lr: 0.002049039915995392
epoch 6 training time: 17.925
---------------
2023-09-23 21:15:28.500276
current #epochs=7, #steps=240
start validation
acc: 0.832536
AUC: 0.850330
Avg Precision: 0.328357
Avg Recall: 1.000000
d_prime: 1.467739
train_loss: 0.152002
valid_loss: 1.140177
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.001024519957997696
Epoch-7 lr: 0.002049039915995392
epoch 7 training time: 15.371
---------------
2023-09-23 21:15:43.871418
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00712	Per Sample Data Time 0.00154	Per Sample DNN Time 0.00558	Train Loss 0.1326	
start validation
acc: 0.856459
AUC: 0.873806
Avg Precision: 0.337761
Avg Recall: 1.000000
d_prime: 1.618664
train_loss: 0.129718
valid_loss: 1.131905
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.001024519957997696
Epoch-8 lr: 0.002049039915995392
epoch 8 training time: 17.779
---------------
2023-09-23 21:16:01.650393
current #epochs=9, #steps=320
start validation
acc: 0.837321
AUC: 0.864648
Avg Precision: 0.315898
Avg Recall: 1.000000
d_prime: 1.557674
train_loss: 0.129657
valid_loss: 1.128569
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.001024519957997696
Epoch-9 lr: 0.002049039915995392
epoch 9 training time: 15.300
---------------
2023-09-23 21:16:16.950515
current #epochs=10, #steps=360
start validation
acc: 0.832536
AUC: 0.875243
Avg Precision: 0.317652
Avg Recall: 1.000000
d_prime: 1.628508
train_loss: 0.161045
valid_loss: 1.134171
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.001024519957997696
Epoch-10 lr: 0.002049039915995392
epoch 10 training time: 15.300
---------------
2023-09-23 21:16:32.250836
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04050	Per Sample Data Time 0.02999	Per Sample DNN Time 0.01051	Train Loss 0.2024	
start validation
acc: 0.770335
AUC: 0.860205
Avg Precision: 0.317079
Avg Recall: 1.000000
d_prime: 1.529103
train_loss: 0.172572
valid_loss: 1.170720
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.001024519957997696
Epoch-11 lr: 0.002049039915995392
epoch 11 training time: 16.273
---------------
2023-09-23 21:16:48.523515
current #epochs=12, #steps=440
start validation
acc: 0.832536
AUC: 0.873777
Avg Precision: 0.330200
Avg Recall: 1.000000
d_prime: 1.618465
train_loss: 0.142010
valid_loss: 1.139598
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0006240586427729931
Epoch-12 lr: 0.0012481172855459861
epoch 12 training time: 15.416
---------------
2023-09-23 21:17:03.939227
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00565	Train Loss 0.1463	
start validation
acc: 0.799043
AUC: 0.855537
Avg Precision: 0.307670
Avg Recall: 1.000000
d_prime: 1.499743
train_loss: 0.136451
valid_loss: 1.159965
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0006240586427729931
Epoch-13 lr: 0.0012481172855459861
epoch 13 training time: 15.417
---------------
2023-09-23 21:17:19.356826
current #epochs=14, #steps=520
start validation
acc: 0.837321
AUC: 0.866932
Avg Precision: 0.339611
Avg Recall: 1.000000
d_prime: 1.572614
train_loss: 0.144434
valid_loss: 1.132442
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0006240586427729931
Epoch-14 lr: 0.0012481172855459861
epoch 14 training time: 15.382
---------------
2023-09-23 21:17:34.739020
current #epochs=15, #steps=560
start validation
acc: 0.827751
AUC: 0.873430
Avg Precision: 0.332052
Avg Recall: 1.000000
d_prime: 1.616104
train_loss: 0.128736
valid_loss: 1.144330
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0006240586427729931
Epoch-15 lr: 0.0012481172855459861
epoch 15 training time: 16.624
---------------
2023-09-23 21:17:51.362962
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04008	Per Sample Data Time 0.02983	Per Sample DNN Time 0.01025	Train Loss 0.1608	
start validation
acc: 0.842105
AUC: 0.879959
Avg Precision: 0.334810
Avg Recall: 1.000000
d_prime: 1.661395
train_loss: 0.123830
valid_loss: 1.146243
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0006240586427729931
Epoch-16 lr: 0.0012481172855459861
epoch 16 training time: 16.625
---------------
2023-09-23 21:18:07.988257
current #epochs=17, #steps=640
start validation
acc: 0.837321
AUC: 0.871298
Avg Precision: 0.314110
Avg Recall: 1.000000
d_prime: 1.601665
train_loss: 0.115921
valid_loss: 1.158409
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0006240586427729931
Epoch-17 lr: 0.0012481172855459861
epoch 17 training time: 15.428
---------------
2023-09-23 21:18:23.416457
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00564	Train Loss 0.1385	
start validation
acc: 0.803828
AUC: 0.863134
Avg Precision: 0.309408
Avg Recall: 1.000000
d_prime: 1.547871
train_loss: 0.138316
valid_loss: 1.165910
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0006240586427729931
Epoch-18 lr: 0.0012481172855459861
epoch 18 training time: 15.284
---------------
2023-09-23 21:18:38.700473
current #epochs=19, #steps=720
start validation
acc: 0.842105
AUC: 0.874362
Avg Precision: 0.348099
Avg Recall: 1.000000
d_prime: 1.622464
train_loss: 0.140073
valid_loss: 1.143814
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0003801284558485351
Epoch-19 lr: 0.0007602569116970702
epoch 19 training time: 15.382
---------------
2023-09-23 21:18:54.082607
current #epochs=20, #steps=760
start validation
acc: 0.832536
AUC: 0.869970
Avg Precision: 0.313705
Avg Recall: 1.000000
d_prime: 1.592757
train_loss: 0.150760
valid_loss: 1.156162
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0003801284558485351
Epoch-20 lr: 0.0007602569116970702
epoch 20 training time: 15.354
---------------
2023-09-23 21:19:09.436054
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04093	Per Sample Data Time 0.03146	Per Sample DNN Time 0.00946	Train Loss 0.0267	
start validation
acc: 0.832536
AUC: 0.880992
Avg Precision: 0.327855
Avg Recall: 1.000000
d_prime: 1.668715
train_loss: 0.107874
valid_loss: 1.146402
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0003801284558485351
Epoch-21 lr: 0.0007602569116970702
epoch 21 training time: 15.387
---------------
2023-09-23 21:19:24.823386
current #epochs=22, #steps=840
start validation
acc: 0.842105
AUC: 0.876693
Avg Precision: 0.316919
Avg Recall: 1.000000
d_prime: 1.638527
train_loss: 0.111163
valid_loss: 1.158874
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0003801284558485351
Epoch-22 lr: 0.0007602569116970702
epoch 22 training time: 15.465
---------------
2023-09-23 21:19:40.288934
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00565	Train Loss 0.1192	
start validation
acc: 0.861244
AUC: 0.875614
Avg Precision: 0.329285
Avg Recall: 1.000000
d_prime: 1.631064
train_loss: 0.111460
valid_loss: 1.148700
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0003801284558485351
Epoch-23 lr: 0.0007602569116970702
epoch 23 training time: 17.737
---------------
2023-09-23 21:19:58.025662
current #epochs=24, #steps=920
start validation
acc: 0.856459
AUC: 0.874113
Avg Precision: 0.330675
Avg Recall: 1.000000
d_prime: 1.620762
train_loss: 0.126154
valid_loss: 1.143770
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0003801284558485351
Epoch-24 lr: 0.0007602569116970702
epoch 24 training time: 15.376
---------------
2023-09-23 21:20:13.401185
current #epochs=25, #steps=960
start validation
acc: 0.822967
AUC: 0.875490
Avg Precision: 0.311210
Avg Recall: 1.000000
d_prime: 1.630211
train_loss: 0.095954
valid_loss: 1.155096
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.0003801284558485351
Epoch-25 lr: 0.0007602569116970702
epoch 25 training time: 15.337
---------------
2023-09-23 21:20:28.738316
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.03988	Per Sample Data Time 0.03099	Per Sample DNN Time 0.00889	Train Loss 0.0756	
start validation
acc: 0.837321
AUC: 0.870784
Avg Precision: 0.310322
Avg Recall: 1.000000
d_prime: 1.598212
train_loss: 0.111294
valid_loss: 1.151762
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.00023154497517047291
Epoch-26 lr: 0.00046308995034094583
epoch 26 training time: 15.347
---------------
2023-09-23 21:20:44.086045
current #epochs=27, #steps=1040
start validation
acc: 0.846890
AUC: 0.874922
Avg Precision: 0.314446
Avg Recall: 1.000000
d_prime: 1.626306
train_loss: 0.100370
valid_loss: 1.151403
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.00023154497517047291
Epoch-27 lr: 0.00046308995034094583
epoch 27 training time: 15.321
---------------
2023-09-23 21:20:59.407140
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00705	Per Sample Data Time 0.00152	Per Sample DNN Time 0.00554	Train Loss 0.1111	
start validation
acc: 0.856459
AUC: 0.872374
Avg Precision: 0.326037
Avg Recall: 1.000000
d_prime: 1.608926
train_loss: 0.111859
valid_loss: 1.140284
validation finished
normal learning rate scheduler step
Epoch-28 lr: 0.00023154497517047291
Epoch-28 lr: 0.00046308995034094583
epoch 28 training time: 15.221
---------------
2023-09-23 21:21:14.627995
current #epochs=29, #steps=1120
start validation
acc: 0.837321
AUC: 0.875055
Avg Precision: 0.321512
Avg Recall: 1.000000
d_prime: 1.627221
train_loss: 0.113454
valid_loss: 1.154060
validation finished
normal learning rate scheduler step
Epoch-29 lr: 0.00023154497517047291
Epoch-29 lr: 0.00046308995034094583
epoch 29 training time: 15.439
---------------
2023-09-23 21:21:30.067189
current #epochs=30, #steps=1160
start validation
acc: 0.842105
AUC: 0.876234
Avg Precision: 0.320264
Avg Recall: 1.000000
d_prime: 1.635345
train_loss: 0.124295
valid_loss: 1.149489
validation finished
normal learning rate scheduler step
Epoch-30 lr: 0.00023154497517047291
Epoch-30 lr: 0.00046308995034094583
epoch 30 training time: 15.504
---------------
2023-09-23 21:21:45.571005
current #epochs=31, #steps=1200
Epoch: [31][0/40]	Per Sample Total Time 0.04068	Per Sample Data Time 0.03014	Per Sample DNN Time 0.01054	Train Loss 0.2361	
start validation
acc: 0.832536
AUC: 0.869731
Avg Precision: 0.312149
Avg Recall: 1.000000
d_prime: 1.591160
train_loss: 0.121387
valid_loss: 1.159890
validation finished
normal learning rate scheduler step
Epoch-31 lr: 0.00023154497517047291
Epoch-31 lr: 0.00046308995034094583
epoch 31 training time: 15.382
---------------
2023-09-23 21:22:00.952615
current #epochs=32, #steps=1240
start validation
acc: 0.842105
AUC: 0.862419
Avg Precision: 0.313249
Avg Recall: 1.000000
d_prime: 1.543261
train_loss: 0.113627
valid_loss: 1.149965
validation finished
normal learning rate scheduler step
Epoch-32 lr: 0.00023154497517047291
Epoch-32 lr: 0.00046308995034094583
epoch 32 training time: 15.611
---------------
2023-09-23 21:22:16.563794
current #epochs=33, #steps=1280
Epoch: [33][20/40]	Per Sample Total Time 0.00723	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00568	Train Loss 0.0897	
start validation
acc: 0.832536
AUC: 0.865597
Avg Precision: 0.319818
Avg Recall: 1.000000
d_prime: 1.563857
train_loss: 0.099141
valid_loss: 1.148931
validation finished
normal learning rate scheduler step
Epoch-33 lr: 0.00014103936367251975
Epoch-33 lr: 0.0002820787273450395
epoch 33 training time: 15.397
---------------
2023-09-23 21:22:31.960793
current #epochs=34, #steps=1320
start validation
acc: 0.827751
AUC: 0.865528
Avg Precision: 0.314086
Avg Recall: 1.000000
d_prime: 1.563409
train_loss: 0.102985
valid_loss: 1.156215
validation finished
normal learning rate scheduler step
Epoch-34 lr: 0.00014103936367251975
Epoch-34 lr: 0.0002820787273450395
epoch 34 training time: 15.568
---------------
2023-09-23 21:22:47.528764
current #epochs=35, #steps=1360
start validation
acc: 0.842105
AUC: 0.873279
Avg Precision: 0.323312
Avg Recall: 1.000000
d_prime: 1.615074
train_loss: 0.117189
valid_loss: 1.142800
validation finished
normal learning rate scheduler step
Epoch-35 lr: 0.00014103936367251975
Epoch-35 lr: 0.0002820787273450395
epoch 35 training time: 15.341
---------------
2023-09-23 21:23:02.869518
current #epochs=36, #steps=1400
Epoch: [36][0/40]	Per Sample Total Time 0.04048	Per Sample Data Time 0.03067	Per Sample DNN Time 0.00981	Train Loss 0.1493	
start validation
[I 2023-09-23 21:23:18,334] Trial 21 finished with value: 0.3120300300069853 and parameters: {'warmup': 'True', 'num_epochs': 36, 'batch_size': 51, 'lr-adaptschedule': 'False', 'lr': 0.0016819591499791422, 'head-lr': 2, 'lr-scheduler-start': 5, 'lr-scheduler-step': 7, 'lr-scheduler-decay': 0.609122973058175}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.837321
AUC: 0.873046
Avg Precision: 0.312030
Avg Recall: 1.000000
d_prime: 1.613490
train_loss: 0.111061
valid_loss: 1.149696
validation finished
normal learning rate scheduler step
Epoch-36 lr: 0.00014103936367251975
Epoch-36 lr: 0.0002820787273450395
epoch 36 training time: 15.460
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 2 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0a6854f0>
The learning rate scheduler starts at 4 epoch with decay rate of 0.603 every 7 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 21:23:18.368062
current #epochs=1, #steps=0
start validation
acc: 0.803828
AUC: 0.820916
Avg Precision: 0.320021
Avg Recall: 1.000000
d_prime: 1.299469
train_loss: 0.186651
valid_loss: 1.150674
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0016421351074531005
Epoch-1 lr: 0.003284270214906201
epoch 1 training time: 17.721
---------------
2023-09-23 21:23:36.089244
current #epochs=2, #steps=40
start validation
acc: 0.822967
AUC: 0.846760
Avg Precision: 0.309063
Avg Recall: 1.000000
d_prime: 1.446225
train_loss: 0.154991
valid_loss: 1.128444
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0016421351074531005
Epoch-2 lr: 0.003284270214906201
epoch 2 training time: 17.731
---------------
2023-09-23 21:23:53.820101
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00711	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00556	Train Loss 0.1666	
start validation
acc: 0.837321
AUC: 0.853016
Avg Precision: 0.332399
Avg Recall: 1.000000
d_prime: 1.484158
train_loss: 0.183276
valid_loss: 1.142426
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0016421351074531005
Epoch-3 lr: 0.003284270214906201
epoch 3 training time: 17.724
---------------
2023-09-23 21:24:11.544265
current #epochs=4, #steps=120
start validation
acc: 0.837321
AUC: 0.851983
Avg Precision: 0.322028
Avg Recall: 1.000000
d_prime: 1.477820
train_loss: 0.175665
valid_loss: 1.144392
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.000990350585209406
Epoch-4 lr: 0.001980701170418812
epoch 4 training time: 15.405
---------------
2023-09-23 21:24:26.948791
current #epochs=5, #steps=160
start validation
acc: 0.832536
AUC: 0.855274
Avg Precision: 0.321461
Avg Recall: 1.000000
d_prime: 1.498112
train_loss: 0.160146
valid_loss: 1.158200
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.000990350585209406
Epoch-5 lr: 0.001980701170418812
epoch 5 training time: 15.272
---------------
2023-09-23 21:24:42.221054
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04173	Per Sample Data Time 0.03214	Per Sample DNN Time 0.00959	Train Loss 0.2157	
start validation
acc: 0.837321
AUC: 0.860273
Avg Precision: 0.339596
Avg Recall: 1.000000
d_prime: 1.529538
train_loss: 0.155701
valid_loss: 1.148358
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.000990350585209406
Epoch-6 lr: 0.001980701170418812
epoch 6 training time: 15.418
---------------
2023-09-23 21:24:57.639287
current #epochs=7, #steps=240
start validation
acc: 0.799043
AUC: 0.835799
Avg Precision: 0.304103
Avg Recall: 1.000000
d_prime: 1.382164
train_loss: 0.146327
valid_loss: 1.157608
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.000990350585209406
Epoch-7 lr: 0.001980701170418812
epoch 7 training time: 15.333
---------------
2023-09-23 21:25:12.972612
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00557	Train Loss 0.1109	
start validation
acc: 0.822967
AUC: 0.870706
Avg Precision: 0.333716
Avg Recall: 1.000000
d_prime: 1.597688
train_loss: 0.104922
valid_loss: 1.147285
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.000990350585209406
Epoch-8 lr: 0.001980701170418812
epoch 8 training time: 15.332
---------------
2023-09-23 21:25:28.304339
current #epochs=9, #steps=320
start validation
acc: 0.822967
AUC: 0.872011
Avg Precision: 0.328077
Avg Recall: 1.000000
d_prime: 1.606474
train_loss: 0.120807
valid_loss: 1.142154
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.000990350585209406
Epoch-9 lr: 0.001980701170418812
epoch 9 training time: 15.406
---------------
2023-09-23 21:25:43.710625
current #epochs=10, #steps=360
start validation
acc: 0.832536
AUC: 0.852166
Avg Precision: 0.327392
Avg Recall: 1.000000
d_prime: 1.478943
train_loss: 0.142169
valid_loss: 1.139081
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.000990350585209406
Epoch-10 lr: 0.001980701170418812
epoch 10 training time: 15.435
---------------
2023-09-23 21:25:59.145339
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04051	Per Sample Data Time 0.03071	Per Sample DNN Time 0.00980	Train Loss 0.1670	
start validation
acc: 0.837321
AUC: 0.854330
Avg Precision: 0.311793
Avg Recall: 1.000000
d_prime: 1.492256
train_loss: 0.125279
valid_loss: 1.138520
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0005972677139494288
Epoch-11 lr: 0.0011945354278988577
epoch 11 training time: 16.239
---------------
2023-09-23 21:26:15.384943
current #epochs=12, #steps=440
start validation
acc: 0.842105
AUC: 0.865026
Avg Precision: 0.310089
Avg Recall: 1.000000
d_prime: 1.560132
train_loss: 0.132065
valid_loss: 1.139480
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0005972677139494288
Epoch-12 lr: 0.0011945354278988577
epoch 12 training time: 17.915
---------------
2023-09-23 21:26:33.299605
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00563	Train Loss 0.1216	
start validation
acc: 0.842105
AUC: 0.847552
Avg Precision: 0.321052
Avg Recall: 1.000000
d_prime: 1.450972
train_loss: 0.114924
valid_loss: 1.153291
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0005972677139494288
Epoch-13 lr: 0.0011945354278988577
epoch 13 training time: 15.270
---------------
2023-09-23 21:26:48.569657
current #epochs=14, #steps=520
start validation
acc: 0.827751
AUC: 0.862093
Avg Precision: 0.318374
Avg Recall: 1.000000
d_prime: 1.541167
train_loss: 0.126381
valid_loss: 1.149051
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0005972677139494288
Epoch-14 lr: 0.0011945354278988577
epoch 14 training time: 16.083
---------------
2023-09-23 21:27:04.652515
current #epochs=15, #steps=560
start validation
acc: 0.799043
AUC: 0.866009
Avg Precision: 0.303417
Avg Recall: 1.000000
d_prime: 1.566554
train_loss: 0.100800
valid_loss: 1.155157
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0005972677139494288
Epoch-15 lr: 0.0011945354278988577
epoch 15 training time: 15.510
---------------
2023-09-23 21:27:20.162746
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03745	Per Sample Data Time 0.02985	Per Sample DNN Time 0.00760	Train Loss 0.1230	
start validation
acc: 0.832536
AUC: 0.854580
Avg Precision: 0.318854
Avg Recall: 1.000000
d_prime: 1.493807
train_loss: 0.109009
valid_loss: 1.154314
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0005972677139494288
Epoch-16 lr: 0.0011945354278988577
epoch 16 training time: 16.275
---------------
2023-09-23 21:27:36.437567
current #epochs=17, #steps=640
start validation
acc: 0.818182
AUC: 0.866031
Avg Precision: 0.324301
Avg Recall: 1.000000
d_prime: 1.566701
train_loss: 0.106745
valid_loss: 1.141890
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0005972677139494288
Epoch-17 lr: 0.0011945354278988577
epoch 17 training time: 15.248
---------------
2023-09-23 21:27:51.685717
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00733	Per Sample Data Time 0.00170	Per Sample DNN Time 0.00563	Train Loss 0.1272	
start validation
acc: 0.794258
AUC: 0.850439
Avg Precision: 0.314469
Avg Recall: 1.000000
d_prime: 1.468402
train_loss: 0.120773
valid_loss: 1.172702
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0003602044846077894
Epoch-18 lr: 0.0007204089692155789
epoch 18 training time: 15.618
---------------
2023-09-23 21:28:07.303493
current #epochs=19, #steps=720
start validation
acc: 0.837321
AUC: 0.864884
Avg Precision: 0.335248
Avg Recall: 1.000000
d_prime: 1.559213
train_loss: 0.109217
valid_loss: 1.144338
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0003602044846077894
Epoch-19 lr: 0.0007204089692155789
epoch 19 training time: 15.372
---------------
2023-09-23 21:28:22.675539
current #epochs=20, #steps=760
start validation
acc: 0.837321
AUC: 0.865175
Avg Precision: 0.317970
Avg Recall: 1.000000
d_prime: 1.561106
train_loss: 0.091828
valid_loss: 1.144505
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0003602044846077894
Epoch-20 lr: 0.0007204089692155789
epoch 20 training time: 15.391
---------------
2023-09-23 21:28:38.066300
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04178	Per Sample Data Time 0.03233	Per Sample DNN Time 0.00945	Train Loss 0.0496	
start validation
acc: 0.837321
AUC: 0.874359
Avg Precision: 0.317154
Avg Recall: 1.000000
d_prime: 1.622441
train_loss: 0.081201
valid_loss: 1.137019
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0003602044846077894
Epoch-21 lr: 0.0007204089692155789
epoch 21 training time: 15.537
---------------
2023-09-23 21:28:53.603073
current #epochs=22, #steps=840
start validation
acc: 0.827751
AUC: 0.865416
Avg Precision: 0.317463
Avg Recall: 1.000000
d_prime: 1.562675
train_loss: 0.101281
valid_loss: 1.138069
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0003602044846077894
Epoch-22 lr: 0.0007204089692155789
epoch 22 training time: 16.609
---------------
2023-09-23 21:29:10.212346
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00723	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00565	Train Loss 0.1161	
start validation
acc: 0.803828
AUC: 0.866253
Avg Precision: 0.320201
Avg Recall: 1.000000
d_prime: 1.568154
train_loss: 0.117043
valid_loss: 1.154106
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0003602044846077894
Epoch-23 lr: 0.0007204089692155789
epoch 23 training time: 15.316
---------------
2023-09-23 21:29:25.528529
current #epochs=24, #steps=920
start validation
acc: 0.822967
AUC: 0.868341
Avg Precision: 0.328537
Avg Recall: 1.000000
d_prime: 1.581915
train_loss: 0.105574
valid_loss: 1.133864
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0003602044846077894
Epoch-24 lr: 0.0007204089692155789
epoch 24 training time: 15.396
---------------
2023-09-23 21:29:40.925034
current #epochs=25, #steps=960
start validation
acc: 0.818182
AUC: 0.866525
Avg Precision: 0.324196
Avg Recall: 1.000000
d_prime: 1.569938
train_loss: 0.103003
valid_loss: 1.157664
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.0002172346967720894
Epoch-25 lr: 0.0004344693935441788
epoch 25 training time: 15.489
---------------
2023-09-23 21:29:56.413766
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.04069	Per Sample Data Time 0.03106	Per Sample DNN Time 0.00962	Train Loss 0.0471	
start validation
acc: 0.837321
AUC: 0.861866
Avg Precision: 0.327943
Avg Recall: 1.000000
d_prime: 1.539711
train_loss: 0.111395
valid_loss: 1.142005
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.0002172346967720894
Epoch-26 lr: 0.0004344693935441788
epoch 26 training time: 15.413
---------------
2023-09-23 21:30:11.826247
current #epochs=27, #steps=1040
start validation
acc: 0.803828
AUC: 0.861799
Avg Precision: 0.321071
Avg Recall: 1.000000
d_prime: 1.539283
train_loss: 0.107379
valid_loss: 1.159855
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.0002172346967720894
Epoch-27 lr: 0.0004344693935441788
epoch 27 training time: 15.496
---------------
2023-09-23 21:30:27.321955
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00730	Per Sample Data Time 0.00165	Per Sample DNN Time 0.00564	Train Loss 0.0946	
start validation
acc: 0.822967
AUC: 0.859751
Avg Precision: 0.324599
Avg Recall: 1.000000
d_prime: 1.526224
train_loss: 0.094182
valid_loss: 1.147364
validation finished
normal learning rate scheduler step
Epoch-28 lr: 0.0002172346967720894
Epoch-28 lr: 0.0004344693935441788
epoch 28 training time: 15.568
---------------
2023-09-23 21:30:42.890696
current #epochs=29, #steps=1120
start validation
acc: 0.822967
AUC: 0.856119
Avg Precision: 0.330621
Avg Recall: 1.000000
d_prime: 1.503369
train_loss: 0.098434
valid_loss: 1.158980
validation finished
normal learning rate scheduler step
Epoch-29 lr: 0.0002172346967720894
Epoch-29 lr: 0.0004344693935441788
epoch 29 training time: 15.390
---------------
2023-09-23 21:30:58.280768
current #epochs=30, #steps=1160
start validation
acc: 0.818182
AUC: 0.849343
Avg Precision: 0.318433
Avg Recall: 1.000000
d_prime: 1.461759
train_loss: 0.102160
valid_loss: 1.169801
validation finished
normal learning rate scheduler step
Epoch-30 lr: 0.0002172346967720894
Epoch-30 lr: 0.0004344693935441788
epoch 30 training time: 15.373
---------------
2023-09-23 21:31:13.653396
current #epochs=31, #steps=1200
Epoch: [31][0/40]	Per Sample Total Time 0.03975	Per Sample Data Time 0.03044	Per Sample DNN Time 0.00931	Train Loss 0.2703	
start validation
acc: 0.813397
AUC: 0.861503
Avg Precision: 0.326098
Avg Recall: 1.000000
d_prime: 1.537389
train_loss: 0.092846
valid_loss: 1.153832
validation finished
normal learning rate scheduler step
Epoch-31 lr: 0.0002172346967720894
Epoch-31 lr: 0.0004344693935441788
epoch 31 training time: 18.108
---------------
2023-09-23 21:31:31.761362
current #epochs=32, #steps=1240
start validation
acc: 0.822967
AUC: 0.859632
Avg Precision: 0.326060
Avg Recall: 1.000000
d_prime: 1.525466
train_loss: 0.120522
valid_loss: 1.150856
validation finished
normal learning rate scheduler step
Epoch-32 lr: 0.00013101145459931102
Epoch-32 lr: 0.00026202290919862204
epoch 32 training time: 15.532
---------------
2023-09-23 21:31:47.293208
current #epochs=33, #steps=1280
Epoch: [33][20/40]	Per Sample Total Time 0.00728	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00566	Train Loss 0.0953	
start validation
acc: 0.827751
AUC: 0.859815
Avg Precision: 0.328507
Avg Recall: 1.000000
d_prime: 1.526627
train_loss: 0.104620
valid_loss: 1.149534
validation finished
normal learning rate scheduler step
Epoch-33 lr: 0.00013101145459931102
Epoch-33 lr: 0.00026202290919862204
epoch 33 training time: 15.490
---------------
2023-09-23 21:32:02.783165
current #epochs=34, #steps=1320
start validation
acc: 0.818182
AUC: 0.864960
Avg Precision: 0.329038
Avg Recall: 1.000000
d_prime: 1.559703
train_loss: 0.121776
valid_loss: 1.146512
validation finished
normal learning rate scheduler step
Epoch-34 lr: 0.00013101145459931102
Epoch-34 lr: 0.00026202290919862204
epoch 34 training time: 15.473
---------------
2023-09-23 21:32:18.256654
current #epochs=35, #steps=1360
start validation
acc: 0.822967
AUC: 0.864262
Avg Precision: 0.328637
Avg Recall: 1.000000
d_prime: 1.555166
train_loss: 0.102234
valid_loss: 1.142832
validation finished
normal learning rate scheduler step
Epoch-35 lr: 0.00013101145459931102
Epoch-35 lr: 0.00026202290919862204
epoch 35 training time: 15.425
---------------
2023-09-23 21:32:33.681070
current #epochs=36, #steps=1400
Epoch: [36][0/40]	Per Sample Total Time 0.03961	Per Sample Data Time 0.02968	Per Sample DNN Time 0.00992	Train Loss 0.0788	
start validation
acc: 0.813397
AUC: 0.868104
Avg Precision: 0.330221
Avg Recall: 1.000000
d_prime: 1.580343
train_loss: 0.079893
valid_loss: 1.146937
validation finished
normal learning rate scheduler step
Epoch-36 lr: 0.00013101145459931102
Epoch-36 lr: 0.00026202290919862204
epoch 36 training time: 15.338
---------------
2023-09-23 21:32:49.019208
current #epochs=37, #steps=1440
start validation
acc: 0.827751
AUC: 0.863602
Avg Precision: 0.326164
Avg Recall: 1.000000
d_prime: 1.550894
train_loss: 0.096862
valid_loss: 1.151370
validation finished
normal learning rate scheduler step
Epoch-37 lr: 0.00013101145459931102
Epoch-37 lr: 0.00026202290919862204
epoch 37 training time: 15.450
---------------
2023-09-23 21:33:04.469088
current #epochs=38, #steps=1480
Epoch: [38][20/40]	Per Sample Total Time 0.00725	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00570	Train Loss 0.0919	
start validation
acc: 0.822967
AUC: 0.866174
Avg Precision: 0.324944
Avg Recall: 1.000000
d_prime: 1.567636
train_loss: 0.095688
valid_loss: 1.156327
validation finished
normal learning rate scheduler step
Epoch-38 lr: 0.00013101145459931102
Epoch-38 lr: 0.00026202290919862204
epoch 38 training time: 16.229
---------------
2023-09-23 21:33:20.697708
current #epochs=39, #steps=1520
start validation
acc: 0.818182
AUC: 0.869652
Avg Precision: 0.323210
Avg Recall: 1.000000
d_prime: 1.590632
train_loss: 0.089764
valid_loss: 1.157429
validation finished
normal learning rate scheduler step
Epoch-39 lr: 7.90113250381676e-05
Epoch-39 lr: 0.0001580226500763352
epoch 39 training time: 15.384
---------------
2023-09-23 21:33:36.081251
current #epochs=40, #steps=1560
start validation
acc: 0.832536
AUC: 0.867259
Avg Precision: 0.325984
Avg Recall: 1.000000
d_prime: 1.574764
train_loss: 0.090227
valid_loss: 1.153252
validation finished
normal learning rate scheduler step
Epoch-40 lr: 7.90113250381676e-05
Epoch-40 lr: 0.0001580226500763352
epoch 40 training time: 15.391
---------------
2023-09-23 21:33:51.472549
current #epochs=41, #steps=1600
Epoch: [41][0/40]	Per Sample Total Time 0.04071	Per Sample Data Time 0.03060	Per Sample DNN Time 0.01011	Train Loss 0.0953	
start validation
acc: 0.837321
AUC: 0.867105
Avg Precision: 0.325754
Avg Recall: 1.000000
d_prime: 1.573753
train_loss: 0.094947
valid_loss: 1.154816
validation finished
normal learning rate scheduler step
Epoch-41 lr: 7.90113250381676e-05
Epoch-41 lr: 0.0001580226500763352
epoch 41 training time: 15.499
---------------
2023-09-23 21:34:06.972134
current #epochs=42, #steps=1640
start validation
acc: 0.827751
AUC: 0.866822
Avg Precision: 0.326330
Avg Recall: 1.000000
d_prime: 1.571891
train_loss: 0.115111
valid_loss: 1.151174
validation finished
normal learning rate scheduler step
Epoch-42 lr: 7.90113250381676e-05
Epoch-42 lr: 0.0001580226500763352
epoch 42 training time: 15.430
---------------
2023-09-23 21:34:22.401495
current #epochs=43, #steps=1680
Epoch: [43][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00566	Train Loss 0.1106	
start validation
[I 2023-09-23 21:34:37,818] Trial 22 finished with value: 0.32748304358876257 and parameters: {'warmup': 'True', 'num_epochs': 43, 'batch_size': 64, 'lr-adaptschedule': 'False', 'lr': 0.0016421351074531005, 'head-lr': 2, 'lr-scheduler-start': 4, 'lr-scheduler-step': 7, 'lr-scheduler-decay': 0.6030871520342856}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.827751
AUC: 0.866245
Avg Precision: 0.327483
Avg Recall: 1.000000
d_prime: 1.568104
train_loss: 0.103273
valid_loss: 1.152074
validation finished
normal learning rate scheduler step
Epoch-43 lr: 7.90113250381676e-05
Epoch-43 lr: 0.0001580226500763352
epoch 43 training time: 15.410
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 1 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0a6f3ee0>
The learning rate scheduler starts at 6 epoch with decay rate of 0.645 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 21:34:37.854966
current #epochs=1, #steps=0
start validation
acc: 0.818182
AUC: 0.874164
Avg Precision: 0.351077
Avg Recall: 1.000000
d_prime: 1.621108
train_loss: 0.211746
valid_loss: 1.126838
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.002122233379790386
Epoch-1 lr: 0.002122233379790386
epoch 1 training time: 18.699
---------------
2023-09-23 21:34:56.553628
current #epochs=2, #steps=40
start validation
acc: 0.837321
AUC: 0.851917
Avg Precision: 0.316107
Avg Recall: 1.000000
d_prime: 1.477417
train_loss: 0.203586
valid_loss: 1.137886
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.002122233379790386
Epoch-2 lr: 0.002122233379790386
epoch 2 training time: 17.748
---------------
2023-09-23 21:35:14.301159
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00554	Train Loss 0.1850	
start validation
acc: 0.846890
AUC: 0.878608
Avg Precision: 0.344286
Avg Recall: 1.000000
d_prime: 1.651883
train_loss: 0.191772
valid_loss: 1.143190
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.002122233379790386
Epoch-3 lr: 0.002122233379790386
epoch 3 training time: 18.261
---------------
2023-09-23 21:35:32.562757
current #epochs=4, #steps=120
start validation
acc: 0.746411
AUC: 0.855840
Avg Precision: 0.289271
Avg Recall: 1.000000
d_prime: 1.501632
train_loss: 0.198203
valid_loss: 1.162932
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.002122233379790386
Epoch-4 lr: 0.002122233379790386
epoch 4 training time: 15.345
---------------
2023-09-23 21:35:47.907129
current #epochs=5, #steps=160
start validation
acc: 0.818182
AUC: 0.852274
Avg Precision: 0.311613
Avg Recall: 1.000000
d_prime: 1.479602
train_loss: 0.286032
valid_loss: 1.148202
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.002122233379790386
Epoch-5 lr: 0.002122233379790386
epoch 5 training time: 15.485
---------------
2023-09-23 21:36:03.392690
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04108	Per Sample Data Time 0.03040	Per Sample DNN Time 0.01068	Train Loss 0.2378	
start validation
[I 2023-09-23 21:36:18,785] Trial 23 finished with value: 0.32312609138940773 and parameters: {'warmup': 'True', 'num_epochs': 6, 'batch_size': 38, 'lr-adaptschedule': 'False', 'lr': 0.002122233379790386, 'head-lr': 1, 'lr-scheduler-start': 6, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.6446836945853528}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.832536
AUC: 0.844748
Avg Precision: 0.323126
Avg Recall: 1.000000
d_prime: 1.434248
train_loss: 0.186933
valid_loss: 1.146385
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0013681692560556262
Epoch-6 lr: 0.0013681692560556262
epoch 6 training time: 15.387
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51db23d0>
The learning rate scheduler starts at 5 epoch with decay rate of 0.672 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 21:36:18.820859
current #epochs=1, #steps=0
start validation
acc: 0.827751
AUC: 0.867564
Avg Precision: 0.320045
Avg Recall: 1.000000
d_prime: 1.576775
train_loss: 0.165351
valid_loss: 1.133110
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0009069335035113887
Epoch-1 lr: 0.002720800510534166
epoch 1 training time: 17.788
---------------
2023-09-23 21:36:36.609273
current #epochs=2, #steps=40
start validation
acc: 0.827751
AUC: 0.867539
Avg Precision: 0.335671
Avg Recall: 1.000000
d_prime: 1.576612
train_loss: 0.148611
valid_loss: 1.120762
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0009069335035113887
Epoch-2 lr: 0.002720800510534166
epoch 2 training time: 15.464
---------------
2023-09-23 21:36:52.073466
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00558	Train Loss 0.1185	
start validation
acc: 0.808612
AUC: 0.854335
Avg Precision: 0.315109
Avg Recall: 1.000000
d_prime: 1.492290
train_loss: 0.126412
valid_loss: 1.142966
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0009069335035113887
Epoch-3 lr: 0.002720800510534166
epoch 3 training time: 15.384
---------------
2023-09-23 21:37:07.457564
current #epochs=4, #steps=120
start validation
acc: 0.794258
AUC: 0.852617
Avg Precision: 0.312819
Avg Recall: 1.000000
d_prime: 1.481707
train_loss: 0.160800
valid_loss: 1.152983
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0009069335035113887
Epoch-4 lr: 0.002720800510534166
epoch 4 training time: 15.312
---------------
2023-09-23 21:37:22.769647
current #epochs=5, #steps=160
start validation
acc: 0.827751
AUC: 0.871482
Avg Precision: 0.348738
Avg Recall: 1.000000
d_prime: 1.602906
train_loss: 0.122794
valid_loss: 1.116863
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0006091060737584056
Epoch-5 lr: 0.0018273182212752168
epoch 5 training time: 15.396
---------------
2023-09-23 21:37:38.165362
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03647	Per Sample Data Time 0.02976	Per Sample DNN Time 0.00671	Train Loss 0.1651	
start validation
acc: 0.837321
AUC: 0.865256
Avg Precision: 0.332323
Avg Recall: 1.000000
d_prime: 1.561633
train_loss: 0.122316
valid_loss: 1.117174
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0006091060737584056
Epoch-6 lr: 0.0018273182212752168
epoch 6 training time: 17.796
---------------
2023-09-23 21:37:55.961538
current #epochs=7, #steps=240
start validation
acc: 0.803828
AUC: 0.853664
Avg Precision: 0.307382
Avg Recall: 1.000000
d_prime: 1.488144
train_loss: 0.122169
valid_loss: 1.142001
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0006091060737584056
Epoch-7 lr: 0.0018273182212752168
epoch 7 training time: 15.357
---------------
2023-09-23 21:38:11.318970
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00557	Train Loss 0.1251	
start validation
acc: 0.827751
AUC: 0.870447
Avg Precision: 0.316466
Avg Recall: 1.000000
d_prime: 1.595948
train_loss: 0.142534
valid_loss: 1.127213
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0006091060737584056
Epoch-8 lr: 0.0018273182212752168
epoch 8 training time: 15.385
---------------
2023-09-23 21:38:26.703848
current #epochs=9, #steps=320
start validation
acc: 0.808612
AUC: 0.848408
Avg Precision: 0.306478
Avg Recall: 1.000000
d_prime: 1.456118
train_loss: 0.129215
valid_loss: 1.142984
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0006091060737584056
Epoch-9 lr: 0.0018273182212752168
epoch 9 training time: 15.573
---------------
2023-09-23 21:38:42.276957
current #epochs=10, #steps=360
start validation
acc: 0.832536
AUC: 0.862015
Avg Precision: 0.319070
Avg Recall: 1.000000
d_prime: 1.540667
train_loss: 0.125654
valid_loss: 1.122188
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0006091060737584056
Epoch-10 lr: 0.0018273182212752168
epoch 10 training time: 15.357
---------------
2023-09-23 21:38:57.633383
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03966	Per Sample Data Time 0.03232	Per Sample DNN Time 0.00734	Train Loss 0.1241	
start validation
acc: 0.837321
AUC: 0.862588
Avg Precision: 0.343153
Avg Recall: 1.000000
d_prime: 1.544353
train_loss: 0.123792
valid_loss: 1.124706
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0006091060737584056
Epoch-11 lr: 0.0018273182212752168
epoch 11 training time: 16.042
---------------
2023-09-23 21:39:13.675481
current #epochs=12, #steps=440
start validation
acc: 0.827751
AUC: 0.862110
Avg Precision: 0.311880
Avg Recall: 1.000000
d_prime: 1.541280
train_loss: 0.121831
valid_loss: 1.145480
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0006091060737584056
Epoch-12 lr: 0.0018273182212752168
epoch 12 training time: 15.242
---------------
2023-09-23 21:39:28.917392
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00154	Per Sample DNN Time 0.00566	Train Loss 0.1094	
start validation
acc: 0.837321
AUC: 0.869358
Avg Precision: 0.332284
Avg Recall: 1.000000
d_prime: 1.588671
train_loss: 0.114308
valid_loss: 1.119969
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0006091060737584056
Epoch-13 lr: 0.0018273182212752168
epoch 13 training time: 15.364
---------------
2023-09-23 21:39:44.281619
current #epochs=14, #steps=520
start validation
acc: 0.846890
AUC: 0.869072
Avg Precision: 0.316797
Avg Recall: 1.000000
d_prime: 1.586770
train_loss: 0.097320
valid_loss: 1.135735
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.00040908204146493013
Epoch-14 lr: 0.0012272461243947902
epoch 14 training time: 19.048
---------------
2023-09-23 21:40:03.329712
current #epochs=15, #steps=560
start validation
acc: 0.808612
AUC: 0.856195
Avg Precision: 0.305532
Avg Recall: 1.000000
d_prime: 1.503847
train_loss: 0.113841
valid_loss: 1.140251
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.00040908204146493013
Epoch-15 lr: 0.0012272461243947902
epoch 15 training time: 15.375
---------------
2023-09-23 21:40:18.704191
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04051	Per Sample Data Time 0.03178	Per Sample DNN Time 0.00873	Train Loss 0.0382	
start validation
acc: 0.827751
AUC: 0.862549
Avg Precision: 0.318786
Avg Recall: 1.000000
d_prime: 1.544099
train_loss: 0.094395
valid_loss: 1.150684
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.00040908204146493013
Epoch-16 lr: 0.0012272461243947902
epoch 16 training time: 16.812
---------------
2023-09-23 21:40:35.516733
current #epochs=17, #steps=640
start validation
acc: 0.808612
AUC: 0.863804
Avg Precision: 0.310929
Avg Recall: 1.000000
d_prime: 1.552202
train_loss: 0.107710
valid_loss: 1.141451
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.00040908204146493013
Epoch-17 lr: 0.0012272461243947902
epoch 17 training time: 15.399
---------------
2023-09-23 21:40:50.915546
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00558	Train Loss 0.1103	
start validation
[I 2023-09-23 21:41:06,248] Trial 24 finished with value: 0.3218768568033274 and parameters: {'warmup': 'True', 'num_epochs': 18, 'batch_size': 23, 'lr-adaptschedule': 'False', 'lr': 0.0009069335035113887, 'head-lr': 3, 'lr-scheduler-start': 5, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.6716105110243695}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.813397
AUC: 0.863196
Avg Precision: 0.321877
Avg Recall: 1.000000
d_prime: 1.548267
train_loss: 0.112463
valid_loss: 1.142967
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.00040908204146493013
Epoch-18 lr: 0.0012272461243947902
epoch 18 training time: 15.326
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 2 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51da2c40>
The learning rate scheduler starts at 7 epoch with decay rate of 0.640 every 6 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 21:41:06.281303
current #epochs=1, #steps=0
start validation
acc: 0.746411
AUC: 0.860575
Avg Precision: 0.309715
Avg Recall: 1.000000
d_prime: 1.531460
train_loss: 0.227514
valid_loss: 1.164647
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.00271489999732364
Epoch-1 lr: 0.00542979999464728
epoch 1 training time: 18.509
---------------
2023-09-23 21:41:24.790510
current #epochs=2, #steps=40
start validation
acc: 0.784689
AUC: 0.870449
Avg Precision: 0.331493
Avg Recall: 1.000000
d_prime: 1.595962
train_loss: 0.242980
valid_loss: 1.139906
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.00271489999732364
Epoch-2 lr: 0.00542979999464728
epoch 2 training time: 17.797
---------------
2023-09-23 21:41:42.587841
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00559	Train Loss 0.1783	
start validation
acc: 0.760766
AUC: 0.876413
Avg Precision: 0.333408
Avg Recall: 1.000000
d_prime: 1.636589
train_loss: 0.181799
valid_loss: 1.158844
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.00271489999732364
Epoch-3 lr: 0.00542979999464728
epoch 3 training time: 15.467
---------------
2023-09-23 21:41:58.055298
current #epochs=4, #steps=120
start validation
acc: 0.832536
AUC: 0.862283
Avg Precision: 0.317735
Avg Recall: 1.000000
d_prime: 1.542389
train_loss: 0.174491
valid_loss: 1.145682
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.00271489999732364
Epoch-4 lr: 0.00542979999464728
epoch 4 training time: 17.685
---------------
2023-09-23 21:42:15.739926
current #epochs=5, #steps=160
start validation
acc: 0.775120
AUC: 0.867291
Avg Precision: 0.305915
Avg Recall: 1.000000
d_prime: 1.574974
train_loss: 0.235707
valid_loss: 1.174450
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.00271489999732364
Epoch-5 lr: 0.00542979999464728
epoch 5 training time: 15.334
---------------
2023-09-23 21:42:31.074125
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03878	Per Sample Data Time 0.03135	Per Sample DNN Time 0.00743	Train Loss 0.1076	
start validation
acc: 0.822967
AUC: 0.840187
Avg Precision: 0.316333
Avg Recall: 1.000000
d_prime: 1.407465
train_loss: 0.189708
valid_loss: 1.184854
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.00271489999732364
Epoch-6 lr: 0.00542979999464728
epoch 6 training time: 15.373
---------------
2023-09-23 21:42:46.447806
current #epochs=7, #steps=240
start validation
acc: 0.760766
AUC: 0.863576
Avg Precision: 0.314395
Avg Recall: 1.000000
d_prime: 1.550724
train_loss: 0.210189
valid_loss: 1.177237
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0017369043848795235
Epoch-7 lr: 0.003473808769759047
epoch 7 training time: 17.284
---------------
2023-09-23 21:43:03.731600
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00557	Train Loss 0.1762	
start validation
acc: 0.789474
AUC: 0.857604
Avg Precision: 0.305379
Avg Recall: 1.000000
d_prime: 1.512666
train_loss: 0.175761
valid_loss: 1.164798
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0017369043848795235
Epoch-8 lr: 0.003473808769759047
epoch 8 training time: 15.386
---------------
2023-09-23 21:43:19.117276
current #epochs=9, #steps=320
start validation
acc: 0.822967
AUC: 0.885054
Avg Precision: 0.338072
Avg Recall: 1.000000
d_prime: 1.697955
train_loss: 0.170640
valid_loss: 1.132839
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0017369043848795235
Epoch-9 lr: 0.003473808769759047
epoch 9 training time: 15.340
---------------
2023-09-23 21:43:34.457499
current #epochs=10, #steps=360
start validation
acc: 0.856459
AUC: 0.876070
Avg Precision: 0.319041
Avg Recall: 1.000000
d_prime: 1.634212
train_loss: 0.140996
valid_loss: 1.130234
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0017369043848795235
Epoch-10 lr: 0.003473808769759047
epoch 10 training time: 18.368
---------------
2023-09-23 21:43:52.825712
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03839	Per Sample Data Time 0.03042	Per Sample DNN Time 0.00796	Train Loss 0.1756	
start validation
acc: 0.832536
AUC: 0.875189
Avg Precision: 0.314397
Avg Recall: 1.000000
d_prime: 1.628136
train_loss: 0.126958
valid_loss: 1.136549
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0017369043848795235
Epoch-11 lr: 0.003473808769759047
epoch 11 training time: 15.430
---------------
2023-09-23 21:44:08.256045
current #epochs=12, #steps=440
start validation
acc: 0.813397
AUC: 0.891497
Avg Precision: 0.339525
Avg Recall: 1.000000
d_prime: 1.745884
train_loss: 0.152159
valid_loss: 1.129978
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0017369043848795235
Epoch-12 lr: 0.003473808769759047
epoch 12 training time: 15.268
---------------
2023-09-23 21:44:23.524168
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00707	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00550	Train Loss 0.1606	
start validation
acc: 0.822967
AUC: 0.869196
Avg Precision: 0.328728
Avg Recall: 1.000000
d_prime: 1.587596
train_loss: 0.153030
valid_loss: 1.129161
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0011112147206850072
Epoch-13 lr: 0.0022224294413700145
epoch 13 training time: 15.233
---------------
2023-09-23 21:44:38.757329
current #epochs=14, #steps=520
start validation
acc: 0.818182
AUC: 0.892745
Avg Precision: 0.316996
Avg Recall: 1.000000
d_prime: 1.755406
train_loss: 0.122701
valid_loss: 1.103210
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0011112147206850072
Epoch-14 lr: 0.0022224294413700145
epoch 14 training time: 15.383
---------------
2023-09-23 21:44:54.139827
current #epochs=15, #steps=560
start validation
acc: 0.818182
AUC: 0.883398
Avg Precision: 0.356264
Avg Recall: 1.000000
d_prime: 1.685948
train_loss: 0.153520
valid_loss: 1.120841
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0011112147206850072
Epoch-15 lr: 0.0022224294413700145
epoch 15 training time: 15.386
---------------
2023-09-23 21:45:09.526105
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03756	Per Sample Data Time 0.02987	Per Sample DNN Time 0.00769	Train Loss 0.1456	
start validation
acc: 0.832536
AUC: 0.872657
Avg Precision: 0.330754
Avg Recall: 1.000000
d_prime: 1.610845
train_loss: 0.139098
valid_loss: 1.124991
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0011112147206850072
Epoch-16 lr: 0.0022224294413700145
epoch 16 training time: 15.274
---------------
2023-09-23 21:45:24.800010
current #epochs=17, #steps=640
start validation
acc: 0.827751
AUC: 0.882040
Avg Precision: 0.386138
Avg Recall: 1.000000
d_prime: 1.676193
train_loss: 0.148414
valid_loss: 1.122708
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0011112147206850072
Epoch-17 lr: 0.0022224294413700145
epoch 17 training time: 15.430
---------------
2023-09-23 21:45:40.230445
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00712	Per Sample Data Time 0.00154	Per Sample DNN Time 0.00559	Train Loss 0.1413	
start validation
acc: 0.822967
AUC: 0.883770
Avg Precision: 0.347429
Avg Recall: 1.000000
d_prime: 1.688634
train_loss: 0.127675
valid_loss: 1.114305
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0011112147206850072
Epoch-18 lr: 0.0022224294413700145
epoch 18 training time: 15.240
---------------
2023-09-23 21:45:55.469958
current #epochs=19, #steps=720
start validation
acc: 0.808612
AUC: 0.852607
Avg Precision: 0.312836
Avg Recall: 1.000000
d_prime: 1.481646
train_loss: 0.105588
valid_loss: 1.144485
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0007109189004394779
Epoch-19 lr: 0.0014218378008789558
epoch 19 training time: 15.264
---------------
2023-09-23 21:46:10.734416
current #epochs=20, #steps=760
start validation
acc: 0.822967
AUC: 0.846988
Avg Precision: 0.335502
Avg Recall: 1.000000
d_prime: 1.447588
train_loss: 0.120832
valid_loss: 1.141637
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0007109189004394779
Epoch-20 lr: 0.0014218378008789558
epoch 20 training time: 15.349
---------------
2023-09-23 21:46:26.083252
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03926	Per Sample Data Time 0.03137	Per Sample DNN Time 0.00790	Train Loss 0.2718	
start validation
acc: 0.827751
AUC: 0.860896
Avg Precision: 0.338052
Avg Recall: 1.000000
d_prime: 1.533507
train_loss: 0.114882
valid_loss: 1.128762
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0007109189004394779
Epoch-21 lr: 0.0014218378008789558
epoch 21 training time: 15.409
---------------
2023-09-23 21:46:41.492089
current #epochs=22, #steps=840
start validation
acc: 0.837321
AUC: 0.869919
Avg Precision: 0.328320
Avg Recall: 1.000000
d_prime: 1.592416
train_loss: 0.102766
valid_loss: 1.142715
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0007109189004394779
Epoch-22 lr: 0.0014218378008789558
epoch 22 training time: 15.288
---------------
2023-09-23 21:46:56.780517
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00711	Per Sample Data Time 0.00153	Per Sample DNN Time 0.00558	Train Loss 0.1274	
start validation
acc: 0.827751
AUC: 0.855368
Avg Precision: 0.321216
Avg Recall: 1.000000
d_prime: 1.498695
train_loss: 0.130687
valid_loss: 1.142258
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0007109189004394779
Epoch-23 lr: 0.0014218378008789558
epoch 23 training time: 15.257
---------------
2023-09-23 21:47:12.037805
current #epochs=24, #steps=920
start validation
acc: 0.822967
AUC: 0.870378
Avg Precision: 0.352205
Avg Recall: 1.000000
d_prime: 1.595490
train_loss: 0.098958
valid_loss: 1.144545
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0007109189004394779
Epoch-24 lr: 0.0014218378008789558
epoch 24 training time: 15.309
---------------
2023-09-23 21:47:27.347317
current #epochs=25, #steps=960
start validation
acc: 0.837321
AUC: 0.873811
Avg Precision: 0.324771
Avg Recall: 1.000000
d_prime: 1.618699
train_loss: 0.108960
valid_loss: 1.133888
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.0004548227031140476
Epoch-25 lr: 0.0009096454062280952
epoch 25 training time: 16.531
---------------
2023-09-23 21:47:43.878640
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.03833	Per Sample Data Time 0.03018	Per Sample DNN Time 0.00815	Train Loss 0.0900	
start validation
acc: 0.799043
AUC: 0.858904
Avg Precision: 0.325229
Avg Recall: 1.000000
d_prime: 1.520855
train_loss: 0.086905
valid_loss: 1.145053
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.0004548227031140476
Epoch-26 lr: 0.0009096454062280952
epoch 26 training time: 15.304
---------------
2023-09-23 21:47:59.182145
current #epochs=27, #steps=1040
start validation
acc: 0.837321
AUC: 0.863280
Avg Precision: 0.340076
Avg Recall: 1.000000
d_prime: 1.548811
train_loss: 0.091897
valid_loss: 1.126985
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.0004548227031140476
Epoch-27 lr: 0.0009096454062280952
epoch 27 training time: 15.358
---------------
2023-09-23 21:48:14.539987
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00560	Train Loss 0.1238	
start validation
[I 2023-09-23 21:48:30,909] Trial 25 finished with value: 0.3273062095380084 and parameters: {'warmup': 'True', 'num_epochs': 28, 'batch_size': 15, 'lr-adaptschedule': 'False', 'lr': 0.00271489999732364, 'head-lr': 2, 'lr-scheduler-start': 7, 'lr-scheduler-step': 6, 'lr-scheduler-decay': 0.6397673529749792}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.822967
AUC: 0.860691
Avg Precision: 0.327306
Avg Recall: 1.000000
d_prime: 1.532199
train_loss: 0.106125
valid_loss: 1.132372
validation finished
normal learning rate scheduler step
Epoch-28 lr: 0.0004548227031140476
Epoch-28 lr: 0.0009096454062280952
epoch 28 training time: 16.365
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 1 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0a685730>
The learning rate scheduler starts at 4 epoch with decay rate of 0.688 every 3 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 21:48:30.943429
current #epochs=1, #steps=0
start validation
acc: 0.818182
AUC: 0.842394
Avg Precision: 0.317439
Avg Recall: 1.000000
d_prime: 1.420361
train_loss: 0.176364
valid_loss: 1.138766
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0018824245742471563
Epoch-1 lr: 0.0018824245742471563
epoch 1 training time: 17.675
---------------
2023-09-23 21:48:48.618700
current #epochs=2, #steps=40
start validation
acc: 0.813397
AUC: 0.860472
Avg Precision: 0.338864
Avg Recall: 1.000000
d_prime: 1.530805
train_loss: 0.184410
valid_loss: 1.113492
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0018824245742471563
Epoch-2 lr: 0.0018824245742471563
epoch 2 training time: 15.457
---------------
2023-09-23 21:49:04.075473
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00707	Per Sample Data Time 0.00154	Per Sample DNN Time 0.00553	Train Loss 0.1504	
start validation
acc: 0.837321
AUC: 0.874923
Avg Precision: 0.366135
Avg Recall: 1.000000
d_prime: 1.626312
train_loss: 0.146311
valid_loss: 1.103633
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0018824245742471563
Epoch-3 lr: 0.0018824245742471563
epoch 3 training time: 19.143
---------------
2023-09-23 21:49:23.218888
current #epochs=4, #steps=120
start validation
acc: 0.842105
AUC: 0.840849
Avg Precision: 0.327037
Avg Recall: 1.000000
d_prime: 1.411321
train_loss: 0.147730
valid_loss: 1.150591
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.00129577867547216
Epoch-4 lr: 0.00129577867547216
epoch 4 training time: 17.703
---------------
2023-09-23 21:49:40.922062
current #epochs=5, #steps=160
start validation
acc: 0.827751
AUC: 0.855261
Avg Precision: 0.353095
Avg Recall: 1.000000
d_prime: 1.498028
train_loss: 0.130870
valid_loss: 1.133826
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.00129577867547216
Epoch-5 lr: 0.00129577867547216
epoch 5 training time: 15.373
---------------
2023-09-23 21:49:56.295394
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03749	Per Sample Data Time 0.02958	Per Sample DNN Time 0.00791	Train Loss 0.1094	
start validation
acc: 0.818182
AUC: 0.870084
Avg Precision: 0.345517
Avg Recall: 1.000000
d_prime: 1.593522
train_loss: 0.168532
valid_loss: 1.131438
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.00129577867547216
Epoch-6 lr: 0.00129577867547216
epoch 6 training time: 15.287
---------------
2023-09-23 21:50:11.583244
current #epochs=7, #steps=240
start validation
acc: 0.813397
AUC: 0.884517
Avg Precision: 0.381623
Avg Recall: 1.000000
d_prime: 1.694050
train_loss: 0.140569
valid_loss: 1.119010
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0008919573186510751
Epoch-7 lr: 0.0008919573186510751
epoch 7 training time: 16.568
---------------
2023-09-23 21:50:28.151521
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00715	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00559	Train Loss 0.1163	
start validation
acc: 0.822967
AUC: 0.884293
Avg Precision: 0.343951
Avg Recall: 1.000000
d_prime: 1.692422
train_loss: 0.114068
valid_loss: 1.114147
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0008919573186510751
Epoch-8 lr: 0.0008919573186510751
epoch 8 training time: 15.332
---------------
2023-09-23 21:50:43.484074
current #epochs=9, #steps=320
start validation
acc: 0.808612
AUC: 0.852369
Avg Precision: 0.327446
Avg Recall: 1.000000
d_prime: 1.480181
train_loss: 0.119377
valid_loss: 1.145087
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0008919573186510751
Epoch-9 lr: 0.0008919573186510751
epoch 9 training time: 16.997
---------------
2023-09-23 21:51:00.481053
current #epochs=10, #steps=360
start validation
acc: 0.803828
AUC: 0.871240
Avg Precision: 0.354227
Avg Recall: 1.000000
d_prime: 1.601278
train_loss: 0.097469
valid_loss: 1.146131
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0006139843735314727
Epoch-10 lr: 0.0006139843735314727
epoch 10 training time: 15.366
---------------
2023-09-23 21:51:15.846985
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03932	Per Sample Data Time 0.03197	Per Sample DNN Time 0.00735	Train Loss 0.1151	
start validation
acc: 0.818182
AUC: 0.858884
Avg Precision: 0.344110
Avg Recall: 1.000000
d_prime: 1.520733
train_loss: 0.103506
valid_loss: 1.136280
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0006139843735314727
Epoch-11 lr: 0.0006139843735314727
epoch 11 training time: 16.257
---------------
2023-09-23 21:51:32.103807
current #epochs=12, #steps=440
start validation
acc: 0.813397
AUC: 0.864412
Avg Precision: 0.347617
Avg Recall: 1.000000
d_prime: 1.556139
train_loss: 0.083452
valid_loss: 1.151523
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0006139843735314727
Epoch-12 lr: 0.0006139843735314727
epoch 12 training time: 15.418
---------------
2023-09-23 21:51:47.521498
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00556	Train Loss 0.0917	
start validation
acc: 0.832536
AUC: 0.870145
Avg Precision: 0.378035
Avg Recall: 1.000000
d_prime: 1.593926
train_loss: 0.093553
valid_loss: 1.125683
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.00042263996612634396
Epoch-13 lr: 0.00042263996612634396
epoch 13 training time: 17.508
---------------
2023-09-23 21:52:05.028944
current #epochs=14, #steps=520
start validation
acc: 0.832536
AUC: 0.863404
Avg Precision: 0.355328
Avg Recall: 1.000000
d_prime: 1.549614
train_loss: 0.107622
valid_loss: 1.117920
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.00042263996612634396
Epoch-14 lr: 0.00042263996612634396
epoch 14 training time: 15.509
---------------
2023-09-23 21:52:20.537793
current #epochs=15, #steps=560
start validation
acc: 0.818182
AUC: 0.869729
Avg Precision: 0.342071
Avg Recall: 1.000000
d_prime: 1.591145
train_loss: 0.106489
valid_loss: 1.133035
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.00042263996612634396
Epoch-15 lr: 0.00042263996612634396
epoch 15 training time: 15.316
---------------
2023-09-23 21:52:35.853825
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03749	Per Sample Data Time 0.02958	Per Sample DNN Time 0.00792	Train Loss 0.0503	
start validation
acc: 0.837321
AUC: 0.871643
Avg Precision: 0.352597
Avg Recall: 1.000000
d_prime: 1.603989
train_loss: 0.084094
valid_loss: 1.121957
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.00029092685199767694
Epoch-16 lr: 0.00029092685199767694
epoch 16 training time: 15.338
---------------
2023-09-23 21:52:51.192320
current #epochs=17, #steps=640
start validation
acc: 0.837321
AUC: 0.871340
Avg Precision: 0.363514
Avg Recall: 1.000000
d_prime: 1.601951
train_loss: 0.103846
valid_loss: 1.122655
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.00029092685199767694
Epoch-17 lr: 0.00029092685199767694
epoch 17 training time: 15.844
---------------
2023-09-23 21:53:07.036677
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00714	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00555	Train Loss 0.1103	
start validation
acc: 0.837321
AUC: 0.872023
Avg Precision: 0.359563
Avg Recall: 1.000000
d_prime: 1.606558
train_loss: 0.101468
valid_loss: 1.123576
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.00029092685199767694
Epoch-18 lr: 0.00029092685199767694
epoch 18 training time: 15.364
---------------
2023-09-23 21:53:22.400340
current #epochs=19, #steps=720
start validation
acc: 0.813397
AUC: 0.873416
Avg Precision: 0.340408
Avg Recall: 1.000000
d_prime: 1.616008
train_loss: 0.089663
valid_loss: 1.140583
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.00020026130985439372
Epoch-19 lr: 0.00020026130985439372
epoch 19 training time: 16.844
---------------
2023-09-23 21:53:39.244362
current #epochs=20, #steps=760
start validation
acc: 0.827751
AUC: 0.871945
Avg Precision: 0.339079
Avg Recall: 1.000000
d_prime: 1.606030
train_loss: 0.090142
valid_loss: 1.124350
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.00020026130985439372
Epoch-20 lr: 0.00020026130985439372
epoch 20 training time: 15.423
---------------
2023-09-23 21:53:54.667783
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03723	Per Sample Data Time 0.02997	Per Sample DNN Time 0.00726	Train Loss 0.0468	
start validation
acc: 0.822967
AUC: 0.874174
Avg Precision: 0.359093
Avg Recall: 1.000000
d_prime: 1.621178
train_loss: 0.078116
valid_loss: 1.126622
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.00020026130985439372
Epoch-21 lr: 0.00020026130985439372
epoch 21 training time: 15.383
---------------
2023-09-23 21:54:10.051129
current #epochs=22, #steps=840
start validation
acc: 0.822967
AUC: 0.877561
Avg Precision: 0.368618
Avg Recall: 1.000000
d_prime: 1.644563
train_loss: 0.095965
valid_loss: 1.126903
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.00013785111944537084
Epoch-22 lr: 0.00013785111944537084
epoch 22 training time: 15.533
---------------
2023-09-23 21:54:25.584199
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00715	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00557	Train Loss 0.0697	
start validation
acc: 0.832536
AUC: 0.874029
Avg Precision: 0.358032
Avg Recall: 1.000000
d_prime: 1.620187
train_loss: 0.070427
valid_loss: 1.118365
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.00013785111944537084
Epoch-23 lr: 0.00013785111944537084
epoch 23 training time: 16.062
---------------
2023-09-23 21:54:41.645814
current #epochs=24, #steps=920
start validation
acc: 0.822967
AUC: 0.876477
Avg Precision: 0.353391
Avg Recall: 1.000000
d_prime: 1.637029
train_loss: 0.097766
valid_loss: 1.122735
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.00013785111944537084
Epoch-24 lr: 0.00013785111944537084
epoch 24 training time: 15.414
---------------
2023-09-23 21:54:57.059588
current #epochs=25, #steps=960
start validation
acc: 0.818182
AUC: 0.870828
Avg Precision: 0.347899
Avg Recall: 1.000000
d_prime: 1.598505
train_loss: 0.098367
valid_loss: 1.132024
validation finished
normal learning rate scheduler step
Epoch-25 lr: 9.489067631765006e-05
Epoch-25 lr: 9.489067631765006e-05
epoch 25 training time: 15.496
---------------
2023-09-23 21:55:12.555383
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.03741	Per Sample Data Time 0.02938	Per Sample DNN Time 0.00803	Train Loss 0.1204	
start validation
acc: 0.818182
AUC: 0.869837
Avg Precision: 0.351712
Avg Recall: 1.000000
d_prime: 1.591870
train_loss: 0.089164
valid_loss: 1.129069
validation finished
normal learning rate scheduler step
Epoch-26 lr: 9.489067631765006e-05
Epoch-26 lr: 9.489067631765006e-05
epoch 26 training time: 15.301
---------------
2023-09-23 21:55:27.857061
current #epochs=27, #steps=1040
start validation
acc: 0.827751
AUC: 0.869247
Avg Precision: 0.354206
Avg Recall: 1.000000
d_prime: 1.587937
train_loss: 0.082066
valid_loss: 1.125081
validation finished
normal learning rate scheduler step
Epoch-27 lr: 9.489067631765006e-05
Epoch-27 lr: 9.489067631765006e-05
epoch 27 training time: 16.709
---------------
2023-09-23 21:55:44.566485
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00559	Train Loss 0.0623	
start validation
acc: 0.827751
AUC: 0.872078
Avg Precision: 0.355198
Avg Recall: 1.000000
d_prime: 1.606927
train_loss: 0.070603
valid_loss: 1.125479
validation finished
normal learning rate scheduler step
Epoch-28 lr: 6.531858782321556e-05
Epoch-28 lr: 6.531858782321556e-05
epoch 28 training time: 15.336
---------------
2023-09-23 21:55:59.902662
current #epochs=29, #steps=1120
start validation
acc: 0.822967
AUC: 0.870445
Avg Precision: 0.359708
Avg Recall: 1.000000
d_prime: 1.595936
train_loss: 0.104842
valid_loss: 1.118794
validation finished
normal learning rate scheduler step
Epoch-29 lr: 6.531858782321556e-05
Epoch-29 lr: 6.531858782321556e-05
epoch 29 training time: 15.335
---------------
2023-09-23 21:56:15.237933
current #epochs=30, #steps=1160
start validation
acc: 0.827751
AUC: 0.872285
Avg Precision: 0.358017
Avg Recall: 1.000000
d_prime: 1.608326
train_loss: 0.089175
valid_loss: 1.123615
validation finished
normal learning rate scheduler step
Epoch-30 lr: 6.531858782321556e-05
Epoch-30 lr: 6.531858782321556e-05
epoch 30 training time: 15.396
---------------
2023-09-23 21:56:30.634027
current #epochs=31, #steps=1200
Epoch: [31][0/40]	Per Sample Total Time 0.03785	Per Sample Data Time 0.03079	Per Sample DNN Time 0.00706	Train Loss 0.1401	
start validation
acc: 0.818182
AUC: 0.873347
Avg Precision: 0.354665
Avg Recall: 1.000000
d_prime: 1.615534
train_loss: 0.075131
valid_loss: 1.126975
validation finished
normal learning rate scheduler step
Epoch-31 lr: 4.4962456595174824e-05
Epoch-31 lr: 4.4962456595174824e-05
epoch 31 training time: 15.451
---------------
2023-09-23 21:56:46.085564
current #epochs=32, #steps=1240
start validation
acc: 0.827751
AUC: 0.873067
Avg Precision: 0.356667
Avg Recall: 1.000000
d_prime: 1.613630
train_loss: 0.077856
valid_loss: 1.123885
validation finished
normal learning rate scheduler step
Epoch-32 lr: 4.4962456595174824e-05
Epoch-32 lr: 4.4962456595174824e-05
epoch 32 training time: 15.395
---------------
2023-09-23 21:57:01.480469
current #epochs=33, #steps=1280
Epoch: [33][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00559	Train Loss 0.0759	
start validation
acc: 0.818182
AUC: 0.873487
Avg Precision: 0.356884
Avg Recall: 1.000000
d_prime: 1.616489
train_loss: 0.083645
valid_loss: 1.126030
validation finished
normal learning rate scheduler step
Epoch-33 lr: 4.4962456595174824e-05
Epoch-33 lr: 4.4962456595174824e-05
epoch 33 training time: 15.352
---------------
2023-09-23 21:57:16.832700
current #epochs=34, #steps=1320
start validation
acc: 0.818182
AUC: 0.872046
Avg Precision: 0.356827
Avg Recall: 1.000000
d_prime: 1.606708
train_loss: 0.090234
valid_loss: 1.123769
validation finished
normal learning rate scheduler step
Epoch-34 lr: 3.095018692909423e-05
Epoch-34 lr: 3.095018692909423e-05
epoch 34 training time: 15.367
---------------
2023-09-23 21:57:32.199839
current #epochs=35, #steps=1360
start validation
acc: 0.813397
AUC: 0.871336
Avg Precision: 0.356258
Avg Recall: 1.000000
d_prime: 1.601921
train_loss: 0.082176
valid_loss: 1.121846
validation finished
normal learning rate scheduler step
Epoch-35 lr: 3.095018692909423e-05
Epoch-35 lr: 3.095018692909423e-05
epoch 35 training time: 15.324
---------------
2023-09-23 21:57:47.523691
current #epochs=36, #steps=1400
Epoch: [36][0/40]	Per Sample Total Time 0.03794	Per Sample Data Time 0.03033	Per Sample DNN Time 0.00760	Train Loss 0.0664	
start validation
acc: 0.818182
AUC: 0.871660
Avg Precision: 0.354288
Avg Recall: 1.000000
d_prime: 1.604103
train_loss: 0.094842
valid_loss: 1.123770
validation finished
normal learning rate scheduler step
Epoch-36 lr: 3.095018692909423e-05
Epoch-36 lr: 3.095018692909423e-05
epoch 36 training time: 15.294
---------------
2023-09-23 21:58:02.817547
current #epochs=37, #steps=1440
start validation
acc: 0.813397
AUC: 0.870111
Avg Precision: 0.352602
Avg Recall: 1.000000
d_prime: 1.593702
train_loss: 0.104181
valid_loss: 1.123451
validation finished
normal learning rate scheduler step
Epoch-37 lr: 2.1304753865443257e-05
Epoch-37 lr: 2.1304753865443257e-05
epoch 37 training time: 15.433
---------------
2023-09-23 21:58:18.250892
current #epochs=38, #steps=1480
Epoch: [38][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00167	Per Sample DNN Time 0.00556	Train Loss 0.0640	
start validation
acc: 0.818182
AUC: 0.869489
Avg Precision: 0.353885
Avg Recall: 1.000000
d_prime: 1.589545
train_loss: 0.069498
valid_loss: 1.121373
validation finished
normal learning rate scheduler step
Epoch-38 lr: 2.1304753865443257e-05
Epoch-38 lr: 2.1304753865443257e-05
epoch 38 training time: 15.974
---------------
2023-09-23 21:58:34.224684
current #epochs=39, #steps=1520
start validation
[I 2023-09-23 21:58:49,576] Trial 26 finished with value: 0.35513736549551156 and parameters: {'warmup': 'True', 'num_epochs': 39, 'batch_size': 54, 'lr-adaptschedule': 'False', 'lr': 0.0018824245742471563, 'head-lr': 1, 'lr-scheduler-start': 4, 'lr-scheduler-step': 3, 'lr-scheduler-decay': 0.6883562259010482}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.822967
AUC: 0.870708
Avg Precision: 0.355137
Avg Recall: 1.000000
d_prime: 1.597698
train_loss: 0.079885
valid_loss: 1.120394
validation finished
normal learning rate scheduler step
Epoch-39 lr: 2.1304753865443257e-05
Epoch-39 lr: 2.1304753865443257e-05
epoch 39 training time: 15.344
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 2 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc09831790>
The learning rate scheduler starts at 5 epoch with decay rate of 0.725 every 5 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 21:58:49.609335
current #epochs=1, #steps=0
start validation
acc: 0.818182
AUC: 0.852375
Avg Precision: 0.344966
Avg Recall: 1.000000
d_prime: 1.480219
train_loss: 0.236591
valid_loss: 1.133964
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.002365670429763256
Epoch-1 lr: 0.004731340859526512
epoch 1 training time: 18.929
---------------
2023-09-23 21:59:08.539273
current #epochs=2, #steps=40
start validation
acc: 0.832536
AUC: 0.859307
Avg Precision: 0.338784
Avg Recall: 1.000000
d_prime: 1.523406
train_loss: 0.202865
valid_loss: 1.118869
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.002365670429763256
Epoch-2 lr: 0.004731340859526512
epoch 2 training time: 18.145
---------------
2023-09-23 21:59:26.683796
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00710	Per Sample Data Time 0.00152	Per Sample DNN Time 0.00559	Train Loss 0.1408	
start validation
acc: 0.822967
AUC: 0.843918
Avg Precision: 0.332238
Avg Recall: 1.000000
d_prime: 1.429333
train_loss: 0.142396
valid_loss: 1.131526
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.002365670429763256
Epoch-3 lr: 0.004731340859526512
epoch 3 training time: 15.165
---------------
2023-09-23 21:59:41.849018
current #epochs=4, #steps=120
start validation
acc: 0.803828
AUC: 0.831201
Avg Precision: 0.352408
Avg Recall: 1.000000
d_prime: 1.356120
train_loss: 0.198629
valid_loss: 1.153613
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.002365670429763256
Epoch-4 lr: 0.004731340859526512
epoch 4 training time: 15.330
---------------
2023-09-23 21:59:57.179049
current #epochs=5, #steps=160
start validation
acc: 0.827751
AUC: 0.888344
Avg Precision: 0.374894
Avg Recall: 1.000000
d_prime: 1.722183
train_loss: 0.189991
valid_loss: 1.120993
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0017142710889807345
Epoch-5 lr: 0.003428542177961469
epoch 5 training time: 15.369
---------------
2023-09-23 22:00:12.547733
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03811	Per Sample Data Time 0.03083	Per Sample DNN Time 0.00728	Train Loss 0.3744	
start validation
acc: 0.818182
AUC: 0.860008
Avg Precision: 0.368747
Avg Recall: 1.000000
d_prime: 1.527855
train_loss: 0.150608
valid_loss: 1.143616
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0017142710889807345
Epoch-6 lr: 0.003428542177961469
epoch 6 training time: 15.922
---------------
2023-09-23 22:00:28.469818
current #epochs=7, #steps=240
start validation
acc: 0.822967
AUC: 0.857703
Avg Precision: 0.366193
Avg Recall: 1.000000
d_prime: 1.513291
train_loss: 0.136360
valid_loss: 1.127673
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0017142710889807345
Epoch-7 lr: 0.003428542177961469
epoch 7 training time: 15.500
---------------
2023-09-23 22:00:43.970086
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00712	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00552	Train Loss 0.1115	
start validation
acc: 0.837321
AUC: 0.888784
Avg Precision: 0.394228
Avg Recall: 1.000000
d_prime: 1.725465
train_loss: 0.124305
valid_loss: 1.114075
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0017142710889807345
Epoch-8 lr: 0.003428542177961469
epoch 8 training time: 17.729
---------------
2023-09-23 22:01:01.699543
current #epochs=9, #steps=320
start validation
acc: 0.832536
AUC: 0.879283
Avg Precision: 0.356908
Avg Recall: 1.000000
d_prime: 1.656623
train_loss: 0.140349
valid_loss: 1.123216
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0017142710889807345
Epoch-9 lr: 0.003428542177961469
epoch 9 training time: 15.377
---------------
2023-09-23 22:01:17.076924
current #epochs=10, #steps=360
start validation
acc: 0.813397
AUC: 0.878081
Avg Precision: 0.336923
Avg Recall: 1.000000
d_prime: 1.648190
train_loss: 0.142053
valid_loss: 1.128798
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0012422378576246926
Epoch-10 lr: 0.002484475715249385
epoch 10 training time: 15.334
---------------
2023-09-23 22:01:32.411533
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03840	Per Sample Data Time 0.03090	Per Sample DNN Time 0.00751	Train Loss 0.2253	
start validation
acc: 0.808612
AUC: 0.893223
Avg Precision: 0.369764
Avg Recall: 1.000000
d_prime: 1.759072
train_loss: 0.112122
valid_loss: 1.141534
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0012422378576246926
Epoch-11 lr: 0.002484475715249385
epoch 11 training time: 15.428
---------------
2023-09-23 22:01:47.839438
current #epochs=12, #steps=440
start validation
acc: 0.822967
AUC: 0.870426
Avg Precision: 0.381535
Avg Recall: 1.000000
d_prime: 1.595812
train_loss: 0.105214
valid_loss: 1.126288
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0012422378576246926
Epoch-12 lr: 0.002484475715249385
epoch 12 training time: 15.373
---------------
2023-09-23 22:02:03.212643
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00557	Train Loss 0.1527	
start validation
acc: 0.775120
AUC: 0.887654
Avg Precision: 0.353525
Avg Recall: 1.000000
d_prime: 1.717059
train_loss: 0.142351
valid_loss: 1.135564
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0012422378576246926
Epoch-13 lr: 0.002484475715249385
epoch 13 training time: 16.677
---------------
2023-09-23 22:02:19.889694
current #epochs=14, #steps=520
start validation
acc: 0.808612
AUC: 0.861108
Avg Precision: 0.340615
Avg Recall: 1.000000
d_prime: 1.534860
train_loss: 0.156779
valid_loss: 1.122908
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0012422378576246926
Epoch-14 lr: 0.002484475715249385
epoch 14 training time: 15.304
---------------
2023-09-23 22:02:35.193932
current #epochs=15, #steps=560
start validation
acc: 0.813397
AUC: 0.879580
Avg Precision: 0.350431
Avg Recall: 1.000000
d_prime: 1.658720
train_loss: 0.127668
valid_loss: 1.115372
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0009001813685334389
Epoch-15 lr: 0.0018003627370668778
epoch 15 training time: 15.389
---------------
2023-09-23 22:02:50.583510
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03845	Per Sample Data Time 0.03049	Per Sample DNN Time 0.00797	Train Loss 0.1006	
start validation
acc: 0.803828
AUC: 0.872937
Avg Precision: 0.354826
Avg Recall: 1.000000
d_prime: 1.612745
train_loss: 0.103710
valid_loss: 1.131729
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0009001813685334389
Epoch-16 lr: 0.0018003627370668778
epoch 16 training time: 15.357
---------------
2023-09-23 22:03:05.940451
current #epochs=17, #steps=640
start validation
acc: 0.822967
AUC: 0.876470
Avg Precision: 0.365844
Avg Recall: 1.000000
d_prime: 1.636977
train_loss: 0.129068
valid_loss: 1.131939
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0009001813685334389
Epoch-17 lr: 0.0018003627370668778
epoch 17 training time: 15.391
---------------
2023-09-23 22:03:21.331338
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00164	Per Sample DNN Time 0.00554	Train Loss 0.1312	
start validation
acc: 0.818182
AUC: 0.865865
Avg Precision: 0.334363
Avg Recall: 1.000000
d_prime: 1.565609
train_loss: 0.122766
valid_loss: 1.148424
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0009001813685334389
Epoch-18 lr: 0.0018003627370668778
epoch 18 training time: 15.359
---------------
2023-09-23 22:03:36.690730
current #epochs=19, #steps=720
start validation
acc: 0.784689
AUC: 0.860595
Avg Precision: 0.340537
Avg Recall: 1.000000
d_prime: 1.531590
train_loss: 0.134343
valid_loss: 1.150516
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0009001813685334389
Epoch-19 lr: 0.0018003627370668778
epoch 19 training time: 15.332
---------------
2023-09-23 22:03:52.022874
current #epochs=20, #steps=760
start validation
acc: 0.803828
AUC: 0.868640
Avg Precision: 0.334238
Avg Recall: 1.000000
d_prime: 1.583901
train_loss: 0.157674
valid_loss: 1.149382
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0006523118670720405
Epoch-20 lr: 0.001304623734144081
epoch 20 training time: 15.865
---------------
2023-09-23 22:04:07.888301
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03987	Per Sample Data Time 0.03208	Per Sample DNN Time 0.00779	Train Loss 0.2126	
start validation
acc: 0.808612
AUC: 0.885442
Avg Precision: 0.344902
Avg Recall: 1.000000
d_prime: 1.700785
train_loss: 0.110473
valid_loss: 1.147842
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0006523118670720405
Epoch-21 lr: 0.001304623734144081
epoch 21 training time: 15.588
---------------
2023-09-23 22:04:23.476217
current #epochs=22, #steps=840
start validation
acc: 0.803828
AUC: 0.888571
Avg Precision: 0.370144
Avg Recall: 1.000000
d_prime: 1.723876
train_loss: 0.088357
valid_loss: 1.132696
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0006523118670720405
Epoch-22 lr: 0.001304623734144081
epoch 22 training time: 16.571
---------------
2023-09-23 22:04:40.046939
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00715	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00558	Train Loss 0.0869	
start validation
acc: 0.818182
AUC: 0.889167
Avg Precision: 0.365677
Avg Recall: 1.000000
d_prime: 1.728323
train_loss: 0.093227
valid_loss: 1.129331
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0006523118670720405
Epoch-23 lr: 0.001304623734144081
epoch 23 training time: 15.368
---------------
2023-09-23 22:04:55.414963
current #epochs=24, #steps=920
start validation
acc: 0.832536
AUC: 0.883947
Avg Precision: 0.364863
Avg Recall: 1.000000
d_prime: 1.689914
train_loss: 0.108766
valid_loss: 1.128401
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0006523118670720405
Epoch-24 lr: 0.001304623734144081
epoch 24 training time: 15.369
---------------
2023-09-23 22:05:10.783641
current #epochs=25, #steps=960
start validation
acc: 0.808612
AUC: 0.887977
Avg Precision: 0.374436
Avg Recall: 1.000000
d_prime: 1.719456
train_loss: 0.092700
valid_loss: 1.125816
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.0004726944889075485
Epoch-25 lr: 0.000945388977815097
epoch 25 training time: 16.703
---------------
2023-09-23 22:05:27.486840
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.03802	Per Sample Data Time 0.03094	Per Sample DNN Time 0.00708	Train Loss 0.0453	
start validation
acc: 0.813397
AUC: 0.892508
Avg Precision: 0.362280
Avg Recall: 1.000000
d_prime: 1.753595
train_loss: 0.096337
valid_loss: 1.133421
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.0004726944889075485
Epoch-26 lr: 0.000945388977815097
epoch 26 training time: 15.386
---------------
2023-09-23 22:05:42.872395
current #epochs=27, #steps=1040
start validation
acc: 0.822967
AUC: 0.894728
Avg Precision: 0.380022
Avg Recall: 1.000000
d_prime: 1.770697
train_loss: 0.101776
valid_loss: 1.125081
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.0004726944889075485
Epoch-27 lr: 0.000945388977815097
epoch 27 training time: 15.486
---------------
2023-09-23 22:05:58.358080
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00715	Per Sample Data Time 0.00164	Per Sample DNN Time 0.00551	Train Loss 0.0941	
start validation
acc: 0.784689
AUC: 0.870694
Avg Precision: 0.344387
Avg Recall: 1.000000
d_prime: 1.597609
train_loss: 0.091588
valid_loss: 1.135518
validation finished
normal learning rate scheduler step
Epoch-28 lr: 0.0004726944889075485
Epoch-28 lr: 0.000945388977815097
epoch 28 training time: 15.325
---------------
2023-09-23 22:06:13.682910
current #epochs=29, #steps=1120
start validation
acc: 0.799043
AUC: 0.880274
Avg Precision: 0.353447
Avg Recall: 1.000000
d_prime: 1.663622
train_loss: 0.098557
valid_loss: 1.136905
validation finished
normal learning rate scheduler step
Epoch-29 lr: 0.0004726944889075485
Epoch-29 lr: 0.000945388977815097
epoch 29 training time: 15.321
---------------
2023-09-23 22:06:29.004316
current #epochs=30, #steps=1160
start validation
acc: 0.803828
AUC: 0.874622
Avg Precision: 0.344863
Avg Recall: 1.000000
d_prime: 1.624246
train_loss: 0.104955
valid_loss: 1.127251
validation finished
normal learning rate scheduler step
Epoch-30 lr: 0.00034253566602505497
Epoch-30 lr: 0.0006850713320501099
epoch 30 training time: 15.247
---------------
2023-09-23 22:06:44.251368
current #epochs=31, #steps=1200
Epoch: [31][0/40]	Per Sample Total Time 0.03968	Per Sample Data Time 0.03221	Per Sample DNN Time 0.00747	Train Loss 0.1076	
start validation
acc: 0.813397
AUC: 0.874194
Avg Precision: 0.354289
Avg Recall: 1.000000
d_prime: 1.621316
train_loss: 0.090129
valid_loss: 1.128028
validation finished
normal learning rate scheduler step
Epoch-31 lr: 0.00034253566602505497
Epoch-31 lr: 0.0006850713320501099
epoch 31 training time: 17.046
---------------
2023-09-23 22:07:01.297687
current #epochs=32, #steps=1240
start validation
acc: 0.822967
AUC: 0.882618
Avg Precision: 0.375625
Avg Recall: 1.000000
d_prime: 1.680335
train_loss: 0.092108
valid_loss: 1.118112
validation finished
normal learning rate scheduler step
Epoch-32 lr: 0.00034253566602505497
Epoch-32 lr: 0.0006850713320501099
epoch 32 training time: 16.832
---------------
2023-09-23 22:07:18.130156
current #epochs=33, #steps=1280
Epoch: [33][20/40]	Per Sample Total Time 0.00715	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00554	Train Loss 0.0974	
start validation
[I 2023-09-23 22:07:33,469] Trial 27 finished with value: 0.3637061840880622 and parameters: {'warmup': 'False', 'num_epochs': 33, 'batch_size': 20, 'lr-adaptschedule': 'True', 'lr': 0.002365670429763256, 'head-lr': 2, 'lr-scheduler-start': 5, 'lr-scheduler-step': 5, 'lr-scheduler-decay': 0.7246449325370693}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.799043
AUC: 0.879521
Avg Precision: 0.363706
Avg Recall: 1.000000
d_prime: 1.658301
train_loss: 0.091362
valid_loss: 1.122081
validation finished
normal learning rate scheduler step
Epoch-33 lr: 0.00034253566602505497
Epoch-33 lr: 0.0006850713320501099
epoch 33 training time: 15.334
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 1 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0983e310>
The learning rate scheduler starts at 6 epoch with decay rate of 0.689 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 22:07:33.503191
current #epochs=1, #steps=0
start validation
acc: 0.779904
AUC: 0.867169
Avg Precision: 0.322618
Avg Recall: 1.000000
d_prime: 1.574173
train_loss: 0.155420
valid_loss: 1.143625
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0014517508930762624
Epoch-1 lr: 0.0014517508930762624
epoch 1 training time: 17.643
---------------
2023-09-23 22:07:51.146657
current #epochs=2, #steps=40
start validation
acc: 0.803828
AUC: 0.856126
Avg Precision: 0.358794
Avg Recall: 1.000000
d_prime: 1.503414
train_loss: 0.152802
valid_loss: 1.145738
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0014517508930762624
Epoch-2 lr: 0.0014517508930762624
epoch 2 training time: 17.790
---------------
2023-09-23 22:08:08.936574
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00559	Train Loss 0.1041	
start validation
acc: 0.789474
AUC: 0.867159
Avg Precision: 0.353999
Avg Recall: 1.000000
d_prime: 1.574104
train_loss: 0.105088
valid_loss: 1.137029
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0014517508930762624
Epoch-3 lr: 0.0014517508930762624
epoch 3 training time: 15.511
---------------
2023-09-23 22:08:24.448347
current #epochs=4, #steps=120
start validation
acc: 0.837321
AUC: 0.845745
Avg Precision: 0.347177
Avg Recall: 1.000000
d_prime: 1.440166
train_loss: 0.122013
valid_loss: 1.116503
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0014517508930762624
Epoch-4 lr: 0.0014517508930762624
epoch 4 training time: 18.743
---------------
2023-09-23 22:08:43.190780
current #epochs=5, #steps=160
start validation
acc: 0.789474
AUC: 0.854957
Avg Precision: 0.310986
Avg Recall: 1.000000
d_prime: 1.496143
train_loss: 0.129159
valid_loss: 1.137877
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0014517508930762624
Epoch-5 lr: 0.0014517508930762624
epoch 5 training time: 15.403
---------------
2023-09-23 22:08:58.593616
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03799	Per Sample Data Time 0.02999	Per Sample DNN Time 0.00799	Train Loss 0.1120	
start validation
acc: 0.808612
AUC: 0.872877
Avg Precision: 0.365292
Avg Recall: 1.000000
d_prime: 1.612340
train_loss: 0.155512
valid_loss: 1.141124
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0009995434396041995
Epoch-6 lr: 0.0009995434396041995
epoch 6 training time: 15.588
---------------
2023-09-23 22:09:14.181339
current #epochs=7, #steps=240
start validation
acc: 0.827751
AUC: 0.874056
Avg Precision: 0.339000
Avg Recall: 1.000000
d_prime: 1.620369
train_loss: 0.137344
valid_loss: 1.113724
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0009995434396041995
Epoch-7 lr: 0.0009995434396041995
epoch 7 training time: 16.200
---------------
2023-09-23 22:09:30.381669
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00560	Train Loss 0.1096	
start validation
acc: 0.818182
AUC: 0.876847
Avg Precision: 0.339265
Avg Recall: 1.000000
d_prime: 1.639596
train_loss: 0.119773
valid_loss: 1.114551
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0009995434396041995
Epoch-8 lr: 0.0009995434396041995
epoch 8 training time: 15.314
---------------
2023-09-23 22:09:45.695768
current #epochs=9, #steps=320
start validation
acc: 0.827751
AUC: 0.877154
Avg Precision: 0.394590
Avg Recall: 1.000000
d_prime: 1.641727
train_loss: 0.121868
valid_loss: 1.114570
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0009995434396041995
Epoch-9 lr: 0.0009995434396041995
epoch 9 training time: 15.307
---------------
2023-09-23 22:10:01.002759
current #epochs=10, #steps=360
start validation
acc: 0.837321
AUC: 0.886862
Avg Precision: 0.347634
Avg Recall: 1.000000
d_prime: 1.711209
train_loss: 0.131998
valid_loss: 1.115226
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0009995434396041995
Epoch-10 lr: 0.0009995434396041995
epoch 10 training time: 15.455
---------------
2023-09-23 22:10:16.457933
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03832	Per Sample Data Time 0.03094	Per Sample DNN Time 0.00738	Train Loss 0.1111	
start validation
acc: 0.837321
AUC: 0.891234
Avg Precision: 0.408915
Avg Recall: 1.000000
d_prime: 1.743890
train_loss: 0.128497
valid_loss: 1.119247
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0009995434396041995
Epoch-11 lr: 0.0009995434396041995
epoch 11 training time: 15.328
---------------
2023-09-23 22:10:31.785878
current #epochs=12, #steps=440
start validation
acc: 0.832536
AUC: 0.891093
Avg Precision: 0.403257
Avg Recall: 1.000000
d_prime: 1.742826
train_loss: 0.116776
valid_loss: 1.108854
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0009995434396041995
Epoch-12 lr: 0.0009995434396041995
epoch 12 training time: 15.362
---------------
2023-09-23 22:10:47.147697
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00714	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00557	Train Loss 0.0842	
start validation
acc: 0.822967
AUC: 0.871856
Avg Precision: 0.341879
Avg Recall: 1.000000
d_prime: 1.605424
train_loss: 0.097160
valid_loss: 1.117585
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0009995434396041995
Epoch-13 lr: 0.0009995434396041995
epoch 13 training time: 15.297
---------------
2023-09-23 22:11:02.444723
current #epochs=14, #steps=520
start validation
acc: 0.827751
AUC: 0.887122
Avg Precision: 0.375757
Avg Recall: 1.000000
d_prime: 1.713128
train_loss: 0.100299
valid_loss: 1.113580
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0009995434396041995
Epoch-14 lr: 0.0009995434396041995
epoch 14 training time: 15.382
---------------
2023-09-23 22:11:17.827015
current #epochs=15, #steps=560
start validation
acc: 0.818182
AUC: 0.895616
Avg Precision: 0.397029
Avg Recall: 1.000000
d_prime: 1.777613
train_loss: 0.093284
valid_loss: 1.110642
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.000688194574166045
Epoch-15 lr: 0.000688194574166045
epoch 15 training time: 15.313
---------------
2023-09-23 22:11:33.140322
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03804	Per Sample Data Time 0.03018	Per Sample DNN Time 0.00786	Train Loss 0.0416	
start validation
acc: 0.832536
AUC: 0.888401
Avg Precision: 0.372563
Avg Recall: 1.000000
d_prime: 1.722605
train_loss: 0.100466
valid_loss: 1.123808
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.000688194574166045
Epoch-16 lr: 0.000688194574166045
epoch 16 training time: 15.353
---------------
2023-09-23 22:11:48.493578
current #epochs=17, #steps=640
start validation
acc: 0.827751
AUC: 0.878063
Avg Precision: 0.353070
Avg Recall: 1.000000
d_prime: 1.648064
train_loss: 0.098413
valid_loss: 1.126675
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.000688194574166045
Epoch-17 lr: 0.000688194574166045
epoch 17 training time: 15.749
---------------
2023-09-23 22:12:04.242758
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00555	Train Loss 0.0778	
start validation
acc: 0.851675
AUC: 0.887747
Avg Precision: 0.375367
Avg Recall: 1.000000
d_prime: 1.717750
train_loss: 0.083993
valid_loss: 1.106466
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.000688194574166045
Epoch-18 lr: 0.000688194574166045
epoch 18 training time: 17.941
---------------
2023-09-23 22:12:22.184094
current #epochs=19, #steps=720
start validation
acc: 0.842105
AUC: 0.885294
Avg Precision: 0.358964
Avg Recall: 1.000000
d_prime: 1.699710
train_loss: 0.097794
valid_loss: 1.121061
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.000688194574166045
Epoch-19 lr: 0.000688194574166045
epoch 19 training time: 15.923
---------------
2023-09-23 22:12:38.107236
current #epochs=20, #steps=760
start validation
acc: 0.832536
AUC: 0.881167
Avg Precision: 0.362293
Avg Recall: 1.000000
d_prime: 1.669960
train_loss: 0.094403
valid_loss: 1.110204
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.000688194574166045
Epoch-20 lr: 0.000688194574166045
epoch 20 training time: 15.368
---------------
2023-09-23 22:12:53.475114
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03883	Per Sample Data Time 0.03150	Per Sample DNN Time 0.00734	Train Loss 0.0163	
start validation
acc: 0.837321
AUC: 0.884295
Avg Precision: 0.367991
Avg Recall: 1.000000
d_prime: 1.692440
train_loss: 0.091858
valid_loss: 1.114140
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.000688194574166045
Epoch-21 lr: 0.000688194574166045
epoch 21 training time: 15.455
---------------
2023-09-23 22:13:08.930323
current #epochs=22, #steps=840
start validation
acc: 0.827751
AUC: 0.858696
Avg Precision: 0.329731
Avg Recall: 1.000000
d_prime: 1.519543
train_loss: 0.106613
valid_loss: 1.123916
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.000688194574166045
Epoch-22 lr: 0.000688194574166045
epoch 22 training time: 15.490
---------------
2023-09-23 22:13:24.419969
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00556	Train Loss 0.1334	
start validation
acc: 0.832536
AUC: 0.881006
Avg Precision: 0.386462
Avg Recall: 1.000000
d_prime: 1.668813
train_loss: 0.118935
valid_loss: 1.110589
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.000688194574166045
Epoch-23 lr: 0.000688194574166045
epoch 23 training time: 16.841
---------------
2023-09-23 22:13:41.261028
current #epochs=24, #steps=920
start validation
acc: 0.832536
AUC: 0.885207
Avg Precision: 0.389890
Avg Recall: 1.000000
d_prime: 1.699069
train_loss: 0.102663
valid_loss: 1.111645
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0004738281030578576
Epoch-24 lr: 0.0004738281030578576
epoch 24 training time: 15.475
---------------
2023-09-23 22:13:56.735991
current #epochs=25, #steps=960
start validation
acc: 0.866029
AUC: 0.890592
Avg Precision: 0.384336
Avg Recall: 1.000000
d_prime: 1.739032
train_loss: 0.103552
valid_loss: 1.111275
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.0004738281030578576
Epoch-25 lr: 0.0004738281030578576
epoch 25 training time: 17.745
---------------
2023-09-23 22:14:14.480879
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.03971	Per Sample Data Time 0.03101	Per Sample DNN Time 0.00870	Train Loss 0.0531	
start validation
[I 2023-09-23 22:14:30,884] Trial 28 finished with value: 0.38941304875090954 and parameters: {'warmup': 'True', 'num_epochs': 26, 'batch_size': 29, 'lr-adaptschedule': 'False', 'lr': 0.0014517508930762624, 'head-lr': 1, 'lr-scheduler-start': 6, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.6885089200711049}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.846890
AUC: 0.880830
Avg Precision: 0.389413
Avg Recall: 1.000000
d_prime: 1.667567
train_loss: 0.097070
valid_loss: 1.120872
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.0004738281030578576
Epoch-26 lr: 0.0004738281030578576
epoch 26 training time: 16.396
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 5 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcbd2c98220>
The learning rate scheduler starts at 6 epoch with decay rate of 0.775 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 22:14:30.919410
current #epochs=1, #steps=0
start validation
acc: 0.818182
AUC: 0.883162
Avg Precision: 0.334036
Avg Recall: 1.000000
d_prime: 1.684247
train_loss: 0.305356
valid_loss: 1.132157
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0030546047516801155
Epoch-1 lr: 0.015273023758400579
epoch 1 training time: 18.466
---------------
2023-09-23 22:14:49.385740
current #epochs=2, #steps=40
start validation
acc: 0.851675
AUC: 0.881530
Avg Precision: 0.362735
Avg Recall: 1.000000
d_prime: 1.672551
train_loss: 0.226826
valid_loss: 1.123476
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0030546047516801155
Epoch-2 lr: 0.015273023758400579
epoch 2 training time: 19.174
---------------
2023-09-23 22:15:08.560198
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00559	Train Loss 0.2669	
start validation
acc: 0.712919
AUC: 0.842968
Avg Precision: 0.309148
Avg Recall: 1.000000
d_prime: 1.423730
train_loss: 0.268451
valid_loss: 1.177282
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0030546047516801155
Epoch-3 lr: 0.015273023758400579
epoch 3 training time: 15.408
---------------
2023-09-23 22:15:23.968671
current #epochs=4, #steps=120
start validation
acc: 0.789474
AUC: 0.863368
Avg Precision: 0.347494
Avg Recall: 1.000000
d_prime: 1.549381
train_loss: 0.205180
valid_loss: 1.139590
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0030546047516801155
Epoch-4 lr: 0.015273023758400579
epoch 4 training time: 15.330
---------------
2023-09-23 22:15:39.299112
current #epochs=5, #steps=160
start validation
acc: 0.803828
AUC: 0.869578
Avg Precision: 0.337472
Avg Recall: 1.000000
d_prime: 1.590138
train_loss: 0.163439
valid_loss: 1.134260
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0030546047516801155
Epoch-5 lr: 0.015273023758400579
epoch 5 training time: 15.345
---------------
2023-09-23 22:15:54.644137
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03788	Per Sample Data Time 0.03026	Per Sample DNN Time 0.00763	Train Loss 0.1557	
start validation
acc: 0.794258
AUC: 0.857090
Avg Precision: 0.307738
Avg Recall: 1.000000
d_prime: 1.509444
train_loss: 0.192769
valid_loss: 1.145752
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0023669693997396004
Epoch-6 lr: 0.011834846998698002
epoch 6 training time: 15.293
---------------
2023-09-23 22:16:09.937685
current #epochs=7, #steps=240
start validation
acc: 0.827751
AUC: 0.868275
Avg Precision: 0.298178
Avg Recall: 1.000000
d_prime: 1.581481
train_loss: 0.185818
valid_loss: 1.113151
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0023669693997396004
Epoch-7 lr: 0.011834846998698002
epoch 7 training time: 16.157
---------------
2023-09-23 22:16:26.095100
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00715	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00558	Train Loss 0.1706	
start validation
acc: 0.818182
AUC: 0.865136
Avg Precision: 0.356167
Avg Recall: 1.000000
d_prime: 1.560855
train_loss: 0.147194
valid_loss: 1.107848
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0023669693997396004
Epoch-8 lr: 0.011834846998698002
epoch 8 training time: 15.362
---------------
2023-09-23 22:16:41.457020
current #epochs=9, #steps=320
start validation
acc: 0.837321
AUC: 0.866196
Avg Precision: 0.342669
Avg Recall: 1.000000
d_prime: 1.567783
train_loss: 0.129879
valid_loss: 1.114059
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0023669693997396004
Epoch-9 lr: 0.011834846998698002
epoch 9 training time: 15.351
---------------
2023-09-23 22:16:56.808577
current #epochs=10, #steps=360
start validation
acc: 0.808612
AUC: 0.861991
Avg Precision: 0.314792
Avg Recall: 1.000000
d_prime: 1.540511
train_loss: 0.209346
valid_loss: 1.136727
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0023669693997396004
Epoch-10 lr: 0.011834846998698002
epoch 10 training time: 17.052
---------------
2023-09-23 22:17:13.860524
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03869	Per Sample Data Time 0.03163	Per Sample DNN Time 0.00705	Train Loss 0.1370	
start validation
acc: 0.813397
AUC: 0.869990
Avg Precision: 0.311176
Avg Recall: 1.000000
d_prime: 1.592894
train_loss: 0.179196
valid_loss: 1.133747
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0023669693997396004
Epoch-11 lr: 0.011834846998698002
epoch 11 training time: 15.313
---------------
2023-09-23 22:17:29.173458
current #epochs=12, #steps=440
start validation
acc: 0.822967
AUC: 0.886940
Avg Precision: 0.384076
Avg Recall: 1.000000
d_prime: 1.711784
train_loss: 0.162920
valid_loss: 1.121850
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0023669693997396004
Epoch-12 lr: 0.011834846998698002
epoch 12 training time: 15.520
---------------
2023-09-23 22:17:44.693740
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00164	Per Sample DNN Time 0.00557	Train Loss 0.1652	
start validation
acc: 0.837321
AUC: 0.879331
Avg Precision: 0.367905
Avg Recall: 1.000000
d_prime: 1.656961
train_loss: 0.186742
valid_loss: 1.126168
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0023669693997396004
Epoch-13 lr: 0.011834846998698002
epoch 13 training time: 15.511
---------------
2023-09-23 22:18:00.205054
current #epochs=14, #steps=520
start validation
acc: 0.803828
AUC: 0.875630
Avg Precision: 0.329640
Avg Recall: 1.000000
d_prime: 1.631176
train_loss: 0.175351
valid_loss: 1.127648
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0023669693997396004
Epoch-14 lr: 0.011834846998698002
epoch 14 training time: 15.352
---------------
2023-09-23 22:18:15.557187
current #epochs=15, #steps=560
start validation
acc: 0.736842
AUC: 0.835384
Avg Precision: 0.295790
Avg Recall: 1.000000
d_prime: 1.379794
train_loss: 0.177372
valid_loss: 1.155067
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0018341306305577154
Epoch-15 lr: 0.009170653152788578
epoch 15 training time: 15.444
---------------
2023-09-23 22:18:31.000756
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03780	Per Sample Data Time 0.02984	Per Sample DNN Time 0.00796	Train Loss 0.2779	
start validation
acc: 0.779904
AUC: 0.836619
Avg Precision: 0.292525
Avg Recall: 1.000000
d_prime: 1.386856
train_loss: 0.476896
valid_loss: 1.169865
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0018341306305577154
Epoch-16 lr: 0.009170653152788578
epoch 16 training time: 15.301
---------------
2023-09-23 22:18:46.301604
current #epochs=17, #steps=640
start validation
acc: 0.813397
AUC: 0.866761
Avg Precision: 0.324895
Avg Recall: 1.000000
d_prime: 1.571485
train_loss: 0.265428
valid_loss: 1.136999
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0018341306305577154
Epoch-17 lr: 0.009170653152788578
epoch 17 training time: 15.803
---------------
2023-09-23 22:19:02.104362
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00166	Per Sample DNN Time 0.00555	Train Loss 0.2060	
start validation
acc: 0.827751
AUC: 0.865207
Avg Precision: 0.335718
Avg Recall: 1.000000
d_prime: 1.561316
train_loss: 0.205061
valid_loss: 1.142834
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0018341306305577154
Epoch-18 lr: 0.009170653152788578
epoch 18 training time: 15.454
---------------
2023-09-23 22:19:17.558436
current #epochs=19, #steps=720
start validation
acc: 0.832536
AUC: 0.859285
Avg Precision: 0.326894
Avg Recall: 1.000000
d_prime: 1.523269
train_loss: 0.183971
valid_loss: 1.126152
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0018341306305577154
Epoch-19 lr: 0.009170653152788578
epoch 19 training time: 15.370
---------------
2023-09-23 22:19:32.927957
current #epochs=20, #steps=760
start validation
acc: 0.813397
AUC: 0.887455
Avg Precision: 0.380036
Avg Recall: 1.000000
d_prime: 1.715589
train_loss: 0.188257
valid_loss: 1.125806
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0018341306305577154
Epoch-20 lr: 0.009170653152788578
epoch 20 training time: 15.373
---------------
2023-09-23 22:19:48.301429
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03886	Per Sample Data Time 0.03132	Per Sample DNN Time 0.00754	Train Loss 0.0663	
start validation
acc: 0.799043
AUC: 0.884215
Avg Precision: 0.361731
Avg Recall: 1.000000
d_prime: 1.691858
train_loss: 0.171649
valid_loss: 1.116034
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0018341306305577154
Epoch-21 lr: 0.009170653152788578
epoch 21 training time: 15.558
---------------
2023-09-23 22:20:03.859775
current #epochs=22, #steps=840
start validation
acc: 0.712919
AUC: 0.864780
Avg Precision: 0.312385
Avg Recall: 1.000000
d_prime: 1.558532
train_loss: 0.170580
valid_loss: 1.160309
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0018341306305577154
Epoch-22 lr: 0.009170653152788578
epoch 22 training time: 15.319
---------------
2023-09-23 22:20:19.178883
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00712	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00554	Train Loss 0.1610	
start validation
acc: 0.779904
AUC: 0.873862
Avg Precision: 0.338418
Avg Recall: 1.000000
d_prime: 1.619044
train_loss: 0.161458
valid_loss: 1.125865
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0018341306305577154
Epoch-23 lr: 0.009170653152788578
epoch 23 training time: 15.347
---------------
2023-09-23 22:20:34.526412
current #epochs=24, #steps=920
start validation
acc: 0.794258
AUC: 0.883750
Avg Precision: 0.351748
Avg Recall: 1.000000
d_prime: 1.688491
train_loss: 0.171899
valid_loss: 1.110352
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0014212415125941778
Epoch-24 lr: 0.007106207562970889
epoch 24 training time: 15.311
---------------
2023-09-23 22:20:49.837574
current #epochs=25, #steps=960
start validation
acc: 0.770335
AUC: 0.888420
Avg Precision: 0.339501
Avg Recall: 1.000000
d_prime: 1.722750
train_loss: 0.155290
valid_loss: 1.118912
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.0014212415125941778
Epoch-25 lr: 0.007106207562970889
epoch 25 training time: 15.524
---------------
2023-09-23 22:21:05.361501
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.03723	Per Sample Data Time 0.03009	Per Sample DNN Time 0.00714	Train Loss 0.0585	
start validation
[I 2023-09-23 22:21:20,742] Trial 29 finished with value: 0.38169694107151053 and parameters: {'warmup': 'False', 'num_epochs': 26, 'batch_size': 29, 'lr-adaptschedule': 'True', 'lr': 0.0030546047516801155, 'head-lr': 5, 'lr-scheduler-start': 6, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.7748856536799738}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.846890
AUC: 0.897636
Avg Precision: 0.381697
Avg Recall: 1.000000
d_prime: 1.793500
train_loss: 0.132295
valid_loss: 1.087204
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.0014212415125941778
Epoch-26 lr: 0.007106207562970889
epoch 26 training time: 15.376
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 5 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc52638070>
The learning rate scheduler starts at 7 epoch with decay rate of 0.775 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 22:21:20.776216
current #epochs=1, #steps=0
start validation
acc: 0.827751
AUC: 0.873007
Avg Precision: 0.329586
Avg Recall: 1.000000
d_prime: 1.613226
train_loss: 0.278546
valid_loss: 1.112009
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.00330665685767622
Epoch-1 lr: 0.0165332842883811
epoch 1 training time: 17.801
---------------
2023-09-23 22:21:38.577997
current #epochs=2, #steps=40
start validation
acc: 0.822967
AUC: 0.858830
Avg Precision: 0.335470
Avg Recall: 1.000000
d_prime: 1.520387
train_loss: 0.223898
valid_loss: 1.108974
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.00330665685767622
Epoch-2 lr: 0.0165332842883811
epoch 2 training time: 16.560
---------------
2023-09-23 22:21:55.137520
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00711	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00550	Train Loss 0.2134	
start validation
acc: 0.775120
AUC: 0.879891
Avg Precision: 0.341949
Avg Recall: 1.000000
d_prime: 1.660909
train_loss: 0.233732
valid_loss: 1.130471
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.00330665685767622
Epoch-3 lr: 0.0165332842883811
epoch 3 training time: 15.324
---------------
2023-09-23 22:22:10.461551
current #epochs=4, #steps=120
start validation
acc: 0.851675
AUC: 0.865053
Avg Precision: 0.347164
Avg Recall: 1.000000
d_prime: 1.560308
train_loss: 0.200152
valid_loss: 1.136126
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.00330665685767622
Epoch-4 lr: 0.0165332842883811
epoch 4 training time: 17.692
---------------
2023-09-23 22:22:28.153445
current #epochs=5, #steps=160
start validation
acc: 0.784689
AUC: 0.875240
Avg Precision: 0.376810
Avg Recall: 1.000000
d_prime: 1.628491
train_loss: 0.175007
valid_loss: 1.130962
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.00330665685767622
Epoch-5 lr: 0.0165332842883811
epoch 5 training time: 15.287
---------------
2023-09-23 22:22:43.441155
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03709	Per Sample Data Time 0.02952	Per Sample DNN Time 0.00757	Train Loss 0.1489	
start validation
acc: 0.799043
AUC: 0.864784
Avg Precision: 0.342591
Avg Recall: 1.000000
d_prime: 1.558563
train_loss: 0.260622
valid_loss: 1.127266
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.00330665685767622
Epoch-6 lr: 0.0165332842883811
epoch 6 training time: 15.345
---------------
2023-09-23 22:22:58.786152
current #epochs=7, #steps=240
start validation
acc: 0.842105
AUC: 0.880660
Avg Precision: 0.389290
Avg Recall: 1.000000
d_prime: 1.666360
train_loss: 0.239246
valid_loss: 1.119160
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0025625433506334624
Epoch-7 lr: 0.012812716753167313
epoch 7 training time: 15.331
---------------
2023-09-23 22:23:14.117500
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00727	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00572	Train Loss 0.1377	
start validation
acc: 0.846890
AUC: 0.877136
Avg Precision: 0.367027
Avg Recall: 1.000000
d_prime: 1.641604
train_loss: 0.148995
valid_loss: 1.106465
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0025625433506334624
Epoch-8 lr: 0.012812716753167313
epoch 8 training time: 15.354
---------------
2023-09-23 22:23:29.471904
current #epochs=9, #steps=320
start validation
acc: 0.803828
AUC: 0.883325
Avg Precision: 0.330417
Avg Recall: 1.000000
d_prime: 1.685420
train_loss: 0.173232
valid_loss: 1.129868
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0025625433506334624
Epoch-9 lr: 0.012812716753167313
epoch 9 training time: 15.448
---------------
2023-09-23 22:23:44.920362
current #epochs=10, #steps=360
start validation
acc: 0.808612
AUC: 0.855433
Avg Precision: 0.345065
Avg Recall: 1.000000
d_prime: 1.499099
train_loss: 0.233333
valid_loss: 1.145606
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0025625433506334624
Epoch-10 lr: 0.012812716753167313
epoch 10 training time: 15.309
---------------
2023-09-23 22:24:00.229200
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03927	Per Sample Data Time 0.02898	Per Sample DNN Time 0.01029	Train Loss 0.2917	
start validation
acc: 0.851675
AUC: 0.878226
Avg Precision: 0.352599
Avg Recall: 1.000000
d_prime: 1.649208
train_loss: 0.197602
valid_loss: 1.113607
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0025625433506334624
Epoch-11 lr: 0.012812716753167313
epoch 11 training time: 15.816
---------------
2023-09-23 22:24:16.045258
current #epochs=12, #steps=440
start validation
acc: 0.822967
AUC: 0.865013
Avg Precision: 0.352534
Avg Recall: 1.000000
d_prime: 1.560050
train_loss: 0.163602
valid_loss: 1.144410
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0025625433506334624
Epoch-12 lr: 0.012812716753167313
epoch 12 training time: 15.451
---------------
2023-09-23 22:24:31.496038
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00728	Per Sample Data Time 0.00164	Per Sample DNN Time 0.00564	Train Loss 0.1603	
start validation
acc: 0.794258
AUC: 0.867638
Avg Precision: 0.320268
Avg Recall: 1.000000
d_prime: 1.577268
train_loss: 0.156067
valid_loss: 1.150572
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0025625433506334624
Epoch-13 lr: 0.012812716753167313
epoch 13 training time: 15.455
---------------
2023-09-23 22:24:46.950753
current #epochs=14, #steps=520
start validation
acc: 0.846890
AUC: 0.855154
Avg Precision: 0.316827
Avg Recall: 1.000000
d_prime: 1.497363
train_loss: 0.187788
valid_loss: 1.130673
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0025625433506334624
Epoch-14 lr: 0.012812716753167313
epoch 14 training time: 15.553
---------------
2023-09-23 22:25:02.503792
current #epochs=15, #steps=560
start validation
acc: 0.837321
AUC: 0.872742
Avg Precision: 0.368568
Avg Recall: 1.000000
d_prime: 1.611421
train_loss: 0.158927
valid_loss: 1.120093
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0025625433506334624
Epoch-15 lr: 0.012812716753167313
epoch 15 training time: 15.524
---------------
2023-09-23 22:25:18.028294
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04131	Per Sample Data Time 0.03124	Per Sample DNN Time 0.01007	Train Loss 0.3353	
start validation
acc: 0.827751
AUC: 0.864680
Avg Precision: 0.311987
Avg Recall: 1.000000
d_prime: 1.557886
train_loss: 0.147713
valid_loss: 1.134735
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0019858814223894174
Epoch-16 lr: 0.009929407111947088
epoch 16 training time: 15.449
---------------
2023-09-23 22:25:33.477037
current #epochs=17, #steps=640
start validation
acc: 0.822967
AUC: 0.856558
Avg Precision: 0.322721
Avg Recall: 1.000000
d_prime: 1.506110
train_loss: 0.183631
valid_loss: 1.132794
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0019858814223894174
Epoch-17 lr: 0.009929407111947088
epoch 17 training time: 15.467
---------------
2023-09-23 22:25:48.944376
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00729	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00567	Train Loss 0.1452	
start validation
acc: 0.765550
AUC: 0.863173
Avg Precision: 0.323997
Avg Recall: 1.000000
d_prime: 1.548117
train_loss: 0.142849
valid_loss: 1.146247
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0019858814223894174
Epoch-18 lr: 0.009929407111947088
epoch 18 training time: 15.625
---------------
2023-09-23 22:26:04.569079
current #epochs=19, #steps=720
start validation
acc: 0.779904
AUC: 0.854926
Avg Precision: 0.314601
Avg Recall: 1.000000
d_prime: 1.495948
train_loss: 0.220605
valid_loss: 1.164647
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0019858814223894174
Epoch-19 lr: 0.009929407111947088
epoch 19 training time: 15.347
---------------
2023-09-23 22:26:19.915905
current #epochs=20, #steps=760
start validation
acc: 0.818182
AUC: 0.876358
Avg Precision: 0.302872
Avg Recall: 1.000000
d_prime: 1.636206
train_loss: 0.164636
valid_loss: 1.156156
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0019858814223894174
Epoch-20 lr: 0.009929407111947088
epoch 20 training time: 15.460
---------------
2023-09-23 22:26:35.375784
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04121	Per Sample Data Time 0.03055	Per Sample DNN Time 0.01066	Train Loss 0.3147	
start validation
acc: 0.794258
AUC: 0.857548
Avg Precision: 0.327717
Avg Recall: 1.000000
d_prime: 1.512316
train_loss: 0.169588
valid_loss: 1.140792
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0019858814223894174
Epoch-21 lr: 0.009929407111947088
epoch 21 training time: 15.634
---------------
2023-09-23 22:26:51.009985
current #epochs=22, #steps=840
start validation
acc: 0.822967
AUC: 0.858402
Avg Precision: 0.309209
Avg Recall: 1.000000
d_prime: 1.517691
train_loss: 0.156415
valid_loss: 1.115418
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0019858814223894174
Epoch-22 lr: 0.009929407111947088
epoch 22 training time: 15.471
---------------
2023-09-23 22:27:06.481606
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00723	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00565	Train Loss 0.1149	
start validation
acc: 0.818182
AUC: 0.871016
Avg Precision: 0.317715
Avg Recall: 1.000000
d_prime: 1.599769
train_loss: 0.122462
valid_loss: 1.128903
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0019858814223894174
Epoch-23 lr: 0.009929407111947088
epoch 23 training time: 15.416
---------------
2023-09-23 22:27:21.897260
current #epochs=24, #steps=920
start validation
acc: 0.837321
AUC: 0.871039
Avg Precision: 0.327067
Avg Recall: 1.000000
d_prime: 1.599922
train_loss: 0.130067
valid_loss: 1.132706
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0019858814223894174
Epoch-24 lr: 0.009929407111947088
epoch 24 training time: 15.501
---------------
2023-09-23 22:27:37.398576
current #epochs=25, #steps=960
start validation
acc: 0.842105
AUC: 0.873191
Avg Precision: 0.331068
Avg Recall: 1.000000
d_prime: 1.614471
train_loss: 0.147954
valid_loss: 1.123776
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.0015389886078674626
Epoch-25 lr: 0.007694943039337314
epoch 25 training time: 15.355
---------------
2023-09-23 22:27:52.753514
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.03876	Per Sample Data Time 0.02916	Per Sample DNN Time 0.00960	Train Loss 0.0744	
start validation
[I 2023-09-23 22:28:08,074] Trial 30 finished with value: 0.3593484376819527 and parameters: {'warmup': 'False', 'num_epochs': 26, 'batch_size': 30, 'lr-adaptschedule': 'True', 'lr': 0.00330665685767622, 'head-lr': 5, 'lr-scheduler-start': 7, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.7749650057231251}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.832536
AUC: 0.886130
Avg Precision: 0.359348
Avg Recall: 1.000000
d_prime: 1.705826
train_loss: 0.128300
valid_loss: 1.123676
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.0015389886078674626
Epoch-26 lr: 0.007694943039337314
epoch 26 training time: 15.314
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 5 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc52630ca0>
The learning rate scheduler starts at 6 epoch with decay rate of 0.725 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 22:28:08.109786
current #epochs=1, #steps=0
start validation
acc: 0.832536
AUC: 0.871495
Avg Precision: 0.350765
Avg Recall: 1.000000
d_prime: 1.602994
train_loss: 0.195582
valid_loss: 1.125803
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0029561102370739838
Epoch-1 lr: 0.014780551185369918
epoch 1 training time: 17.777
---------------
2023-09-23 22:28:25.887250
current #epochs=2, #steps=40
start validation
acc: 0.822967
AUC: 0.868508
Avg Precision: 0.302625
Avg Recall: 1.000000
d_prime: 1.583020
train_loss: 0.204000
valid_loss: 1.123694
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0029561102370739838
Epoch-2 lr: 0.014780551185369918
epoch 2 training time: 16.623
---------------
2023-09-23 22:28:42.510300
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00709	Per Sample Data Time 0.00154	Per Sample DNN Time 0.00555	Train Loss 0.1666	
start validation
acc: 0.789474
AUC: 0.855766
Avg Precision: 0.297055
Avg Recall: 1.000000
d_prime: 1.501171
train_loss: 0.168354
valid_loss: 1.150989
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0029561102370739838
Epoch-3 lr: 0.014780551185369918
epoch 3 training time: 15.263
---------------
2023-09-23 22:28:57.772979
current #epochs=4, #steps=120
start validation
acc: 0.799043
AUC: 0.887541
Avg Precision: 0.332363
Avg Recall: 1.000000
d_prime: 1.716225
train_loss: 0.185810
valid_loss: 1.148018
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0029561102370739838
Epoch-4 lr: 0.014780551185369918
epoch 4 training time: 15.300
---------------
2023-09-23 22:29:13.073276
current #epochs=5, #steps=160
start validation
acc: 0.799043
AUC: 0.856912
Avg Precision: 0.310300
Avg Recall: 1.000000
d_prime: 1.508329
train_loss: 0.171978
valid_loss: 1.151452
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0029561102370739838
Epoch-5 lr: 0.014780551185369918
epoch 5 training time: 15.399
---------------
2023-09-23 22:29:28.472317
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03948	Per Sample Data Time 0.02957	Per Sample DNN Time 0.00991	Train Loss 0.1135	
start validation
acc: 0.794258
AUC: 0.869929
Avg Precision: 0.313766
Avg Recall: 1.000000
d_prime: 1.592481
train_loss: 0.170676
valid_loss: 1.131683
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0021445588111080466
Epoch-6 lr: 0.010722794055540231
epoch 6 training time: 15.350
---------------
2023-09-23 22:29:43.822104
current #epochs=7, #steps=240
start validation
acc: 0.789474
AUC: 0.880815
Avg Precision: 0.359644
Avg Recall: 1.000000
d_prime: 1.667455
train_loss: 0.186297
valid_loss: 1.138259
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0021445588111080466
Epoch-7 lr: 0.010722794055540231
epoch 7 training time: 15.555
---------------
2023-09-23 22:29:59.377023
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00564	Train Loss 0.1564	
start validation
acc: 0.822967
AUC: 0.875828
Avg Precision: 0.340652
Avg Recall: 1.000000
d_prime: 1.632540
train_loss: 0.163891
valid_loss: 1.168614
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0021445588111080466
Epoch-8 lr: 0.010722794055540231
epoch 8 training time: 15.278
---------------
2023-09-23 22:30:14.655349
current #epochs=9, #steps=320
start validation
acc: 0.851675
AUC: 0.903222
Avg Precision: 0.363411
Avg Recall: 1.000000
d_prime: 1.838664
train_loss: 0.165990
valid_loss: 1.108389
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0021445588111080466
Epoch-9 lr: 0.010722794055540231
epoch 9 training time: 19.060
---------------
2023-09-23 22:30:33.714982
current #epochs=10, #steps=360
start validation
acc: 0.837321
AUC: 0.868417
Avg Precision: 0.322776
Avg Recall: 1.000000
d_prime: 1.582420
train_loss: 0.160303
valid_loss: 1.129771
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0021445588111080466
Epoch-10 lr: 0.010722794055540231
epoch 10 training time: 15.463
---------------
2023-09-23 22:30:49.177681
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04017	Per Sample Data Time 0.02936	Per Sample DNN Time 0.01081	Train Loss 0.2092	
start validation
acc: 0.837321
AUC: 0.900603
Avg Precision: 0.367892
Avg Recall: 1.000000
d_prime: 1.817259
train_loss: 0.144830
valid_loss: 1.098653
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0021445588111080466
Epoch-11 lr: 0.010722794055540231
epoch 11 training time: 15.350
---------------
2023-09-23 22:31:04.527636
current #epochs=12, #steps=440
start validation
acc: 0.803828
AUC: 0.882351
Avg Precision: 0.335252
Avg Recall: 1.000000
d_prime: 1.678422
train_loss: 0.126283
valid_loss: 1.112564
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0021445588111080466
Epoch-12 lr: 0.010722794055540231
epoch 12 training time: 15.626
---------------
2023-09-23 22:31:20.153662
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00561	Train Loss 0.1095	
start validation
acc: 0.842105
AUC: 0.885370
Avg Precision: 0.336358
Avg Recall: 1.000000
d_prime: 1.700266
train_loss: 0.110874
valid_loss: 1.101501
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0021445588111080466
Epoch-13 lr: 0.010722794055540231
epoch 13 training time: 15.377
---------------
2023-09-23 22:31:35.531315
current #epochs=14, #steps=520
start validation
acc: 0.832536
AUC: 0.872174
Avg Precision: 0.346794
Avg Recall: 1.000000
d_prime: 1.607577
train_loss: 0.151533
valid_loss: 1.120398
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0021445588111080466
Epoch-14 lr: 0.010722794055540231
epoch 14 training time: 15.201
---------------
2023-09-23 22:31:50.732637
current #epochs=15, #steps=560
start validation
acc: 0.851675
AUC: 0.894251
Avg Precision: 0.352986
Avg Recall: 1.000000
d_prime: 1.766997
train_loss: 0.153384
valid_loss: 1.125810
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.001555805475932951
Epoch-15 lr: 0.007779027379664754
epoch 15 training time: 15.462
---------------
2023-09-23 22:32:06.194770
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04045	Per Sample Data Time 0.02981	Per Sample DNN Time 0.01064	Train Loss 0.2640	
start validation
acc: 0.842105
AUC: 0.877111
Avg Precision: 0.343047
Avg Recall: 1.000000
d_prime: 1.641428
train_loss: 0.132756
valid_loss: 1.127769
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.001555805475932951
Epoch-16 lr: 0.007779027379664754
epoch 16 training time: 15.407
---------------
2023-09-23 22:32:21.602318
current #epochs=17, #steps=640
start validation
acc: 0.822967
AUC: 0.895071
Avg Precision: 0.368773
Avg Recall: 1.000000
d_prime: 1.773358
train_loss: 0.147643
valid_loss: 1.106771
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.001555805475932951
Epoch-17 lr: 0.007779027379664754
epoch 17 training time: 15.473
---------------
2023-09-23 22:32:37.074929
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00563	Train Loss 0.1333	
start validation
acc: 0.813397
AUC: 0.867180
Avg Precision: 0.352209
Avg Recall: 1.000000
d_prime: 1.574245
train_loss: 0.133012
valid_loss: 1.125128
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.001555805475932951
Epoch-18 lr: 0.007779027379664754
epoch 18 training time: 15.283
---------------
2023-09-23 22:32:52.357590
current #epochs=19, #steps=720
start validation
acc: 0.846890
AUC: 0.875540
Avg Precision: 0.362400
Avg Recall: 1.000000
d_prime: 1.630555
train_loss: 0.152451
valid_loss: 1.095887
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.001555805475932951
Epoch-19 lr: 0.007779027379664754
epoch 19 training time: 15.333
---------------
2023-09-23 22:33:07.690633
current #epochs=20, #steps=760
start validation
acc: 0.818182
AUC: 0.873965
Avg Precision: 0.324431
Avg Recall: 1.000000
d_prime: 1.619753
train_loss: 0.132425
valid_loss: 1.123212
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.001555805475932951
Epoch-20 lr: 0.007779027379664754
epoch 20 training time: 15.461
---------------
2023-09-23 22:33:23.151138
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03996	Per Sample Data Time 0.03027	Per Sample DNN Time 0.00969	Train Loss 0.1511	
start validation
acc: 0.803828
AUC: 0.883331
Avg Precision: 0.349511
Avg Recall: 1.000000
d_prime: 1.685462
train_loss: 0.132617
valid_loss: 1.103875
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.001555805475932951
Epoch-21 lr: 0.007779027379664754
epoch 21 training time: 15.370
---------------
2023-09-23 22:33:38.520912
current #epochs=22, #steps=840
start validation
[I 2023-09-23 22:33:55,334] Trial 31 finished with value: 0.3802877242890536 and parameters: {'warmup': 'False', 'num_epochs': 22, 'batch_size': 25, 'lr-adaptschedule': 'True', 'lr': 0.0029561102370739838, 'head-lr': 5, 'lr-scheduler-start': 6, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.7254664539272301}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.837321
AUC: 0.894387
Avg Precision: 0.380288
Avg Recall: 1.000000
d_prime: 1.768054
train_loss: 0.110446
valid_loss: 1.095449
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.001555805475932951
Epoch-22 lr: 0.007779027379664754
epoch 22 training time: 16.806
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 5 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0a685280>
The learning rate scheduler starts at 6 epoch with decay rate of 0.736 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 22:33:55.369508
current #epochs=1, #steps=0
start validation
acc: 0.813397
AUC: 0.890644
Avg Precision: 0.348058
Avg Recall: 1.000000
d_prime: 1.739425
train_loss: 0.201605
valid_loss: 1.123792
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0030558822485560874
Epoch-1 lr: 0.015279411242780438
epoch 1 training time: 18.958
---------------
2023-09-23 22:34:14.327320
current #epochs=2, #steps=40
start validation
acc: 0.827751
AUC: 0.858918
Avg Precision: 0.329778
Avg Recall: 1.000000
d_prime: 1.520949
train_loss: 0.170355
valid_loss: 1.142593
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0030558822485560874
Epoch-2 lr: 0.015279411242780438
epoch 2 training time: 17.557
---------------
2023-09-23 22:34:31.884797
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00557	Train Loss 0.2037	
start validation
acc: 0.822967
AUC: 0.857177
Avg Precision: 0.342414
Avg Recall: 1.000000
d_prime: 1.509987
train_loss: 0.199871
valid_loss: 1.116083
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0030558822485560874
Epoch-3 lr: 0.015279411242780438
epoch 3 training time: 15.796
---------------
2023-09-23 22:34:47.680657
current #epochs=4, #steps=120
start validation
acc: 0.803828
AUC: 0.865601
Avg Precision: 0.322435
Avg Recall: 1.000000
d_prime: 1.563887
train_loss: 0.176411
valid_loss: 1.166105
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0030558822485560874
Epoch-4 lr: 0.015279411242780438
epoch 4 training time: 15.368
---------------
2023-09-23 22:35:03.048270
current #epochs=5, #steps=160
start validation
acc: 0.866029
AUC: 0.866100
Avg Precision: 0.412458
Avg Recall: 1.000000
d_prime: 1.567153
train_loss: 0.187389
valid_loss: 1.112166
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0030558822485560874
Epoch-5 lr: 0.015279411242780438
epoch 5 training time: 17.989
---------------
2023-09-23 22:35:21.037090
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04247	Per Sample Data Time 0.03158	Per Sample DNN Time 0.01089	Train Loss 0.1035	
start validation
acc: 0.784689
AUC: 0.825863
Avg Precision: 0.289381
Avg Recall: 1.000000
d_prime: 1.326452
train_loss: 0.299201
valid_loss: 1.147268
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0022490285431164487
Epoch-6 lr: 0.011245142715582244
epoch 6 training time: 15.393
---------------
2023-09-23 22:35:36.430133
current #epochs=7, #steps=240
start validation
acc: 0.861244
AUC: 0.872693
Avg Precision: 0.333087
Avg Recall: 1.000000
d_prime: 1.611093
train_loss: 0.197198
valid_loss: 1.066402
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0022490285431164487
Epoch-7 lr: 0.011245142715582244
epoch 7 training time: 15.454
---------------
2023-09-23 22:35:51.884290
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00730	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00570	Train Loss 0.1333	
start validation
acc: 0.837321
AUC: 0.883704
Avg Precision: 0.365406
Avg Recall: 1.000000
d_prime: 1.688158
train_loss: 0.146041
valid_loss: 1.080292
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0022490285431164487
Epoch-8 lr: 0.011245142715582244
epoch 8 training time: 15.323
---------------
2023-09-23 22:36:07.207362
current #epochs=9, #steps=320
start validation
acc: 0.846890
AUC: 0.871862
Avg Precision: 0.341896
Avg Recall: 1.000000
d_prime: 1.605470
train_loss: 0.123704
valid_loss: 1.109203
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0022490285431164487
Epoch-9 lr: 0.011245142715582244
epoch 9 training time: 15.332
---------------
2023-09-23 22:36:22.539489
current #epochs=10, #steps=360
start validation
acc: 0.885167
AUC: 0.877608
Avg Precision: 0.352390
Avg Recall: 1.000000
d_prime: 1.644889
train_loss: 0.153282
valid_loss: 1.096974
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0022490285431164487
Epoch-10 lr: 0.011245142715582244
epoch 10 training time: 17.772
---------------
2023-09-23 22:36:40.311833
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04012	Per Sample Data Time 0.03080	Per Sample DNN Time 0.00932	Train Loss 0.1213	
start validation
acc: 0.794258
AUC: 0.862892
Avg Precision: 0.331984
Avg Recall: 1.000000
d_prime: 1.546310
train_loss: 0.157325
valid_loss: 1.131118
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0022490285431164487
Epoch-11 lr: 0.011245142715582244
epoch 11 training time: 16.233
---------------
2023-09-23 22:36:56.544919
current #epochs=12, #steps=440
start validation
acc: 0.822967
AUC: 0.865893
Avg Precision: 0.356496
Avg Recall: 1.000000
d_prime: 1.565793
train_loss: 0.115608
valid_loss: 1.101337
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0022490285431164487
Epoch-12 lr: 0.011245142715582244
epoch 12 training time: 15.391
---------------
2023-09-23 22:37:11.935901
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00730	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00571	Train Loss 0.1515	
start validation
acc: 0.794258
AUC: 0.861293
Avg Precision: 0.322914
Avg Recall: 1.000000
d_prime: 1.536045
train_loss: 0.147049
valid_loss: 1.120996
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0022490285431164487
Epoch-13 lr: 0.011245142715582244
epoch 13 training time: 15.389
---------------
2023-09-23 22:37:27.324885
current #epochs=14, #steps=520
start validation
acc: 0.813397
AUC: 0.864019
Avg Precision: 0.354622
Avg Recall: 1.000000
d_prime: 1.553591
train_loss: 0.141365
valid_loss: 1.113330
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0022490285431164487
Epoch-14 lr: 0.011245142715582244
epoch 14 training time: 15.418
---------------
2023-09-23 22:37:42.742586
current #epochs=15, #steps=560
start validation
acc: 0.851675
AUC: 0.879174
Avg Precision: 0.400880
Avg Recall: 1.000000
d_prime: 1.655855
train_loss: 0.106322
valid_loss: 1.083340
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0016552108282779795
Epoch-15 lr: 0.008276054141389898
epoch 15 training time: 15.366
---------------
2023-09-23 22:37:58.108907
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04327	Per Sample Data Time 0.03313	Per Sample DNN Time 0.01013	Train Loss 0.1742	
start validation
acc: 0.842105
AUC: 0.854828
Avg Precision: 0.401069
Avg Recall: 1.000000
d_prime: 1.495344
train_loss: 0.132906
valid_loss: 1.106462
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0016552108282779795
Epoch-16 lr: 0.008276054141389898
epoch 16 training time: 15.477
---------------
2023-09-23 22:38:13.585521
current #epochs=17, #steps=640
start validation
acc: 0.799043
AUC: 0.870911
Avg Precision: 0.346277
Avg Recall: 1.000000
d_prime: 1.599064
train_loss: 0.111491
valid_loss: 1.100881
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0016552108282779795
Epoch-17 lr: 0.008276054141389898
epoch 17 training time: 15.407
---------------
2023-09-23 22:38:28.992243
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00713	Per Sample Data Time 0.00151	Per Sample DNN Time 0.00561	Train Loss 0.1324	
start validation
acc: 0.827751
AUC: 0.877991
Avg Precision: 0.369264
Avg Recall: 1.000000
d_prime: 1.647564
train_loss: 0.129458
valid_loss: 1.094604
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0016552108282779795
Epoch-18 lr: 0.008276054141389898
epoch 18 training time: 15.392
---------------
2023-09-23 22:38:44.384618
current #epochs=19, #steps=720
start validation
acc: 0.818182
AUC: 0.870466
Avg Precision: 0.361865
Avg Recall: 1.000000
d_prime: 1.596079
train_loss: 0.132910
valid_loss: 1.101148
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0016552108282779795
Epoch-19 lr: 0.008276054141389898
epoch 19 training time: 15.309
---------------
2023-09-23 22:38:59.693903
current #epochs=20, #steps=760
start validation
acc: 0.827751
AUC: 0.874523
Avg Precision: 0.379157
Avg Recall: 1.000000
d_prime: 1.623567
train_loss: 0.123066
valid_loss: 1.094827
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0016552108282779795
Epoch-20 lr: 0.008276054141389898
epoch 20 training time: 16.574
---------------
2023-09-23 22:39:16.268307
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03922	Per Sample Data Time 0.02938	Per Sample DNN Time 0.00984	Train Loss 0.1052	
start validation
[I 2023-09-23 22:39:31,585] Trial 32 finished with value: 0.425283662831681 and parameters: {'warmup': 'False', 'num_epochs': 21, 'batch_size': 35, 'lr-adaptschedule': 'True', 'lr': 0.0030558822485560874, 'head-lr': 5, 'lr-scheduler-start': 6, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.7359670171123645}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.813397
AUC: 0.854771
Avg Precision: 0.425284
Avg Recall: 1.000000
d_prime: 1.494988
train_loss: 0.123698
valid_loss: 1.122600
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0016552108282779795
Epoch-21 lr: 0.008276054141389898
epoch 21 training time: 15.311
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 5 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0a6f3fa0>
The learning rate scheduler starts at 6 epoch with decay rate of 0.773 every 10 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 22:39:31.619748
current #epochs=1, #steps=0
start validation
acc: 0.851675
AUC: 0.866837
Avg Precision: 0.336448
Avg Recall: 1.000000
d_prime: 1.571990
train_loss: 0.251478
valid_loss: 1.114999
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.003598584186291411
Epoch-1 lr: 0.017992920931457053
epoch 1 training time: 17.733
---------------
2023-09-23 22:39:49.353462
current #epochs=2, #steps=40
start validation
acc: 0.708134
AUC: 0.851640
Avg Precision: 0.308766
Avg Recall: 1.000000
d_prime: 1.475722
train_loss: 0.242220
valid_loss: 1.149149
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.003598584186291411
Epoch-2 lr: 0.017992920931457053
epoch 2 training time: 15.412
---------------
2023-09-23 22:40:04.765746
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00556	Train Loss 0.2280	
start validation
acc: 0.808612
AUC: 0.866241
Avg Precision: 0.311663
Avg Recall: 1.000000
d_prime: 1.568074
train_loss: 0.217427
valid_loss: 1.127803
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.003598584186291411
Epoch-3 lr: 0.017992920931457053
epoch 3 training time: 15.409
---------------
2023-09-23 22:40:20.174987
current #epochs=4, #steps=120
start validation
acc: 0.818182
AUC: 0.859883
Avg Precision: 0.370660
Avg Recall: 1.000000
d_prime: 1.527062
train_loss: 0.179698
valid_loss: 1.122270
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.003598584186291411
Epoch-4 lr: 0.017992920931457053
epoch 4 training time: 15.271
---------------
2023-09-23 22:40:35.446016
current #epochs=5, #steps=160
start validation
acc: 0.794258
AUC: 0.880802
Avg Precision: 0.340644
Avg Recall: 1.000000
d_prime: 1.667366
train_loss: 0.215050
valid_loss: 1.117751
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.003598584186291411
Epoch-5 lr: 0.017992920931457053
epoch 5 training time: 15.462
---------------
2023-09-23 22:40:50.907983
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04019	Per Sample Data Time 0.03057	Per Sample DNN Time 0.00963	Train Loss 0.2175	
start validation
acc: 0.842105
AUC: 0.870683
Avg Precision: 0.335649
Avg Recall: 1.000000
d_prime: 1.597532
train_loss: 0.170869
valid_loss: 1.122155
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.002779918192662847
Epoch-6 lr: 0.013899590963314234
epoch 6 training time: 15.355
---------------
2023-09-23 22:41:06.263157
current #epochs=7, #steps=240
start validation
acc: 0.870813
AUC: 0.883045
Avg Precision: 0.371503
Avg Recall: 1.000000
d_prime: 1.683402
train_loss: 0.144702
valid_loss: 1.079844
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.002779918192662847
Epoch-7 lr: 0.013899590963314234
epoch 7 training time: 18.969
---------------
2023-09-23 22:41:25.232386
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00562	Train Loss 0.1380	
start validation
acc: 0.827751
AUC: 0.864563
Avg Precision: 0.376040
Avg Recall: 1.000000
d_prime: 1.557123
train_loss: 0.142850
valid_loss: 1.097464
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.002779918192662847
Epoch-8 lr: 0.013899590963314234
epoch 8 training time: 15.414
---------------
2023-09-23 22:41:40.646328
current #epochs=9, #steps=320
start validation
acc: 0.799043
AUC: 0.880961
Avg Precision: 0.339418
Avg Recall: 1.000000
d_prime: 1.668497
train_loss: 0.145649
valid_loss: 1.110452
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.002779918192662847
Epoch-9 lr: 0.013899590963314234
epoch 9 training time: 15.416
---------------
2023-09-23 22:41:56.061813
current #epochs=10, #steps=360
start validation
acc: 0.837321
AUC: 0.835964
Avg Precision: 0.359303
Avg Recall: 1.000000
d_prime: 1.383105
train_loss: 0.147214
valid_loss: 1.132285
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.002779918192662847
Epoch-10 lr: 0.013899590963314234
epoch 10 training time: 15.367
---------------
2023-09-23 22:42:11.428661
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03787	Per Sample Data Time 0.03103	Per Sample DNN Time 0.00684	Train Loss 0.1442	
start validation
acc: 0.827751
AUC: 0.851041
Avg Precision: 0.329042
Avg Recall: 1.000000
d_prime: 1.472067
train_loss: 0.217903
valid_loss: 1.115556
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.002779918192662847
Epoch-11 lr: 0.013899590963314234
epoch 11 training time: 15.405
---------------
2023-09-23 22:42:26.833916
current #epochs=12, #steps=440
start validation
acc: 0.736842
AUC: 0.863389
Avg Precision: 0.339192
Avg Recall: 1.000000
d_prime: 1.549516
train_loss: 0.245681
valid_loss: 1.152500
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.002779918192662847
Epoch-12 lr: 0.013899590963314234
epoch 12 training time: 15.284
---------------
2023-09-23 22:42:42.118037
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00730	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00568	Train Loss 0.3233	
start validation
acc: 0.842105
AUC: 0.865479
Avg Precision: 0.383095
Avg Recall: 1.000000
d_prime: 1.563088
train_loss: 0.278502
valid_loss: 1.115272
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.002779918192662847
Epoch-13 lr: 0.013899590963314234
epoch 13 training time: 15.416
---------------
2023-09-23 22:42:57.533918
current #epochs=14, #steps=520
start validation
acc: 0.808612
AUC: 0.866028
Avg Precision: 0.370074
Avg Recall: 1.000000
d_prime: 1.566682
train_loss: 0.182351
valid_loss: 1.129798
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.002779918192662847
Epoch-14 lr: 0.013899590963314234
epoch 14 training time: 15.444
---------------
2023-09-23 22:43:12.977573
current #epochs=15, #steps=560
start validation
[I 2023-09-23 22:43:28,364] Trial 33 finished with value: 0.3207984732386934 and parameters: {'warmup': 'False', 'num_epochs': 15, 'batch_size': 39, 'lr-adaptschedule': 'True', 'lr': 0.003598584186291411, 'head-lr': 5, 'lr-scheduler-start': 6, 'lr-scheduler-step': 10, 'lr-scheduler-decay': 0.7725033092883522}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.818182
AUC: 0.874249
Avg Precision: 0.320798
Avg Recall: 1.000000
d_prime: 1.621691
train_loss: 0.191080
valid_loss: 1.131253
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.002779918192662847
Epoch-15 lr: 0.013899590963314234
epoch 15 training time: 15.378
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 5 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51df15b0>
The learning rate scheduler starts at 7 epoch with decay rate of 0.745 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 22:43:28.400103
current #epochs=1, #steps=0
start validation
acc: 0.818182
AUC: 0.877675
Avg Precision: 0.373734
Avg Recall: 1.000000
d_prime: 1.645355
train_loss: 0.252184
valid_loss: 1.112220
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0025658603160205514
Epoch-1 lr: 0.012829301580102757
epoch 1 training time: 19.323
---------------
2023-09-23 22:43:47.723216
current #epochs=2, #steps=40
start validation
acc: 0.842105
AUC: 0.884262
Avg Precision: 0.362341
Avg Recall: 1.000000
d_prime: 1.692198
train_loss: 0.160412
valid_loss: 1.098950
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0025658603160205514
Epoch-2 lr: 0.012829301580102757
epoch 2 training time: 17.659
---------------
2023-09-23 22:44:05.382217
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00727	Per Sample Data Time 0.00168	Per Sample DNN Time 0.00559	Train Loss 0.1262	
start validation
acc: 0.818182
AUC: 0.886383
Avg Precision: 0.376633
Avg Recall: 1.000000
d_prime: 1.707681
train_loss: 0.123603
valid_loss: 1.104292
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0025658603160205514
Epoch-3 lr: 0.012829301580102757
epoch 3 training time: 15.403
---------------
2023-09-23 22:44:20.785420
current #epochs=4, #steps=120
start validation
acc: 0.842105
AUC: 0.877251
Avg Precision: 0.406688
Avg Recall: 1.000000
d_prime: 1.642400
train_loss: 0.138825
valid_loss: 1.108202
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0025658603160205514
Epoch-4 lr: 0.012829301580102757
epoch 4 training time: 15.349
---------------
2023-09-23 22:44:36.134417
current #epochs=5, #steps=160
start validation
acc: 0.813397
AUC: 0.855861
Avg Precision: 0.327153
Avg Recall: 1.000000
d_prime: 1.501762
train_loss: 0.179143
valid_loss: 1.129777
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0025658603160205514
Epoch-5 lr: 0.012829301580102757
epoch 5 training time: 15.385
---------------
2023-09-23 22:44:51.519276
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04187	Per Sample Data Time 0.03144	Per Sample DNN Time 0.01043	Train Loss 0.2742	
start validation
acc: 0.842105
AUC: 0.872282
Avg Precision: 0.337956
Avg Recall: 1.000000
d_prime: 1.608308
train_loss: 0.186962
valid_loss: 1.122921
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0025658603160205514
Epoch-6 lr: 0.012829301580102757
epoch 6 training time: 15.479
---------------
2023-09-23 22:45:06.998976
current #epochs=7, #steps=240
start validation
acc: 0.808612
AUC: 0.855403
Avg Precision: 0.332639
Avg Recall: 1.000000
d_prime: 1.498914
train_loss: 0.163816
valid_loss: 1.118935
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0019125026664123805
Epoch-7 lr: 0.009562513332061902
epoch 7 training time: 15.405
---------------
2023-09-23 22:45:22.403834
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00154	Per Sample DNN Time 0.00565	Train Loss 0.1467	
start validation
acc: 0.799043
AUC: 0.857754
Avg Precision: 0.323679
Avg Recall: 1.000000
d_prime: 1.513609
train_loss: 0.138416
valid_loss: 1.116771
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0019125026664123805
Epoch-8 lr: 0.009562513332061902
epoch 8 training time: 15.247
---------------
2023-09-23 22:45:37.650577
current #epochs=9, #steps=320
start validation
acc: 0.784689
AUC: 0.873021
Avg Precision: 0.339973
Avg Recall: 1.000000
d_prime: 1.613316
train_loss: 0.125735
valid_loss: 1.130262
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0019125026664123805
Epoch-9 lr: 0.009562513332061902
epoch 9 training time: 15.404
---------------
2023-09-23 22:45:53.054549
current #epochs=10, #steps=360
start validation
acc: 0.813397
AUC: 0.849704
Avg Precision: 0.310046
Avg Recall: 1.000000
d_prime: 1.463946
train_loss: 0.156351
valid_loss: 1.109194
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0019125026664123805
Epoch-10 lr: 0.009562513332061902
epoch 10 training time: 15.429
---------------
2023-09-23 22:46:08.483695
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04060	Per Sample Data Time 0.03025	Per Sample DNN Time 0.01035	Train Loss 0.2735	
start validation
acc: 0.832536
AUC: 0.852447
Avg Precision: 0.308095
Avg Recall: 1.000000
d_prime: 1.480660
train_loss: 0.257769
valid_loss: 1.113039
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0019125026664123805
Epoch-11 lr: 0.009562513332061902
epoch 11 training time: 15.402
---------------
2023-09-23 22:46:23.886189
current #epochs=12, #steps=440
start validation
acc: 0.799043
AUC: 0.871015
Avg Precision: 0.334299
Avg Recall: 1.000000
d_prime: 1.599764
train_loss: 0.185278
valid_loss: 1.135005
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0019125026664123805
Epoch-12 lr: 0.009562513332061902
epoch 12 training time: 17.330
---------------
2023-09-23 22:46:41.216618
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00732	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00571	Train Loss 0.1700	
start validation
acc: 0.822967
AUC: 0.869781
Avg Precision: 0.322896
Avg Recall: 1.000000
d_prime: 1.591491
train_loss: 0.184070
valid_loss: 1.122392
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0019125026664123805
Epoch-13 lr: 0.009562513332061902
epoch 13 training time: 15.395
---------------
2023-09-23 22:46:56.611044
current #epochs=14, #steps=520
start validation
acc: 0.746411
AUC: 0.847827
Avg Precision: 0.312691
Avg Recall: 1.000000
d_prime: 1.452624
train_loss: 0.192490
valid_loss: 1.143173
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0019125026664123805
Epoch-14 lr: 0.009562513332061902
epoch 14 training time: 15.316
---------------
2023-09-23 22:47:11.927528
current #epochs=15, #steps=560
start validation
acc: 0.770335
AUC: 0.883144
Avg Precision: 0.329990
Avg Recall: 1.000000
d_prime: 1.684116
train_loss: 0.247499
valid_loss: 1.116743
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0014255126930320275
Epoch-15 lr: 0.007127563465160137
epoch 15 training time: 15.406
---------------
2023-09-23 22:47:27.333495
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04106	Per Sample Data Time 0.03081	Per Sample DNN Time 0.01025	Train Loss 0.1656	
start validation
acc: 0.789474
AUC: 0.892422
Avg Precision: 0.360621
Avg Recall: 1.000000
d_prime: 1.752937
train_loss: 0.151491
valid_loss: 1.099719
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0014255126930320275
Epoch-16 lr: 0.007127563465160137
epoch 16 training time: 15.366
---------------
2023-09-23 22:47:42.699303
current #epochs=17, #steps=640
start validation
acc: 0.808612
AUC: 0.877766
Avg Precision: 0.360636
Avg Recall: 1.000000
d_prime: 1.645989
train_loss: 0.157871
valid_loss: 1.101148
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0014255126930320275
Epoch-17 lr: 0.007127563465160137
epoch 17 training time: 15.439
---------------
2023-09-23 22:47:58.137683
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00727	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00565	Train Loss 0.1497	
start validation
acc: 0.765550
AUC: 0.868032
Avg Precision: 0.322309
Avg Recall: 1.000000
d_prime: 1.579866
train_loss: 0.138173
valid_loss: 1.115869
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0014255126930320275
Epoch-18 lr: 0.007127563465160137
epoch 18 training time: 15.363
---------------
2023-09-23 22:48:13.500945
current #epochs=19, #steps=720
start validation
[I 2023-09-23 22:48:28,878] Trial 34 finished with value: 0.31577809247050054 and parameters: {'warmup': 'False', 'num_epochs': 19, 'batch_size': 35, 'lr-adaptschedule': 'True', 'lr': 0.0025658603160205514, 'head-lr': 5, 'lr-scheduler-start': 7, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.7453650748137851}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.799043
AUC: 0.872736
Avg Precision: 0.315778
Avg Recall: 1.000000
d_prime: 1.611382
train_loss: 0.121991
valid_loss: 1.099773
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0014255126930320275
Epoch-19 lr: 0.007127563465160137
epoch 19 training time: 15.372
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc52630a90>
The learning rate scheduler starts at 8 epoch with decay rate of 0.791 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 22:48:28.913200
current #epochs=1, #steps=0
start validation
acc: 0.765550
AUC: 0.877723
Avg Precision: 0.325817
Avg Recall: 1.000000
d_prime: 1.645692
train_loss: 0.148172
valid_loss: 1.122700
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0014392655020575497
Epoch-1 lr: 0.005757062008230199
epoch 1 training time: 18.994
---------------
2023-09-23 22:48:47.907720
current #epochs=2, #steps=40
start validation
acc: 0.765550
AUC: 0.855724
Avg Precision: 0.304245
Avg Recall: 1.000000
d_prime: 1.500907
train_loss: 0.141832
valid_loss: 1.123084
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0014392655020575497
Epoch-2 lr: 0.005757062008230199
epoch 2 training time: 16.594
---------------
2023-09-23 22:49:04.501659
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00726	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00564	Train Loss 0.1347	
start validation
acc: 0.765550
AUC: 0.877806
Avg Precision: 0.306046
Avg Recall: 1.000000
d_prime: 1.646267
train_loss: 0.139454
valid_loss: 1.096342
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0014392655020575497
Epoch-3 lr: 0.005757062008230199
epoch 3 training time: 15.496
---------------
2023-09-23 22:49:19.997388
current #epochs=4, #steps=120
start validation
acc: 0.784689
AUC: 0.834656
Avg Precision: 0.332957
Avg Recall: 1.000000
d_prime: 1.375644
train_loss: 0.147223
valid_loss: 1.134496
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0014392655020575497
Epoch-4 lr: 0.005757062008230199
epoch 4 training time: 17.594
---------------
2023-09-23 22:49:37.591275
current #epochs=5, #steps=160
start validation
acc: 0.842105
AUC: 0.860889
Avg Precision: 0.363024
Avg Recall: 1.000000
d_prime: 1.533461
train_loss: 0.177598
valid_loss: 1.111924
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0014392655020575497
Epoch-5 lr: 0.005757062008230199
epoch 5 training time: 17.718
---------------
2023-09-23 22:49:55.309699
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03770	Per Sample Data Time 0.03022	Per Sample DNN Time 0.00748	Train Loss 0.1926	
start validation
acc: 0.784689
AUC: 0.842397
Avg Precision: 0.314568
Avg Recall: 1.000000
d_prime: 1.420379
train_loss: 0.135615
valid_loss: 1.112798
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0014392655020575497
Epoch-6 lr: 0.005757062008230199
epoch 6 training time: 15.307
---------------
2023-09-23 22:50:10.616544
current #epochs=7, #steps=240
start validation
acc: 0.822967
AUC: 0.841217
Avg Precision: 0.324942
Avg Recall: 1.000000
d_prime: 1.413466
train_loss: 0.111932
valid_loss: 1.106966
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0014392655020575497
Epoch-7 lr: 0.005757062008230199
epoch 7 training time: 15.175
---------------
2023-09-23 22:50:25.790997
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00725	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00567	Train Loss 0.1165	
start validation
acc: 0.808612
AUC: 0.856422
Avg Precision: 0.347313
Avg Recall: 1.000000
d_prime: 1.505260
train_loss: 0.127359
valid_loss: 1.113865
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0011386063840543418
Epoch-8 lr: 0.004554425536217367
epoch 8 training time: 15.731
---------------
2023-09-23 22:50:41.521513
current #epochs=9, #steps=320
start validation
acc: 0.822967
AUC: 0.868873
Avg Precision: 0.329466
Avg Recall: 1.000000
d_prime: 1.585447
train_loss: 0.108118
valid_loss: 1.090405
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0011386063840543418
Epoch-9 lr: 0.004554425536217367
epoch 9 training time: 15.542
---------------
2023-09-23 22:50:57.064261
current #epochs=10, #steps=360
start validation
acc: 0.822967
AUC: 0.860963
Avg Precision: 0.318736
Avg Recall: 1.000000
d_prime: 1.533938
train_loss: 0.120219
valid_loss: 1.104905
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0011386063840543418
Epoch-10 lr: 0.004554425536217367
epoch 10 training time: 15.342
---------------
2023-09-23 22:51:12.406002
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03991	Per Sample Data Time 0.02932	Per Sample DNN Time 0.01059	Train Loss 0.1574	
start validation
acc: 0.803828
AUC: 0.867911
Avg Precision: 0.327997
Avg Recall: 1.000000
d_prime: 1.579070
train_loss: 0.110550
valid_loss: 1.094711
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0011386063840543418
Epoch-11 lr: 0.004554425536217367
epoch 11 training time: 15.365
---------------
2023-09-23 22:51:27.771344
current #epochs=12, #steps=440
start validation
acc: 0.799043
AUC: 0.856760
Avg Precision: 0.322191
Avg Recall: 1.000000
d_prime: 1.507375
train_loss: 0.097853
valid_loss: 1.103497
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0011386063840543418
Epoch-12 lr: 0.004554425536217367
epoch 12 training time: 15.453
---------------
2023-09-23 22:51:43.224130
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00727	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00564	Train Loss 0.1035	
start validation
acc: 0.827751
AUC: 0.887801
Avg Precision: 0.328777
Avg Recall: 1.000000
d_prime: 1.718155
train_loss: 0.099231
valid_loss: 1.088226
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0011386063840543418
Epoch-13 lr: 0.004554425536217367
epoch 13 training time: 15.419
---------------
2023-09-23 22:51:58.643322
current #epochs=14, #steps=520
start validation
acc: 0.827751
AUC: 0.875386
Avg Precision: 0.328648
Avg Recall: 1.000000
d_prime: 1.629491
train_loss: 0.124390
valid_loss: 1.115915
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0011386063840543418
Epoch-14 lr: 0.004554425536217367
epoch 14 training time: 17.082
---------------
2023-09-23 22:52:15.725879
current #epochs=15, #steps=560
start validation
acc: 0.832536
AUC: 0.874461
Avg Precision: 0.322111
Avg Recall: 1.000000
d_prime: 1.623141
train_loss: 0.098304
valid_loss: 1.116069
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0011386063840543418
Epoch-15 lr: 0.004554425536217367
epoch 15 training time: 15.399
---------------
2023-09-23 22:52:31.124448
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04112	Per Sample Data Time 0.03079	Per Sample DNN Time 0.01033	Train Loss 0.0691	
start validation
acc: 0.789474
AUC: 0.869964
Avg Precision: 0.305384
Avg Recall: 1.000000
d_prime: 1.592719
train_loss: 0.097668
valid_loss: 1.101376
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0011386063840543418
Epoch-16 lr: 0.004554425536217367
epoch 16 training time: 15.494
---------------
2023-09-23 22:52:46.618160
current #epochs=17, #steps=640
start validation
acc: 0.784689
AUC: 0.879525
Avg Precision: 0.317395
Avg Recall: 1.000000
d_prime: 1.658330
train_loss: 0.102502
valid_loss: 1.122054
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.000900754236071077
Epoch-17 lr: 0.003603016944284308
epoch 17 training time: 15.351
---------------
2023-09-23 22:53:01.969800
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00731	Per Sample Data Time 0.00165	Per Sample DNN Time 0.00566	Train Loss 0.0948	
start validation
acc: 0.837321
AUC: 0.882218
Avg Precision: 0.321613
Avg Recall: 1.000000
d_prime: 1.677467
train_loss: 0.097395
valid_loss: 1.110851
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.000900754236071077
Epoch-18 lr: 0.003603016944284308
epoch 18 training time: 15.498
---------------
2023-09-23 22:53:17.467316
current #epochs=19, #steps=720
start validation
acc: 0.813397
AUC: 0.884626
Avg Precision: 0.323117
Avg Recall: 1.000000
d_prime: 1.694843
train_loss: 0.085569
valid_loss: 1.112571
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.000900754236071077
Epoch-19 lr: 0.003603016944284308
epoch 19 training time: 15.320
---------------
2023-09-23 22:53:32.787396
current #epochs=20, #steps=760
start validation
acc: 0.846890
AUC: 0.886676
Avg Precision: 0.329453
Avg Recall: 1.000000
d_prime: 1.709837
train_loss: 0.103495
valid_loss: 1.111211
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.000900754236071077
Epoch-20 lr: 0.003603016944284308
epoch 20 training time: 17.733
---------------
2023-09-23 22:53:50.520395
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04105	Per Sample Data Time 0.03016	Per Sample DNN Time 0.01088	Train Loss 0.0447	
start validation
acc: 0.880383
AUC: 0.893695
Avg Precision: 0.352294
Avg Recall: 1.000000
d_prime: 1.762706
train_loss: 0.078084
valid_loss: 1.092514
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.000900754236071077
Epoch-21 lr: 0.003603016944284308
epoch 21 training time: 17.838
---------------
2023-09-23 22:54:08.358743
current #epochs=22, #steps=840
start validation
acc: 0.779904
AUC: 0.870866
Avg Precision: 0.312301
Avg Recall: 1.000000
d_prime: 1.598759
train_loss: 0.080142
valid_loss: 1.113995
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.000900754236071077
Epoch-22 lr: 0.003603016944284308
epoch 22 training time: 15.364
---------------
2023-09-23 22:54:23.722624
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00559	Train Loss 0.0823	
start validation
acc: 0.851675
AUC: 0.883853
Avg Precision: 0.331677
Avg Recall: 1.000000
d_prime: 1.689233
train_loss: 0.081633
valid_loss: 1.088546
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.000900754236071077
Epoch-23 lr: 0.003603016944284308
epoch 23 training time: 15.248
---------------
2023-09-23 22:54:38.970193
current #epochs=24, #steps=920
start validation
acc: 0.827751
AUC: 0.873386
Avg Precision: 0.319258
Avg Recall: 1.000000
d_prime: 1.615799
train_loss: 0.083533
valid_loss: 1.104649
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.000900754236071077
Epoch-24 lr: 0.003603016944284308
epoch 24 training time: 15.462
---------------
2023-09-23 22:54:54.431520
current #epochs=25, #steps=960
start validation
acc: 0.851675
AUC: 0.877453
Avg Precision: 0.358541
Avg Recall: 1.000000
d_prime: 1.643805
train_loss: 0.085352
valid_loss: 1.097434
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.000900754236071077
Epoch-25 lr: 0.003603016944284308
epoch 25 training time: 15.414
---------------
2023-09-23 22:55:09.845945
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.04162	Per Sample Data Time 0.03100	Per Sample DNN Time 0.01062	Train Loss 0.1101	
start validation
[I 2023-09-23 22:55:25,302] Trial 35 finished with value: 0.33705760997307666 and parameters: {'warmup': 'False', 'num_epochs': 26, 'batch_size': 31, 'lr-adaptschedule': 'True', 'lr': 0.0014392655020575497, 'head-lr': 4, 'lr-scheduler-start': 8, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.7911023938436719}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.851675
AUC: 0.870335
Avg Precision: 0.337058
Avg Recall: 1.000000
d_prime: 1.595199
train_loss: 0.080795
valid_loss: 1.111884
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.0007125888324206569
Epoch-26 lr: 0.0028503553296826277
epoch 26 training time: 15.450
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcbd147c2b0>
The learning rate scheduler starts at 7 epoch with decay rate of 0.762 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 22:55:25.339615
current #epochs=1, #steps=0
start validation
acc: 0.813397
AUC: 0.866590
Avg Precision: 0.350691
Avg Recall: 1.000000
d_prime: 1.570367
train_loss: 0.096399
valid_loss: 1.110668
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0011416718190950521
Epoch-1 lr: 0.0045666872763802085
epoch 1 training time: 18.088
---------------
2023-09-23 22:55:43.428076
current #epochs=2, #steps=40
start validation
acc: 0.842105
AUC: 0.871185
Avg Precision: 0.329184
Avg Recall: 1.000000
d_prime: 1.600907
train_loss: 0.107243
valid_loss: 1.082196
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0011416718190950521
Epoch-2 lr: 0.0045666872763802085
epoch 2 training time: 17.869
---------------
2023-09-23 22:56:01.297532
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00556	Train Loss 0.0648	
start validation
acc: 0.856459
AUC: 0.872486
Avg Precision: 0.337892
Avg Recall: 1.000000
d_prime: 1.609689
train_loss: 0.083644
valid_loss: 1.096059
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0011416718190950521
Epoch-3 lr: 0.0045666872763802085
epoch 3 training time: 18.230
---------------
2023-09-23 22:56:19.527750
current #epochs=4, #steps=120
start validation
acc: 0.846890
AUC: 0.873134
Avg Precision: 0.341324
Avg Recall: 1.000000
d_prime: 1.614086
train_loss: 0.093465
valid_loss: 1.101386
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0011416718190950521
Epoch-4 lr: 0.0045666872763802085
epoch 4 training time: 15.298
---------------
2023-09-23 22:56:34.826005
current #epochs=5, #steps=160
start validation
acc: 0.837321
AUC: 0.884178
Avg Precision: 0.334756
Avg Recall: 1.000000
d_prime: 1.691590
train_loss: 0.102986
valid_loss: 1.087578
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0011416718190950521
Epoch-5 lr: 0.0045666872763802085
epoch 5 training time: 15.382
---------------
2023-09-23 22:56:50.208111
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04114	Per Sample Data Time 0.03106	Per Sample DNN Time 0.01008	Train Loss 0.1937	
start validation
acc: 0.837321
AUC: 0.896957
Avg Precision: 0.363638
Avg Recall: 1.000000
d_prime: 1.788133
train_loss: 0.129720
valid_loss: 1.087363
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0011416718190950521
Epoch-6 lr: 0.0045666872763802085
epoch 6 training time: 15.407
---------------
2023-09-23 22:57:05.615259
current #epochs=7, #steps=240
start validation
acc: 0.856459
AUC: 0.875004
Avg Precision: 0.356304
Avg Recall: 1.000000
d_prime: 1.626864
train_loss: 0.099386
valid_loss: 1.115201
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0008699853870710395
Epoch-7 lr: 0.003479941548284158
epoch 7 training time: 15.355
---------------
2023-09-23 22:57:20.970898
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00713	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00557	Train Loss 0.0960	
start validation
acc: 0.822967
AUC: 0.869298
Avg Precision: 0.327905
Avg Recall: 1.000000
d_prime: 1.588271
train_loss: 0.081888
valid_loss: 1.116165
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0008699853870710395
Epoch-8 lr: 0.003479941548284158
epoch 8 training time: 15.179
---------------
2023-09-23 22:57:36.149475
current #epochs=9, #steps=320
start validation
acc: 0.856459
AUC: 0.884205
Avg Precision: 0.365132
Avg Recall: 1.000000
d_prime: 1.691784
train_loss: 0.084108
valid_loss: 1.087377
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0008699853870710395
Epoch-9 lr: 0.003479941548284158
epoch 9 training time: 15.521
---------------
2023-09-23 22:57:51.670274
current #epochs=10, #steps=360
start validation
acc: 0.866029
AUC: 0.885278
Avg Precision: 0.408422
Avg Recall: 1.000000
d_prime: 1.699594
train_loss: 0.092563
valid_loss: 1.103921
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0008699853870710395
Epoch-10 lr: 0.003479941548284158
epoch 10 training time: 18.166
---------------
2023-09-23 22:58:09.836452
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04150	Per Sample Data Time 0.03173	Per Sample DNN Time 0.00977	Train Loss 0.0433	
start validation
acc: 0.827751
AUC: 0.890007
Avg Precision: 0.371206
Avg Recall: 1.000000
d_prime: 1.734628
train_loss: 0.098769
valid_loss: 1.095462
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0008699853870710395
Epoch-11 lr: 0.003479941548284158
epoch 11 training time: 15.504
---------------
2023-09-23 22:58:25.340739
current #epochs=12, #steps=440
start validation
[I 2023-09-23 22:58:40,735] Trial 36 finished with value: 0.3760910026865447 and parameters: {'warmup': 'False', 'num_epochs': 12, 'batch_size': 42, 'lr-adaptschedule': 'True', 'lr': 0.0011416718190950521, 'head-lr': 4, 'lr-scheduler-start': 7, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.7620275568863868}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.842105
AUC: 0.862637
Avg Precision: 0.376091
Avg Recall: 1.000000
d_prime: 1.544666
train_loss: 0.103058
valid_loss: 1.106603
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0008699853870710395
Epoch-12 lr: 0.003479941548284158
epoch 12 training time: 15.387
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 5 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc09831160>
The learning rate scheduler starts at 6 epoch with decay rate of 0.842 every 10 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 22:58:40.770176
current #epochs=1, #steps=0
start validation
acc: 0.751196
AUC: 0.835745
Avg Precision: 0.328446
Avg Recall: 1.000000
d_prime: 1.381858
train_loss: 0.231150
valid_loss: 1.137144
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.003092827671954901
Epoch-1 lr: 0.015464138359774504
epoch 1 training time: 17.698
---------------
2023-09-23 22:58:58.468782
current #epochs=2, #steps=40
start validation
acc: 0.827751
AUC: 0.844687
Avg Precision: 0.389254
Avg Recall: 1.000000
d_prime: 1.433882
train_loss: 0.166835
valid_loss: 1.117769
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.003092827671954901
Epoch-2 lr: 0.015464138359774504
epoch 2 training time: 17.744
---------------
2023-09-23 22:59:16.212682
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00729	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00567	Train Loss 0.1344	
start validation
acc: 0.846890
AUC: 0.866196
Avg Precision: 0.359934
Avg Recall: 1.000000
d_prime: 1.567782
train_loss: 0.159078
valid_loss: 1.081993
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.003092827671954901
Epoch-3 lr: 0.015464138359774504
epoch 3 training time: 17.805
---------------
2023-09-23 22:59:34.017381
current #epochs=4, #steps=120
start validation
acc: 0.813397
AUC: 0.870710
Avg Precision: 0.328099
Avg Recall: 1.000000
d_prime: 1.597711
train_loss: 0.150731
valid_loss: 1.109410
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.003092827671954901
Epoch-4 lr: 0.015464138359774504
epoch 4 training time: 15.339
---------------
2023-09-23 22:59:49.356055
current #epochs=5, #steps=160
start validation
acc: 0.708134
AUC: 0.864940
Avg Precision: 0.338196
Avg Recall: 1.000000
d_prime: 1.559577
train_loss: 0.149519
valid_loss: 1.139104
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.003092827671954901
Epoch-5 lr: 0.015464138359774504
epoch 5 training time: 15.307
---------------
2023-09-23 23:00:04.663521
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03970	Per Sample Data Time 0.02969	Per Sample DNN Time 0.01001	Train Loss 0.2984	
start validation
acc: 0.837321
AUC: 0.877258
Avg Precision: 0.370539
Avg Recall: 1.000000
d_prime: 1.642454
train_loss: 0.206832
valid_loss: 1.085031
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0026029905580911795
Epoch-6 lr: 0.013014952790455897
epoch 6 training time: 15.395
---------------
2023-09-23 23:00:20.058260
current #epochs=7, #steps=240
start validation
acc: 0.866029
AUC: 0.868884
Avg Precision: 0.366065
Avg Recall: 1.000000
d_prime: 1.585522
train_loss: 0.195267
valid_loss: 1.125953
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0026029905580911795
Epoch-7 lr: 0.013014952790455897
epoch 7 training time: 19.677
---------------
2023-09-23 23:00:39.735584
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00726	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00569	Train Loss 0.1718	
start validation
acc: 0.708134
AUC: 0.818431
Avg Precision: 0.285528
Avg Recall: 1.000000
d_prime: 1.286089
train_loss: 0.243635
valid_loss: 1.195910
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0026029905580911795
Epoch-8 lr: 0.013014952790455897
epoch 8 training time: 15.509
---------------
2023-09-23 23:00:55.244679
current #epochs=9, #steps=320
start validation
acc: 0.818182
AUC: 0.873216
Avg Precision: 0.350639
Avg Recall: 1.000000
d_prime: 1.614645
train_loss: 0.233268
valid_loss: 1.131585
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0026029905580911795
Epoch-9 lr: 0.013014952790455897
epoch 9 training time: 15.433
---------------
2023-09-23 23:01:10.678041
current #epochs=10, #steps=360
start validation
acc: 0.837321
AUC: 0.875580
Avg Precision: 0.331945
Avg Recall: 1.000000
d_prime: 1.630830
train_loss: 0.164829
valid_loss: 1.099046
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0026029905580911795
Epoch-10 lr: 0.013014952790455897
epoch 10 training time: 15.364
---------------
2023-09-23 23:01:26.041844
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03865	Per Sample Data Time 0.03079	Per Sample DNN Time 0.00785	Train Loss 0.0598	
start validation
acc: 0.837321
AUC: 0.869828
Avg Precision: 0.371137
Avg Recall: 1.000000
d_prime: 1.591808
train_loss: 0.189697
valid_loss: 1.097111
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0026029905580911795
Epoch-11 lr: 0.013014952790455897
epoch 11 training time: 15.436
---------------
2023-09-23 23:01:41.478063
current #epochs=12, #steps=440
start validation
acc: 0.842105
AUC: 0.879294
Avg Precision: 0.377167
Avg Recall: 1.000000
d_prime: 1.656703
train_loss: 0.155122
valid_loss: 1.068365
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0026029905580911795
Epoch-12 lr: 0.013014952790455897
epoch 12 training time: 15.287
---------------
2023-09-23 23:01:56.764948
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00726	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00567	Train Loss 0.1498	
start validation
acc: 0.827751
AUC: 0.900402
Avg Precision: 0.333765
Avg Recall: 1.000000
d_prime: 1.815634
train_loss: 0.151592
valid_loss: 1.111769
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0026029905580911795
Epoch-13 lr: 0.013014952790455897
epoch 13 training time: 16.144
---------------
2023-09-23 23:02:12.909305
current #epochs=14, #steps=520
start validation
acc: 0.822967
AUC: 0.871853
Avg Precision: 0.351200
Avg Recall: 1.000000
d_prime: 1.605407
train_loss: 0.171076
valid_loss: 1.139068
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0026029905580911795
Epoch-14 lr: 0.013014952790455897
epoch 14 training time: 15.722
---------------
2023-09-23 23:02:28.631376
current #epochs=15, #steps=560
start validation
acc: 0.842105
AUC: 0.866019
Avg Precision: 0.315153
Avg Recall: 1.000000
d_prime: 1.566620
train_loss: 0.359053
valid_loss: 1.121925
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0026029905580911795
Epoch-15 lr: 0.013014952790455897
epoch 15 training time: 15.567
---------------
2023-09-23 23:02:44.198577
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04091	Per Sample Data Time 0.03096	Per Sample DNN Time 0.00995	Train Loss 0.3981	
start validation
acc: 0.755981
AUC: 0.882610
Avg Precision: 0.350886
Avg Recall: 1.000000
d_prime: 1.680276
train_loss: 0.305621
valid_loss: 1.122817
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.002190733065068952
Epoch-16 lr: 0.010953665325344758
epoch 16 training time: 16.197
---------------
2023-09-23 23:03:00.395497
current #epochs=17, #steps=640
start validation
acc: 0.808612
AUC: 0.877840
Avg Precision: 0.390664
Avg Recall: 1.000000
d_prime: 1.646506
train_loss: 0.208798
valid_loss: 1.118385
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.002190733065068952
Epoch-17 lr: 0.010953665325344758
epoch 17 training time: 15.751
---------------
2023-09-23 23:03:16.146946
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00727	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00572	Train Loss 0.1543	
start validation
acc: 0.837321
AUC: 0.872051
Avg Precision: 0.346385
Avg Recall: 1.000000
d_prime: 1.606745
train_loss: 0.158228
valid_loss: 1.120958
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.002190733065068952
Epoch-18 lr: 0.010953665325344758
epoch 18 training time: 15.427
---------------
2023-09-23 23:03:31.573829
current #epochs=19, #steps=720
start validation
acc: 0.837321
AUC: 0.885756
Avg Precision: 0.419411
Avg Recall: 1.000000
d_prime: 1.703087
train_loss: 0.149995
valid_loss: 1.104958
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.002190733065068952
Epoch-19 lr: 0.010953665325344758
epoch 19 training time: 16.344
---------------
2023-09-23 23:03:47.918146
current #epochs=20, #steps=760
start validation
acc: 0.822967
AUC: 0.885387
Avg Precision: 0.399786
Avg Recall: 1.000000
d_prime: 1.700388
train_loss: 0.116847
valid_loss: 1.111319
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.002190733065068952
Epoch-20 lr: 0.010953665325344758
epoch 20 training time: 15.460
---------------
2023-09-23 23:04:03.377728
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03943	Per Sample Data Time 0.02970	Per Sample DNN Time 0.00973	Train Loss 0.1857	
start validation
acc: 0.822967
AUC: 0.875328
Avg Precision: 0.353349
Avg Recall: 1.000000
d_prime: 1.629095
train_loss: 0.106391
valid_loss: 1.111255
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.002190733065068952
Epoch-21 lr: 0.010953665325344758
epoch 21 training time: 15.361
---------------
2023-09-23 23:04:18.738542
current #epochs=22, #steps=840
start validation
acc: 0.837321
AUC: 0.877433
Avg Precision: 0.405119
Avg Recall: 1.000000
d_prime: 1.643668
train_loss: 0.127224
valid_loss: 1.096734
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.002190733065068952
Epoch-22 lr: 0.010953665325344758
epoch 22 training time: 15.387
---------------
2023-09-23 23:04:34.125228
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00727	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00566	Train Loss 0.0945	
start validation
acc: 0.846890
AUC: 0.896411
Avg Precision: 0.386038
Avg Recall: 1.000000
d_prime: 1.783834
train_loss: 0.097012
valid_loss: 1.075068
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.002190733065068952
Epoch-23 lr: 0.010953665325344758
epoch 23 training time: 16.560
---------------
2023-09-23 23:04:50.685469
current #epochs=24, #steps=920
start validation
acc: 0.832536
AUC: 0.865387
Avg Precision: 0.377720
Avg Recall: 1.000000
d_prime: 1.562492
train_loss: 0.160629
valid_loss: 1.117732
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.002190733065068952
Epoch-24 lr: 0.010953665325344758
epoch 24 training time: 15.450
---------------
2023-09-23 23:05:06.135202
current #epochs=25, #steps=960
start validation
acc: 0.899522
AUC: 0.896394
Avg Precision: 0.382310
Avg Recall: 1.000000
d_prime: 1.783707
train_loss: 0.125691
valid_loss: 1.070588
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.002190733065068952
Epoch-25 lr: 0.010953665325344758
epoch 25 training time: 18.780
---------------
2023-09-23 23:05:24.914954
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.04208	Per Sample Data Time 0.03166	Per Sample DNN Time 0.01042	Train Loss 0.1098	
start validation
acc: 0.832536
AUC: 0.868415
Avg Precision: 0.315599
Avg Recall: 1.000000
d_prime: 1.582406
train_loss: 0.204406
valid_loss: 1.116461
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.0018437682562728258
Epoch-26 lr: 0.009218841281364128
epoch 26 training time: 15.468
---------------
2023-09-23 23:05:40.382246
current #epochs=27, #steps=1040
start validation
acc: 0.822967
AUC: 0.892825
Avg Precision: 0.338267
Avg Recall: 1.000000
d_prime: 1.756017
train_loss: 0.137201
valid_loss: 1.082481
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.0018437682562728258
Epoch-27 lr: 0.009218841281364128
epoch 27 training time: 15.279
---------------
2023-09-23 23:05:55.661361
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00726	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00565	Train Loss 0.1091	
start validation
acc: 0.803828
AUC: 0.874754
Avg Precision: 0.377312
Avg Recall: 1.000000
d_prime: 1.625151
train_loss: 0.117460
valid_loss: 1.100044
validation finished
normal learning rate scheduler step
Epoch-28 lr: 0.0018437682562728258
Epoch-28 lr: 0.009218841281364128
epoch 28 training time: 15.410
---------------
2023-09-23 23:06:11.071180
current #epochs=29, #steps=1120
start validation
[I 2023-09-23 23:06:26,340] Trial 37 finished with value: 0.3794762360197174 and parameters: {'warmup': 'False', 'num_epochs': 29, 'batch_size': 13, 'lr-adaptschedule': 'True', 'lr': 0.003092827671954901, 'head-lr': 5, 'lr-scheduler-start': 6, 'lr-scheduler-step': 10, 'lr-scheduler-decay': 0.8416215949225172}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.803828
AUC: 0.894639
Avg Precision: 0.379476
Avg Recall: 1.000000
d_prime: 1.770008
train_loss: 0.100337
valid_loss: 1.088063
validation finished
normal learning rate scheduler step
Epoch-29 lr: 0.0018437682562728258
Epoch-29 lr: 0.009218841281364128
epoch 29 training time: 15.260
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcbd2c98640>
The learning rate scheduler starts at 8 epoch with decay rate of 0.799 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 23:06:26.374978
current #epochs=1, #steps=0
start validation
acc: 0.837321
AUC: 0.877615
Avg Precision: 0.368256
Avg Recall: 1.000000
d_prime: 1.644939
train_loss: 0.150819
valid_loss: 1.079247
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.002494260608617827
Epoch-1 lr: 0.009977042434471308
epoch 1 training time: 18.035
---------------
2023-09-23 23:06:44.410293
current #epochs=2, #steps=40
start validation
acc: 0.875598
AUC: 0.869974
Avg Precision: 0.397536
Avg Recall: 1.000000
d_prime: 1.592783
train_loss: 0.139529
valid_loss: 1.067818
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.002494260608617827
Epoch-2 lr: 0.009977042434471308
epoch 2 training time: 17.764
---------------
2023-09-23 23:07:02.174915
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00729	Per Sample Data Time 0.00169	Per Sample DNN Time 0.00560	Train Loss 0.0979	
start validation
acc: 0.827751
AUC: 0.887348
Avg Precision: 0.356875
Avg Recall: 1.000000
d_prime: 1.714798
train_loss: 0.097327
valid_loss: 1.072025
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.002494260608617827
Epoch-3 lr: 0.009977042434471308
epoch 3 training time: 16.550
---------------
2023-09-23 23:07:18.724650
current #epochs=4, #steps=120
start validation
acc: 0.846890
AUC: 0.887547
Avg Precision: 0.344071
Avg Recall: 1.000000
d_prime: 1.716271
train_loss: 0.151593
valid_loss: 1.085222
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.002494260608617827
Epoch-4 lr: 0.009977042434471308
epoch 4 training time: 16.481
---------------
2023-09-23 23:07:35.205209
current #epochs=5, #steps=160
start validation
acc: 0.808612
AUC: 0.887095
Avg Precision: 0.335115
Avg Recall: 1.000000
d_prime: 1.712927
train_loss: 0.131037
valid_loss: 1.099638
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.002494260608617827
Epoch-5 lr: 0.009977042434471308
epoch 5 training time: 16.347
---------------
2023-09-23 23:07:51.552391
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03868	Per Sample Data Time 0.03086	Per Sample DNN Time 0.00782	Train Loss 0.0560	
start validation
acc: 0.861244
AUC: 0.873779
Avg Precision: 0.407455
Avg Recall: 1.000000
d_prime: 1.618482
train_loss: 0.123439
valid_loss: 1.103692
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.002494260608617827
Epoch-6 lr: 0.009977042434471308
epoch 6 training time: 15.326
---------------
2023-09-23 23:08:06.878748
current #epochs=7, #steps=240
start validation
acc: 0.775120
AUC: 0.872248
Avg Precision: 0.329326
Avg Recall: 1.000000
d_prime: 1.608076
train_loss: 0.163306
valid_loss: 1.144300
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.002494260608617827
Epoch-7 lr: 0.009977042434471308
epoch 7 training time: 15.364
---------------
2023-09-23 23:08:22.242904
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00559	Train Loss 0.1427	
start validation
acc: 0.822967
AUC: 0.877151
Avg Precision: 0.338472
Avg Recall: 1.000000
d_prime: 1.641704
train_loss: 0.195498
valid_loss: 1.112359
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0019923920385967572
Epoch-8 lr: 0.007969568154387029
epoch 8 training time: 15.374
---------------
2023-09-23 23:08:37.617272
current #epochs=9, #steps=320
start validation
acc: 0.842105
AUC: 0.899082
Avg Precision: 0.347502
Avg Recall: 1.000000
d_prime: 1.805018
train_loss: 0.268972
valid_loss: 1.100635
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0019923920385967572
Epoch-9 lr: 0.007969568154387029
epoch 9 training time: 15.390
---------------
2023-09-23 23:08:53.007430
current #epochs=10, #steps=360
start validation
acc: 0.818182
AUC: 0.877583
Avg Precision: 0.331600
Avg Recall: 1.000000
d_prime: 1.644715
train_loss: 0.175156
valid_loss: 1.092629
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0019923920385967572
Epoch-10 lr: 0.007969568154387029
epoch 10 training time: 15.323
---------------
2023-09-23 23:09:08.330982
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03919	Per Sample Data Time 0.03124	Per Sample DNN Time 0.00795	Train Loss 0.1216	
start validation
acc: 0.851675
AUC: 0.878968
Avg Precision: 0.357937
Avg Recall: 1.000000
d_prime: 1.654406
train_loss: 0.166776
valid_loss: 1.105201
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0019923920385967572
Epoch-11 lr: 0.007969568154387029
epoch 11 training time: 15.404
---------------
2023-09-23 23:09:23.735150
current #epochs=12, #steps=440
start validation
acc: 0.818182
AUC: 0.891561
Avg Precision: 0.399910
Avg Recall: 1.000000
d_prime: 1.746371
train_loss: 0.155385
valid_loss: 1.092700
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0019923920385967572
Epoch-12 lr: 0.007969568154387029
epoch 12 training time: 15.486
---------------
2023-09-23 23:09:39.221187
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00556	Train Loss 0.1182	
start validation
acc: 0.808612
AUC: 0.871282
Avg Precision: 0.388095
Avg Recall: 1.000000
d_prime: 1.601560
train_loss: 0.125783
valid_loss: 1.110887
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0019923920385967572
Epoch-13 lr: 0.007969568154387029
epoch 13 training time: 15.396
---------------
2023-09-23 23:09:54.617616
current #epochs=14, #steps=520
start validation
acc: 0.880383
AUC: 0.899153
Avg Precision: 0.405061
Avg Recall: 1.000000
d_prime: 1.805580
train_loss: 0.126448
valid_loss: 1.056479
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0019923920385967572
Epoch-14 lr: 0.007969568154387029
epoch 14 training time: 17.771
---------------
2023-09-23 23:10:12.388530
current #epochs=15, #steps=560
start validation
acc: 0.779904
AUC: 0.880169
Avg Precision: 0.373194
Avg Recall: 1.000000
d_prime: 1.662875
train_loss: 0.121256
valid_loss: 1.084447
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0019923920385967572
Epoch-15 lr: 0.007969568154387029
epoch 15 training time: 15.317
---------------
2023-09-23 23:10:27.705639
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03944	Per Sample Data Time 0.03188	Per Sample DNN Time 0.00756	Train Loss 0.2594	
start validation
acc: 0.827751
AUC: 0.877785
Avg Precision: 0.375846
Avg Recall: 1.000000
d_prime: 1.646122
train_loss: 0.126229
valid_loss: 1.099942
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0019923920385967572
Epoch-16 lr: 0.007969568154387029
epoch 16 training time: 15.460
---------------
2023-09-23 23:10:43.165850
current #epochs=17, #steps=640
start validation
acc: 0.775120
AUC: 0.864236
Avg Precision: 0.335697
Avg Recall: 1.000000
d_prime: 1.554997
train_loss: 0.297787
valid_loss: 1.127526
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0015915041201983607
Epoch-17 lr: 0.006366016480793443
epoch 17 training time: 15.387
---------------
2023-09-23 23:10:58.552934
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00557	Train Loss 0.2894	
start validation
acc: 0.803828
AUC: 0.872583
Avg Precision: 0.348490
Avg Recall: 1.000000
d_prime: 1.610347
train_loss: 0.233470
valid_loss: 1.112377
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0015915041201983607
Epoch-18 lr: 0.006366016480793443
epoch 18 training time: 15.400
---------------
2023-09-23 23:11:13.953166
current #epochs=19, #steps=720
start validation
acc: 0.808612
AUC: 0.865098
Avg Precision: 0.338137
Avg Recall: 1.000000
d_prime: 1.560606
train_loss: 0.159932
valid_loss: 1.120399
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0015915041201983607
Epoch-19 lr: 0.006366016480793443
epoch 19 training time: 15.344
---------------
2023-09-23 23:11:29.297840
current #epochs=20, #steps=760
start validation
acc: 0.775120
AUC: 0.863303
Avg Precision: 0.345891
Avg Recall: 1.000000
d_prime: 1.548961
train_loss: 0.171110
valid_loss: 1.119286
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0015915041201983607
Epoch-20 lr: 0.006366016480793443
epoch 20 training time: 15.370
---------------
2023-09-23 23:11:44.667864
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03926	Per Sample Data Time 0.03119	Per Sample DNN Time 0.00807	Train Loss 0.1711	
start validation
acc: 0.837321
AUC: 0.871725
Avg Precision: 0.367802
Avg Recall: 1.000000
d_prime: 1.604542
train_loss: 0.140015
valid_loss: 1.103015
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0015915041201983607
Epoch-21 lr: 0.006366016480793443
epoch 21 training time: 15.507
---------------
2023-09-23 23:12:00.175012
current #epochs=22, #steps=840
start validation
acc: 0.818182
AUC: 0.873382
Avg Precision: 0.387745
Avg Recall: 1.000000
d_prime: 1.615774
train_loss: 0.110956
valid_loss: 1.098262
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0015915041201983607
Epoch-22 lr: 0.006366016480793443
epoch 22 training time: 15.195
---------------
2023-09-23 23:12:15.369973
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00555	Train Loss 0.0936	
start validation
acc: 0.775120
AUC: 0.871461
Avg Precision: 0.332847
Avg Recall: 1.000000
d_prime: 1.602766
train_loss: 0.099401
valid_loss: 1.123772
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0015915041201983607
Epoch-23 lr: 0.006366016480793443
epoch 23 training time: 15.427
---------------
2023-09-23 23:12:30.797580
current #epochs=24, #steps=920
start validation
acc: 0.813397
AUC: 0.884883
Avg Precision: 0.351665
Avg Recall: 1.000000
d_prime: 1.696710
train_loss: 0.106896
valid_loss: 1.090963
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0015915041201983607
Epoch-24 lr: 0.006366016480793443
epoch 24 training time: 15.347
---------------
2023-09-23 23:12:46.144749
current #epochs=25, #steps=960
start validation
acc: 0.794258
AUC: 0.880759
Avg Precision: 0.367305
Avg Recall: 1.000000
d_prime: 1.667060
train_loss: 0.096795
valid_loss: 1.087866
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.0015915041201983607
Epoch-25 lr: 0.006366016480793443
epoch 25 training time: 15.403
---------------
2023-09-23 23:13:01.547602
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.03828	Per Sample Data Time 0.03037	Per Sample DNN Time 0.00791	Train Loss 0.1276	
start validation
acc: 0.837321
AUC: 0.879619
Avg Precision: 0.383879
Avg Recall: 1.000000
d_prime: 1.658991
train_loss: 0.090387
valid_loss: 1.098197
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.0012712786015709391
Epoch-26 lr: 0.005085114406283757
epoch 26 training time: 15.377
---------------
2023-09-23 23:13:16.924966
current #epochs=27, #steps=1040
start validation
acc: 0.779904
AUC: 0.848899
Avg Precision: 0.350204
Avg Recall: 1.000000
d_prime: 1.459079
train_loss: 0.109291
valid_loss: 1.120986
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.0012712786015709391
Epoch-27 lr: 0.005085114406283757
epoch 27 training time: 15.396
---------------
2023-09-23 23:13:32.321183
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00707	Per Sample Data Time 0.00151	Per Sample DNN Time 0.00556	Train Loss 0.0957	
start validation
acc: 0.794258
AUC: 0.886226
Avg Precision: 0.379152
Avg Recall: 1.000000
d_prime: 1.706533
train_loss: 0.106012
valid_loss: 1.093023
validation finished
normal learning rate scheduler step
Epoch-28 lr: 0.0012712786015709391
Epoch-28 lr: 0.005085114406283757
epoch 28 training time: 15.721
---------------
2023-09-23 23:13:48.042297
current #epochs=29, #steps=1120
start validation
acc: 0.799043
AUC: 0.858555
Avg Precision: 0.345389
Avg Recall: 1.000000
d_prime: 1.518652
train_loss: 0.135101
valid_loss: 1.115938
validation finished
normal learning rate scheduler step
Epoch-29 lr: 0.0012712786015709391
Epoch-29 lr: 0.005085114406283757
epoch 29 training time: 15.347
---------------
2023-09-23 23:14:03.389300
current #epochs=30, #steps=1160
start validation
acc: 0.827751
AUC: 0.855637
Avg Precision: 0.383457
Avg Recall: 1.000000
d_prime: 1.500370
train_loss: 0.106942
valid_loss: 1.132088
validation finished
normal learning rate scheduler step
Epoch-30 lr: 0.0012712786015709391
Epoch-30 lr: 0.005085114406283757
epoch 30 training time: 15.359
---------------
2023-09-23 23:14:18.748083
current #epochs=31, #steps=1200
Epoch: [31][0/40]	Per Sample Total Time 0.03885	Per Sample Data Time 0.03089	Per Sample DNN Time 0.00795	Train Loss 0.0837	
start validation
acc: 0.789474
AUC: 0.868283
Avg Precision: 0.346471
Avg Recall: 1.000000
d_prime: 1.581529
train_loss: 0.093510
valid_loss: 1.112695
validation finished
normal learning rate scheduler step
Epoch-31 lr: 0.0012712786015709391
Epoch-31 lr: 0.005085114406283757
epoch 31 training time: 15.351
---------------
2023-09-23 23:14:34.099180
current #epochs=32, #steps=1240
start validation
[I 2023-09-23 23:14:49,421] Trial 38 finished with value: 0.3660732587165752 and parameters: {'warmup': 'False', 'num_epochs': 32, 'batch_size': 34, 'lr-adaptschedule': 'True', 'lr': 0.002494260608617827, 'head-lr': 4, 'lr-scheduler-start': 8, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.7987906442947131}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.803828
AUC: 0.879424
Avg Precision: 0.366073
Avg Recall: 1.000000
d_prime: 1.657620
train_loss: 0.086203
valid_loss: 1.090132
validation finished
normal learning rate scheduler step
Epoch-32 lr: 0.0012712786015709391
Epoch-32 lr: 0.005085114406283757
epoch 32 training time: 15.314
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51db27c0>
The learning rate scheduler starts at 10 epoch with decay rate of 0.733 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 23:14:49.457021
current #epochs=1, #steps=0
start validation
acc: 0.779904
AUC: 0.877039
Avg Precision: 0.363075
Avg Recall: 1.000000
d_prime: 1.640925
train_loss: 0.133213
valid_loss: 1.121847
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.001410422659068762
Epoch-1 lr: 0.005641690636275048
epoch 1 training time: 17.892
---------------
2023-09-23 23:15:07.349833
current #epochs=2, #steps=40
start validation
acc: 0.760766
AUC: 0.841377
Avg Precision: 0.342648
Avg Recall: 1.000000
d_prime: 1.414404
train_loss: 0.104050
valid_loss: 1.139176
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.001410422659068762
Epoch-2 lr: 0.005641690636275048
epoch 2 training time: 15.234
---------------
2023-09-23 23:15:22.583813
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00560	Train Loss 0.1112	
start validation
acc: 0.789474
AUC: 0.893226
Avg Precision: 0.363988
Avg Recall: 1.000000
d_prime: 1.759092
train_loss: 0.122587
valid_loss: 1.097061
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.001410422659068762
Epoch-3 lr: 0.005641690636275048
epoch 3 training time: 17.681
---------------
2023-09-23 23:15:40.264981
current #epochs=4, #steps=120
start validation
acc: 0.808612
AUC: 0.870007
Avg Precision: 0.409334
Avg Recall: 1.000000
d_prime: 1.593007
train_loss: 0.104484
valid_loss: 1.107373
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.001410422659068762
Epoch-4 lr: 0.005641690636275048
epoch 4 training time: 17.688
---------------
2023-09-23 23:15:57.953316
current #epochs=5, #steps=160
start validation
acc: 0.818182
AUC: 0.883908
Avg Precision: 0.387983
Avg Recall: 1.000000
d_prime: 1.689635
train_loss: 0.087352
valid_loss: 1.086562
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.001410422659068762
Epoch-5 lr: 0.005641690636275048
epoch 5 training time: 17.703
---------------
2023-09-23 23:16:15.656035
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03790	Per Sample Data Time 0.02992	Per Sample DNN Time 0.00799	Train Loss 0.1441	
start validation
acc: 0.851675
AUC: 0.871007
Avg Precision: 0.389905
Avg Recall: 1.000000
d_prime: 1.599707
train_loss: 0.120464
valid_loss: 1.087695
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.001410422659068762
Epoch-6 lr: 0.005641690636275048
epoch 6 training time: 17.765
---------------
2023-09-23 23:16:33.421417
current #epochs=7, #steps=240
start validation
acc: 0.837321
AUC: 0.873578
Avg Precision: 0.393583
Avg Recall: 1.000000
d_prime: 1.617107
train_loss: 0.142607
valid_loss: 1.089932
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.001410422659068762
Epoch-7 lr: 0.005641690636275048
epoch 7 training time: 15.341
---------------
2023-09-23 23:16:48.762795
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00723	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00565	Train Loss 0.1089	
start validation
acc: 0.832536
AUC: 0.865083
Avg Precision: 0.336826
Avg Recall: 1.000000
d_prime: 1.560509
train_loss: 0.101966
valid_loss: 1.094364
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.001410422659068762
Epoch-8 lr: 0.005641690636275048
epoch 8 training time: 15.290
---------------
2023-09-23 23:17:04.052488
current #epochs=9, #steps=320
start validation
acc: 0.813397
AUC: 0.866013
Avg Precision: 0.363322
Avg Recall: 1.000000
d_prime: 1.566579
train_loss: 0.117179
valid_loss: 1.111889
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.001410422659068762
Epoch-9 lr: 0.005641690636275048
epoch 9 training time: 15.264
---------------
2023-09-23 23:17:19.316348
current #epochs=10, #steps=360
start validation
acc: 0.818182
AUC: 0.892637
Avg Precision: 0.386888
Avg Recall: 1.000000
d_prime: 1.754578
train_loss: 0.100831
valid_loss: 1.090124
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0010336978861500827
Epoch-10 lr: 0.004134791544600331
epoch 10 training time: 15.387
---------------
2023-09-23 23:17:34.703567
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03838	Per Sample Data Time 0.03052	Per Sample DNN Time 0.00787	Train Loss 0.0601	
start validation
acc: 0.794258
AUC: 0.871513
Avg Precision: 0.348317
Avg Recall: 1.000000
d_prime: 1.603112
train_loss: 0.088107
valid_loss: 1.084436
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0010336978861500827
Epoch-11 lr: 0.004134791544600331
epoch 11 training time: 15.370
---------------
2023-09-23 23:17:50.073124
current #epochs=12, #steps=440
start validation
acc: 0.808612
AUC: 0.880246
Avg Precision: 0.390336
Avg Recall: 1.000000
d_prime: 1.663420
train_loss: 0.075444
valid_loss: 1.087148
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0010336978861500827
Epoch-12 lr: 0.004134791544600331
epoch 12 training time: 15.257
---------------
2023-09-23 23:18:05.330004
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00557	Train Loss 0.0759	
start validation
acc: 0.808612
AUC: 0.879799
Avg Precision: 0.385762
Avg Recall: 1.000000
d_prime: 1.660260
train_loss: 0.068760
valid_loss: 1.095995
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0010336978861500827
Epoch-13 lr: 0.004134791544600331
epoch 13 training time: 15.353
---------------
2023-09-23 23:18:20.682595
current #epochs=14, #steps=520
start validation
acc: 0.789474
AUC: 0.858264
Avg Precision: 0.326733
Avg Recall: 1.000000
d_prime: 1.516816
train_loss: 0.097930
valid_loss: 1.113998
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0010336978861500827
Epoch-14 lr: 0.004134791544600331
epoch 14 training time: 15.366
---------------
2023-09-23 23:18:36.048664
current #epochs=15, #steps=560
start validation
acc: 0.818182
AUC: 0.859649
Avg Precision: 0.381926
Avg Recall: 1.000000
d_prime: 1.525572
train_loss: 0.091564
valid_loss: 1.107064
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0010336978861500827
Epoch-15 lr: 0.004134791544600331
epoch 15 training time: 15.903
---------------
2023-09-23 23:18:51.951652
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03894	Per Sample Data Time 0.03117	Per Sample DNN Time 0.00777	Train Loss 0.0481	
start validation
acc: 0.837321
AUC: 0.859975
Avg Precision: 0.402386
Avg Recall: 1.000000
d_prime: 1.527640
train_loss: 0.087648
valid_loss: 1.098933
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0010336978861500827
Epoch-16 lr: 0.004134791544600331
epoch 16 training time: 15.333
---------------
2023-09-23 23:19:07.284554
current #epochs=17, #steps=640
start validation
acc: 0.827751
AUC: 0.864796
Avg Precision: 0.372676
Avg Recall: 1.000000
d_prime: 1.558639
train_loss: 0.083940
valid_loss: 1.086983
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0010336978861500827
Epoch-17 lr: 0.004134791544600331
epoch 17 training time: 15.465
---------------
2023-09-23 23:19:22.749980
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00559	Train Loss 0.0836	
start validation
acc: 0.818182
AUC: 0.874561
Avg Precision: 0.324001
Avg Recall: 1.000000
d_prime: 1.623830
train_loss: 0.078167
valid_loss: 1.098774
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0007575965353085379
Epoch-18 lr: 0.0030303861412341515
epoch 18 training time: 15.367
---------------
2023-09-23 23:19:38.116423
current #epochs=19, #steps=720
start validation
acc: 0.818182
AUC: 0.880322
Avg Precision: 0.346959
Avg Recall: 1.000000
d_prime: 1.663961
train_loss: 0.090224
valid_loss: 1.084693
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0007575965353085379
Epoch-19 lr: 0.0030303861412341515
epoch 19 training time: 15.278
---------------
2023-09-23 23:19:53.395046
current #epochs=20, #steps=760
start validation
acc: 0.803828
AUC: 0.870764
Avg Precision: 0.325158
Avg Recall: 1.000000
d_prime: 1.598078
train_loss: 0.074632
valid_loss: 1.108324
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0007575965353085379
Epoch-20 lr: 0.0030303861412341515
epoch 20 training time: 15.343
---------------
2023-09-23 23:20:08.738419
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03891	Per Sample Data Time 0.03101	Per Sample DNN Time 0.00790	Train Loss 0.0408	
start validation
[I 2023-09-23 23:20:24,200] Trial 39 finished with value: 0.3550920423828851 and parameters: {'warmup': 'False', 'num_epochs': 21, 'batch_size': 28, 'lr-adaptschedule': 'True', 'lr': 0.001410422659068762, 'head-lr': 4, 'lr-scheduler-start': 10, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.7328993755904251}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.832536
AUC: 0.874270
Avg Precision: 0.355092
Avg Recall: 1.000000
d_prime: 1.621834
train_loss: 0.084115
valid_loss: 1.093914
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0007575965353085379
Epoch-21 lr: 0.0030303861412341515
epoch 21 training time: 15.454
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcbd147c0a0>
The learning rate scheduler starts at 7 epoch with decay rate of 0.691 every 10 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 23:20:24.235091
current #epochs=1, #steps=0
start validation
acc: 0.789474
AUC: 0.853929
Avg Precision: 0.325241
Avg Recall: 1.000000
d_prime: 1.489779
train_loss: 0.159569
valid_loss: 1.155452
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.002107258915276079
Epoch-1 lr: 0.006321776745828237
epoch 1 training time: 17.748
---------------
2023-09-23 23:20:41.983549
current #epochs=2, #steps=40
start validation
acc: 0.827751
AUC: 0.849719
Avg Precision: 0.371532
Avg Recall: 1.000000
d_prime: 1.464032
train_loss: 0.116256
valid_loss: 1.116524
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.002107258915276079
Epoch-2 lr: 0.006321776745828237
epoch 2 training time: 18.164
---------------
2023-09-23 23:21:00.147118
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00712	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00555	Train Loss 0.1253	
start validation
acc: 0.822967
AUC: 0.860930
Avg Precision: 0.295200
Avg Recall: 1.000000
d_prime: 1.533723
train_loss: 0.128878
valid_loss: 1.129727
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.002107258915276079
Epoch-3 lr: 0.006321776745828237
epoch 3 training time: 15.324
---------------
2023-09-23 23:21:15.470522
current #epochs=4, #steps=120
start validation
acc: 0.813397
AUC: 0.879616
Avg Precision: 0.345421
Avg Recall: 1.000000
d_prime: 1.658972
train_loss: 0.140149
valid_loss: 1.110642
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.002107258915276079
Epoch-4 lr: 0.006321776745828237
epoch 4 training time: 15.439
---------------
2023-09-23 23:21:30.910065
current #epochs=5, #steps=160
start validation
acc: 0.799043
AUC: 0.883979
Avg Precision: 0.365204
Avg Recall: 1.000000
d_prime: 1.690151
train_loss: 0.108464
valid_loss: 1.113827
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.002107258915276079
Epoch-5 lr: 0.006321776745828237
epoch 5 training time: 15.386
---------------
2023-09-23 23:21:46.296179
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03807	Per Sample Data Time 0.03088	Per Sample DNN Time 0.00719	Train Loss 0.0486	
start validation
acc: 0.880383
AUC: 0.890968
Avg Precision: 0.433960
Avg Recall: 1.000000
d_prime: 1.741879
train_loss: 0.097313
valid_loss: 1.066808
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.002107258915276079
Epoch-6 lr: 0.006321776745828237
epoch 6 training time: 17.646
---------------
2023-09-23 23:22:03.942140
current #epochs=7, #steps=240
start validation
acc: 0.818182
AUC: 0.880857
Avg Precision: 0.364823
Avg Recall: 1.000000
d_prime: 1.667756
train_loss: 0.082450
valid_loss: 1.098768
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0014564844568467755
Epoch-7 lr: 0.004369453370540326
epoch 7 training time: 15.297
---------------
2023-09-23 23:22:19.238925
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00558	Train Loss 0.0822	
start validation
acc: 0.822967
AUC: 0.887271
Avg Precision: 0.372680
Avg Recall: 1.000000
d_prime: 1.714229
train_loss: 0.091325
valid_loss: 1.091726
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0014564844568467755
Epoch-8 lr: 0.004369453370540326
epoch 8 training time: 15.355
---------------
2023-09-23 23:22:34.594198
current #epochs=9, #steps=320
start validation
acc: 0.818182
AUC: 0.885712
Avg Precision: 0.369406
Avg Recall: 1.000000
d_prime: 1.702760
train_loss: 0.086034
valid_loss: 1.092719
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0014564844568467755
Epoch-9 lr: 0.004369453370540326
epoch 9 training time: 15.253
---------------
2023-09-23 23:22:49.847174
current #epochs=10, #steps=360
start validation
acc: 0.813397
AUC: 0.872478
Avg Precision: 0.343339
Avg Recall: 1.000000
d_prime: 1.609635
train_loss: 0.091675
valid_loss: 1.085286
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0014564844568467755
Epoch-10 lr: 0.004369453370540326
epoch 10 training time: 15.316
---------------
2023-09-23 23:23:05.163586
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03637	Per Sample Data Time 0.02927	Per Sample DNN Time 0.00709	Train Loss 0.0185	
start validation
acc: 0.842105
AUC: 0.883196
Avg Precision: 0.382352
Avg Recall: 1.000000
d_prime: 1.684490
train_loss: 0.073868
valid_loss: 1.093402
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0014564844568467755
Epoch-11 lr: 0.004369453370540326
epoch 11 training time: 15.256
---------------
2023-09-23 23:23:20.419544
current #epochs=12, #steps=440
start validation
acc: 0.875598
AUC: 0.886250
Avg Precision: 0.434896
Avg Recall: 1.000000
d_prime: 1.706707
train_loss: 0.102031
valid_loss: 1.066912
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0014564844568467755
Epoch-12 lr: 0.004369453370540326
epoch 12 training time: 15.274
---------------
2023-09-23 23:23:35.693458
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00558	Train Loss 0.0972	
start validation
acc: 0.813397
AUC: 0.857497
Avg Precision: 0.387723
Avg Recall: 1.000000
d_prime: 1.511997
train_loss: 0.091337
valid_loss: 1.114913
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0014564844568467755
Epoch-13 lr: 0.004369453370540326
epoch 13 training time: 15.251
---------------
2023-09-23 23:23:50.944155
current #epochs=14, #steps=520
start validation
acc: 0.832536
AUC: 0.891240
Avg Precision: 0.394486
Avg Recall: 1.000000
d_prime: 1.743939
train_loss: 0.112522
valid_loss: 1.099531
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0014564844568467755
Epoch-14 lr: 0.004369453370540326
epoch 14 training time: 16.783
---------------
2023-09-23 23:24:07.727759
current #epochs=15, #steps=560
start validation
acc: 0.832536
AUC: 0.889143
Avg Precision: 0.403571
Avg Recall: 1.000000
d_prime: 1.728146
train_loss: 0.090781
valid_loss: 1.100084
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0014564844568467755
Epoch-15 lr: 0.004369453370540326
epoch 15 training time: 15.378
---------------
2023-09-23 23:24:23.105417
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03854	Per Sample Data Time 0.03125	Per Sample DNN Time 0.00729	Train Loss 0.0152	
start validation
acc: 0.846890
AUC: 0.885263
Avg Precision: 0.335256
Avg Recall: 1.000000
d_prime: 1.699479
train_loss: 0.081074
valid_loss: 1.100098
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0014564844568467755
Epoch-16 lr: 0.004369453370540326
epoch 16 training time: 15.436
---------------
2023-09-23 23:24:38.541094
current #epochs=17, #steps=640
start validation
[I 2023-09-23 23:24:53,968] Trial 40 finished with value: 0.39933761422593933 and parameters: {'warmup': 'False', 'num_epochs': 17, 'batch_size': 38, 'lr-adaptschedule': 'True', 'lr': 0.002107258915276079, 'head-lr': 3, 'lr-scheduler-start': 7, 'lr-scheduler-step': 10, 'lr-scheduler-decay': 0.6911748937391287}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.808612
AUC: 0.885563
Avg Precision: 0.399338
Avg Recall: 1.000000
d_prime: 1.701674
train_loss: 0.091567
valid_loss: 1.087717
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0010066854896937625
Epoch-17 lr: 0.003020056469081288
epoch 17 training time: 15.420
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51db2760>
The learning rate scheduler starts at 7 epoch with decay rate of 0.686 every 10 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 23:24:54.004820
current #epochs=1, #steps=0
start validation
acc: 0.861244
AUC: 0.883700
Avg Precision: 0.434472
Avg Recall: 1.000000
d_prime: 1.688129
train_loss: 0.134347
valid_loss: 1.085543
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0021093577025317486
Epoch-1 lr: 0.006328073107595245
epoch 1 training time: 18.041
---------------
2023-09-23 23:25:12.045648
current #epochs=2, #steps=40
start validation
acc: 0.822967
AUC: 0.863083
Avg Precision: 0.390758
Avg Recall: 1.000000
d_prime: 1.547537
train_loss: 0.092573
valid_loss: 1.123729
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0021093577025317486
Epoch-2 lr: 0.006328073107595245
epoch 2 training time: 15.522
---------------
2023-09-23 23:25:27.568074
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00164	Per Sample DNN Time 0.00553	Train Loss 0.1586	
start validation
acc: 0.803828
AUC: 0.847607
Avg Precision: 0.362679
Avg Recall: 1.000000
d_prime: 1.451300
train_loss: 0.213534
valid_loss: 1.135762
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0021093577025317486
Epoch-3 lr: 0.006328073107595245
epoch 3 training time: 15.356
---------------
2023-09-23 23:25:42.923821
current #epochs=4, #steps=120
start validation
acc: 0.813397
AUC: 0.857639
Avg Precision: 0.333397
Avg Recall: 1.000000
d_prime: 1.512888
train_loss: 0.190070
valid_loss: 1.125448
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0021093577025317486
Epoch-4 lr: 0.006328073107595245
epoch 4 training time: 15.415
---------------
2023-09-23 23:25:58.339374
current #epochs=5, #steps=160
start validation
acc: 0.789474
AUC: 0.845699
Avg Precision: 0.338631
Avg Recall: 1.000000
d_prime: 1.439898
train_loss: 0.190931
valid_loss: 1.142604
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0021093577025317486
Epoch-5 lr: 0.006328073107595245
epoch 5 training time: 15.433
---------------
2023-09-23 23:26:13.772248
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03880	Per Sample Data Time 0.03103	Per Sample DNN Time 0.00776	Train Loss 0.1482	
start validation
acc: 0.799043
AUC: 0.858750
Avg Precision: 0.330267
Avg Recall: 1.000000
d_prime: 1.519881
train_loss: 0.143873
valid_loss: 1.130420
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0021093577025317486
Epoch-6 lr: 0.006328073107595245
epoch 6 training time: 15.394
---------------
2023-09-23 23:26:29.166102
current #epochs=7, #steps=240
start validation
acc: 0.822967
AUC: 0.853553
Avg Precision: 0.413600
Avg Recall: 1.000000
d_prime: 1.487461
train_loss: 0.114487
valid_loss: 1.113726
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0014471296154617676
Epoch-7 lr: 0.004341388846385303
epoch 7 training time: 15.405
---------------
2023-09-23 23:26:44.571399
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00557	Train Loss 0.1177	
start validation
acc: 0.851675
AUC: 0.882965
Avg Precision: 0.410220
Avg Recall: 1.000000
d_prime: 1.682830
train_loss: 0.108687
valid_loss: 1.080172
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0014471296154617676
Epoch-8 lr: 0.004341388846385303
epoch 8 training time: 15.382
---------------
2023-09-23 23:26:59.952853
current #epochs=9, #steps=320
start validation
acc: 0.813397
AUC: 0.862361
Avg Precision: 0.378410
Avg Recall: 1.000000
d_prime: 1.542892
train_loss: 0.081914
valid_loss: 1.109078
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0014471296154617676
Epoch-9 lr: 0.004341388846385303
epoch 9 training time: 15.308
---------------
2023-09-23 23:27:15.261159
current #epochs=10, #steps=360
start validation
acc: 0.822967
AUC: 0.861420
Avg Precision: 0.412943
Avg Recall: 1.000000
d_prime: 1.536854
train_loss: 0.081978
valid_loss: 1.098869
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0014471296154617676
Epoch-10 lr: 0.004341388846385303
epoch 10 training time: 15.367
---------------
2023-09-23 23:27:30.628691
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03924	Per Sample Data Time 0.03152	Per Sample DNN Time 0.00772	Train Loss 0.1074	
start validation
acc: 0.813397
AUC: 0.872906
Avg Precision: 0.388841
Avg Recall: 1.000000
d_prime: 1.612538
train_loss: 0.096053
valid_loss: 1.105377
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0014471296154617676
Epoch-11 lr: 0.004341388846385303
epoch 11 training time: 16.515
---------------
2023-09-23 23:27:47.143958
current #epochs=12, #steps=440
start validation
acc: 0.765550
AUC: 0.865517
Avg Precision: 0.384181
Avg Recall: 1.000000
d_prime: 1.563341
train_loss: 0.097462
valid_loss: 1.127251
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0014471296154617676
Epoch-12 lr: 0.004341388846385303
epoch 12 training time: 15.237
---------------
2023-09-23 23:28:02.381475
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00557	Train Loss 0.1194	
start validation
acc: 0.813397
AUC: 0.865116
Avg Precision: 0.387623
Avg Recall: 1.000000
d_prime: 1.560721
train_loss: 0.128903
valid_loss: 1.130524
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0014471296154617676
Epoch-13 lr: 0.004341388846385303
epoch 13 training time: 15.353
---------------
2023-09-23 23:28:17.734373
current #epochs=14, #steps=520
start validation
acc: 0.789474
AUC: 0.867107
Avg Precision: 0.356453
Avg Recall: 1.000000
d_prime: 1.573767
train_loss: 0.091083
valid_loss: 1.126141
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0014471296154617676
Epoch-14 lr: 0.004341388846385303
epoch 14 training time: 15.438
---------------
2023-09-23 23:28:33.172339
current #epochs=15, #steps=560
start validation
acc: 0.808612
AUC: 0.870184
Avg Precision: 0.355961
Avg Recall: 1.000000
d_prime: 1.594191
train_loss: 0.097269
valid_loss: 1.126015
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0014471296154617676
Epoch-15 lr: 0.004341388846385303
epoch 15 training time: 15.412
---------------
2023-09-23 23:28:48.584852
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03802	Per Sample Data Time 0.03062	Per Sample DNN Time 0.00740	Train Loss 0.0261	
start validation
acc: 0.779904
AUC: 0.872344
Avg Precision: 0.344995
Avg Recall: 1.000000
d_prime: 1.608729
train_loss: 0.102290
valid_loss: 1.128852
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0014471296154617676
Epoch-16 lr: 0.004341388846385303
epoch 16 training time: 15.377
---------------
2023-09-23 23:29:03.961445
current #epochs=17, #steps=640
start validation
[I 2023-09-23 23:29:19,385] Trial 41 finished with value: 0.3284452991297012 and parameters: {'warmup': 'False', 'num_epochs': 17, 'batch_size': 37, 'lr-adaptschedule': 'True', 'lr': 0.0021093577025317486, 'head-lr': 3, 'lr-scheduler-start': 7, 'lr-scheduler-step': 10, 'lr-scheduler-decay': 0.6860522583366756}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.755981
AUC: 0.868108
Avg Precision: 0.328445
Avg Recall: 1.000000
d_prime: 1.580370
train_loss: 0.095653
valid_loss: 1.112379
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0009928065407934306
Epoch-17 lr: 0.0029784196223802918
epoch 17 training time: 15.414
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc097f9940>
The learning rate scheduler starts at 9 epoch with decay rate of 0.755 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 23:29:19.423966
current #epochs=1, #steps=0
start validation
acc: 0.775120
AUC: 0.867587
Avg Precision: 0.372708
Avg Recall: 1.000000
d_prime: 1.576926
train_loss: 0.121371
valid_loss: 1.120207
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.001548820227110196
Epoch-1 lr: 0.004646460681330587
epoch 1 training time: 18.706
---------------
2023-09-23 23:29:38.130330
current #epochs=2, #steps=40
start validation
acc: 0.842105
AUC: 0.886960
Avg Precision: 0.401392
Avg Recall: 1.000000
d_prime: 1.711929
train_loss: 0.100774
valid_loss: 1.096589
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.001548820227110196
Epoch-2 lr: 0.004646460681330587
epoch 2 training time: 18.819
---------------
2023-09-23 23:29:56.949129
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00557	Train Loss 0.0933	
start validation
acc: 0.799043
AUC: 0.897951
Avg Precision: 0.363378
Avg Recall: 1.000000
d_prime: 1.795999
train_loss: 0.102158
valid_loss: 1.127885
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.001548820227110196
Epoch-3 lr: 0.004646460681330587
epoch 3 training time: 15.248
---------------
2023-09-23 23:30:12.196855
current #epochs=4, #steps=120
start validation
acc: 0.794258
AUC: 0.878287
Avg Precision: 0.344236
Avg Recall: 1.000000
d_prime: 1.649633
train_loss: 0.094935
valid_loss: 1.094377
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.001548820227110196
Epoch-4 lr: 0.004646460681330587
epoch 4 training time: 15.856
---------------
2023-09-23 23:30:28.052760
current #epochs=5, #steps=160
start validation
acc: 0.851675
AUC: 0.880524
Avg Precision: 0.427096
Avg Recall: 1.000000
d_prime: 1.665394
train_loss: 0.086345
valid_loss: 1.104363
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.001548820227110196
Epoch-5 lr: 0.004646460681330587
epoch 5 training time: 17.741
---------------
2023-09-23 23:30:45.794190
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03960	Per Sample Data Time 0.03200	Per Sample DNN Time 0.00760	Train Loss 0.0533	
start validation
acc: 0.827751
AUC: 0.871735
Avg Precision: 0.361294
Avg Recall: 1.000000
d_prime: 1.604611
train_loss: 0.089654
valid_loss: 1.118144
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.001548820227110196
Epoch-6 lr: 0.004646460681330587
epoch 6 training time: 15.395
---------------
2023-09-23 23:31:01.188969
current #epochs=7, #steps=240
start validation
acc: 0.808612
AUC: 0.868320
Avg Precision: 0.355720
Avg Recall: 1.000000
d_prime: 1.581777
train_loss: 0.092850
valid_loss: 1.101580
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.001548820227110196
Epoch-7 lr: 0.004646460681330587
epoch 7 training time: 15.433
---------------
2023-09-23 23:31:16.622311
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00712	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00555	Train Loss 0.0909	
start validation
acc: 0.799043
AUC: 0.872803
Avg Precision: 0.335308
Avg Recall: 1.000000
d_prime: 1.611836
train_loss: 0.081958
valid_loss: 1.104731
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.001548820227110196
Epoch-8 lr: 0.004646460681330587
epoch 8 training time: 15.265
---------------
2023-09-23 23:31:31.887841
current #epochs=9, #steps=320
start validation
acc: 0.822967
AUC: 0.863113
Avg Precision: 0.355361
Avg Recall: 1.000000
d_prime: 1.547731
train_loss: 0.089019
valid_loss: 1.107666
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0011692580091083754
Epoch-9 lr: 0.0035077740273251256
epoch 9 training time: 15.337
---------------
2023-09-23 23:31:47.224492
current #epochs=10, #steps=360
start validation
acc: 0.846890
AUC: 0.881145
Avg Precision: 0.343079
Avg Recall: 1.000000
d_prime: 1.669806
train_loss: 0.083172
valid_loss: 1.106124
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0011692580091083754
Epoch-10 lr: 0.0035077740273251256
epoch 10 training time: 15.342
---------------
2023-09-23 23:32:02.566564
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03759	Per Sample Data Time 0.03027	Per Sample DNN Time 0.00732	Train Loss 0.0417	
start validation
acc: 0.822967
AUC: 0.881461
Avg Precision: 0.322635
Avg Recall: 1.000000
d_prime: 1.672055
train_loss: 0.086728
valid_loss: 1.095785
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0011692580091083754
Epoch-11 lr: 0.0035077740273251256
epoch 11 training time: 15.331
---------------
2023-09-23 23:32:17.897760
current #epochs=12, #steps=440
start validation
acc: 0.822967
AUC: 0.885004
Avg Precision: 0.337420
Avg Recall: 1.000000
d_prime: 1.697594
train_loss: 0.084464
valid_loss: 1.087515
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0011692580091083754
Epoch-12 lr: 0.0035077740273251256
epoch 12 training time: 15.357
---------------
2023-09-23 23:32:33.255281
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00558	Train Loss 0.0762	
start validation
acc: 0.827751
AUC: 0.876004
Avg Precision: 0.326271
Avg Recall: 1.000000
d_prime: 1.633759
train_loss: 0.071612
valid_loss: 1.104155
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0011692580091083754
Epoch-13 lr: 0.0035077740273251256
epoch 13 training time: 15.359
---------------
2023-09-23 23:32:48.614561
current #epochs=14, #steps=520
start validation
acc: 0.808612
AUC: 0.884769
Avg Precision: 0.327082
Avg Recall: 1.000000
d_prime: 1.695879
train_loss: 0.091417
valid_loss: 1.105057
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0011692580091083754
Epoch-14 lr: 0.0035077740273251256
epoch 14 training time: 15.459
---------------
2023-09-23 23:33:04.073581
current #epochs=15, #steps=560
start validation
acc: 0.822967
AUC: 0.864375
Avg Precision: 0.320296
Avg Recall: 1.000000
d_prime: 1.555904
train_loss: 0.089765
valid_loss: 1.120045
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0011692580091083754
Epoch-15 lr: 0.0035077740273251256
epoch 15 training time: 15.382
---------------
2023-09-23 23:33:19.455077
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03866	Per Sample Data Time 0.03073	Per Sample DNN Time 0.00793	Train Loss 0.1471	
start validation
acc: 0.842105
AUC: 0.877328
Avg Precision: 0.330887
Avg Recall: 1.000000
d_prime: 1.642938
train_loss: 0.079204
valid_loss: 1.100358
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0011692580091083754
Epoch-16 lr: 0.0035077740273251256
epoch 16 training time: 15.370
---------------
2023-09-23 23:33:34.824882
current #epochs=17, #steps=640
start validation
acc: 0.861244
AUC: 0.888077
Avg Precision: 0.356534
Avg Recall: 1.000000
d_prime: 1.720203
train_loss: 0.062671
valid_loss: 1.091541
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0011692580091083754
Epoch-17 lr: 0.0035077740273251256
epoch 17 training time: 17.812
---------------
2023-09-23 23:33:52.636884
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00711	Per Sample Data Time 0.00153	Per Sample DNN Time 0.00558	Train Loss 0.0977	
start validation
acc: 0.846890
AUC: 0.874221
Avg Precision: 0.360774
Avg Recall: 1.000000
d_prime: 1.621502
train_loss: 0.106958
valid_loss: 1.102890
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0008827133504157227
Epoch-18 lr: 0.0026481400512471677
epoch 18 training time: 15.315
---------------
2023-09-23 23:34:07.951550
current #epochs=19, #steps=720
start validation
acc: 0.827751
AUC: 0.865575
Avg Precision: 0.355772
Avg Recall: 1.000000
d_prime: 1.563719
train_loss: 0.117831
valid_loss: 1.112449
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0008827133504157227
Epoch-19 lr: 0.0026481400512471677
epoch 19 training time: 15.243
---------------
2023-09-23 23:34:23.194837
current #epochs=20, #steps=760
start validation
acc: 0.832536
AUC: 0.880063
Avg Precision: 0.341383
Avg Recall: 1.000000
d_prime: 1.662129
train_loss: 0.071658
valid_loss: 1.110881
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0008827133504157227
Epoch-20 lr: 0.0026481400512471677
epoch 20 training time: 15.279
---------------
2023-09-23 23:34:38.474574
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03854	Per Sample Data Time 0.03024	Per Sample DNN Time 0.00831	Train Loss 0.1466	
start validation
acc: 0.765550
AUC: 0.853219
Avg Precision: 0.299996
Avg Recall: 1.000000
d_prime: 1.485407
train_loss: 0.094952
valid_loss: 1.126880
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0008827133504157227
Epoch-21 lr: 0.0026481400512471677
epoch 21 training time: 15.382
---------------
2023-09-23 23:34:53.856256
current #epochs=22, #steps=840
start validation
acc: 0.832536
AUC: 0.875468
Avg Precision: 0.363712
Avg Recall: 1.000000
d_prime: 1.630058
train_loss: 0.106303
valid_loss: 1.105340
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0008827133504157227
Epoch-22 lr: 0.0026481400512471677
epoch 22 training time: 15.258
---------------
2023-09-23 23:35:09.113537
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00715	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00557	Train Loss 0.0883	
start validation
acc: 0.846890
AUC: 0.882733
Avg Precision: 0.389561
Avg Recall: 1.000000
d_prime: 1.681164
train_loss: 0.077359
valid_loss: 1.098364
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0008827133504157227
Epoch-23 lr: 0.0026481400512471677
epoch 23 training time: 15.329
---------------
2023-09-23 23:35:24.442882
current #epochs=24, #steps=920
start validation
acc: 0.870813
AUC: 0.880875
Avg Precision: 0.389332
Avg Recall: 1.000000
d_prime: 1.667885
train_loss: 0.088669
valid_loss: 1.088133
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0008827133504157227
Epoch-24 lr: 0.0026481400512471677
epoch 24 training time: 18.079
---------------
2023-09-23 23:35:42.521850
current #epochs=25, #steps=960
start validation
[I 2023-09-23 23:35:59,343] Trial 42 finished with value: 0.35306038855643285 and parameters: {'warmup': 'False', 'num_epochs': 25, 'batch_size': 41, 'lr-adaptschedule': 'True', 'lr': 0.001548820227110196, 'head-lr': 3, 'lr-scheduler-start': 9, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.7549346196814517}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.813397
AUC: 0.880127
Avg Precision: 0.353060
Avg Recall: 1.000000
d_prime: 1.662579
train_loss: 0.081978
valid_loss: 1.104318
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.0008827133504157227
Epoch-25 lr: 0.0026481400512471677
epoch 25 training time: 16.814
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc09831250>
The learning rate scheduler starts at 6 epoch with decay rate of 0.737 every 10 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 23:35:59.378756
current #epochs=1, #steps=0
start validation
acc: 0.842105
AUC: 0.875014
Avg Precision: 0.416642
Avg Recall: 1.000000
d_prime: 1.626935
train_loss: 0.116278
valid_loss: 1.093603
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0018310395357511089
Epoch-1 lr: 0.005493118607253327
epoch 1 training time: 18.142
---------------
2023-09-23 23:36:17.521203
current #epochs=2, #steps=40
start validation
acc: 0.861244
AUC: 0.897917
Avg Precision: 0.409025
Avg Recall: 1.000000
d_prime: 1.795731
train_loss: 0.096368
valid_loss: 1.094116
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0018310395357511089
Epoch-2 lr: 0.005493118607253327
epoch 2 training time: 18.329
---------------
2023-09-23 23:36:35.850172
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00723	Per Sample Data Time 0.00165	Per Sample DNN Time 0.00558	Train Loss 0.0866	
start validation
acc: 0.808612
AUC: 0.875917
Avg Precision: 0.416667
Avg Recall: 1.000000
d_prime: 1.633155
train_loss: 0.084853
valid_loss: 1.099101
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0018310395357511089
Epoch-3 lr: 0.005493118607253327
epoch 3 training time: 15.469
---------------
2023-09-23 23:36:51.318900
current #epochs=4, #steps=120
start validation
acc: 0.837321
AUC: 0.882908
Avg Precision: 0.386824
Avg Recall: 1.000000
d_prime: 1.682416
train_loss: 0.103595
valid_loss: 1.089765
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0018310395357511089
Epoch-4 lr: 0.005493118607253327
epoch 4 training time: 16.086
---------------
2023-09-23 23:37:07.405287
current #epochs=5, #steps=160
start validation
acc: 0.837321
AUC: 0.866906
Avg Precision: 0.389556
Avg Recall: 1.000000
d_prime: 1.572443
train_loss: 0.125931
valid_loss: 1.100247
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0018310395357511089
Epoch-5 lr: 0.005493118607253327
epoch 5 training time: 15.266
---------------
2023-09-23 23:37:22.670868
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03837	Per Sample Data Time 0.03148	Per Sample DNN Time 0.00689	Train Loss 0.2088	
start validation
acc: 0.818182
AUC: 0.883834
Avg Precision: 0.345302
Avg Recall: 1.000000
d_prime: 1.689100
train_loss: 0.098006
valid_loss: 1.100713
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0013498336019736818
Epoch-6 lr: 0.004049500805921045
epoch 6 training time: 15.382
---------------
2023-09-23 23:37:38.052788
current #epochs=7, #steps=240
start validation
acc: 0.818182
AUC: 0.884811
Avg Precision: 0.377119
Avg Recall: 1.000000
d_prime: 1.696188
train_loss: 0.071706
valid_loss: 1.080256
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0013498336019736818
Epoch-7 lr: 0.004049500805921045
epoch 7 training time: 15.417
---------------
2023-09-23 23:37:53.469989
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00559	Train Loss 0.0567	
start validation
acc: 0.832536
AUC: 0.887231
Avg Precision: 0.410145
Avg Recall: 1.000000
d_prime: 1.713935
train_loss: 0.071061
valid_loss: 1.079827
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0013498336019736818
Epoch-8 lr: 0.004049500805921045
epoch 8 training time: 15.481
---------------
2023-09-23 23:38:08.950620
current #epochs=9, #steps=320
start validation
acc: 0.837321
AUC: 0.871981
Avg Precision: 0.396686
Avg Recall: 1.000000
d_prime: 1.606273
train_loss: 0.095782
valid_loss: 1.091306
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0013498336019736818
Epoch-9 lr: 0.004049500805921045
epoch 9 training time: 15.401
---------------
2023-09-23 23:38:24.352100
current #epochs=10, #steps=360
start validation
acc: 0.799043
AUC: 0.882728
Avg Precision: 0.378796
Avg Recall: 1.000000
d_prime: 1.681129
train_loss: 0.084731
valid_loss: 1.108988
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0013498336019736818
Epoch-10 lr: 0.004049500805921045
epoch 10 training time: 15.318
---------------
2023-09-23 23:38:39.670124
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03764	Per Sample Data Time 0.03010	Per Sample DNN Time 0.00754	Train Loss 0.1166	
start validation
acc: 0.813397
AUC: 0.880695
Avg Precision: 0.338977
Avg Recall: 1.000000
d_prime: 1.666604
train_loss: 0.080265
valid_loss: 1.100816
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0013498336019736818
Epoch-11 lr: 0.004049500805921045
epoch 11 training time: 15.379
---------------
2023-09-23 23:38:55.048663
current #epochs=12, #steps=440
start validation
[I 2023-09-23 23:39:12,781] Trial 43 finished with value: 0.36951117658415383 and parameters: {'warmup': 'False', 'num_epochs': 12, 'batch_size': 48, 'lr-adaptschedule': 'True', 'lr': 0.0018310395357511089, 'head-lr': 3, 'lr-scheduler-start': 6, 'lr-scheduler-step': 10, 'lr-scheduler-decay': 0.7371952246896558}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.870813
AUC: 0.878059
Avg Precision: 0.369511
Avg Recall: 1.000000
d_prime: 1.648037
train_loss: 0.140077
valid_loss: 1.088002
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0013498336019736818
Epoch-12 lr: 0.004049500805921045
epoch 12 training time: 17.725
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 5 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcbd2c98820>
The learning rate scheduler starts at 8 epoch with decay rate of 0.765 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 23:39:12.819362
current #epochs=1, #steps=0
start validation
acc: 0.846890
AUC: 0.871005
Avg Precision: 0.389028
Avg Recall: 1.000000
d_prime: 1.599697
train_loss: 0.181079
valid_loss: 1.093213
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0023654496734027137
Epoch-1 lr: 0.011827248367013569
epoch 1 training time: 17.795
---------------
2023-09-23 23:39:30.614541
current #epochs=2, #steps=40
start validation
acc: 0.846890
AUC: 0.884773
Avg Precision: 0.385471
Avg Recall: 1.000000
d_prime: 1.695912
train_loss: 0.161382
valid_loss: 1.092429
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0023654496734027137
Epoch-2 lr: 0.011827248367013569
epoch 2 training time: 15.158
---------------
2023-09-23 23:39:45.773013
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00557	Train Loss 0.1354	
start validation
acc: 0.784689
AUC: 0.872898
Avg Precision: 0.322545
Avg Recall: 1.000000
d_prime: 1.612482
train_loss: 0.149237
valid_loss: 1.122824
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0023654496734027137
Epoch-3 lr: 0.011827248367013569
epoch 3 training time: 15.343
---------------
2023-09-23 23:40:01.115660
current #epochs=4, #steps=120
start validation
acc: 0.851675
AUC: 0.891461
Avg Precision: 0.358956
Avg Recall: 1.000000
d_prime: 1.745612
train_loss: 0.124057
valid_loss: 1.098536
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0023654496734027137
Epoch-4 lr: 0.011827248367013569
epoch 4 training time: 17.694
---------------
2023-09-23 23:40:18.809241
current #epochs=5, #steps=160
start validation
acc: 0.846890
AUC: 0.906686
Avg Precision: 0.345703
Avg Recall: 1.000000
d_prime: 1.867641
train_loss: 0.104411
valid_loss: 1.067886
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0023654496734027137
Epoch-5 lr: 0.011827248367013569
epoch 5 training time: 16.160
---------------
2023-09-23 23:40:34.969198
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03960	Per Sample Data Time 0.03198	Per Sample DNN Time 0.00762	Train Loss 0.0452	
start validation
acc: 0.837321
AUC: 0.884176
Avg Precision: 0.338588
Avg Recall: 1.000000
d_prime: 1.691572
train_loss: 0.107696
valid_loss: 1.103137
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0023654496734027137
Epoch-6 lr: 0.011827248367013569
epoch 6 training time: 15.445
---------------
2023-09-23 23:40:50.414909
current #epochs=7, #steps=240
start validation
acc: 0.751196
AUC: 0.864480
Avg Precision: 0.329266
Avg Recall: 1.000000
d_prime: 1.556587
train_loss: 0.118936
valid_loss: 1.118872
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0023654496734027137
Epoch-7 lr: 0.011827248367013569
epoch 7 training time: 15.315
---------------
2023-09-23 23:41:05.730155
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00559	Train Loss 0.1498	
start validation
acc: 0.861244
AUC: 0.889064
Avg Precision: 0.387357
Avg Recall: 1.000000
d_prime: 1.727556
train_loss: 0.124406
valid_loss: 1.105097
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.001808855924497652
Epoch-8 lr: 0.009044279622488261
epoch 8 training time: 17.821
---------------
2023-09-23 23:41:23.551574
current #epochs=9, #steps=320
start validation
acc: 0.837321
AUC: 0.891716
Avg Precision: 0.368835
Avg Recall: 1.000000
d_prime: 1.747550
train_loss: 0.112227
valid_loss: 1.100498
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.001808855924497652
Epoch-9 lr: 0.009044279622488261
epoch 9 training time: 15.294
---------------
2023-09-23 23:41:38.845080
current #epochs=10, #steps=360
start validation
acc: 0.770335
AUC: 0.857766
Avg Precision: 0.333300
Avg Recall: 1.000000
d_prime: 1.513681
train_loss: 0.144299
valid_loss: 1.143471
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.001808855924497652
Epoch-10 lr: 0.009044279622488261
epoch 10 training time: 37.887
---------------
2023-09-23 23:42:16.732111
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03923	Per Sample Data Time 0.02992	Per Sample DNN Time 0.00931	Train Loss 0.0751	
start validation
acc: 0.856459
AUC: 0.881653
Avg Precision: 0.377579
Avg Recall: 1.000000
d_prime: 1.673429
train_loss: 0.109142
valid_loss: 1.088421
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.001808855924497652
Epoch-11 lr: 0.009044279622488261
epoch 11 training time: 16.149
---------------
2023-09-23 23:42:32.880731
current #epochs=12, #steps=440
start validation
acc: 0.827751
AUC: 0.882791
Avg Precision: 0.350389
Avg Recall: 1.000000
d_prime: 1.681580
train_loss: 0.170910
valid_loss: 1.089530
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.001808855924497652
Epoch-12 lr: 0.009044279622488261
epoch 12 training time: 15.271
---------------
2023-09-23 23:42:48.152015
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00705	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00548	Train Loss 0.1816	
start validation
acc: 0.846890
AUC: 0.885132
Avg Precision: 0.358192
Avg Recall: 1.000000
d_prime: 1.698526
train_loss: 0.175820
valid_loss: 1.091478
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.001808855924497652
Epoch-13 lr: 0.009044279622488261
epoch 13 training time: 15.147
---------------
2023-09-23 23:43:03.299137
current #epochs=14, #steps=520
start validation
acc: 0.808612
AUC: 0.873358
Avg Precision: 0.354143
Avg Recall: 1.000000
d_prime: 1.615611
train_loss: 0.147550
valid_loss: 1.092413
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.001808855924497652
Epoch-14 lr: 0.009044279622488261
epoch 14 training time: 15.215
---------------
2023-09-23 23:43:18.513923
current #epochs=15, #steps=560
start validation
acc: 0.760766
AUC: 0.878059
Avg Precision: 0.312981
Avg Recall: 1.000000
d_prime: 1.648038
train_loss: 0.116498
valid_loss: 1.120084
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.001808855924497652
Epoch-15 lr: 0.009044279622488261
epoch 15 training time: 15.284
---------------
2023-09-23 23:43:33.797612
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03859	Per Sample Data Time 0.03104	Per Sample DNN Time 0.00754	Train Loss 0.1205	
start validation
acc: 0.856459
AUC: 0.871280
Avg Precision: 0.352622
Avg Recall: 1.000000
d_prime: 1.601542
train_loss: 0.122483
valid_loss: 1.097199
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.001808855924497652
Epoch-16 lr: 0.009044279622488261
epoch 16 training time: 15.242
---------------
2023-09-23 23:43:49.039819
current #epochs=17, #steps=640
start validation
acc: 0.808612
AUC: 0.860344
Avg Precision: 0.318289
Avg Recall: 1.000000
d_prime: 1.529990
train_loss: 0.108379
valid_loss: 1.108295
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.001383229494324232
Epoch-17 lr: 0.0069161474716211615
epoch 17 training time: 15.241
---------------
2023-09-23 23:44:04.280700
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00711	Per Sample Data Time 0.00153	Per Sample DNN Time 0.00558	Train Loss 0.1427	
start validation
acc: 0.837321
AUC: 0.886272
Avg Precision: 0.355250
Avg Recall: 1.000000
d_prime: 1.706868
train_loss: 0.156320
valid_loss: 1.102056
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.001383229494324232
Epoch-18 lr: 0.0069161474716211615
epoch 18 training time: 15.180
---------------
2023-09-23 23:44:19.460766
current #epochs=19, #steps=720
start validation
acc: 0.765550
AUC: 0.895406
Avg Precision: 0.385685
Avg Recall: 1.000000
d_prime: 1.775968
train_loss: 0.153661
valid_loss: 1.122762
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.001383229494324232
Epoch-19 lr: 0.0069161474716211615
epoch 19 training time: 15.391
---------------
2023-09-23 23:44:34.851859
current #epochs=20, #steps=760
start validation
acc: 0.818182
AUC: 0.881574
Avg Precision: 0.389658
Avg Recall: 1.000000
d_prime: 1.672861
train_loss: 0.128435
valid_loss: 1.104787
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.001383229494324232
Epoch-20 lr: 0.0069161474716211615
epoch 20 training time: 15.301
---------------
2023-09-23 23:44:50.152649
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03809	Per Sample Data Time 0.03000	Per Sample DNN Time 0.00810	Train Loss 0.0672	
start validation
acc: 0.779904
AUC: 0.882125
Avg Precision: 0.363642
Avg Recall: 1.000000
d_prime: 1.676803
train_loss: 0.108005
valid_loss: 1.129239
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.001383229494324232
Epoch-21 lr: 0.0069161474716211615
epoch 21 training time: 15.264
---------------
2023-09-23 23:45:05.416952
current #epochs=22, #steps=840
start validation
acc: 0.808612
AUC: 0.847668
Avg Precision: 0.420627
Avg Recall: 1.000000
d_prime: 1.451668
train_loss: 0.101643
valid_loss: 1.155314
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.001383229494324232
Epoch-22 lr: 0.0069161474716211615
epoch 22 training time: 15.368
---------------
2023-09-23 23:45:20.785107
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00712	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00554	Train Loss 0.0917	
start validation
acc: 0.832536
AUC: 0.873443
Avg Precision: 0.369531
Avg Recall: 1.000000
d_prime: 1.616191
train_loss: 0.106860
valid_loss: 1.104970
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.001383229494324232
Epoch-23 lr: 0.0069161474716211615
epoch 23 training time: 15.249
---------------
2023-09-23 23:45:36.034152
current #epochs=24, #steps=920
start validation
acc: 0.842105
AUC: 0.878948
Avg Precision: 0.344688
Avg Recall: 1.000000
d_prime: 1.654266
train_loss: 0.100668
valid_loss: 1.101778
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.001383229494324232
Epoch-24 lr: 0.0069161474716211615
epoch 24 training time: 15.275
---------------
2023-09-23 23:45:51.309421
current #epochs=25, #steps=960
start validation
acc: 0.851675
AUC: 0.886180
Avg Precision: 0.384469
Avg Recall: 1.000000
d_prime: 1.706192
train_loss: 0.094553
valid_loss: 1.105787
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.001383229494324232
Epoch-25 lr: 0.0069161474716211615
epoch 25 training time: 15.248
---------------
2023-09-23 23:46:06.557262
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.03647	Per Sample Data Time 0.02936	Per Sample DNN Time 0.00711	Train Loss 0.1034	
start validation
acc: 0.779904
AUC: 0.875495
Avg Precision: 0.342870
Avg Recall: 1.000000
d_prime: 1.630246
train_loss: 0.090972
valid_loss: 1.113740
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.0010577535822814807
Epoch-26 lr: 0.005288767911407404
epoch 26 training time: 15.165
---------------
2023-09-23 23:46:21.722585
current #epochs=27, #steps=1040
start validation
[I 2023-09-23 23:46:37,083] Trial 44 finished with value: 0.34013793714405166 and parameters: {'warmup': 'False', 'num_epochs': 27, 'batch_size': 34, 'lr-adaptschedule': 'True', 'lr': 0.0023654496734027137, 'head-lr': 5, 'lr-scheduler-start': 8, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.7646985454125523}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.813397
AUC: 0.874723
Avg Precision: 0.340138
Avg Recall: 1.000000
d_prime: 1.624937
train_loss: 0.077780
valid_loss: 1.110170
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.0010577535822814807
Epoch-27 lr: 0.005288767911407404
epoch 27 training time: 15.353
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc09830460>
The learning rate scheduler starts at 7 epoch with decay rate of 0.789 every 10 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 23:46:37.120266
current #epochs=1, #steps=0
start validation
acc: 0.832536
AUC: 0.868903
Avg Precision: 0.352201
Avg Recall: 1.000000
d_prime: 1.585643
train_loss: 0.104065
valid_loss: 1.106124
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0012228974938850376
Epoch-1 lr: 0.00489158997554015
epoch 1 training time: 17.563
---------------
2023-09-23 23:46:54.683602
current #epochs=2, #steps=40
start validation
acc: 0.870813
AUC: 0.880543
Avg Precision: 0.396053
Avg Recall: 1.000000
d_prime: 1.665524
train_loss: 0.105329
valid_loss: 1.088240
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0012228974938850376
Epoch-2 lr: 0.00489158997554015
epoch 2 training time: 17.629
---------------
2023-09-23 23:47:12.312528
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00715	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00557	Train Loss 0.1327	
start validation
acc: 0.803828
AUC: 0.867050
Avg Precision: 0.341730
Avg Recall: 1.000000
d_prime: 1.573391
train_loss: 0.123782
valid_loss: 1.112205
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0012228974938850376
Epoch-3 lr: 0.00489158997554015
epoch 3 training time: 16.317
---------------
2023-09-23 23:47:28.630024
current #epochs=4, #steps=120
start validation
acc: 0.866029
AUC: 0.883045
Avg Precision: 0.361008
Avg Recall: 1.000000
d_prime: 1.683408
train_loss: 0.098124
valid_loss: 1.076760
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0012228974938850376
Epoch-4 lr: 0.00489158997554015
epoch 4 training time: 15.340
---------------
2023-09-23 23:47:43.969396
current #epochs=5, #steps=160
start validation
acc: 0.765550
AUC: 0.879813
Avg Precision: 0.362508
Avg Recall: 1.000000
d_prime: 1.660359
train_loss: 0.113613
valid_loss: 1.111808
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0012228974938850376
Epoch-5 lr: 0.00489158997554015
epoch 5 training time: 15.195
---------------
2023-09-23 23:47:59.164717
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03783	Per Sample Data Time 0.03018	Per Sample DNN Time 0.00765	Train Loss 0.1348	
start validation
acc: 0.885167
AUC: 0.891969
Avg Precision: 0.408716
Avg Recall: 1.000000
d_prime: 1.749477
train_loss: 0.090528
valid_loss: 1.104053
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0012228974938850376
Epoch-6 lr: 0.00489158997554015
epoch 6 training time: 17.679
---------------
2023-09-23 23:48:16.843760
current #epochs=7, #steps=240
start validation
acc: 0.784689
AUC: 0.877996
Avg Precision: 0.378654
Avg Recall: 1.000000
d_prime: 1.647595
train_loss: 0.100600
valid_loss: 1.106862
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0009646409816328331
Epoch-7 lr: 0.0038585639265313323
epoch 7 training time: 15.193
---------------
2023-09-23 23:48:32.037050
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00714	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00551	Train Loss 0.0856	
start validation
acc: 0.870813
AUC: 0.888772
Avg Precision: 0.436730
Avg Recall: 1.000000
d_prime: 1.725377
train_loss: 0.101164
valid_loss: 1.074146
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0009646409816328331
Epoch-8 lr: 0.0038585639265313323
epoch 8 training time: 15.213
---------------
2023-09-23 23:48:47.250529
current #epochs=9, #steps=320
start validation
acc: 0.813397
AUC: 0.871064
Avg Precision: 0.332134
Avg Recall: 1.000000
d_prime: 1.600092
train_loss: 0.095868
valid_loss: 1.099735
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0009646409816328331
Epoch-9 lr: 0.0038585639265313323
epoch 9 training time: 15.103
---------------
2023-09-23 23:49:02.353144
current #epochs=10, #steps=360
start validation
acc: 0.760766
AUC: 0.872930
Avg Precision: 0.323224
Avg Recall: 1.000000
d_prime: 1.612700
train_loss: 0.097514
valid_loss: 1.119323
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0009646409816328331
Epoch-10 lr: 0.0038585639265313323
epoch 10 training time: 16.273
---------------
2023-09-23 23:49:18.626681
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03809	Per Sample Data Time 0.02992	Per Sample DNN Time 0.00817	Train Loss 0.0416	
start validation
acc: 0.808612
AUC: 0.887854
Avg Precision: 0.343038
Avg Recall: 1.000000
d_prime: 1.718545
train_loss: 0.090358
valid_loss: 1.098405
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0009646409816328331
Epoch-11 lr: 0.0038585639265313323
epoch 11 training time: 15.246
---------------
2023-09-23 23:49:33.872292
current #epochs=12, #steps=440
start validation
acc: 0.846890
AUC: 0.894872
Avg Precision: 0.396243
Avg Recall: 1.000000
d_prime: 1.771811
train_loss: 0.087468
valid_loss: 1.100214
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0009646409816328331
Epoch-12 lr: 0.0038585639265313323
epoch 12 training time: 15.865
---------------
2023-09-23 23:49:49.736885
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00713	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00550	Train Loss 0.0805	
start validation
[I 2023-09-23 23:50:05,102] Trial 45 finished with value: 0.3707132316793554 and parameters: {'warmup': 'False', 'num_epochs': 13, 'batch_size': 44, 'lr-adaptschedule': 'True', 'lr': 0.0012228974938850376, 'head-lr': 4, 'lr-scheduler-start': 7, 'lr-scheduler-step': 10, 'lr-scheduler-decay': 0.7888158954093967}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.799043
AUC: 0.890825
Avg Precision: 0.370713
Avg Recall: 1.000000
d_prime: 1.740795
train_loss: 0.084079
valid_loss: 1.096145
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0009646409816328331
Epoch-13 lr: 0.0038585639265313323
epoch 13 training time: 15.358
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc098301f0>
The learning rate scheduler starts at 6 epoch with decay rate of 0.692 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 23:50:05.138734
current #epochs=1, #steps=0
start validation
acc: 0.832536
AUC: 0.855199
Avg Precision: 0.402921
Avg Recall: 1.000000
d_prime: 1.497646
train_loss: 0.158094
valid_loss: 1.137736
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.002638223694403749
Epoch-1 lr: 0.010552894777614997
epoch 1 training time: 17.689
---------------
2023-09-23 23:50:22.827927
current #epochs=2, #steps=40
start validation
acc: 0.837321
AUC: 0.872191
Avg Precision: 0.412837
Avg Recall: 1.000000
d_prime: 1.607693
train_loss: 0.128533
valid_loss: 1.123944
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.002638223694403749
Epoch-2 lr: 0.010552894777614997
epoch 2 training time: 18.222
---------------
2023-09-23 23:50:41.049927
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00712	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00555	Train Loss 0.1299	
start validation
acc: 0.808612
AUC: 0.868198
Avg Precision: 0.312805
Avg Recall: 1.000000
d_prime: 1.580967
train_loss: 0.149114
valid_loss: 1.123713
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.002638223694403749
Epoch-3 lr: 0.010552894777614997
epoch 3 training time: 15.208
---------------
2023-09-23 23:50:56.258316
current #epochs=4, #steps=120
start validation
acc: 0.832536
AUC: 0.901381
Avg Precision: 0.368007
Avg Recall: 1.000000
d_prime: 1.823572
train_loss: 0.134312
valid_loss: 1.087095
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.002638223694403749
Epoch-4 lr: 0.010552894777614997
epoch 4 training time: 15.376
---------------
2023-09-23 23:51:11.634625
current #epochs=5, #steps=160
start validation
acc: 0.813397
AUC: 0.894979
Avg Precision: 0.334203
Avg Recall: 1.000000
d_prime: 1.772648
train_loss: 0.153743
valid_loss: 1.105948
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.002638223694403749
Epoch-5 lr: 0.010552894777614997
epoch 5 training time: 15.210
---------------
2023-09-23 23:51:26.844392
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03952	Per Sample Data Time 0.02915	Per Sample DNN Time 0.01036	Train Loss 0.2645	
start validation
acc: 0.832536
AUC: 0.893849
Avg Precision: 0.353466
Avg Recall: 1.000000
d_prime: 1.763889
train_loss: 0.122268
valid_loss: 1.102612
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.001826640925430322
Epoch-6 lr: 0.007306563701721288
epoch 6 training time: 15.259
---------------
2023-09-23 23:51:42.103365
current #epochs=7, #steps=240
start validation
acc: 0.832536
AUC: 0.883057
Avg Precision: 0.345710
Avg Recall: 1.000000
d_prime: 1.683490
train_loss: 0.102175
valid_loss: 1.104352
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.001826640925430322
Epoch-7 lr: 0.007306563701721288
epoch 7 training time: 15.248
---------------
2023-09-23 23:51:57.351492
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00555	Train Loss 0.1063	
start validation
acc: 0.846890
AUC: 0.891053
Avg Precision: 0.355688
Avg Recall: 1.000000
d_prime: 1.742518
train_loss: 0.099124
valid_loss: 1.080184
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.001826640925430322
Epoch-8 lr: 0.007306563701721288
epoch 8 training time: 17.612
---------------
2023-09-23 23:52:14.963907
current #epochs=9, #steps=320
start validation
[I 2023-09-23 23:52:30,302] Trial 46 finished with value: 0.371869339767177 and parameters: {'warmup': 'False', 'num_epochs': 9, 'batch_size': 40, 'lr-adaptschedule': 'True', 'lr': 0.002638223694403749, 'head-lr': 4, 'lr-scheduler-start': 6, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.6923753013457608}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.827751
AUC: 0.890163
Avg Precision: 0.371869
Avg Recall: 1.000000
d_prime: 1.735798
train_loss: 0.101853
valid_loss: 1.088866
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.001826640925430322
Epoch-9 lr: 0.007306563701721288
epoch 9 training time: 15.331
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 5 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51dc5ac0>
The learning rate scheduler starts at 9 epoch with decay rate of 0.727 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 23:52:30.338779
current #epochs=1, #steps=0
start validation
acc: 0.813397
AUC: 0.891537
Avg Precision: 0.358550
Avg Recall: 1.000000
d_prime: 1.746195
train_loss: 0.181401
valid_loss: 1.099488
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.00183397284236769
Epoch-1 lr: 0.00916986421183845
epoch 1 training time: 18.108
---------------
2023-09-23 23:52:48.446764
current #epochs=2, #steps=40
start validation
acc: 0.794258
AUC: 0.876415
Avg Precision: 0.366139
Avg Recall: 1.000000
d_prime: 1.636601
train_loss: 0.135130
valid_loss: 1.100886
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.00183397284236769
Epoch-2 lr: 0.00916986421183845
epoch 2 training time: 15.608
---------------
2023-09-23 23:53:04.054432
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00562	Train Loss 0.0788	
start validation
acc: 0.842105
AUC: 0.850986
Avg Precision: 0.334330
Avg Recall: 1.000000
d_prime: 1.471730
train_loss: 0.102095
valid_loss: 1.091626
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.00183397284236769
Epoch-3 lr: 0.00916986421183845
epoch 3 training time: 18.062
---------------
2023-09-23 23:53:22.116935
current #epochs=4, #steps=120
start validation
acc: 0.832536
AUC: 0.850926
Avg Precision: 0.346448
Avg Recall: 1.000000
d_prime: 1.471366
train_loss: 0.132215
valid_loss: 1.125829
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.00183397284236769
Epoch-4 lr: 0.00916986421183845
epoch 4 training time: 15.428
---------------
2023-09-23 23:53:37.545104
current #epochs=5, #steps=160
start validation
acc: 0.842105
AUC: 0.868252
Avg Precision: 0.382352
Avg Recall: 1.000000
d_prime: 1.581329
train_loss: 0.133190
valid_loss: 1.115409
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.00183397284236769
Epoch-5 lr: 0.00916986421183845
epoch 5 training time: 15.334
---------------
2023-09-23 23:53:52.878988
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04138	Per Sample Data Time 0.03101	Per Sample DNN Time 0.01038	Train Loss 0.0552	
start validation
acc: 0.851675
AUC: 0.874198
Avg Precision: 0.335038
Avg Recall: 1.000000
d_prime: 1.621343
train_loss: 0.103202
valid_loss: 1.102744
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.00183397284236769
Epoch-6 lr: 0.00916986421183845
epoch 6 training time: 17.937
---------------
2023-09-23 23:54:10.816409
current #epochs=7, #steps=240
start validation
acc: 0.784689
AUC: 0.865945
Avg Precision: 0.322338
Avg Recall: 1.000000
d_prime: 1.566133
train_loss: 0.106347
valid_loss: 1.143112
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.00183397284236769
Epoch-7 lr: 0.00916986421183845
epoch 7 training time: 15.125
---------------
2023-09-23 23:54:25.941366
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00562	Train Loss 0.1368	
start validation
acc: 0.794258
AUC: 0.840828
Avg Precision: 0.326359
Avg Recall: 1.000000
d_prime: 1.411197
train_loss: 0.147554
valid_loss: 1.113051
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.00183397284236769
Epoch-8 lr: 0.00916986421183845
epoch 8 training time: 15.349
---------------
2023-09-23 23:54:41.290376
current #epochs=9, #steps=320
start validation
acc: 0.832536
AUC: 0.879913
Avg Precision: 0.354208
Avg Recall: 1.000000
d_prime: 1.661064
train_loss: 0.114022
valid_loss: 1.098539
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.001332601360914042
Epoch-9 lr: 0.006663006804570209
epoch 9 training time: 15.325
---------------
2023-09-23 23:54:56.615398
current #epochs=10, #steps=360
start validation
acc: 0.827751
AUC: 0.889402
Avg Precision: 0.376280
Avg Recall: 1.000000
d_prime: 1.730087
train_loss: 0.092011
valid_loss: 1.098657
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.001332601360914042
Epoch-10 lr: 0.006663006804570209
epoch 10 training time: 15.324
---------------
2023-09-23 23:55:11.939104
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04033	Per Sample Data Time 0.02996	Per Sample DNN Time 0.01037	Train Loss 0.1376	
start validation
acc: 0.822967
AUC: 0.879559
Avg Precision: 0.382830
Avg Recall: 1.000000
d_prime: 1.658566
train_loss: 0.087248
valid_loss: 1.108818
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.001332601360914042
Epoch-11 lr: 0.006663006804570209
epoch 11 training time: 15.303
---------------
2023-09-23 23:55:27.241974
current #epochs=12, #steps=440
start validation
acc: 0.870813
AUC: 0.880111
Avg Precision: 0.380127
Avg Recall: 1.000000
d_prime: 1.662467
train_loss: 0.082430
valid_loss: 1.098325
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.001332601360914042
Epoch-12 lr: 0.006663006804570209
epoch 12 training time: 18.097
---------------
2023-09-23 23:55:45.338833
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00167	Per Sample DNN Time 0.00555	Train Loss 0.0771	
start validation
acc: 0.842105
AUC: 0.876633
Avg Precision: 0.389874
Avg Recall: 1.000000
d_prime: 1.638108
train_loss: 0.081933
valid_loss: 1.114613
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.001332601360914042
Epoch-13 lr: 0.006663006804570209
epoch 13 training time: 15.320
---------------
2023-09-23 23:56:00.658872
current #epochs=14, #steps=520
start validation
acc: 0.861244
AUC: 0.875177
Avg Precision: 0.433623
Avg Recall: 1.000000
d_prime: 1.628059
train_loss: 0.084855
valid_loss: 1.103903
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.001332601360914042
Epoch-14 lr: 0.006663006804570209
epoch 14 training time: 15.197
---------------
2023-09-23 23:56:15.855898
current #epochs=15, #steps=560
start validation
acc: 0.832536
AUC: 0.877318
Avg Precision: 0.371479
Avg Recall: 1.000000
d_prime: 1.642868
train_loss: 0.080593
valid_loss: 1.093367
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.001332601360914042
Epoch-15 lr: 0.006663006804570209
epoch 15 training time: 15.420
---------------
2023-09-23 23:56:31.275797
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03728	Per Sample Data Time 0.02994	Per Sample DNN Time 0.00733	Train Loss 0.0546	
start validation
acc: 0.856459
AUC: 0.856754
Avg Precision: 0.390824
Avg Recall: 1.000000
d_prime: 1.507338
train_loss: 0.075891
valid_loss: 1.110524
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.001332601360914042
Epoch-16 lr: 0.006663006804570209
epoch 16 training time: 15.186
---------------
2023-09-23 23:56:46.462064
current #epochs=17, #steps=640
start validation
acc: 0.770335
AUC: 0.847317
Avg Precision: 0.368803
Avg Recall: 1.000000
d_prime: 1.449558
train_loss: 0.142813
valid_loss: 1.129486
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0009682948111801562
Epoch-17 lr: 0.004841474055900781
epoch 17 training time: 15.879
---------------
2023-09-23 23:57:02.340997
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00565	Train Loss 0.1528	
start validation
acc: 0.775120
AUC: 0.876114
Avg Precision: 0.341157
Avg Recall: 1.000000
d_prime: 1.634520
train_loss: 0.166057
valid_loss: 1.108597
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0009682948111801562
Epoch-18 lr: 0.004841474055900781
epoch 18 training time: 15.279
---------------
2023-09-23 23:57:17.619794
current #epochs=19, #steps=720
start validation
acc: 0.832536
AUC: 0.887422
Avg Precision: 0.372420
Avg Recall: 1.000000
d_prime: 1.715347
train_loss: 0.124973
valid_loss: 1.086547
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0009682948111801562
Epoch-19 lr: 0.004841474055900781
epoch 19 training time: 15.410
---------------
2023-09-23 23:57:33.029765
current #epochs=20, #steps=760
start validation
acc: 0.803828
AUC: 0.886828
Avg Precision: 0.395141
Avg Recall: 1.000000
d_prime: 1.710960
train_loss: 0.107184
valid_loss: 1.085217
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0009682948111801562
Epoch-20 lr: 0.004841474055900781
epoch 20 training time: 15.592
---------------
2023-09-23 23:57:48.621775
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04155	Per Sample Data Time 0.03139	Per Sample DNN Time 0.01017	Train Loss 0.1290	
start validation
acc: 0.818182
AUC: 0.884292
Avg Precision: 0.386070
Avg Recall: 1.000000
d_prime: 1.692419
train_loss: 0.082625
valid_loss: 1.089215
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0009682948111801562
Epoch-21 lr: 0.004841474055900781
epoch 21 training time: 15.314
---------------
2023-09-23 23:58:03.935065
current #epochs=22, #steps=840
start validation
[I 2023-09-23 23:58:19,180] Trial 47 finished with value: 0.4258912570404506 and parameters: {'warmup': 'False', 'num_epochs': 22, 'batch_size': 28, 'lr-adaptschedule': 'True', 'lr': 0.00183397284236769, 'head-lr': 5, 'lr-scheduler-start': 9, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.7266200077388447}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.837321
AUC: 0.885534
Avg Precision: 0.425891
Avg Recall: 1.000000
d_prime: 1.701463
train_loss: 0.077095
valid_loss: 1.089792
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0009682948111801562
Epoch-22 lr: 0.004841474055900781
epoch 22 training time: 15.236
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc09820f40>
The learning rate scheduler starts at 9 epoch with decay rate of 0.723 every 7 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-23 23:58:19.216596
current #epochs=1, #steps=0
start validation
acc: 0.842105
AUC: 0.893642
Avg Precision: 0.402333
Avg Recall: 1.000000
d_prime: 1.762296
train_loss: 0.146810
valid_loss: 1.095177
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0018865054293637255
Epoch-1 lr: 0.005659516288091177
epoch 1 training time: 17.749
---------------
2023-09-23 23:58:36.966350
current #epochs=2, #steps=40
start validation
acc: 0.803828
AUC: 0.869801
Avg Precision: 0.383401
Avg Recall: 1.000000
d_prime: 1.591626
train_loss: 0.124532
valid_loss: 1.120467
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0018865054293637255
Epoch-2 lr: 0.005659516288091177
epoch 2 training time: 15.286
---------------
2023-09-23 23:58:52.252260
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00164	Per Sample DNN Time 0.00554	Train Loss 0.1124	
start validation
acc: 0.870813
AUC: 0.889169
Avg Precision: 0.410066
Avg Recall: 1.000000
d_prime: 1.728342
train_loss: 0.101767
valid_loss: 1.069342
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0018865054293637255
Epoch-3 lr: 0.005659516288091177
epoch 3 training time: 19.278
---------------
2023-09-23 23:59:11.529747
current #epochs=4, #steps=120
start validation
acc: 0.822967
AUC: 0.866884
Avg Precision: 0.395569
Avg Recall: 1.000000
d_prime: 1.572299
train_loss: 0.080285
valid_loss: 1.119889
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0018865054293637255
Epoch-4 lr: 0.005659516288091177
epoch 4 training time: 15.214
---------------
2023-09-23 23:59:26.744116
current #epochs=5, #steps=160
start validation
acc: 0.822967
AUC: 0.888618
Avg Precision: 0.331946
Avg Recall: 1.000000
d_prime: 1.724224
train_loss: 0.104613
valid_loss: 1.117383
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0018865054293637255
Epoch-5 lr: 0.005659516288091177
epoch 5 training time: 15.219
---------------
2023-09-23 23:59:41.963112
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03935	Per Sample Data Time 0.03255	Per Sample DNN Time 0.00679	Train Loss 0.1153	
start validation
acc: 0.808612
AUC: 0.846376
Avg Precision: 0.302789
Avg Recall: 1.000000
d_prime: 1.443931
train_loss: 0.117507
valid_loss: 1.128550
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0018865054293637255
Epoch-6 lr: 0.005659516288091177
epoch 6 training time: 15.247
---------------
2023-09-23 23:59:57.210311
current #epochs=7, #steps=240
start validation
acc: 0.837321
AUC: 0.867082
Avg Precision: 0.363746
Avg Recall: 1.000000
d_prime: 1.573600
train_loss: 0.147703
valid_loss: 1.115857
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0018865054293637255
Epoch-7 lr: 0.005659516288091177
epoch 7 training time: 15.319
---------------
2023-09-24 00:00:12.529737
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00560	Train Loss 0.1223	
start validation
acc: 0.770335
AUC: 0.873163
Avg Precision: 0.390421
Avg Recall: 1.000000
d_prime: 1.614281
train_loss: 0.134752
valid_loss: 1.146333
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0018865054293637255
Epoch-8 lr: 0.005659516288091177
epoch 8 training time: 15.336
---------------
2023-09-24 00:00:27.865928
current #epochs=9, #steps=320
start validation
acc: 0.784689
AUC: 0.873229
Avg Precision: 0.362855
Avg Recall: 1.000000
d_prime: 1.614734
train_loss: 0.173617
valid_loss: 1.142623
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0013639851577670905
Epoch-9 lr: 0.004091955473301271
epoch 9 training time: 15.341
---------------
2023-09-24 00:00:43.207283
current #epochs=10, #steps=360
start validation
acc: 0.842105
AUC: 0.866354
Avg Precision: 0.365699
Avg Recall: 1.000000
d_prime: 1.568813
train_loss: 0.141829
valid_loss: 1.113869
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0013639851577670905
Epoch-10 lr: 0.004091955473301271
epoch 10 training time: 15.371
---------------
2023-09-24 00:00:58.578331
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04058	Per Sample Data Time 0.03123	Per Sample DNN Time 0.00935	Train Loss 0.1427	
start validation
acc: 0.842105
AUC: 0.880807
Avg Precision: 0.348044
Avg Recall: 1.000000
d_prime: 1.667403
train_loss: 0.108431
valid_loss: 1.097190
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0013639851577670905
Epoch-11 lr: 0.004091955473301271
epoch 11 training time: 15.278
---------------
2023-09-24 00:01:13.856716
current #epochs=12, #steps=440
start validation
acc: 0.846890
AUC: 0.875548
Avg Precision: 0.360534
Avg Recall: 1.000000
d_prime: 1.630610
train_loss: 0.090216
valid_loss: 1.113585
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0013639851577670905
Epoch-12 lr: 0.004091955473301271
epoch 12 training time: 15.385
---------------
2023-09-24 00:01:29.241741
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00725	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00563	Train Loss 0.0918	
start validation
acc: 0.813397
AUC: 0.887696
Avg Precision: 0.335842
Avg Recall: 1.000000
d_prime: 1.717372
train_loss: 0.084052
valid_loss: 1.086910
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0013639851577670905
Epoch-13 lr: 0.004091955473301271
epoch 13 training time: 15.419
---------------
2023-09-24 00:01:44.660484
current #epochs=14, #steps=520
start validation
acc: 0.784689
AUC: 0.899960
Avg Precision: 0.367333
Avg Recall: 1.000000
d_prime: 1.812067
train_loss: 0.090567
valid_loss: 1.081588
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0013639851577670905
Epoch-14 lr: 0.004091955473301271
epoch 14 training time: 15.471
---------------
2023-09-24 00:02:00.131422
current #epochs=15, #steps=560
start validation
acc: 0.818182
AUC: 0.862031
Avg Precision: 0.370067
Avg Recall: 1.000000
d_prime: 1.540770
train_loss: 0.112698
valid_loss: 1.097766
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0013639851577670905
Epoch-15 lr: 0.004091955473301271
epoch 15 training time: 15.338
---------------
2023-09-24 00:02:15.469714
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04160	Per Sample Data Time 0.03196	Per Sample DNN Time 0.00964	Train Loss 0.1358	
start validation
acc: 0.866029
AUC: 0.858161
Avg Precision: 0.384562
Avg Recall: 1.000000
d_prime: 1.516172
train_loss: 0.174461
valid_loss: 1.103666
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.000986191442468524
Epoch-16 lr: 0.0029585743274055717
epoch 16 training time: 15.468
---------------
2023-09-24 00:02:30.937603
current #epochs=17, #steps=640
start validation
acc: 0.866029
AUC: 0.880858
Avg Precision: 0.372504
Avg Recall: 1.000000
d_prime: 1.667766
train_loss: 0.134523
valid_loss: 1.095350
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.000986191442468524
Epoch-17 lr: 0.0029585743274055717
epoch 17 training time: 17.288
---------------
2023-09-24 00:02:48.225358
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00563	Train Loss 0.0909	
start validation
acc: 0.866029
AUC: 0.882161
Avg Precision: 0.377892
Avg Recall: 1.000000
d_prime: 1.677061
train_loss: 0.087352
valid_loss: 1.082961
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.000986191442468524
Epoch-18 lr: 0.0029585743274055717
epoch 18 training time: 15.660
---------------
2023-09-24 00:03:03.885440
current #epochs=19, #steps=720
start validation
acc: 0.851675
AUC: 0.883075
Avg Precision: 0.389448
Avg Recall: 1.000000
d_prime: 1.683620
train_loss: 0.079698
valid_loss: 1.089751
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.000986191442468524
Epoch-19 lr: 0.0029585743274055717
epoch 19 training time: 15.234
---------------
2023-09-24 00:03:19.119540
current #epochs=20, #steps=760
start validation
acc: 0.827751
AUC: 0.879451
Avg Precision: 0.357911
Avg Recall: 1.000000
d_prime: 1.657809
train_loss: 0.097906
valid_loss: 1.093271
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.000986191442468524
Epoch-20 lr: 0.0029585743274055717
epoch 20 training time: 17.083
---------------
2023-09-24 00:03:36.202762
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04106	Per Sample Data Time 0.03090	Per Sample DNN Time 0.01016	Train Loss 0.0632	
start validation
acc: 0.861244
AUC: 0.876563
Avg Precision: 0.390616
Avg Recall: 1.000000
d_prime: 1.637622
train_loss: 0.082465
valid_loss: 1.072027
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.000986191442468524
Epoch-21 lr: 0.0029585743274055717
epoch 21 training time: 16.541
---------------
2023-09-24 00:03:52.743576
current #epochs=22, #steps=840
start validation
acc: 0.837321
AUC: 0.878709
Avg Precision: 0.359642
Avg Recall: 1.000000
d_prime: 1.652591
train_loss: 0.069240
valid_loss: 1.077823
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.000986191442468524
Epoch-22 lr: 0.0029585743274055717
epoch 22 training time: 16.988
---------------
2023-09-24 00:04:09.731788
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00723	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00561	Train Loss 0.1054	
start validation
[I 2023-09-24 00:04:25,381] Trial 48 finished with value: 0.3760415294767879 and parameters: {'warmup': 'False', 'num_epochs': 23, 'batch_size': 33, 'lr-adaptschedule': 'True', 'lr': 0.0018865054293637255, 'head-lr': 3, 'lr-scheduler-start': 9, 'lr-scheduler-step': 7, 'lr-scheduler-decay': 0.723022121503849}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.832536
AUC: 0.876828
Avg Precision: 0.376042
Avg Recall: 1.000000
d_prime: 1.639462
train_loss: 0.091604
valid_loss: 1.086542
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0007130382289425334
Epoch-23 lr: 0.0021391146868275997
epoch 23 training time: 15.640
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0983e940>
The learning rate scheduler starts at 9 epoch with decay rate of 0.661 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 00:04:25.418164
current #epochs=1, #steps=0
start validation
acc: 0.789474
AUC: 0.874981
Avg Precision: 0.344170
Avg Recall: 1.000000
d_prime: 1.626707
train_loss: 0.153647
valid_loss: 1.129168
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0015919795819101556
Epoch-1 lr: 0.006367918327640622
epoch 1 training time: 18.009
---------------
2023-09-24 00:04:43.427052
current #epochs=2, #steps=40
start validation
acc: 0.789474
AUC: 0.871520
Avg Precision: 0.371986
Avg Recall: 1.000000
d_prime: 1.603162
train_loss: 0.168737
valid_loss: 1.103912
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0015919795819101556
Epoch-2 lr: 0.006367918327640622
epoch 2 training time: 15.370
---------------
2023-09-24 00:04:58.797464
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00556	Train Loss 0.1146	
start validation
acc: 0.846890
AUC: 0.898461
Avg Precision: 0.416156
Avg Recall: 1.000000
d_prime: 1.800053
train_loss: 0.110113
valid_loss: 1.099766
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0015919795819101556
Epoch-3 lr: 0.006367918327640622
epoch 3 training time: 18.564
---------------
2023-09-24 00:05:17.361300
current #epochs=4, #steps=120
start validation
acc: 0.822967
AUC: 0.883129
Avg Precision: 0.379297
Avg Recall: 1.000000
d_prime: 1.684008
train_loss: 0.101656
valid_loss: 1.087968
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0015919795819101556
Epoch-4 lr: 0.006367918327640622
epoch 4 training time: 15.224
---------------
2023-09-24 00:05:32.585368
current #epochs=5, #steps=160
start validation
acc: 0.875598
AUC: 0.889343
Avg Precision: 0.416655
Avg Recall: 1.000000
d_prime: 1.729644
train_loss: 0.090605
valid_loss: 1.063657
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0015919795819101556
Epoch-5 lr: 0.006367918327640622
epoch 5 training time: 17.811
---------------
2023-09-24 00:05:50.396994
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03812	Per Sample Data Time 0.03011	Per Sample DNN Time 0.00801	Train Loss 0.1100	
start validation
acc: 0.799043
AUC: 0.886989
Avg Precision: 0.378175
Avg Recall: 1.000000
d_prime: 1.712147
train_loss: 0.112930
valid_loss: 1.098127
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0015919795819101556
Epoch-6 lr: 0.006367918327640622
epoch 6 training time: 15.197
---------------
2023-09-24 00:06:05.594388
current #epochs=7, #steps=240
start validation
acc: 0.856459
AUC: 0.885922
Avg Precision: 0.423438
Avg Recall: 1.000000
d_prime: 1.704302
train_loss: 0.115613
valid_loss: 1.091691
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0015919795819101556
Epoch-7 lr: 0.006367918327640622
epoch 7 training time: 15.361
---------------
2023-09-24 00:06:20.954978
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00723	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00563	Train Loss 0.0947	
start validation
acc: 0.837321
AUC: 0.862819
Avg Precision: 0.349111
Avg Recall: 1.000000
d_prime: 1.545840
train_loss: 0.084556
valid_loss: 1.088293
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0015919795819101556
Epoch-8 lr: 0.006367918327640622
epoch 8 training time: 16.862
---------------
2023-09-24 00:06:37.817397
current #epochs=9, #steps=320
start validation
acc: 0.846890
AUC: 0.883494
Avg Precision: 0.346660
Avg Recall: 1.000000
d_prime: 1.686641
train_loss: 0.068229
valid_loss: 1.088866
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0010516231897082697
Epoch-9 lr: 0.004206492758833079
epoch 9 training time: 16.480
---------------
2023-09-24 00:06:54.296784
current #epochs=10, #steps=360
start validation
acc: 0.861244
AUC: 0.884905
Avg Precision: 0.361667
Avg Recall: 1.000000
d_prime: 1.696872
train_loss: 0.084273
valid_loss: 1.091283
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0010516231897082697
Epoch-10 lr: 0.004206492758833079
epoch 10 training time: 16.596
---------------
2023-09-24 00:07:10.892521
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04088	Per Sample Data Time 0.03040	Per Sample DNN Time 0.01048	Train Loss 0.0555	
start validation
acc: 0.846890
AUC: 0.880630
Avg Precision: 0.381992
Avg Recall: 1.000000
d_prime: 1.666147
train_loss: 0.067919
valid_loss: 1.102918
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0010516231897082697
Epoch-11 lr: 0.004206492758833079
epoch 11 training time: 17.179
---------------
2023-09-24 00:07:28.071320
current #epochs=12, #steps=440
start validation
acc: 0.861244
AUC: 0.876869
Avg Precision: 0.388104
Avg Recall: 1.000000
d_prime: 1.639751
train_loss: 0.073015
valid_loss: 1.101001
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0010516231897082697
Epoch-12 lr: 0.004206492758833079
epoch 12 training time: 15.304
---------------
2023-09-24 00:07:43.374712
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00560	Train Loss 0.0701	
start validation
acc: 0.842105
AUC: 0.865476
Avg Precision: 0.337499
Avg Recall: 1.000000
d_prime: 1.563069
train_loss: 0.072652
valid_loss: 1.095442
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0010516231897082697
Epoch-13 lr: 0.004206492758833079
epoch 13 training time: 15.436
---------------
2023-09-24 00:07:58.810967
current #epochs=14, #steps=520
start validation
acc: 0.856459
AUC: 0.862111
Avg Precision: 0.374039
Avg Recall: 1.000000
d_prime: 1.541282
train_loss: 0.067970
valid_loss: 1.105688
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0010516231897082697
Epoch-14 lr: 0.004206492758833079
epoch 14 training time: 15.362
---------------
2023-09-24 00:08:14.173198
current #epochs=15, #steps=560
start validation
acc: 0.822967
AUC: 0.878465
Avg Precision: 0.387844
Avg Recall: 1.000000
d_prime: 1.650880
train_loss: 0.072280
valid_loss: 1.102700
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0010516231897082697
Epoch-15 lr: 0.004206492758833079
epoch 15 training time: 16.485
---------------
2023-09-24 00:08:30.658872
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04053	Per Sample Data Time 0.02962	Per Sample DNN Time 0.01091	Train Loss 0.0089	
start validation
[I 2023-09-24 00:08:48,953] Trial 49 finished with value: 0.42543113591175413 and parameters: {'warmup': 'True', 'num_epochs': 16, 'batch_size': 37, 'lr-adaptschedule': 'True', 'lr': 0.0015919795819101556, 'head-lr': 4, 'lr-scheduler-start': 9, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.6605758023896683}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.880383
AUC: 0.887830
Avg Precision: 0.425431
Avg Recall: 1.000000
d_prime: 1.718366
train_loss: 0.066779
valid_loss: 1.080953
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0010516231897082697
Epoch-16 lr: 0.004206492758833079
epoch 16 training time: 18.287
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc09820fa0>
The learning rate scheduler starts at 10 epoch with decay rate of 0.661 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 00:08:48.990220
current #epochs=1, #steps=0
start validation
acc: 0.837321
AUC: 0.868394
Avg Precision: 0.343917
Avg Recall: 1.000000
d_prime: 1.582266
train_loss: 0.160178
valid_loss: 1.115170
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0019920576455070694
Epoch-1 lr: 0.007968230582028278
epoch 1 training time: 18.504
---------------
2023-09-24 00:09:07.494795
current #epochs=2, #steps=40
start validation
acc: 0.818182
AUC: 0.865809
Avg Precision: 0.339866
Avg Recall: 1.000000
d_prime: 1.565244
train_loss: 0.092039
valid_loss: 1.131299
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0019920576455070694
Epoch-2 lr: 0.007968230582028278
epoch 2 training time: 15.383
---------------
2023-09-24 00:09:22.878162
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00713	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00554	Train Loss 0.0941	
start validation
acc: 0.837321
AUC: 0.853699
Avg Precision: 0.370441
Avg Recall: 1.000000
d_prime: 1.488362
train_loss: 0.095481
valid_loss: 1.111704
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0019920576455070694
Epoch-3 lr: 0.007968230582028278
epoch 3 training time: 15.368
---------------
2023-09-24 00:09:38.246581
current #epochs=4, #steps=120
start validation
acc: 0.851675
AUC: 0.876546
Avg Precision: 0.340602
Avg Recall: 1.000000
d_prime: 1.637507
train_loss: 0.140263
valid_loss: 1.114124
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0019920576455070694
Epoch-4 lr: 0.007968230582028278
epoch 4 training time: 17.899
---------------
2023-09-24 00:09:56.145630
current #epochs=5, #steps=160
start validation
acc: 0.837321
AUC: 0.869309
Avg Precision: 0.318729
Avg Recall: 1.000000
d_prime: 1.588348
train_loss: 0.237587
valid_loss: 1.130331
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0019920576455070694
Epoch-5 lr: 0.007968230582028278
epoch 5 training time: 15.469
---------------
2023-09-24 00:10:11.614732
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04137	Per Sample Data Time 0.03057	Per Sample DNN Time 0.01080	Train Loss 0.2796	
start validation
acc: 0.822967
AUC: 0.862799
Avg Precision: 0.345380
Avg Recall: 1.000000
d_prime: 1.545709
train_loss: 0.236837
valid_loss: 1.111252
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0019920576455070694
Epoch-6 lr: 0.007968230582028278
epoch 6 training time: 16.027
---------------
2023-09-24 00:10:27.641596
current #epochs=7, #steps=240
start validation
acc: 0.866029
AUC: 0.880583
Avg Precision: 0.366725
Avg Recall: 1.000000
d_prime: 1.665812
train_loss: 0.209098
valid_loss: 1.097198
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0019920576455070694
Epoch-7 lr: 0.007968230582028278
epoch 7 training time: 18.733
---------------
2023-09-24 00:10:46.374739
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00708	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00547	Train Loss 0.1246	
start validation
acc: 0.813397
AUC: 0.879231
Avg Precision: 0.330659
Avg Recall: 1.000000
d_prime: 1.656260
train_loss: 0.145469
valid_loss: 1.124529
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0019920576455070694
Epoch-8 lr: 0.007968230582028278
epoch 8 training time: 15.108
---------------
2023-09-24 00:11:01.483141
current #epochs=9, #steps=320
start validation
acc: 0.818182
AUC: 0.884636
Avg Precision: 0.349974
Avg Recall: 1.000000
d_prime: 1.694915
train_loss: 0.134288
valid_loss: 1.096126
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0019920576455070694
Epoch-9 lr: 0.007968230582028278
epoch 9 training time: 15.506
---------------
2023-09-24 00:11:16.989542
current #epochs=10, #steps=360
start validation
acc: 0.827751
AUC: 0.893184
Avg Precision: 0.364077
Avg Recall: 1.000000
d_prime: 1.758775
train_loss: 0.119897
valid_loss: 1.082748
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0013171308093736683
Epoch-10 lr: 0.005268523237494673
epoch 10 training time: 15.243
---------------
2023-09-24 00:11:32.232659
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04176	Per Sample Data Time 0.03181	Per Sample DNN Time 0.00995	Train Loss 0.0861	
start validation
acc: 0.866029
AUC: 0.894276
Avg Precision: 0.382405
Avg Recall: 1.000000
d_prime: 1.767192
train_loss: 0.092138
valid_loss: 1.078408
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0013171308093736683
Epoch-11 lr: 0.005268523237494673
epoch 11 training time: 15.352
---------------
2023-09-24 00:11:47.584241
current #epochs=12, #steps=440
start validation
acc: 0.832536
AUC: 0.898899
Avg Precision: 0.360916
Avg Recall: 1.000000
d_prime: 1.803547
train_loss: 0.102737
valid_loss: 1.076527
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0013171308093736683
Epoch-12 lr: 0.005268523237494673
epoch 12 training time: 16.685
---------------
2023-09-24 00:12:04.269610
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00154	Per Sample DNN Time 0.00562	Train Loss 0.1282	
start validation
acc: 0.870813
AUC: 0.910246
Avg Precision: 0.382546
Avg Recall: 1.000000
d_prime: 1.898256
train_loss: 0.120876
valid_loss: 1.074702
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0013171308093736683
Epoch-13 lr: 0.005268523237494673
epoch 13 training time: 17.602
---------------
2023-09-24 00:12:21.871476
current #epochs=14, #steps=520
start validation
acc: 0.846890
AUC: 0.898555
Avg Precision: 0.371830
Avg Recall: 1.000000
d_prime: 1.800803
train_loss: 0.080940
valid_loss: 1.090371
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0013171308093736683
Epoch-14 lr: 0.005268523237494673
epoch 14 training time: 15.300
---------------
2023-09-24 00:12:37.171940
current #epochs=15, #steps=560
start validation
acc: 0.842105
AUC: 0.887985
Avg Precision: 0.363463
Avg Recall: 1.000000
d_prime: 1.719519
train_loss: 0.080950
valid_loss: 1.090286
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0013171308093736683
Epoch-15 lr: 0.005268523237494673
epoch 15 training time: 15.362
---------------
2023-09-24 00:12:52.533621
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03922	Per Sample Data Time 0.02953	Per Sample DNN Time 0.00969	Train Loss 0.0163	
start validation
[I 2023-09-24 00:13:08,537] Trial 50 finished with value: 0.36407545853269535 and parameters: {'warmup': 'False', 'num_epochs': 16, 'batch_size': 36, 'lr-adaptschedule': 'True', 'lr': 0.0019920576455070694, 'head-lr': 4, 'lr-scheduler-start': 10, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.6611911117855219}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.851675
AUC: 0.898522
Avg Precision: 0.364075
Avg Recall: 1.000000
d_prime: 1.800544
train_loss: 0.071212
valid_loss: 1.082502
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0013171308093736683
Epoch-16 lr: 0.005268523237494673
epoch 16 training time: 15.996
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 5 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51db2bb0>
The learning rate scheduler starts at 9 epoch with decay rate of 0.699 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 00:13:08.577102
current #epochs=1, #steps=0
start validation
acc: 0.832536
AUC: 0.881281
Avg Precision: 0.361766
Avg Recall: 1.000000
d_prime: 1.670772
train_loss: 0.110086
valid_loss: 1.078139
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0015896446560104982
Epoch-1 lr: 0.00794822328005249
epoch 1 training time: 39.264
---------------
2023-09-24 00:13:47.841577
current #epochs=2, #steps=40
start validation
acc: 0.870813
AUC: 0.887769
Avg Precision: 0.382692
Avg Recall: 1.000000
d_prime: 1.717914
train_loss: 0.114216
valid_loss: 1.085907
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0015896446560104982
Epoch-2 lr: 0.00794822328005249
epoch 2 training time: 17.678
---------------
2023-09-24 00:14:05.519904
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00714	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00552	Train Loss 0.1013	
start validation
acc: 0.870813
AUC: 0.897268
Avg Precision: 0.384142
Avg Recall: 1.000000
d_prime: 1.790585
train_loss: 0.110800
valid_loss: 1.070560
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0015896446560104982
Epoch-3 lr: 0.00794822328005249
epoch 3 training time: 16.698
---------------
2023-09-24 00:14:22.218184
current #epochs=4, #steps=120
start validation
acc: 0.880383
AUC: 0.901343
Avg Precision: 0.392485
Avg Recall: 1.000000
d_prime: 1.823260
train_loss: 0.084967
valid_loss: 1.080987
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0015896446560104982
Epoch-4 lr: 0.00794822328005249
epoch 4 training time: 18.861
---------------
2023-09-24 00:14:41.079484
current #epochs=5, #steps=160
start validation
acc: 0.885167
AUC: 0.891536
Avg Precision: 0.377821
Avg Recall: 1.000000
d_prime: 1.746184
train_loss: 0.099461
valid_loss: 1.083001
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0015896446560104982
Epoch-5 lr: 0.00794822328005249
epoch 5 training time: 17.574
---------------
2023-09-24 00:14:58.653011
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03665	Per Sample Data Time 0.02953	Per Sample DNN Time 0.00711	Train Loss 0.0506	
start validation
acc: 0.832536
AUC: 0.887553
Avg Precision: 0.375185
Avg Recall: 1.000000
d_prime: 1.716311
train_loss: 0.101830
valid_loss: 1.090197
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0015896446560104982
Epoch-6 lr: 0.00794822328005249
epoch 6 training time: 15.188
---------------
2023-09-24 00:15:13.840657
current #epochs=7, #steps=240
start validation
acc: 0.880383
AUC: 0.895059
Avg Precision: 0.394274
Avg Recall: 1.000000
d_prime: 1.773266
train_loss: 0.103288
valid_loss: 1.066311
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0015896446560104982
Epoch-7 lr: 0.00794822328005249
epoch 7 training time: 15.208
---------------
2023-09-24 00:15:29.049188
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00714	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00554	Train Loss 0.1116	
start validation
acc: 0.866029
AUC: 0.890596
Avg Precision: 0.427727
Avg Recall: 1.000000
d_prime: 1.739063
train_loss: 0.095454
valid_loss: 1.080124
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0015896446560104982
Epoch-8 lr: 0.00794822328005249
epoch 8 training time: 15.346
---------------
2023-09-24 00:15:44.394604
current #epochs=9, #steps=320
start validation
acc: 0.832536
AUC: 0.896091
Avg Precision: 0.393264
Avg Recall: 1.000000
d_prime: 1.781325
train_loss: 0.089343
valid_loss: 1.069326
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0011111703134511351
Epoch-9 lr: 0.005555851567255675
epoch 9 training time: 15.506
---------------
2023-09-24 00:15:59.900615
current #epochs=10, #steps=360
start validation
acc: 0.856459
AUC: 0.882296
Avg Precision: 0.397337
Avg Recall: 1.000000
d_prime: 1.678023
train_loss: 0.073759
valid_loss: 1.079752
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0011111703134511351
Epoch-10 lr: 0.005555851567255675
epoch 10 training time: 15.295
---------------
2023-09-24 00:16:15.196291
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03803	Per Sample Data Time 0.03077	Per Sample DNN Time 0.00726	Train Loss 0.0736	
start validation
acc: 0.842105
AUC: 0.879966
Avg Precision: 0.428584
Avg Recall: 1.000000
d_prime: 1.661445
train_loss: 0.071917
valid_loss: 1.075379
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0011111703134511351
Epoch-11 lr: 0.005555851567255675
epoch 11 training time: 15.267
---------------
2023-09-24 00:16:30.463542
current #epochs=12, #steps=440
start validation
acc: 0.846890
AUC: 0.875607
Avg Precision: 0.432983
Avg Recall: 1.000000
d_prime: 1.631020
train_loss: 0.116377
valid_loss: 1.091253
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0011111703134511351
Epoch-12 lr: 0.005555851567255675
epoch 12 training time: 16.893
---------------
2023-09-24 00:16:47.356334
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00560	Train Loss 0.0954	
start validation
acc: 0.851675
AUC: 0.873846
Avg Precision: 0.394266
Avg Recall: 1.000000
d_prime: 1.618934
train_loss: 0.095923
valid_loss: 1.087946
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0011111703134511351
Epoch-13 lr: 0.005555851567255675
epoch 13 training time: 15.376
---------------
2023-09-24 00:17:02.732068
current #epochs=14, #steps=520
start validation
acc: 0.866029
AUC: 0.879636
Avg Precision: 0.415212
Avg Recall: 1.000000
d_prime: 1.659110
train_loss: 0.077045
valid_loss: 1.095472
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0011111703134511351
Epoch-14 lr: 0.005555851567255675
epoch 14 training time: 15.256
---------------
2023-09-24 00:17:17.988072
current #epochs=15, #steps=560
start validation
acc: 0.856459
AUC: 0.879780
Avg Precision: 0.379649
Avg Recall: 1.000000
d_prime: 1.660127
train_loss: 0.070089
valid_loss: 1.090074
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0011111703134511351
Epoch-15 lr: 0.005555851567255675
epoch 15 training time: 15.300
---------------
2023-09-24 00:17:33.287681
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03790	Per Sample Data Time 0.03002	Per Sample DNN Time 0.00788	Train Loss 0.0246	
start validation
acc: 0.870813
AUC: 0.885348
Avg Precision: 0.428111
Avg Recall: 1.000000
d_prime: 1.700100
train_loss: 0.083419
valid_loss: 1.094305
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0011111703134511351
Epoch-16 lr: 0.005555851567255675
epoch 16 training time: 15.292
---------------
2023-09-24 00:17:48.579360
current #epochs=17, #steps=640
start validation
acc: 0.837321
AUC: 0.884775
Avg Precision: 0.405185
Avg Recall: 1.000000
d_prime: 1.695926
train_loss: 0.079517
valid_loss: 1.084277
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0007767141296809039
Epoch-17 lr: 0.003883570648404519
epoch 17 training time: 15.223
---------------
2023-09-24 00:18:03.802760
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00711	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00556	Train Loss 0.0731	
start validation
acc: 0.827751
AUC: 0.890688
Avg Precision: 0.424175
Avg Recall: 1.000000
d_prime: 1.739760
train_loss: 0.070742
valid_loss: 1.086388
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0007767141296809039
Epoch-18 lr: 0.003883570648404519
epoch 18 training time: 15.259
---------------
2023-09-24 00:18:19.062098
current #epochs=19, #steps=720
start validation
acc: 0.842105
AUC: 0.894776
Avg Precision: 0.419054
Avg Recall: 1.000000
d_prime: 1.771066
train_loss: 0.064068
valid_loss: 1.065562
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0007767141296809039
Epoch-19 lr: 0.003883570648404519
epoch 19 training time: 15.219
---------------
2023-09-24 00:18:34.281527
current #epochs=20, #steps=760
start validation
[I 2023-09-24 00:18:49,471] Trial 51 finished with value: 0.3839902019062716 and parameters: {'warmup': 'True', 'num_epochs': 20, 'batch_size': 44, 'lr-adaptschedule': 'True', 'lr': 0.0015896446560104982, 'head-lr': 5, 'lr-scheduler-start': 9, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.6990054722291325}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.837321
AUC: 0.881753
Avg Precision: 0.383990
Avg Recall: 1.000000
d_prime: 1.674142
train_loss: 0.075431
valid_loss: 1.089011
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0007767141296809039
Epoch-20 lr: 0.003883570648404519
epoch 20 training time: 15.180
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 5 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51da2550>
The learning rate scheduler starts at 9 epoch with decay rate of 0.715 every 7 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 00:18:49.508731
current #epochs=1, #steps=0
start validation
acc: 0.827751
AUC: 0.867183
Avg Precision: 0.444415
Avg Recall: 1.000000
d_prime: 1.574265
train_loss: 0.127946
valid_loss: 1.094379
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0022158648416123316
Epoch-1 lr: 0.011079324208061658
epoch 1 training time: 18.437
---------------
2023-09-24 00:19:07.945964
current #epochs=2, #steps=40
start validation
acc: 0.837321
AUC: 0.881846
Avg Precision: 0.348287
Avg Recall: 1.000000
d_prime: 1.674804
train_loss: 0.131468
valid_loss: 1.074055
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0022158648416123316
Epoch-2 lr: 0.011079324208061658
epoch 2 training time: 17.707
---------------
2023-09-24 00:19:25.652499
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00554	Train Loss 0.0846	
start validation
acc: 0.861244
AUC: 0.901524
Avg Precision: 0.430861
Avg Recall: 1.000000
d_prime: 1.824738
train_loss: 0.090381
valid_loss: 1.054800
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0022158648416123316
Epoch-3 lr: 0.011079324208061658
epoch 3 training time: 17.597
---------------
2023-09-24 00:19:43.249952
current #epochs=4, #steps=120
start validation
acc: 0.832536
AUC: 0.900635
Avg Precision: 0.432560
Avg Recall: 1.000000
d_prime: 1.817514
train_loss: 0.116236
valid_loss: 1.080556
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0022158648416123316
Epoch-4 lr: 0.011079324208061658
epoch 4 training time: 15.252
---------------
2023-09-24 00:19:58.502004
current #epochs=5, #steps=160
start validation
acc: 0.794258
AUC: 0.867652
Avg Precision: 0.390169
Avg Recall: 1.000000
d_prime: 1.577356
train_loss: 0.111415
valid_loss: 1.116129
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0022158648416123316
Epoch-5 lr: 0.011079324208061658
epoch 5 training time: 16.487
---------------
2023-09-24 00:20:14.988897
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03955	Per Sample Data Time 0.03095	Per Sample DNN Time 0.00860	Train Loss 0.0366	
start validation
acc: 0.875598
AUC: 0.893667
Avg Precision: 0.413981
Avg Recall: 1.000000
d_prime: 1.762486
train_loss: 0.102713
valid_loss: 1.064325
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0022158648416123316
Epoch-6 lr: 0.011079324208061658
epoch 6 training time: 17.749
---------------
2023-09-24 00:20:32.737792
current #epochs=7, #steps=240
start validation
acc: 0.851675
AUC: 0.873427
Avg Precision: 0.405344
Avg Recall: 1.000000
d_prime: 1.616081
train_loss: 0.118551
valid_loss: 1.095810
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0022158648416123316
Epoch-7 lr: 0.011079324208061658
epoch 7 training time: 15.313
---------------
2023-09-24 00:20:48.050433
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00715	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00557	Train Loss 0.0890	
start validation
acc: 0.851675
AUC: 0.884720
Avg Precision: 0.400991
Avg Recall: 1.000000
d_prime: 1.695526
train_loss: 0.093263
valid_loss: 1.098591
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0022158648416123316
Epoch-8 lr: 0.011079324208061658
epoch 8 training time: 16.480
---------------
2023-09-24 00:21:04.530001
current #epochs=9, #steps=320
start validation
[I 2023-09-24 00:21:19,819] Trial 52 finished with value: 0.3742277482552082 and parameters: {'warmup': 'True', 'num_epochs': 9, 'batch_size': 28, 'lr-adaptschedule': 'True', 'lr': 0.0022158648416123316, 'head-lr': 5, 'lr-scheduler-start': 9, 'lr-scheduler-step': 7, 'lr-scheduler-decay': 0.7145685866971386}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.846890
AUC: 0.880502
Avg Precision: 0.374228
Avg Recall: 1.000000
d_prime: 1.665236
train_loss: 0.099422
valid_loss: 1.083837
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0015833874081828028
Epoch-9 lr: 0.007916937040914014
epoch 9 training time: 15.279
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0a68b820>
The learning rate scheduler starts at 8 epoch with decay rate of 0.701 every 6 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 00:21:19.856803
current #epochs=1, #steps=0
start validation
acc: 0.851675
AUC: 0.885722
Avg Precision: 0.362990
Avg Recall: 1.000000
d_prime: 1.702835
train_loss: 0.100384
valid_loss: 1.099587
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0013318734957915852
Epoch-1 lr: 0.003995620487374755
epoch 1 training time: 19.708
---------------
2023-09-24 00:21:39.565262
current #epochs=2, #steps=40
start validation
acc: 0.837321
AUC: 0.881686
Avg Precision: 0.356343
Avg Recall: 1.000000
d_prime: 1.673662
train_loss: 0.114048
valid_loss: 1.108657
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0013318734957915852
Epoch-2 lr: 0.003995620487374755
epoch 2 training time: 15.384
---------------
2023-09-24 00:21:54.949780
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00713	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00550	Train Loss 0.1204	
start validation
acc: 0.856459
AUC: 0.889043
Avg Precision: 0.363114
Avg Recall: 1.000000
d_prime: 1.727396
train_loss: 0.101274
valid_loss: 1.090102
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0013318734957915852
Epoch-3 lr: 0.003995620487374755
epoch 3 training time: 19.185
---------------
2023-09-24 00:22:14.134952
current #epochs=4, #steps=120
start validation
acc: 0.842105
AUC: 0.893037
Avg Precision: 0.367047
Avg Recall: 1.000000
d_prime: 1.757645
train_loss: 0.083982
valid_loss: 1.099007
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0013318734957915852
Epoch-4 lr: 0.003995620487374755
epoch 4 training time: 15.188
---------------
2023-09-24 00:22:29.322577
current #epochs=5, #steps=160
start validation
acc: 0.889952
AUC: 0.902201
Avg Precision: 0.344414
Avg Recall: 1.000000
d_prime: 1.830271
train_loss: 0.058066
valid_loss: 1.064465
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0013318734957915852
Epoch-5 lr: 0.003995620487374755
epoch 5 training time: 19.437
---------------
2023-09-24 00:22:48.759534
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03969	Per Sample Data Time 0.03157	Per Sample DNN Time 0.00812	Train Loss 0.0353	
start validation
acc: 0.789474
AUC: 0.867369
Avg Precision: 0.330121
Avg Recall: 1.000000
d_prime: 1.575492
train_loss: 0.068599
valid_loss: 1.111520
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0013318734957915852
Epoch-6 lr: 0.003995620487374755
epoch 6 training time: 15.331
---------------
2023-09-24 00:23:04.090885
current #epochs=7, #steps=240
start validation
acc: 0.813397
AUC: 0.899309
Avg Precision: 0.329742
Avg Recall: 1.000000
d_prime: 1.806830
train_loss: 0.086578
valid_loss: 1.114805
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0013318734957915852
Epoch-7 lr: 0.003995620487374755
epoch 7 training time: 16.104
---------------
2023-09-24 00:23:20.194840
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00562	Train Loss 0.0810	
start validation
acc: 0.846890
AUC: 0.908632
Avg Precision: 0.344498
Avg Recall: 1.000000
d_prime: 1.884269
train_loss: 0.083770
valid_loss: 1.080869
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0009338818050465894
Epoch-8 lr: 0.0028016454151397682
epoch 8 training time: 15.315
---------------
2023-09-24 00:23:35.509199
current #epochs=9, #steps=320
start validation
acc: 0.813397
AUC: 0.902862
Avg Precision: 0.325874
Avg Recall: 1.000000
d_prime: 1.835695
train_loss: 0.078070
valid_loss: 1.110931
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0009338818050465894
Epoch-9 lr: 0.0028016454151397682
epoch 9 training time: 15.272
---------------
2023-09-24 00:23:50.781749
current #epochs=10, #steps=360
start validation
acc: 0.827751
AUC: 0.888970
Avg Precision: 0.342220
Avg Recall: 1.000000
d_prime: 1.726855
train_loss: 0.071967
valid_loss: 1.088264
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0009338818050465894
Epoch-10 lr: 0.0028016454151397682
epoch 10 training time: 15.309
---------------
2023-09-24 00:24:06.090547
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04027	Per Sample Data Time 0.02977	Per Sample DNN Time 0.01051	Train Loss 0.0550	
start validation
acc: 0.822967
AUC: 0.896119
Avg Precision: 0.334588
Avg Recall: 1.000000
d_prime: 1.781545
train_loss: 0.073386
valid_loss: 1.094412
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0009338818050465894
Epoch-11 lr: 0.0028016454151397682
epoch 11 training time: 15.257
---------------
2023-09-24 00:24:21.347404
current #epochs=12, #steps=440
start validation
acc: 0.842105
AUC: 0.883806
Avg Precision: 0.387173
Avg Recall: 1.000000
d_prime: 1.688895
train_loss: 0.083571
valid_loss: 1.101297
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0009338818050465894
Epoch-12 lr: 0.0028016454151397682
epoch 12 training time: 16.356
---------------
2023-09-24 00:24:37.703630
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00726	Per Sample Data Time 0.00165	Per Sample DNN Time 0.00562	Train Loss 0.1010	
start validation
acc: 0.837321
AUC: 0.890675
Avg Precision: 0.377444
Avg Recall: 1.000000
d_prime: 1.739662
train_loss: 0.082342
valid_loss: 1.085862
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0009338818050465894
Epoch-13 lr: 0.0028016454151397682
epoch 13 training time: 16.290
---------------
2023-09-24 00:24:53.993715
current #epochs=14, #steps=520
start validation
[I 2023-09-24 00:25:09,290] Trial 53 finished with value: 0.37797366613237293 and parameters: {'warmup': 'True', 'num_epochs': 14, 'batch_size': 37, 'lr-adaptschedule': 'True', 'lr': 0.0013318734957915852, 'head-lr': 3, 'lr-scheduler-start': 8, 'lr-scheduler-step': 6, 'lr-scheduler-decay': 0.7011790594207646}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.827751
AUC: 0.886657
Avg Precision: 0.377974
Avg Recall: 1.000000
d_prime: 1.709703
train_loss: 0.091314
valid_loss: 1.096666
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0006548183656727335
Epoch-14 lr: 0.0019644550970182003
epoch 14 training time: 15.286
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51dc5370>
The learning rate scheduler starts at 10 epoch with decay rate of 0.680 every 10 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 00:25:09.330516
current #epochs=1, #steps=0
start validation
acc: 0.822967
AUC: 0.905947
Avg Precision: 0.345559
Avg Recall: 1.000000
d_prime: 1.861393
train_loss: 0.140268
valid_loss: 1.093349
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0017776424433230491
Epoch-1 lr: 0.0071105697732921965
epoch 1 training time: 18.011
---------------
2023-09-24 00:25:27.342199
current #epochs=2, #steps=40
start validation
acc: 0.889952
AUC: 0.909784
Avg Precision: 0.375727
Avg Recall: 1.000000
d_prime: 1.894238
train_loss: 0.126989
valid_loss: 1.060523
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0017776424433230491
Epoch-2 lr: 0.0071105697732921965
epoch 2 training time: 17.749
---------------
2023-09-24 00:25:45.091699
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00726	Per Sample Data Time 0.00169	Per Sample DNN Time 0.00557	Train Loss 0.1512	
start validation
acc: 0.818182
AUC: 0.910847
Avg Precision: 0.372810
Avg Recall: 1.000000
d_prime: 1.903514
train_loss: 0.129195
valid_loss: 1.075116
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0017776424433230491
Epoch-3 lr: 0.0071105697732921965
epoch 3 training time: 15.344
---------------
2023-09-24 00:26:00.435560
current #epochs=4, #steps=120
start validation
acc: 0.861244
AUC: 0.899689
Avg Precision: 0.422579
Avg Recall: 1.000000
d_prime: 1.809883
train_loss: 0.124996
valid_loss: 1.099016
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0017776424433230491
Epoch-4 lr: 0.0071105697732921965
epoch 4 training time: 15.354
---------------
2023-09-24 00:26:15.789869
current #epochs=5, #steps=160
start validation
acc: 0.856459
AUC: 0.917015
Avg Precision: 0.404421
Avg Recall: 1.000000
d_prime: 1.959071
train_loss: 0.099509
valid_loss: 1.082418
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0017776424433230491
Epoch-5 lr: 0.0071105697732921965
epoch 5 training time: 15.271
---------------
2023-09-24 00:26:31.060316
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03955	Per Sample Data Time 0.03038	Per Sample DNN Time 0.00918	Train Loss 0.0302	
start validation
acc: 0.827751
AUC: 0.910301
Avg Precision: 0.334573
Avg Recall: 1.000000
d_prime: 1.898737
train_loss: 0.115800
valid_loss: 1.084886
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0017776424433230491
Epoch-6 lr: 0.0071105697732921965
epoch 6 training time: 15.240
---------------
2023-09-24 00:26:46.300567
current #epochs=7, #steps=240
start validation
acc: 0.799043
AUC: 0.874319
Avg Precision: 0.355433
Avg Recall: 1.000000
d_prime: 1.622167
train_loss: 0.114713
valid_loss: 1.109665
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0017776424433230491
Epoch-7 lr: 0.0071105697732921965
epoch 7 training time: 15.257
---------------
2023-09-24 00:27:01.557483
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00732	Per Sample Data Time 0.00164	Per Sample DNN Time 0.00568	Train Loss 0.1162	
start validation
acc: 0.842105
AUC: 0.906351
Avg Precision: 0.449063
Avg Recall: 1.000000
d_prime: 1.864802
train_loss: 0.121302
valid_loss: 1.077421
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0017776424433230491
Epoch-8 lr: 0.0071105697732921965
epoch 8 training time: 15.382
---------------
2023-09-24 00:27:16.939386
current #epochs=9, #steps=320
start validation
acc: 0.846890
AUC: 0.892904
Avg Precision: 0.398807
Avg Recall: 1.000000
d_prime: 1.756621
train_loss: 0.094164
valid_loss: 1.090081
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0017776424433230491
Epoch-9 lr: 0.0071105697732921965
epoch 9 training time: 15.212
---------------
2023-09-24 00:27:32.151555
current #epochs=10, #steps=360
start validation
acc: 0.885167
AUC: 0.898497
Avg Precision: 0.423710
Avg Recall: 1.000000
d_prime: 1.800342
train_loss: 0.102846
valid_loss: 1.075199
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0012085228312361748
Epoch-10 lr: 0.004834091324944699
epoch 10 training time: 16.193
---------------
2023-09-24 00:27:48.344732
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03974	Per Sample Data Time 0.02949	Per Sample DNN Time 0.01025	Train Loss 0.1849	
start validation
acc: 0.885167
AUC: 0.905139
Avg Precision: 0.436477
Avg Recall: 1.000000
d_prime: 1.854603
train_loss: 0.075350
valid_loss: 1.082052
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0012085228312361748
Epoch-11 lr: 0.004834091324944699
epoch 11 training time: 15.209
---------------
2023-09-24 00:28:03.553620
current #epochs=12, #steps=440
start validation
acc: 0.856459
AUC: 0.903176
Avg Precision: 0.433884
Avg Recall: 1.000000
d_prime: 1.838283
train_loss: 0.068127
valid_loss: 1.089216
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0012085228312361748
Epoch-12 lr: 0.004834091324944699
epoch 12 training time: 16.109
---------------
2023-09-24 00:28:19.662165
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00729	Per Sample Data Time 0.00169	Per Sample DNN Time 0.00560	Train Loss 0.0663	
start validation
acc: 0.870813
AUC: 0.903850
Avg Precision: 0.425504
Avg Recall: 1.000000
d_prime: 1.843857
train_loss: 0.070976
valid_loss: 1.079854
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0012085228312361748
Epoch-13 lr: 0.004834091324944699
epoch 13 training time: 16.553
---------------
2023-09-24 00:28:36.214965
current #epochs=14, #steps=520
start validation
acc: 0.846890
AUC: 0.906033
Avg Precision: 0.427624
Avg Recall: 1.000000
d_prime: 1.862114
train_loss: 0.102954
valid_loss: 1.067515
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0012085228312361748
Epoch-14 lr: 0.004834091324944699
epoch 14 training time: 15.278
---------------
2023-09-24 00:28:51.492997
current #epochs=15, #steps=560
start validation
acc: 0.866029
AUC: 0.915643
Avg Precision: 0.431145
Avg Recall: 1.000000
d_prime: 1.946452
train_loss: 0.081251
valid_loss: 1.048913
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0012085228312361748
Epoch-15 lr: 0.004834091324944699
epoch 15 training time: 15.368
---------------
2023-09-24 00:29:06.860842
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04122	Per Sample Data Time 0.03114	Per Sample DNN Time 0.01008	Train Loss 0.0223	
start validation
acc: 0.861244
AUC: 0.907202
Avg Precision: 0.415993
Avg Recall: 1.000000
d_prime: 1.872025
train_loss: 0.072617
valid_loss: 1.070819
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0012085228312361748
Epoch-16 lr: 0.004834091324944699
epoch 16 training time: 15.275
---------------
2023-09-24 00:29:22.135938
current #epochs=17, #steps=640
start validation
[I 2023-09-24 00:29:37,567] Trial 54 finished with value: 0.4278932992387254 and parameters: {'warmup': 'True', 'num_epochs': 17, 'batch_size': 21, 'lr-adaptschedule': 'False', 'lr': 0.0017776424433230491, 'head-lr': 4, 'lr-scheduler-start': 10, 'lr-scheduler-step': 10, 'lr-scheduler-decay': 0.6798458462642316}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.889952
AUC: 0.906971
Avg Precision: 0.427893
Avg Recall: 1.000000
d_prime: 1.870059
train_loss: 0.071366
valid_loss: 1.053807
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0012085228312361748
Epoch-17 lr: 0.004834091324944699
epoch 17 training time: 15.423
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0a683e50>
The learning rate scheduler starts at 10 epoch with decay rate of 0.740 every 10 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 00:29:37.604609
current #epochs=1, #steps=0
start validation
acc: 0.866029
AUC: 0.886110
Avg Precision: 0.391078
Avg Recall: 1.000000
d_prime: 1.705676
train_loss: 0.167167
valid_loss: 1.071401
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0018669045173163598
Epoch-1 lr: 0.007467618069265439
epoch 1 training time: 17.933
---------------
2023-09-24 00:29:55.537651
current #epochs=2, #steps=40
start validation
acc: 0.861244
AUC: 0.880334
Avg Precision: 0.332549
Avg Recall: 1.000000
d_prime: 1.664047
train_loss: 0.176325
valid_loss: 1.079081
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0018669045173163598
Epoch-2 lr: 0.007467618069265439
epoch 2 training time: 15.340
---------------
2023-09-24 00:30:10.877740
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00713	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00554	Train Loss 0.1428	
start validation
acc: 0.866029
AUC: 0.891352
Avg Precision: 0.354709
Avg Recall: 1.000000
d_prime: 1.744783
train_loss: 0.119990
valid_loss: 1.058630
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0018669045173163598
Epoch-3 lr: 0.007467618069265439
epoch 3 training time: 16.772
---------------
2023-09-24 00:30:27.649397
current #epochs=4, #steps=120
start validation
acc: 0.875598
AUC: 0.909621
Avg Precision: 0.417645
Avg Recall: 1.000000
d_prime: 1.892817
train_loss: 0.085835
valid_loss: 1.044203
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0018669045173163598
Epoch-4 lr: 0.007467618069265439
epoch 4 training time: 17.692
---------------
2023-09-24 00:30:45.341605
current #epochs=5, #steps=160
start validation
acc: 0.885167
AUC: 0.901705
Avg Precision: 0.423317
Avg Recall: 1.000000
d_prime: 1.826212
train_loss: 0.115960
valid_loss: 1.046899
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0018669045173163598
Epoch-5 lr: 0.007467618069265439
epoch 5 training time: 17.779
---------------
2023-09-24 00:31:03.121059
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03826	Per Sample Data Time 0.03021	Per Sample DNN Time 0.00805	Train Loss 0.1688	
start validation
acc: 0.861244
AUC: 0.871124
Avg Precision: 0.367398
Avg Recall: 1.000000
d_prime: 1.600498
train_loss: 0.116140
valid_loss: 1.069495
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0018669045173163598
Epoch-6 lr: 0.007467618069265439
epoch 6 training time: 15.310
---------------
2023-09-24 00:31:18.430505
current #epochs=7, #steps=240
start validation
acc: 0.870813
AUC: 0.878407
Avg Precision: 0.421215
Avg Recall: 1.000000
d_prime: 1.650471
train_loss: 0.097261
valid_loss: 1.075978
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0018669045173163598
Epoch-7 lr: 0.007467618069265439
epoch 7 training time: 16.175
---------------
2023-09-24 00:31:34.605509
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00151	Per Sample DNN Time 0.00568	Train Loss 0.0893	
start validation
acc: 0.856459
AUC: 0.880263
Avg Precision: 0.403817
Avg Recall: 1.000000
d_prime: 1.663540
train_loss: 0.098432
valid_loss: 1.062499
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0018669045173163598
Epoch-8 lr: 0.007467618069265439
epoch 8 training time: 15.387
---------------
2023-09-24 00:31:49.992208
current #epochs=9, #steps=320
start validation
acc: 0.889952
AUC: 0.908054
Avg Precision: 0.413582
Avg Recall: 1.000000
d_prime: 1.879300
train_loss: 0.117836
valid_loss: 1.081431
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0018669045173163598
Epoch-9 lr: 0.007467618069265439
epoch 9 training time: 17.704
---------------
2023-09-24 00:32:07.696453
current #epochs=10, #steps=360
start validation
acc: 0.875598
AUC: 0.887747
Avg Precision: 0.417082
Avg Recall: 1.000000
d_prime: 1.717753
train_loss: 0.086317
valid_loss: 1.090698
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0013811912064682222
Epoch-10 lr: 0.005524764825872889
epoch 10 training time: 15.267
---------------
2023-09-24 00:32:22.963852
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04061	Per Sample Data Time 0.02991	Per Sample DNN Time 0.01070	Train Loss 0.0980	
start validation
acc: 0.875598
AUC: 0.897846
Avg Precision: 0.429391
Avg Recall: 1.000000
d_prime: 1.795163
train_loss: 0.078789
valid_loss: 1.088436
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0013811912064682222
Epoch-11 lr: 0.005524764825872889
epoch 11 training time: 15.335
---------------
2023-09-24 00:32:38.298708
current #epochs=12, #steps=440
start validation
acc: 0.899522
AUC: 0.901699
Avg Precision: 0.442248
Avg Recall: 1.000000
d_prime: 1.826165
train_loss: 0.072233
valid_loss: 1.068667
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0013811912064682222
Epoch-12 lr: 0.005524764825872889
epoch 12 training time: 17.686
---------------
2023-09-24 00:32:55.985070
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00711	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00550	Train Loss 0.0598	
start validation
acc: 0.842105
AUC: 0.896187
Avg Precision: 0.404884
Avg Recall: 1.000000
d_prime: 1.782083
train_loss: 0.075929
valid_loss: 1.067319
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0013811912064682222
Epoch-13 lr: 0.005524764825872889
epoch 13 training time: 15.253
---------------
2023-09-24 00:33:11.238015
current #epochs=14, #steps=520
start validation
acc: 0.842105
AUC: 0.890871
Avg Precision: 0.397008
Avg Recall: 1.000000
d_prime: 1.741140
train_loss: 0.064664
valid_loss: 1.059947
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0013811912064682222
Epoch-14 lr: 0.005524764825872889
epoch 14 training time: 15.384
---------------
2023-09-24 00:33:26.621584
current #epochs=15, #steps=560
start validation
acc: 0.861244
AUC: 0.891366
Avg Precision: 0.417951
Avg Recall: 1.000000
d_prime: 1.744896
train_loss: 0.085143
valid_loss: 1.053755
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0013811912064682222
Epoch-15 lr: 0.005524764825872889
epoch 15 training time: 15.378
---------------
2023-09-24 00:33:41.999810
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04191	Per Sample Data Time 0.03234	Per Sample DNN Time 0.00957	Train Loss 0.2531	
start validation
acc: 0.889952
AUC: 0.895190
Avg Precision: 0.446737
Avg Recall: 1.000000
d_prime: 1.774288
train_loss: 0.097339
valid_loss: 1.059720
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0013811912064682222
Epoch-16 lr: 0.005524764825872889
epoch 16 training time: 15.339
---------------
2023-09-24 00:33:57.339235
current #epochs=17, #steps=640
start validation
acc: 0.803828
AUC: 0.902407
Avg Precision: 0.401903
Avg Recall: 1.000000
d_prime: 1.831954
train_loss: 0.105689
valid_loss: 1.086396
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0013811912064682222
Epoch-17 lr: 0.005524764825872889
epoch 17 training time: 15.355
---------------
2023-09-24 00:34:12.694433
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00727	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00565	Train Loss 0.0910	
start validation
[I 2023-09-24 00:34:28,115] Trial 55 finished with value: 0.4387187981795824 and parameters: {'warmup': 'True', 'num_epochs': 18, 'batch_size': 22, 'lr-adaptschedule': 'False', 'lr': 0.0018669045173163598, 'head-lr': 4, 'lr-scheduler-start': 10, 'lr-scheduler-step': 10, 'lr-scheduler-decay': 0.7398295915281509}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.827751
AUC: 0.907111
Avg Precision: 0.438719
Avg Recall: 1.000000
d_prime: 1.871247
train_loss: 0.091241
valid_loss: 1.062630
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0013811912064682222
Epoch-18 lr: 0.005524764825872889
epoch 18 training time: 15.413
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51df14f0>
The learning rate scheduler starts at 10 epoch with decay rate of 0.740 every 10 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 00:34:28.153177
current #epochs=1, #steps=0
start validation
acc: 0.851675
AUC: 0.915690
Avg Precision: 0.403256
Avg Recall: 1.000000
d_prime: 1.946877
train_loss: 0.122688
valid_loss: 1.068924
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0017108803086843352
Epoch-1 lr: 0.006843521234737341
epoch 1 training time: 18.998
---------------
2023-09-24 00:34:47.151648
current #epochs=2, #steps=40
start validation
acc: 0.856459
AUC: 0.902330
Avg Precision: 0.414094
Avg Recall: 1.000000
d_prime: 1.831325
train_loss: 0.132061
valid_loss: 1.082465
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0017108803086843352
Epoch-2 lr: 0.006843521234737341
epoch 2 training time: 18.924
---------------
2023-09-24 00:35:06.075642
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00560	Train Loss 0.0950	
start validation
acc: 0.846890
AUC: 0.904514
Avg Precision: 0.441130
Avg Recall: 1.000000
d_prime: 1.849381
train_loss: 0.104855
valid_loss: 1.080263
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0017108803086843352
Epoch-3 lr: 0.006843521234737341
epoch 3 training time: 15.307
---------------
2023-09-24 00:35:21.382689
current #epochs=4, #steps=120
start validation
acc: 0.856459
AUC: 0.892434
Avg Precision: 0.448811
Avg Recall: 1.000000
d_prime: 1.753030
train_loss: 0.107941
valid_loss: 1.071273
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0017108803086843352
Epoch-4 lr: 0.006843521234737341
epoch 4 training time: 15.275
---------------
2023-09-24 00:35:36.658076
current #epochs=5, #steps=160
start validation
acc: 0.856459
AUC: 0.889337
Avg Precision: 0.433888
Avg Recall: 1.000000
d_prime: 1.729600
train_loss: 0.089494
valid_loss: 1.083119
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0017108803086843352
Epoch-5 lr: 0.006843521234737341
epoch 5 training time: 16.208
---------------
2023-09-24 00:35:52.866043
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04142	Per Sample Data Time 0.03043	Per Sample DNN Time 0.01100	Train Loss 0.1461	
start validation
acc: 0.851675
AUC: 0.896179
Avg Precision: 0.415255
Avg Recall: 1.000000
d_prime: 1.782017
train_loss: 0.093134
valid_loss: 1.080914
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0017108803086843352
Epoch-6 lr: 0.006843521234737341
epoch 6 training time: 15.372
---------------
2023-09-24 00:36:08.237825
current #epochs=7, #steps=240
start validation
acc: 0.851675
AUC: 0.908754
Avg Precision: 0.449674
Avg Recall: 1.000000
d_prime: 1.885322
train_loss: 0.085630
valid_loss: 1.076061
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0017108803086843352
Epoch-7 lr: 0.006843521234737341
epoch 7 training time: 15.277
---------------
2023-09-24 00:36:23.514538
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00564	Train Loss 0.1117	
start validation
acc: 0.851675
AUC: 0.891764
Avg Precision: 0.420208
Avg Recall: 1.000000
d_prime: 1.747919
train_loss: 0.101397
valid_loss: 1.087623
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0017108803086843352
Epoch-8 lr: 0.006843521234737341
epoch 8 training time: 15.239
---------------
2023-09-24 00:36:38.753625
current #epochs=9, #steps=320
start validation
acc: 0.894737
AUC: 0.925305
Avg Precision: 0.452353
Avg Recall: 1.000000
d_prime: 2.038853
train_loss: 0.105726
valid_loss: 1.051844
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0017108803086843352
Epoch-9 lr: 0.006843521234737341
epoch 9 training time: 18.490
---------------
2023-09-24 00:36:57.243753
current #epochs=10, #steps=360
start validation
acc: 0.832536
AUC: 0.903994
Avg Precision: 0.439668
Avg Recall: 1.000000
d_prime: 1.845057
train_loss: 0.086064
valid_loss: 1.070434
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0012666542319210332
Epoch-10 lr: 0.005066616927684133
epoch 10 training time: 16.155
---------------
2023-09-24 00:37:13.399115
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04016	Per Sample Data Time 0.03021	Per Sample DNN Time 0.00995	Train Loss 0.0863	
start validation
acc: 0.861244
AUC: 0.897219
Avg Precision: 0.467565
Avg Recall: 1.000000
d_prime: 1.790203
train_loss: 0.075119
valid_loss: 1.062828
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0012666542319210332
Epoch-11 lr: 0.005066616927684133
epoch 11 training time: 15.247
---------------
2023-09-24 00:37:28.646219
current #epochs=12, #steps=440
start validation
acc: 0.856459
AUC: 0.899652
Avg Precision: 0.464376
Avg Recall: 1.000000
d_prime: 1.809585
train_loss: 0.057850
valid_loss: 1.050714
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0012666542319210332
Epoch-12 lr: 0.005066616927684133
epoch 12 training time: 15.521
---------------
2023-09-24 00:37:44.167477
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00709	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00554	Train Loss 0.0711	
start validation
acc: 0.880383
AUC: 0.900524
Avg Precision: 0.450189
Avg Recall: 1.000000
d_prime: 1.816622
train_loss: 0.075574
valid_loss: 1.067865
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0012666542319210332
Epoch-13 lr: 0.005066616927684133
epoch 13 training time: 15.344
---------------
2023-09-24 00:37:59.510964
current #epochs=14, #steps=520
start validation
acc: 0.827751
AUC: 0.909380
Avg Precision: 0.438758
Avg Recall: 1.000000
d_prime: 1.890729
train_loss: 0.079458
valid_loss: 1.089638
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0012666542319210332
Epoch-14 lr: 0.005066616927684133
epoch 14 training time: 15.237
---------------
2023-09-24 00:38:14.748154
current #epochs=15, #steps=560
start validation
acc: 0.851675
AUC: 0.896869
Avg Precision: 0.432103
Avg Recall: 1.000000
d_prime: 1.787437
train_loss: 0.082355
valid_loss: 1.070767
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0012666542319210332
Epoch-15 lr: 0.005066616927684133
epoch 15 training time: 15.334
---------------
2023-09-24 00:38:30.081751
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03995	Per Sample Data Time 0.02993	Per Sample DNN Time 0.01002	Train Loss 0.0393	
start validation
acc: 0.861244
AUC: 0.886343
Avg Precision: 0.413006
Avg Recall: 1.000000
d_prime: 1.707387
train_loss: 0.081422
valid_loss: 1.069646
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0012666542319210332
Epoch-16 lr: 0.005066616927684133
epoch 16 training time: 15.345
---------------
2023-09-24 00:38:45.427231
current #epochs=17, #steps=640
start validation
acc: 0.866029
AUC: 0.908312
Avg Precision: 0.426843
Avg Recall: 1.000000
d_prime: 1.881511
train_loss: 0.061604
valid_loss: 1.075730
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0012666542319210332
Epoch-17 lr: 0.005066616927684133
epoch 17 training time: 15.591
---------------
2023-09-24 00:39:01.018808
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00153	Per Sample DNN Time 0.00564	Train Loss 0.0632	
start validation
acc: 0.866029
AUC: 0.914847
Avg Precision: 0.414010
Avg Recall: 1.000000
d_prime: 1.939199
train_loss: 0.072270
valid_loss: 1.055511
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0012666542319210332
Epoch-18 lr: 0.005066616927684133
epoch 18 training time: 15.316
---------------
2023-09-24 00:39:16.334490
current #epochs=19, #steps=720
start validation
[I 2023-09-24 00:39:31,561] Trial 56 finished with value: 0.3930426856929379 and parameters: {'warmup': 'True', 'num_epochs': 19, 'batch_size': 20, 'lr-adaptschedule': 'False', 'lr': 0.0017108803086843352, 'head-lr': 4, 'lr-scheduler-start': 10, 'lr-scheduler-step': 10, 'lr-scheduler-decay': 0.7403523352811797}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.861244
AUC: 0.899108
Avg Precision: 0.393043
Avg Recall: 1.000000
d_prime: 1.805221
train_loss: 0.092202
valid_loss: 1.075239
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0012666542319210332
Epoch-19 lr: 0.005066616927684133
epoch 19 training time: 15.218
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcbd147c9a0>
The learning rate scheduler starts at 10 epoch with decay rate of 0.752 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 00:39:31.605274
current #epochs=1, #steps=0
start validation
acc: 0.846890
AUC: 0.873123
Avg Precision: 0.413855
Avg Recall: 1.000000
d_prime: 1.614013
train_loss: 0.098992
valid_loss: 1.060367
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0017314816928369902
Epoch-1 lr: 0.006925926771347961
epoch 1 training time: 17.845
---------------
2023-09-24 00:39:49.451147
current #epochs=2, #steps=40
start validation
acc: 0.827751
AUC: 0.892519
Avg Precision: 0.420226
Avg Recall: 1.000000
d_prime: 1.753672
train_loss: 0.129666
valid_loss: 1.073626
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0017314816928369902
Epoch-2 lr: 0.006925926771347961
epoch 2 training time: 15.225
---------------
2023-09-24 00:40:04.676955
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00715	Per Sample Data Time 0.00165	Per Sample DNN Time 0.00550	Train Loss 0.0870	
start validation
acc: 0.832536
AUC: 0.867715
Avg Precision: 0.404239
Avg Recall: 1.000000
d_prime: 1.577773
train_loss: 0.086091
valid_loss: 1.083430
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0017314816928369902
Epoch-3 lr: 0.006925926771347961
epoch 3 training time: 15.386
---------------
2023-09-24 00:40:20.062063
current #epochs=4, #steps=120
start validation
acc: 0.851675
AUC: 0.915143
Avg Precision: 0.446677
Avg Recall: 1.000000
d_prime: 1.941893
train_loss: 0.082896
valid_loss: 1.087609
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0017314816928369902
Epoch-4 lr: 0.006925926771347961
epoch 4 training time: 17.669
---------------
2023-09-24 00:40:37.731306
current #epochs=5, #steps=160
start validation
acc: 0.822967
AUC: 0.902460
Avg Precision: 0.397276
Avg Recall: 1.000000
d_prime: 1.832388
train_loss: 0.108416
valid_loss: 1.084700
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0017314816928369902
Epoch-5 lr: 0.006925926771347961
epoch 5 training time: 15.401
---------------
2023-09-24 00:40:53.132101
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03968	Per Sample Data Time 0.03033	Per Sample DNN Time 0.00935	Train Loss 0.0463	
start validation
acc: 0.818182
AUC: 0.900955
Avg Precision: 0.415482
Avg Recall: 1.000000
d_prime: 1.820114
train_loss: 0.091400
valid_loss: 1.090187
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0017314816928369902
Epoch-6 lr: 0.006925926771347961
epoch 6 training time: 15.244
---------------
2023-09-24 00:41:08.376586
current #epochs=7, #steps=240
start validation
acc: 0.837321
AUC: 0.909655
Avg Precision: 0.389404
Avg Recall: 1.000000
d_prime: 1.893110
train_loss: 0.069100
valid_loss: 1.085957
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0017314816928369902
Epoch-7 lr: 0.006925926771347961
epoch 7 training time: 15.386
---------------
2023-09-24 00:41:23.762352
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00166	Per Sample DNN Time 0.00556	Train Loss 0.0974	
start validation
acc: 0.866029
AUC: 0.907482
Avg Precision: 0.416249
Avg Recall: 1.000000
d_prime: 1.874406
train_loss: 0.088667
valid_loss: 1.059876
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0017314816928369902
Epoch-8 lr: 0.006925926771347961
epoch 8 training time: 17.915
---------------
2023-09-24 00:41:41.677532
current #epochs=9, #steps=320
start validation
acc: 0.851675
AUC: 0.900361
Avg Precision: 0.423296
Avg Recall: 1.000000
d_prime: 1.815299
train_loss: 0.073214
valid_loss: 1.076353
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0017314816928369902
Epoch-9 lr: 0.006925926771347961
epoch 9 training time: 16.665
---------------
2023-09-24 00:41:58.343141
current #epochs=10, #steps=360
start validation
acc: 0.827751
AUC: 0.878404
Avg Precision: 0.366365
Avg Recall: 1.000000
d_prime: 1.650450
train_loss: 0.077209
valid_loss: 1.109938
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.001302166127236308
Epoch-10 lr: 0.005208664508945232
epoch 10 training time: 15.254
---------------
2023-09-24 00:42:13.597405
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03872	Per Sample Data Time 0.03107	Per Sample DNN Time 0.00765	Train Loss 0.1121	
start validation
[I 2023-09-24 00:42:28,864] Trial 57 finished with value: 0.4026347401912636 and parameters: {'warmup': 'True', 'num_epochs': 11, 'batch_size': 11, 'lr-adaptschedule': 'False', 'lr': 0.0017314816928369902, 'head-lr': 4, 'lr-scheduler-start': 10, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.7520530725928386}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.822967
AUC: 0.887125
Avg Precision: 0.402635
Avg Recall: 1.000000
d_prime: 1.713151
train_loss: 0.071505
valid_loss: 1.107413
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.001302166127236308
Epoch-11 lr: 0.005208664508945232
epoch 11 training time: 15.259
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc526387c0>
The learning rate scheduler starts at 10 epoch with decay rate of 0.717 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 00:42:28.901611
current #epochs=1, #steps=0
start validation
acc: 0.870813
AUC: 0.895080
Avg Precision: 0.428905
Avg Recall: 1.000000
d_prime: 1.773435
train_loss: 0.106181
valid_loss: 1.091411
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0022574205871857644
Epoch-1 lr: 0.009029682348743058
epoch 1 training time: 17.894
---------------
2023-09-24 00:42:46.795941
current #epochs=2, #steps=40
start validation
acc: 0.808612
AUC: 0.880006
Avg Precision: 0.380114
Avg Recall: 1.000000
d_prime: 1.661721
train_loss: 0.120766
valid_loss: 1.096510
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0022574205871857644
Epoch-2 lr: 0.009029682348743058
epoch 2 training time: 17.060
---------------
2023-09-24 00:43:03.855879
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00727	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00563	Train Loss 0.1448	
start validation
acc: 0.808612
AUC: 0.885965
Avg Precision: 0.428797
Avg Recall: 1.000000
d_prime: 1.704615
train_loss: 0.151041
valid_loss: 1.099009
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0022574205871857644
Epoch-3 lr: 0.009029682348743058
epoch 3 training time: 15.350
---------------
2023-09-24 00:43:19.205420
current #epochs=4, #steps=120
start validation
acc: 0.842105
AUC: 0.903598
Avg Precision: 0.391960
Avg Recall: 1.000000
d_prime: 1.841774
train_loss: 0.125371
valid_loss: 1.093560
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0022574205871857644
Epoch-4 lr: 0.009029682348743058
epoch 4 training time: 15.270
---------------
2023-09-24 00:43:34.475363
current #epochs=5, #steps=160
start validation
acc: 0.851675
AUC: 0.882741
Avg Precision: 0.385891
Avg Recall: 1.000000
d_prime: 1.681218
train_loss: 0.109413
valid_loss: 1.096442
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0022574205871857644
Epoch-5 lr: 0.009029682348743058
epoch 5 training time: 15.192
---------------
2023-09-24 00:43:49.667836
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04096	Per Sample Data Time 0.03020	Per Sample DNN Time 0.01076	Train Loss 0.1109	
start validation
acc: 0.856459
AUC: 0.890733
Avg Precision: 0.384791
Avg Recall: 1.000000
d_prime: 1.740096
train_loss: 0.094235
valid_loss: 1.069309
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0022574205871857644
Epoch-6 lr: 0.009029682348743058
epoch 6 training time: 15.331
---------------
2023-09-24 00:44:04.998767
current #epochs=7, #steps=240
start validation
acc: 0.842105
AUC: 0.872863
Avg Precision: 0.425554
Avg Recall: 1.000000
d_prime: 1.612243
train_loss: 0.119710
valid_loss: 1.102627
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0022574205871857644
Epoch-7 lr: 0.009029682348743058
epoch 7 training time: 15.288
---------------
2023-09-24 00:44:20.286597
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00563	Train Loss 0.1027	
start validation
acc: 0.856459
AUC: 0.888939
Avg Precision: 0.332777
Avg Recall: 1.000000
d_prime: 1.726620
train_loss: 0.113182
valid_loss: 1.115618
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0022574205871857644
Epoch-8 lr: 0.009029682348743058
epoch 8 training time: 15.397
---------------
2023-09-24 00:44:35.683166
current #epochs=9, #steps=320
start validation
acc: 0.842105
AUC: 0.882911
Avg Precision: 0.344000
Avg Recall: 1.000000
d_prime: 1.682440
train_loss: 0.131053
valid_loss: 1.087499
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0022574205871857644
Epoch-9 lr: 0.009029682348743058
epoch 9 training time: 16.511
---------------
2023-09-24 00:44:52.194690
current #epochs=10, #steps=360
start validation
acc: 0.808612
AUC: 0.887783
Avg Precision: 0.356107
Avg Recall: 1.000000
d_prime: 1.718021
train_loss: 0.186681
valid_loss: 1.094840
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0016175811373421922
Epoch-10 lr: 0.006470324549368769
epoch 10 training time: 15.412
---------------
2023-09-24 00:45:07.607302
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04120	Per Sample Data Time 0.03048	Per Sample DNN Time 0.01071	Train Loss 0.0707	
start validation
acc: 0.846890
AUC: 0.896973
Avg Precision: 0.405743
Avg Recall: 1.000000
d_prime: 1.788259
train_loss: 0.140388
valid_loss: 1.082747
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0016175811373421922
Epoch-11 lr: 0.006470324549368769
epoch 11 training time: 15.350
---------------
2023-09-24 00:45:22.957767
current #epochs=12, #steps=440
start validation
acc: 0.870813
AUC: 0.899112
Avg Precision: 0.362632
Avg Recall: 1.000000
d_prime: 1.805256
train_loss: 0.117703
valid_loss: 1.070673
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0016175811373421922
Epoch-12 lr: 0.006470324549368769
epoch 12 training time: 15.400
---------------
2023-09-24 00:45:38.357991
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00561	Train Loss 0.1103	
start validation
acc: 0.799043
AUC: 0.857877
Avg Precision: 0.315704
Avg Recall: 1.000000
d_prime: 1.514382
train_loss: 0.126739
valid_loss: 1.098136
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0016175811373421922
Epoch-13 lr: 0.006470324549368769
epoch 13 training time: 15.330
---------------
2023-09-24 00:45:53.687882
current #epochs=14, #steps=520
start validation
acc: 0.827751
AUC: 0.906797
Avg Precision: 0.390810
Avg Recall: 1.000000
d_prime: 1.868578
train_loss: 0.216023
valid_loss: 1.077218
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0016175811373421922
Epoch-14 lr: 0.006470324549368769
epoch 14 training time: 15.281
---------------
2023-09-24 00:46:08.969080
current #epochs=15, #steps=560
start validation
acc: 0.851675
AUC: 0.931632
Avg Precision: 0.453015
Avg Recall: 1.000000
d_prime: 2.104428
train_loss: 0.202505
valid_loss: 1.033392
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0016175811373421922
Epoch-15 lr: 0.006470324549368769
epoch 15 training time: 16.597
---------------
2023-09-24 00:46:25.566511
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04096	Per Sample Data Time 0.03051	Per Sample DNN Time 0.01045	Train Loss 0.2049	
start validation
acc: 0.794258
AUC: 0.914649
Avg Precision: 0.406591
Avg Recall: 1.000000
d_prime: 1.937408
train_loss: 0.142143
valid_loss: 1.065486
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0016175811373421922
Epoch-16 lr: 0.006470324549368769
epoch 16 training time: 15.334
---------------
2023-09-24 00:46:40.900308
current #epochs=17, #steps=640
start validation
acc: 0.832536
AUC: 0.918152
Avg Precision: 0.418010
Avg Recall: 1.000000
d_prime: 1.969646
train_loss: 0.156021
valid_loss: 1.037818
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0016175811373421922
Epoch-17 lr: 0.006470324549368769
epoch 17 training time: 15.338
---------------
2023-09-24 00:46:56.238028
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00563	Train Loss 0.1551	
start validation
acc: 0.808612
AUC: 0.910966
Avg Precision: 0.413217
Avg Recall: 1.000000
d_prime: 1.904562
train_loss: 0.147110
valid_loss: 1.066715
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0016175811373421922
Epoch-18 lr: 0.006470324549368769
epoch 18 training time: 15.285
---------------
2023-09-24 00:47:11.522723
current #epochs=19, #steps=720
start validation
acc: 0.842105
AUC: 0.907685
Avg Precision: 0.427467
Avg Recall: 1.000000
d_prime: 1.876140
train_loss: 0.136185
valid_loss: 1.060450
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0011590966923657017
Epoch-19 lr: 0.004636386769462807
epoch 19 training time: 15.410
---------------
2023-09-24 00:47:26.932828
current #epochs=20, #steps=760
start validation
acc: 0.866029
AUC: 0.907662
Avg Precision: 0.445943
Avg Recall: 1.000000
d_prime: 1.875945
train_loss: 0.121256
valid_loss: 1.049495
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0011590966923657017
Epoch-20 lr: 0.004636386769462807
epoch 20 training time: 15.385
---------------
2023-09-24 00:47:42.318025
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03922	Per Sample Data Time 0.02907	Per Sample DNN Time 0.01015	Train Loss 0.2196	
start validation
acc: 0.846890
AUC: 0.903983
Avg Precision: 0.423454
Avg Recall: 1.000000
d_prime: 1.844959
train_loss: 0.111787
valid_loss: 1.050627
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0011590966923657017
Epoch-21 lr: 0.004636386769462807
epoch 21 training time: 15.289
---------------
2023-09-24 00:47:57.606613
current #epochs=22, #steps=840
start validation
[I 2023-09-24 00:48:12,976] Trial 58 finished with value: 0.44367764710718227 and parameters: {'warmup': 'True', 'num_epochs': 22, 'batch_size': 23, 'lr-adaptschedule': 'False', 'lr': 0.0022574205871857644, 'head-lr': 4, 'lr-scheduler-start': 10, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.7165617016715372}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.861244
AUC: 0.915222
Avg Precision: 0.443678
Avg Recall: 1.000000
d_prime: 1.942612
train_loss: 0.115323
valid_loss: 1.052345
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0011590966923657017
Epoch-22 lr: 0.004636386769462807
epoch 22 training time: 15.361
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51db2d60>
The learning rate scheduler starts at 10 epoch with decay rate of 0.665 every 10 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 00:48:13.012996
current #epochs=1, #steps=0
start validation
acc: 0.851675
AUC: 0.916580
Avg Precision: 0.406700
Avg Recall: 1.000000
d_prime: 1.955047
train_loss: 0.121329
valid_loss: 1.059169
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0019232553416835589
Epoch-1 lr: 0.007693021366734235
epoch 1 training time: 18.215
---------------
2023-09-24 00:48:31.227831
current #epochs=2, #steps=40
start validation
acc: 0.846890
AUC: 0.916371
Avg Precision: 0.411144
Avg Recall: 1.000000
d_prime: 1.953124
train_loss: 0.123728
valid_loss: 1.102567
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0019232553416835589
Epoch-2 lr: 0.007693021366734235
epoch 2 training time: 15.258
---------------
2023-09-24 00:48:46.485753
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00557	Train Loss 0.1246	
start validation
acc: 0.813397
AUC: 0.867677
Avg Precision: 0.378807
Avg Recall: 1.000000
d_prime: 1.577524
train_loss: 0.155285
valid_loss: 1.112149
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0019232553416835589
Epoch-3 lr: 0.007693021366734235
epoch 3 training time: 15.409
---------------
2023-09-24 00:49:01.894545
current #epochs=4, #steps=120
start validation
acc: 0.832536
AUC: 0.884820
Avg Precision: 0.380682
Avg Recall: 1.000000
d_prime: 1.696251
train_loss: 0.136149
valid_loss: 1.057207
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0019232553416835589
Epoch-4 lr: 0.007693021366734235
epoch 4 training time: 15.243
---------------
2023-09-24 00:49:17.137794
current #epochs=5, #steps=160
start validation
acc: 0.813397
AUC: 0.894567
Avg Precision: 0.368902
Avg Recall: 1.000000
d_prime: 1.769444
train_loss: 0.128502
valid_loss: 1.095838
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0019232553416835589
Epoch-5 lr: 0.007693021366734235
epoch 5 training time: 15.189
---------------
2023-09-24 00:49:32.327405
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04073	Per Sample Data Time 0.03096	Per Sample DNN Time 0.00978	Train Loss 0.2061	
start validation
acc: 0.856459
AUC: 0.881489
Avg Precision: 0.372534
Avg Recall: 1.000000
d_prime: 1.672257
train_loss: 0.114660
valid_loss: 1.084494
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0019232553416835589
Epoch-6 lr: 0.007693021366734235
epoch 6 training time: 17.818
---------------
2023-09-24 00:49:50.145593
current #epochs=7, #steps=240
start validation
acc: 0.832536
AUC: 0.920044
Avg Precision: 0.385887
Avg Recall: 1.000000
d_prime: 1.987486
train_loss: 0.121438
valid_loss: 1.079720
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0019232553416835589
Epoch-7 lr: 0.007693021366734235
epoch 7 training time: 15.295
---------------
2023-09-24 00:50:05.440544
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00559	Train Loss 0.1483	
start validation
acc: 0.851675
AUC: 0.877488
Avg Precision: 0.339196
Avg Recall: 1.000000
d_prime: 1.644055
train_loss: 0.161506
valid_loss: 1.090111
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0019232553416835589
Epoch-8 lr: 0.007693021366734235
epoch 8 training time: 16.237
---------------
2023-09-24 00:50:21.677746
current #epochs=9, #steps=320
start validation
acc: 0.775120
AUC: 0.872919
Avg Precision: 0.313075
Avg Recall: 1.000000
d_prime: 1.612627
train_loss: 0.160188
valid_loss: 1.100147
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0019232553416835589
Epoch-9 lr: 0.007693021366734235
epoch 9 training time: 15.293
---------------
2023-09-24 00:50:36.970066
current #epochs=10, #steps=360
start validation
acc: 0.808612
AUC: 0.890545
Avg Precision: 0.372505
Avg Recall: 1.000000
d_prime: 1.738681
train_loss: 0.183877
valid_loss: 1.090261
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.001279417870545983
Epoch-10 lr: 0.005117671482183932
epoch 10 training time: 15.353
---------------
2023-09-24 00:50:52.322925
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03642	Per Sample Data Time 0.02948	Per Sample DNN Time 0.00694	Train Loss 0.1265	
start validation
acc: 0.822967
AUC: 0.883114
Avg Precision: 0.361337
Avg Recall: 1.000000
d_prime: 1.683900
train_loss: 0.140646
valid_loss: 1.082796
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.001279417870545983
Epoch-11 lr: 0.005117671482183932
epoch 11 training time: 15.127
---------------
2023-09-24 00:51:07.449609
current #epochs=12, #steps=440
start validation
acc: 0.822967
AUC: 0.879069
Avg Precision: 0.374966
Avg Recall: 1.000000
d_prime: 1.655119
train_loss: 0.141133
valid_loss: 1.094451
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.001279417870545983
Epoch-12 lr: 0.005117671482183932
epoch 12 training time: 15.409
---------------
2023-09-24 00:51:22.858173
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00561	Train Loss 0.1100	
start validation
acc: 0.842105
AUC: 0.885337
Avg Precision: 0.374533
Avg Recall: 1.000000
d_prime: 1.700019
train_loss: 0.092339
valid_loss: 1.120262
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.001279417870545983
Epoch-13 lr: 0.005117671482183932
epoch 13 training time: 16.532
---------------
2023-09-24 00:51:39.390121
current #epochs=14, #steps=520
start validation
acc: 0.799043
AUC: 0.870043
Avg Precision: 0.328805
Avg Recall: 1.000000
d_prime: 1.593245
train_loss: 0.131775
valid_loss: 1.110195
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.001279417870545983
Epoch-14 lr: 0.005117671482183932
epoch 14 training time: 15.301
---------------
2023-09-24 00:51:54.691528
current #epochs=15, #steps=560
start validation
acc: 0.827751
AUC: 0.879407
Avg Precision: 0.363705
Avg Recall: 1.000000
d_prime: 1.657495
train_loss: 0.098684
valid_loss: 1.097236
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.001279417870545983
Epoch-15 lr: 0.005117671482183932
epoch 15 training time: 15.360
---------------
2023-09-24 00:52:10.051608
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03935	Per Sample Data Time 0.02956	Per Sample DNN Time 0.00979	Train Loss 0.0955	
start validation
acc: 0.818182
AUC: 0.879212
Avg Precision: 0.369142
Avg Recall: 1.000000
d_prime: 1.656126
train_loss: 0.094175
valid_loss: 1.102142
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.001279417870545983
Epoch-16 lr: 0.005117671482183932
epoch 16 training time: 15.200
---------------
2023-09-24 00:52:25.251722
current #epochs=17, #steps=640
start validation
acc: 0.846890
AUC: 0.886450
Avg Precision: 0.394835
Avg Recall: 1.000000
d_prime: 1.708174
train_loss: 0.096958
valid_loss: 1.067524
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.001279417870545983
Epoch-17 lr: 0.005117671482183932
epoch 17 training time: 15.438
---------------
2023-09-24 00:52:40.689715
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00563	Train Loss 0.0825	
start validation
acc: 0.822967
AUC: 0.889959
Avg Precision: 0.418538
Avg Recall: 1.000000
d_prime: 1.734264
train_loss: 0.094102
valid_loss: 1.088701
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.001279417870545983
Epoch-18 lr: 0.005117671482183932
epoch 18 training time: 15.284
---------------
2023-09-24 00:52:55.973128
current #epochs=19, #steps=720
start validation
acc: 0.818182
AUC: 0.878819
Avg Precision: 0.376501
Avg Recall: 1.000000
d_prime: 1.653364
train_loss: 0.101364
valid_loss: 1.104022
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.001279417870545983
Epoch-19 lr: 0.005117671482183932
epoch 19 training time: 15.456
---------------
2023-09-24 00:53:11.428733
current #epochs=20, #steps=760
start validation
acc: 0.818182
AUC: 0.877158
Avg Precision: 0.368868
Avg Recall: 1.000000
d_prime: 1.641754
train_loss: 0.087675
valid_loss: 1.110645
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0008511142810811159
Epoch-20 lr: 0.0034044571243244635
epoch 20 training time: 15.443
---------------
2023-09-24 00:53:26.871817
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04100	Per Sample Data Time 0.03107	Per Sample DNN Time 0.00993	Train Loss 0.0473	
start validation
acc: 0.832536
AUC: 0.890403
Avg Precision: 0.397182
Avg Recall: 1.000000
d_prime: 1.737606
train_loss: 0.080270
valid_loss: 1.074482
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0008511142810811159
Epoch-21 lr: 0.0034044571243244635
epoch 21 training time: 16.304
---------------
2023-09-24 00:53:43.175592
current #epochs=22, #steps=840
start validation
acc: 0.818182
AUC: 0.883119
Avg Precision: 0.397137
Avg Recall: 1.000000
d_prime: 1.683941
train_loss: 0.070485
valid_loss: 1.091330
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0008511142810811159
Epoch-22 lr: 0.0034044571243244635
epoch 22 training time: 15.414
---------------
2023-09-24 00:53:58.588879
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00564	Train Loss 0.0772	
start validation
acc: 0.837321
AUC: 0.888661
Avg Precision: 0.421743
Avg Recall: 1.000000
d_prime: 1.724549
train_loss: 0.081608
valid_loss: 1.081860
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0008511142810811159
Epoch-23 lr: 0.0034044571243244635
epoch 23 training time: 15.345
---------------
2023-09-24 00:54:13.933500
current #epochs=24, #steps=920
start validation
[I 2023-09-24 00:54:29,294] Trial 59 finished with value: 0.41398942610703793 and parameters: {'warmup': 'True', 'num_epochs': 24, 'batch_size': 22, 'lr-adaptschedule': 'False', 'lr': 0.0019232553416835589, 'head-lr': 4, 'lr-scheduler-start': 10, 'lr-scheduler-step': 10, 'lr-scheduler-decay': 0.6652355736737587}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.842105
AUC: 0.896411
Avg Precision: 0.413989
Avg Recall: 1.000000
d_prime: 1.783837
train_loss: 0.077359
valid_loss: 1.073464
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0008511142810811159
Epoch-24 lr: 0.0034044571243244635
epoch 24 training time: 15.351
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0a683df0>
The learning rate scheduler starts at 10 epoch with decay rate of 0.719 every 7 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 00:54:29.332545
current #epochs=1, #steps=0
start validation
acc: 0.856459
AUC: 0.893652
Avg Precision: 0.367180
Avg Recall: 1.000000
d_prime: 1.762370
train_loss: 0.093321
valid_loss: 1.087991
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0009648455893317313
Epoch-1 lr: 0.003859382357326925
epoch 1 training time: 17.812
---------------
2023-09-24 00:54:47.144875
current #epochs=2, #steps=40
start validation
acc: 0.827751
AUC: 0.889092
Avg Precision: 0.420431
Avg Recall: 1.000000
d_prime: 1.727761
train_loss: 0.072319
valid_loss: 1.088980
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0009648455893317313
Epoch-2 lr: 0.003859382357326925
epoch 2 training time: 15.149
---------------
2023-09-24 00:55:02.294234
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00715	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00559	Train Loss 0.0948	
start validation
acc: 0.827751
AUC: 0.864357
Avg Precision: 0.377370
Avg Recall: 1.000000
d_prime: 1.555783
train_loss: 0.081939
valid_loss: 1.106647
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0009648455893317313
Epoch-3 lr: 0.003859382357326925
epoch 3 training time: 15.372
---------------
2023-09-24 00:55:17.666267
current #epochs=4, #steps=120
start validation
acc: 0.818182
AUC: 0.877152
Avg Precision: 0.326463
Avg Recall: 1.000000
d_prime: 1.641711
train_loss: 0.094461
valid_loss: 1.092807
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0009648455893317313
Epoch-4 lr: 0.003859382357326925
epoch 4 training time: 16.069
---------------
2023-09-24 00:55:33.735193
current #epochs=5, #steps=160
start validation
acc: 0.856459
AUC: 0.883313
Avg Precision: 0.382405
Avg Recall: 1.000000
d_prime: 1.685333
train_loss: 0.097544
valid_loss: 1.077133
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0009648455893317313
Epoch-5 lr: 0.003859382357326925
epoch 5 training time: 16.837
---------------
2023-09-24 00:55:50.571987
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03962	Per Sample Data Time 0.02943	Per Sample DNN Time 0.01018	Train Loss 0.0295	
start validation
acc: 0.842105
AUC: 0.882043
Avg Precision: 0.398416
Avg Recall: 1.000000
d_prime: 1.676217
train_loss: 0.097735
valid_loss: 1.083994
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0009648455893317313
Epoch-6 lr: 0.003859382357326925
epoch 6 training time: 15.288
---------------
2023-09-24 00:56:05.859633
current #epochs=7, #steps=240
start validation
acc: 0.837321
AUC: 0.893305
Avg Precision: 0.403424
Avg Recall: 1.000000
d_prime: 1.759704
train_loss: 0.074208
valid_loss: 1.075256
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0009648455893317313
Epoch-7 lr: 0.003859382357326925
epoch 7 training time: 15.367
---------------
2023-09-24 00:56:21.226375
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00563	Train Loss 0.0792	
start validation
acc: 0.808612
AUC: 0.881872
Avg Precision: 0.380728
Avg Recall: 1.000000
d_prime: 1.674993
train_loss: 0.072141
valid_loss: 1.082090
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0009648455893317313
Epoch-8 lr: 0.003859382357326925
epoch 8 training time: 15.340
---------------
2023-09-24 00:56:36.566271
current #epochs=9, #steps=320
start validation
acc: 0.827751
AUC: 0.890266
Avg Precision: 0.411471
Avg Recall: 1.000000
d_prime: 1.736574
train_loss: 0.078915
valid_loss: 1.084222
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0009648455893317313
Epoch-9 lr: 0.003859382357326925
epoch 9 training time: 15.311
---------------
2023-09-24 00:56:51.877147
current #epochs=10, #steps=360
start validation
acc: 0.832536
AUC: 0.889286
Avg Precision: 0.402777
Avg Recall: 1.000000
d_prime: 1.729215
train_loss: 0.078792
valid_loss: 1.073657
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0006938923382659477
Epoch-10 lr: 0.0027755693530637907
epoch 10 training time: 15.257
---------------
2023-09-24 00:57:07.134505
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04126	Per Sample Data Time 0.03115	Per Sample DNN Time 0.01011	Train Loss 0.0231	
start validation
acc: 0.818182
AUC: 0.883948
Avg Precision: 0.396457
Avg Recall: 1.000000
d_prime: 1.689923
train_loss: 0.099405
valid_loss: 1.060188
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0006938923382659477
Epoch-11 lr: 0.0027755693530637907
epoch 11 training time: 15.380
---------------
2023-09-24 00:57:22.514083
current #epochs=12, #steps=440
start validation
acc: 0.803828
AUC: 0.891476
Avg Precision: 0.435914
Avg Recall: 1.000000
d_prime: 1.745725
train_loss: 0.088631
valid_loss: 1.088999
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0006938923382659477
Epoch-12 lr: 0.0027755693530637907
epoch 12 training time: 15.391
---------------
2023-09-24 00:57:37.904908
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00725	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00563	Train Loss 0.0773	
start validation
acc: 0.842105
AUC: 0.888371
Avg Precision: 0.413452
Avg Recall: 1.000000
d_prime: 1.722382
train_loss: 0.092636
valid_loss: 1.087707
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0006938923382659477
Epoch-13 lr: 0.0027755693530637907
epoch 13 training time: 15.376
---------------
2023-09-24 00:57:53.280589
current #epochs=14, #steps=520
start validation
acc: 0.861244
AUC: 0.897755
Avg Precision: 0.375654
Avg Recall: 1.000000
d_prime: 1.794443
train_loss: 0.090408
valid_loss: 1.076280
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0006938923382659477
Epoch-14 lr: 0.0027755693530637907
epoch 14 training time: 17.997
---------------
2023-09-24 00:58:11.278250
current #epochs=15, #steps=560
start validation
acc: 0.842105
AUC: 0.897615
Avg Precision: 0.408953
Avg Recall: 1.000000
d_prime: 1.793337
train_loss: 0.066942
valid_loss: 1.068819
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0006938923382659477
Epoch-15 lr: 0.0027755693530637907
epoch 15 training time: 15.270
---------------
2023-09-24 00:58:26.548412
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04048	Per Sample Data Time 0.02979	Per Sample DNN Time 0.01069	Train Loss 0.1225	
start validation
acc: 0.842105
AUC: 0.884622
Avg Precision: 0.386080
Avg Recall: 1.000000
d_prime: 1.694811
train_loss: 0.076271
valid_loss: 1.083240
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0006938923382659477
Epoch-16 lr: 0.0027755693530637907
epoch 16 training time: 15.259
---------------
2023-09-24 00:58:41.807576
current #epochs=17, #steps=640
start validation
acc: 0.880383
AUC: 0.896648
Avg Precision: 0.421889
Avg Recall: 1.000000
d_prime: 1.785701
train_loss: 0.074032
valid_loss: 1.069373
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0004990296710976005
Epoch-17 lr: 0.001996118684390402
epoch 17 training time: 17.902
---------------
2023-09-24 00:58:59.709532
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00705	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00548	Train Loss 0.0729	
start validation
acc: 0.870813
AUC: 0.898242
Avg Precision: 0.425956
Avg Recall: 1.000000
d_prime: 1.798315
train_loss: 0.078373
valid_loss: 1.078911
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0004990296710976005
Epoch-18 lr: 0.001996118684390402
epoch 18 training time: 15.170
---------------
2023-09-24 00:59:14.879291
current #epochs=19, #steps=720
start validation
acc: 0.846890
AUC: 0.897824
Avg Precision: 0.405908
Avg Recall: 1.000000
d_prime: 1.794993
train_loss: 0.061557
valid_loss: 1.075547
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0004990296710976005
Epoch-19 lr: 0.001996118684390402
epoch 19 training time: 15.257
---------------
2023-09-24 00:59:30.136525
current #epochs=20, #steps=760
start validation
acc: 0.875598
AUC: 0.887967
Avg Precision: 0.410531
Avg Recall: 1.000000
d_prime: 1.719381
train_loss: 0.063864
valid_loss: 1.074209
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0004990296710976005
Epoch-20 lr: 0.001996118684390402
epoch 20 training time: 15.319
---------------
2023-09-24 00:59:45.455477
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04245	Per Sample Data Time 0.03273	Per Sample DNN Time 0.00971	Train Loss 0.1489	
start validation
acc: 0.837321
AUC: 0.891400
Avg Precision: 0.398380
Avg Recall: 1.000000
d_prime: 1.745152
train_loss: 0.072607
valid_loss: 1.074883
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0004990296710976005
Epoch-21 lr: 0.001996118684390402
epoch 21 training time: 16.392
---------------
2023-09-24 01:00:01.847117
current #epochs=22, #steps=840
start validation
acc: 0.856459
AUC: 0.888709
Avg Precision: 0.411757
Avg Recall: 1.000000
d_prime: 1.724901
train_loss: 0.066167
valid_loss: 1.071238
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0004990296710976005
Epoch-22 lr: 0.001996118684390402
epoch 22 training time: 15.804
---------------
2023-09-24 01:00:17.651106
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00564	Train Loss 0.0698	
start validation
acc: 0.870813
AUC: 0.904369
Avg Precision: 0.413074
Avg Recall: 1.000000
d_prime: 1.848172
train_loss: 0.083552
valid_loss: 1.055354
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0004990296710976005
Epoch-23 lr: 0.001996118684390402
epoch 23 training time: 16.703
---------------
2023-09-24 01:00:34.354571
current #epochs=24, #steps=920
start validation
acc: 0.866029
AUC: 0.895237
Avg Precision: 0.400475
Avg Recall: 1.000000
d_prime: 1.774654
train_loss: 0.083160
valid_loss: 1.081710
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.00035888941108373144
Epoch-24 lr: 0.0014355576443349258
epoch 24 training time: 15.238
---------------
2023-09-24 01:00:49.593125
current #epochs=25, #steps=960
start validation
acc: 0.856459
AUC: 0.901545
Avg Precision: 0.400975
Avg Recall: 1.000000
d_prime: 1.824908
train_loss: 0.064372
valid_loss: 1.066815
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.00035888941108373144
Epoch-25 lr: 0.0014355576443349258
epoch 25 training time: 15.342
---------------
2023-09-24 01:01:04.934724
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.04100	Per Sample Data Time 0.03089	Per Sample DNN Time 0.01011	Train Loss 0.0483	
start validation
acc: 0.870813
AUC: 0.898520
Avg Precision: 0.408874
Avg Recall: 1.000000
d_prime: 1.800526
train_loss: 0.058145
valid_loss: 1.069871
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.00035888941108373144
Epoch-26 lr: 0.0014355576443349258
epoch 26 training time: 15.402
---------------
2023-09-24 01:01:20.337011
current #epochs=27, #steps=1040
start validation
acc: 0.851675
AUC: 0.894443
Avg Precision: 0.402245
Avg Recall: 1.000000
d_prime: 1.768483
train_loss: 0.072937
valid_loss: 1.086007
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.00035888941108373144
Epoch-27 lr: 0.0014355576443349258
epoch 27 training time: 15.346
---------------
2023-09-24 01:01:35.682587
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00565	Train Loss 0.0752	
start validation
acc: 0.866029
AUC: 0.893692
Avg Precision: 0.419731
Avg Recall: 1.000000
d_prime: 1.762681
train_loss: 0.065374
valid_loss: 1.083037
validation finished
normal learning rate scheduler step
Epoch-28 lr: 0.00035888941108373144
Epoch-28 lr: 0.0014355576443349258
epoch 28 training time: 16.553
---------------
2023-09-24 01:01:52.235444
current #epochs=29, #steps=1120
start validation
acc: 0.875598
AUC: 0.893676
Avg Precision: 0.409283
Avg Recall: 1.000000
d_prime: 1.762559
train_loss: 0.070608
valid_loss: 1.078158
validation finished
normal learning rate scheduler step
Epoch-29 lr: 0.00035888941108373144
Epoch-29 lr: 0.0014355576443349258
epoch 29 training time: 15.371
---------------
2023-09-24 01:02:07.606822
current #epochs=30, #steps=1160
start validation
acc: 0.846890
AUC: 0.891692
Avg Precision: 0.423119
Avg Recall: 1.000000
d_prime: 1.747371
train_loss: 0.067221
valid_loss: 1.085550
validation finished
normal learning rate scheduler step
Epoch-30 lr: 0.00035888941108373144
Epoch-30 lr: 0.0014355576443349258
epoch 30 training time: 15.302
---------------
2023-09-24 01:02:22.908829
current #epochs=31, #steps=1200
Epoch: [31][0/40]	Per Sample Total Time 0.04164	Per Sample Data Time 0.03129	Per Sample DNN Time 0.01035	Train Loss 0.1145	
start validation
acc: 0.832536
AUC: 0.885311
Avg Precision: 0.422978
Avg Recall: 1.000000
d_prime: 1.699834
train_loss: 0.060774
valid_loss: 1.083155
validation finished
normal learning rate scheduler step
Epoch-31 lr: 0.000258104110532611
Epoch-31 lr: 0.001032416442130444
epoch 31 training time: 15.382
---------------
2023-09-24 01:02:38.290875
current #epochs=32, #steps=1240
start validation
acc: 0.818182
AUC: 0.880065
Avg Precision: 0.387221
Avg Recall: 1.000000
d_prime: 1.662141
train_loss: 0.073028
valid_loss: 1.090045
validation finished
normal learning rate scheduler step
Epoch-32 lr: 0.000258104110532611
Epoch-32 lr: 0.001032416442130444
epoch 32 training time: 15.317
---------------
2023-09-24 01:02:53.608135
current #epochs=33, #steps=1280
Epoch: [33][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00563	Train Loss 0.0749	
start validation
acc: 0.827751
AUC: 0.878142
Avg Precision: 0.396962
Avg Recall: 1.000000
d_prime: 1.648617
train_loss: 0.070994
valid_loss: 1.087524
validation finished
normal learning rate scheduler step
Epoch-33 lr: 0.000258104110532611
Epoch-33 lr: 0.001032416442130444
epoch 33 training time: 15.335
---------------
2023-09-24 01:03:08.943255
current #epochs=34, #steps=1320
start validation
acc: 0.813397
AUC: 0.885156
Avg Precision: 0.397605
Avg Recall: 1.000000
d_prime: 1.698701
train_loss: 0.063033
valid_loss: 1.085718
validation finished
normal learning rate scheduler step
Epoch-34 lr: 0.000258104110532611
Epoch-34 lr: 0.001032416442130444
epoch 34 training time: 15.394
---------------
2023-09-24 01:03:24.336832
current #epochs=35, #steps=1360
start validation
[I 2023-09-24 01:03:41,162] Trial 60 finished with value: 0.4111036026906248 and parameters: {'warmup': 'True', 'num_epochs': 35, 'batch_size': 15, 'lr-adaptschedule': 'False', 'lr': 0.0009648455893317313, 'head-lr': 4, 'lr-scheduler-start': 10, 'lr-scheduler-step': 7, 'lr-scheduler-decay': 0.7191744937617941}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.822967
AUC: 0.889387
Avg Precision: 0.411104
Avg Recall: 1.000000
d_prime: 1.729974
train_loss: 0.071004
valid_loss: 1.080243
validation finished
normal learning rate scheduler step
Epoch-35 lr: 0.000258104110532611
Epoch-35 lr: 0.001032416442130444
epoch 35 training time: 16.815
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc097f9d30>
The learning rate scheduler starts at 9 epoch with decay rate of 0.733 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 01:03:41.200155
current #epochs=1, #steps=0
start validation
acc: 0.760766
AUC: 0.877738
Avg Precision: 0.350263
Avg Recall: 1.000000
d_prime: 1.645793
train_loss: 0.124550
valid_loss: 1.096495
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0022121674449750543
Epoch-1 lr: 0.008848669779900217
epoch 1 training time: 19.259
---------------
2023-09-24 01:04:00.459379
current #epochs=2, #steps=40
start validation
acc: 0.842105
AUC: 0.867529
Avg Precision: 0.367086
Avg Recall: 1.000000
d_prime: 1.576548
train_loss: 0.126325
valid_loss: 1.107743
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0022121674449750543
Epoch-2 lr: 0.008848669779900217
epoch 2 training time: 17.493
---------------
2023-09-24 01:04:17.952511
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00559	Train Loss 0.0945	
start validation
acc: 0.818182
AUC: 0.895522
Avg Precision: 0.370221
Avg Recall: 1.000000
d_prime: 1.776878
train_loss: 0.083083
valid_loss: 1.086754
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0022121674449750543
Epoch-3 lr: 0.008848669779900217
epoch 3 training time: 15.234
---------------
2023-09-24 01:04:33.185883
current #epochs=4, #steps=120
start validation
acc: 0.856459
AUC: 0.898156
Avg Precision: 0.361772
Avg Recall: 1.000000
d_prime: 1.797629
train_loss: 0.114812
valid_loss: 1.078833
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0022121674449750543
Epoch-4 lr: 0.008848669779900217
epoch 4 training time: 17.883
---------------
2023-09-24 01:04:51.068835
current #epochs=5, #steps=160
start validation
acc: 0.822967
AUC: 0.864307
Avg Precision: 0.305618
Avg Recall: 1.000000
d_prime: 1.555460
train_loss: 0.081051
valid_loss: 1.101023
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0022121674449750543
Epoch-5 lr: 0.008848669779900217
epoch 5 training time: 15.766
---------------
2023-09-24 01:05:06.834368
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04140	Per Sample Data Time 0.03052	Per Sample DNN Time 0.01088	Train Loss 0.0596	
start validation
acc: 0.851675
AUC: 0.896373
Avg Precision: 0.341210
Avg Recall: 1.000000
d_prime: 1.783538
train_loss: 0.089824
valid_loss: 1.053861
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0022121674449750543
Epoch-6 lr: 0.008848669779900217
epoch 6 training time: 15.369
---------------
2023-09-24 01:05:22.203717
current #epochs=7, #steps=240
start validation
acc: 0.885167
AUC: 0.888577
Avg Precision: 0.366378
Avg Recall: 1.000000
d_prime: 1.723920
train_loss: 0.126691
valid_loss: 1.072638
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0022121674449750543
Epoch-7 lr: 0.008848669779900217
epoch 7 training time: 17.765
---------------
2023-09-24 01:05:39.968912
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00707	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00549	Train Loss 0.1054	
start validation
acc: 0.880383
AUC: 0.896316
Avg Precision: 0.395131
Avg Recall: 1.000000
d_prime: 1.783092
train_loss: 0.100243
valid_loss: 1.076249
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0022121674449750543
Epoch-8 lr: 0.008848669779900217
epoch 8 training time: 15.153
---------------
2023-09-24 01:05:55.121520
current #epochs=9, #steps=320
start validation
acc: 0.846890
AUC: 0.891381
Avg Precision: 0.374700
Avg Recall: 1.000000
d_prime: 1.745005
train_loss: 0.105165
valid_loss: 1.090506
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0016220841755169018
Epoch-9 lr: 0.006488336702067607
epoch 9 training time: 16.332
---------------
2023-09-24 01:06:11.453653
current #epochs=10, #steps=360
start validation
acc: 0.846890
AUC: 0.890137
Avg Precision: 0.399625
Avg Recall: 1.000000
d_prime: 1.735606
train_loss: 0.077693
valid_loss: 1.075531
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0016220841755169018
Epoch-10 lr: 0.006488336702067607
epoch 10 training time: 15.313
---------------
2023-09-24 01:06:26.766770
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03939	Per Sample Data Time 0.02906	Per Sample DNN Time 0.01034	Train Loss 0.0862	
start validation
acc: 0.846890
AUC: 0.880860
Avg Precision: 0.397953
Avg Recall: 1.000000
d_prime: 1.667781
train_loss: 0.098183
valid_loss: 1.074826
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0016220841755169018
Epoch-11 lr: 0.006488336702067607
epoch 11 training time: 17.154
---------------
2023-09-24 01:06:43.920969
current #epochs=12, #steps=440
start validation
acc: 0.870813
AUC: 0.882202
Avg Precision: 0.406192
Avg Recall: 1.000000
d_prime: 1.677349
train_loss: 0.091748
valid_loss: 1.079052
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0016220841755169018
Epoch-12 lr: 0.006488336702067607
epoch 12 training time: 15.350
---------------
2023-09-24 01:06:59.270822
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00565	Train Loss 0.0855	
start validation
acc: 0.861244
AUC: 0.864108
Avg Precision: 0.354917
Avg Recall: 1.000000
d_prime: 1.554169
train_loss: 0.086286
valid_loss: 1.111325
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0016220841755169018
Epoch-13 lr: 0.006488336702067607
epoch 13 training time: 15.433
---------------
2023-09-24 01:07:14.703908
current #epochs=14, #steps=520
start validation
acc: 0.799043
AUC: 0.872809
Avg Precision: 0.358064
Avg Recall: 1.000000
d_prime: 1.611877
train_loss: 0.093347
valid_loss: 1.108651
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0016220841755169018
Epoch-14 lr: 0.006488336702067607
epoch 14 training time: 15.292
---------------
2023-09-24 01:07:29.996505
current #epochs=15, #steps=560
start validation
acc: 0.832536
AUC: 0.879211
Avg Precision: 0.388951
Avg Recall: 1.000000
d_prime: 1.656119
train_loss: 0.109684
valid_loss: 1.100729
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0016220841755169018
Epoch-15 lr: 0.006488336702067607
epoch 15 training time: 15.341
---------------
2023-09-24 01:07:45.337579
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04123	Per Sample Data Time 0.03081	Per Sample DNN Time 0.01042	Train Loss 0.1255	
start validation
acc: 0.875598
AUC: 0.876892
Avg Precision: 0.374790
Avg Recall: 1.000000
d_prime: 1.639911
train_loss: 0.127097
valid_loss: 1.096391
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0016220841755169018
Epoch-16 lr: 0.006488336702067607
epoch 16 training time: 15.373
---------------
2023-09-24 01:08:00.710792
current #epochs=17, #steps=640
start validation
acc: 0.889952
AUC: 0.889873
Avg Precision: 0.390690
Avg Recall: 1.000000
d_prime: 1.733618
train_loss: 0.114049
valid_loss: 1.091304
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0016220841755169018
Epoch-17 lr: 0.006488336702067607
epoch 17 training time: 17.833
---------------
2023-09-24 01:08:18.543493
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00556	Train Loss 0.1098	
start validation
acc: 0.861244
AUC: 0.877433
Avg Precision: 0.399671
Avg Recall: 1.000000
d_prime: 1.643666
train_loss: 0.120192
valid_loss: 1.100037
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.001189402311492753
Epoch-18 lr: 0.004757609245971012
epoch 18 training time: 15.257
---------------
2023-09-24 01:08:33.800616
current #epochs=19, #steps=720
start validation
acc: 0.808612
AUC: 0.867353
Avg Precision: 0.332004
Avg Recall: 1.000000
d_prime: 1.575385
train_loss: 0.213209
valid_loss: 1.130679
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.001189402311492753
Epoch-19 lr: 0.004757609245971012
epoch 19 training time: 15.259
---------------
2023-09-24 01:08:49.059506
current #epochs=20, #steps=760
start validation
acc: 0.818182
AUC: 0.883149
Avg Precision: 0.359897
Avg Recall: 1.000000
d_prime: 1.684157
train_loss: 0.133027
valid_loss: 1.076034
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.001189402311492753
Epoch-20 lr: 0.004757609245971012
epoch 20 training time: 15.297
---------------
2023-09-24 01:09:04.356959
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03709	Per Sample Data Time 0.02923	Per Sample DNN Time 0.00786	Train Loss 0.0672	
start validation
[I 2023-09-24 01:09:19,683] Trial 61 finished with value: 0.4267933980144757 and parameters: {'warmup': 'True', 'num_epochs': 21, 'batch_size': 24, 'lr-adaptschedule': 'False', 'lr': 0.0022121674449750543, 'head-lr': 4, 'lr-scheduler-start': 9, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.7332556037751443}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.842105
AUC: 0.887659
Avg Precision: 0.426793
Avg Recall: 1.000000
d_prime: 1.717098
train_loss: 0.126587
valid_loss: 1.076039
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.001189402311492753
Epoch-21 lr: 0.004757609245971012
epoch 21 training time: 15.318
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcbd14805b0>
The learning rate scheduler starts at 9 epoch with decay rate of 0.716 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 01:09:19.721876
current #epochs=1, #steps=0
start validation
acc: 0.803828
AUC: 0.834860
Avg Precision: 0.319049
Avg Recall: 1.000000
d_prime: 1.376808
train_loss: 0.146309
valid_loss: 1.131891
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0023098068702007905
Epoch-1 lr: 0.009239227480803162
epoch 1 training time: 17.771
---------------
2023-09-24 01:09:37.492923
current #epochs=2, #steps=40
start validation
acc: 0.784689
AUC: 0.883272
Avg Precision: 0.321466
Avg Recall: 1.000000
d_prime: 1.685043
train_loss: 0.131279
valid_loss: 1.119755
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0023098068702007905
Epoch-2 lr: 0.009239227480803162
epoch 2 training time: 15.300
---------------
2023-09-24 01:09:52.793426
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00707	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00550	Train Loss 0.1510	
start validation
acc: 0.784689
AUC: 0.842993
Avg Precision: 0.338507
Avg Recall: 1.000000
d_prime: 1.423879
train_loss: 0.172629
valid_loss: 1.149669
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0023098068702007905
Epoch-3 lr: 0.009239227480803162
epoch 3 training time: 16.326
---------------
2023-09-24 01:10:09.119355
current #epochs=4, #steps=120
start validation
acc: 0.799043
AUC: 0.887860
Avg Precision: 0.325044
Avg Recall: 1.000000
d_prime: 1.718589
train_loss: 0.136809
valid_loss: 1.115393
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0023098068702007905
Epoch-4 lr: 0.009239227480803162
epoch 4 training time: 15.204
---------------
2023-09-24 01:10:24.323890
current #epochs=5, #steps=160
start validation
acc: 0.861244
AUC: 0.892545
Avg Precision: 0.432771
Avg Recall: 1.000000
d_prime: 1.753874
train_loss: 0.122694
valid_loss: 1.104095
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0023098068702007905
Epoch-5 lr: 0.009239227480803162
epoch 5 training time: 17.740
---------------
2023-09-24 01:10:42.063988
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03947	Per Sample Data Time 0.03125	Per Sample DNN Time 0.00822	Train Loss 0.0356	
start validation
acc: 0.851675
AUC: 0.895839
Avg Precision: 0.414700
Avg Recall: 1.000000
d_prime: 1.779357
train_loss: 0.081202
valid_loss: 1.114236
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0023098068702007905
Epoch-6 lr: 0.009239227480803162
epoch 6 training time: 15.198
---------------
2023-09-24 01:10:57.262236
current #epochs=7, #steps=240
start validation
acc: 0.837321
AUC: 0.886034
Avg Precision: 0.385671
Avg Recall: 1.000000
d_prime: 1.705123
train_loss: 0.109449
valid_loss: 1.082194
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0023098068702007905
Epoch-7 lr: 0.009239227480803162
epoch 7 training time: 16.798
---------------
2023-09-24 01:11:14.060703
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00560	Train Loss 0.1001	
start validation
acc: 0.875598
AUC: 0.902019
Avg Precision: 0.409877
Avg Recall: 1.000000
d_prime: 1.828781
train_loss: 0.098922
valid_loss: 1.064268
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0023098068702007905
Epoch-8 lr: 0.009239227480803162
epoch 8 training time: 17.933
---------------
2023-09-24 01:11:31.993649
current #epochs=9, #steps=320
start validation
acc: 0.880383
AUC: 0.901022
Avg Precision: 0.395975
Avg Recall: 1.000000
d_prime: 1.820651
train_loss: 0.096912
valid_loss: 1.076798
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.001653343041656572
Epoch-9 lr: 0.006613372166626288
epoch 9 training time: 17.925
---------------
2023-09-24 01:11:49.918997
current #epochs=10, #steps=360
start validation
acc: 0.861244
AUC: 0.879387
Avg Precision: 0.440620
Avg Recall: 1.000000
d_prime: 1.657354
train_loss: 0.078102
valid_loss: 1.094766
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.001653343041656572
Epoch-10 lr: 0.006613372166626288
epoch 10 training time: 15.209
---------------
2023-09-24 01:12:05.128022
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03975	Per Sample Data Time 0.03251	Per Sample DNN Time 0.00724	Train Loss 0.1119	
start validation
acc: 0.822967
AUC: 0.880892
Avg Precision: 0.415748
Avg Recall: 1.000000
d_prime: 1.668007
train_loss: 0.090542
valid_loss: 1.112041
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.001653343041656572
Epoch-11 lr: 0.006613372166626288
epoch 11 training time: 15.420
---------------
2023-09-24 01:12:20.548120
current #epochs=12, #steps=440
start validation
acc: 0.837321
AUC: 0.884704
Avg Precision: 0.398086
Avg Recall: 1.000000
d_prime: 1.695406
train_loss: 0.065179
valid_loss: 1.097757
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.001653343041656572
Epoch-12 lr: 0.006613372166626288
epoch 12 training time: 15.477
---------------
2023-09-24 01:12:36.025628
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00556	Train Loss 0.0809	
start validation
acc: 0.861244
AUC: 0.900432
Avg Precision: 0.424223
Avg Recall: 1.000000
d_prime: 1.815876
train_loss: 0.103117
valid_loss: 1.045328
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.001653343041656572
Epoch-13 lr: 0.006613372166626288
epoch 13 training time: 15.592
---------------
2023-09-24 01:12:51.617666
current #epochs=14, #steps=520
start validation
acc: 0.880383
AUC: 0.896610
Avg Precision: 0.385048
Avg Recall: 1.000000
d_prime: 1.785401
train_loss: 0.082595
valid_loss: 1.059137
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.001653343041656572
Epoch-14 lr: 0.006613372166626288
epoch 14 training time: 17.064
---------------
2023-09-24 01:13:08.681755
current #epochs=15, #steps=560
start validation
acc: 0.885167
AUC: 0.889296
Avg Precision: 0.415911
Avg Recall: 1.000000
d_prime: 1.729291
train_loss: 0.093044
valid_loss: 1.069273
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.001653343041656572
Epoch-15 lr: 0.006613372166626288
epoch 15 training time: 17.679
---------------
2023-09-24 01:13:26.360467
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03829	Per Sample Data Time 0.03066	Per Sample DNN Time 0.00763	Train Loss 0.0858	
start validation
acc: 0.846890
AUC: 0.901995
Avg Precision: 0.405562
Avg Recall: 1.000000
d_prime: 1.828582
train_loss: 0.071500
valid_loss: 1.076063
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.001653343041656572
Epoch-16 lr: 0.006613372166626288
epoch 16 training time: 15.279
---------------
2023-09-24 01:13:41.639443
current #epochs=17, #steps=640
start validation
acc: 0.813397
AUC: 0.883026
Avg Precision: 0.405196
Avg Recall: 1.000000
d_prime: 1.683271
train_loss: 0.078971
valid_loss: 1.108135
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.001653343041656572
Epoch-17 lr: 0.006613372166626288
epoch 17 training time: 15.165
---------------
2023-09-24 01:13:56.804347
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00709	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00547	Train Loss 0.0782	
start validation
[I 2023-09-24 01:14:12,019] Trial 62 finished with value: 0.3892683424666755 and parameters: {'warmup': 'True', 'num_epochs': 18, 'batch_size': 24, 'lr-adaptschedule': 'False', 'lr': 0.0023098068702007905, 'head-lr': 4, 'lr-scheduler-start': 9, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.7157927630169563}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.832536
AUC: 0.890667
Avg Precision: 0.389268
Avg Recall: 1.000000
d_prime: 1.739601
train_loss: 0.075996
valid_loss: 1.111544
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0011834509840022163
Epoch-18 lr: 0.004733803936008865
epoch 18 training time: 15.206
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0a6838e0>
The learning rate scheduler starts at 9 epoch with decay rate of 0.707 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 01:14:12.056858
current #epochs=1, #steps=0
start validation
acc: 0.808612
AUC: 0.859638
Avg Precision: 0.332669
Avg Recall: 1.000000
d_prime: 1.525505
train_loss: 0.143973
valid_loss: 1.123788
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0019838446409296785
Epoch-1 lr: 0.007935378563718714
epoch 1 training time: 17.648
---------------
2023-09-24 01:14:29.704997
current #epochs=2, #steps=40
start validation
acc: 0.789474
AUC: 0.885242
Avg Precision: 0.385259
Avg Recall: 1.000000
d_prime: 1.699326
train_loss: 0.099906
valid_loss: 1.106837
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0019838446409296785
Epoch-2 lr: 0.007935378563718714
epoch 2 training time: 15.307
---------------
2023-09-24 01:14:45.012458
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00707	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00550	Train Loss 0.0832	
start validation
acc: 0.799043
AUC: 0.874290
Avg Precision: 0.349947
Avg Recall: 1.000000
d_prime: 1.621970
train_loss: 0.076331
valid_loss: 1.108077
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0019838446409296785
Epoch-3 lr: 0.007935378563718714
epoch 3 training time: 16.772
---------------
2023-09-24 01:15:01.784528
current #epochs=4, #steps=120
start validation
acc: 0.832536
AUC: 0.896143
Avg Precision: 0.348660
Avg Recall: 1.000000
d_prime: 1.781732
train_loss: 0.104462
valid_loss: 1.076153
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0019838446409296785
Epoch-4 lr: 0.007935378563718714
epoch 4 training time: 17.647
---------------
2023-09-24 01:15:19.431236
current #epochs=5, #steps=160
start validation
acc: 0.789474
AUC: 0.894922
Avg Precision: 0.349502
Avg Recall: 1.000000
d_prime: 1.772205
train_loss: 0.112427
valid_loss: 1.077106
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0019838446409296785
Epoch-5 lr: 0.007935378563718714
epoch 5 training time: 15.405
---------------
2023-09-24 01:15:34.836841
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03900	Per Sample Data Time 0.03130	Per Sample DNN Time 0.00770	Train Loss 0.0893	
start validation
acc: 0.822967
AUC: 0.905300
Avg Precision: 0.374120
Avg Recall: 1.000000
d_prime: 1.855955
train_loss: 0.122076
valid_loss: 1.081814
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0019838446409296785
Epoch-6 lr: 0.007935378563718714
epoch 6 training time: 15.436
---------------
2023-09-24 01:15:50.272882
current #epochs=7, #steps=240
start validation
acc: 0.832536
AUC: 0.912333
Avg Precision: 0.417245
Avg Recall: 1.000000
d_prime: 1.916628
train_loss: 0.091627
valid_loss: 1.078608
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0019838446409296785
Epoch-7 lr: 0.007935378563718714
epoch 7 training time: 15.216
---------------
2023-09-24 01:16:05.488749
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00715	Per Sample Data Time 0.00153	Per Sample DNN Time 0.00561	Train Loss 0.0914	
start validation
acc: 0.818182
AUC: 0.882396
Avg Precision: 0.399865
Avg Recall: 1.000000
d_prime: 1.678745
train_loss: 0.091336
valid_loss: 1.094920
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0019838446409296785
Epoch-8 lr: 0.007935378563718714
epoch 8 training time: 15.195
---------------
2023-09-24 01:16:20.683600
current #epochs=9, #steps=320
start validation
acc: 0.856459
AUC: 0.879430
Avg Precision: 0.416461
Avg Recall: 1.000000
d_prime: 1.657656
train_loss: 0.096893
valid_loss: 1.108973
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.001402548710981319
Epoch-9 lr: 0.005610194843925276
epoch 9 training time: 18.005
---------------
2023-09-24 01:16:38.688784
current #epochs=10, #steps=360
start validation
acc: 0.822967
AUC: 0.871835
Avg Precision: 0.388410
Avg Recall: 1.000000
d_prime: 1.605283
train_loss: 0.073466
valid_loss: 1.108224
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.001402548710981319
Epoch-10 lr: 0.005610194843925276
epoch 10 training time: 15.323
---------------
2023-09-24 01:16:54.011590
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03836	Per Sample Data Time 0.03040	Per Sample DNN Time 0.00796	Train Loss 0.0458	
start validation
acc: 0.822967
AUC: 0.863282
Avg Precision: 0.355563
Avg Recall: 1.000000
d_prime: 1.548821
train_loss: 0.074553
valid_loss: 1.110927
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.001402548710981319
Epoch-11 lr: 0.005610194843925276
epoch 11 training time: 15.199
---------------
2023-09-24 01:17:09.210208
current #epochs=12, #steps=440
start validation
acc: 0.813397
AUC: 0.858876
Avg Precision: 0.348217
Avg Recall: 1.000000
d_prime: 1.520680
train_loss: 0.070472
valid_loss: 1.107745
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.001402548710981319
Epoch-12 lr: 0.005610194843925276
epoch 12 training time: 15.264
---------------
2023-09-24 01:17:24.474701
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00152	Per Sample DNN Time 0.00568	Train Loss 0.0900	
start validation
acc: 0.803828
AUC: 0.862193
Avg Precision: 0.346570
Avg Recall: 1.000000
d_prime: 1.541813
train_loss: 0.087179
valid_loss: 1.097021
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.001402548710981319
Epoch-13 lr: 0.005610194843925276
epoch 13 training time: 15.232
---------------
2023-09-24 01:17:39.707260
current #epochs=14, #steps=520
start validation
acc: 0.803828
AUC: 0.861238
Avg Precision: 0.316286
Avg Recall: 1.000000
d_prime: 1.535689
train_loss: 0.077549
valid_loss: 1.099927
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.001402548710981319
Epoch-14 lr: 0.005610194843925276
epoch 14 training time: 16.636
---------------
2023-09-24 01:17:56.343567
current #epochs=15, #steps=560
start validation
acc: 0.832536
AUC: 0.874476
Avg Precision: 0.344658
Avg Recall: 1.000000
d_prime: 1.623245
train_loss: 0.074842
valid_loss: 1.085096
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.001402548710981319
Epoch-15 lr: 0.005610194843925276
epoch 15 training time: 15.232
---------------
2023-09-24 01:18:11.575107
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04078	Per Sample Data Time 0.03022	Per Sample DNN Time 0.01056	Train Loss 0.0686	
start validation
acc: 0.851675
AUC: 0.881869
Avg Precision: 0.358685
Avg Recall: 1.000000
d_prime: 1.674967
train_loss: 0.068216
valid_loss: 1.097167
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.001402548710981319
Epoch-16 lr: 0.005610194843925276
epoch 16 training time: 15.405
---------------
2023-09-24 01:18:26.980246
current #epochs=17, #steps=640
start validation
acc: 0.842105
AUC: 0.867349
Avg Precision: 0.356440
Avg Recall: 1.000000
d_prime: 1.575361
train_loss: 0.073165
valid_loss: 1.106817
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0009915811178407134
Epoch-17 lr: 0.0039663244713628535
epoch 17 training time: 15.335
---------------
2023-09-24 01:18:42.315025
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00565	Train Loss 0.0653	
start validation
acc: 0.794258
AUC: 0.873670
Avg Precision: 0.349052
Avg Recall: 1.000000
d_prime: 1.617737
train_loss: 0.065043
valid_loss: 1.101680
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0009915811178407134
Epoch-18 lr: 0.0039663244713628535
epoch 18 training time: 16.262
---------------
2023-09-24 01:18:58.576976
current #epochs=19, #steps=720
start validation
acc: 0.861244
AUC: 0.883870
Avg Precision: 0.400380
Avg Recall: 1.000000
d_prime: 1.689357
train_loss: 0.067118
valid_loss: 1.092421
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0009915811178407134
Epoch-19 lr: 0.0039663244713628535
epoch 19 training time: 17.634
---------------
2023-09-24 01:19:16.211277
current #epochs=20, #steps=760
start validation
acc: 0.866029
AUC: 0.893604
Avg Precision: 0.415717
Avg Recall: 1.000000
d_prime: 1.762007
train_loss: 0.047163
valid_loss: 1.069265
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0009915811178407134
Epoch-20 lr: 0.0039663244713628535
epoch 20 training time: 18.665
---------------
2023-09-24 01:19:34.875753
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03912	Per Sample Data Time 0.03144	Per Sample DNN Time 0.00768	Train Loss 0.0206	
start validation
[I 2023-09-24 01:19:50,209] Trial 63 finished with value: 0.42671720487525494 and parameters: {'warmup': 'True', 'num_epochs': 21, 'batch_size': 17, 'lr-adaptschedule': 'False', 'lr': 0.0019838446409296785, 'head-lr': 4, 'lr-scheduler-start': 9, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.7069851550089377}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.866029
AUC: 0.886054
Avg Precision: 0.426717
Avg Recall: 1.000000
d_prime: 1.705265
train_loss: 0.077723
valid_loss: 1.072065
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0009915811178407134
Epoch-21 lr: 0.0039663244713628535
epoch 21 training time: 15.325
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0a683b20>
The learning rate scheduler starts at 10 epoch with decay rate of 0.709 every 10 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 01:19:50.248322
current #epochs=1, #steps=0
start validation
acc: 0.789474
AUC: 0.873739
Avg Precision: 0.392597
Avg Recall: 1.000000
d_prime: 1.618209
train_loss: 0.124759
valid_loss: 1.103307
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0020295238609094575
Epoch-1 lr: 0.006088571582728373
epoch 1 training time: 17.811
---------------
2023-09-24 01:20:08.059473
current #epochs=2, #steps=40
start validation
acc: 0.813397
AUC: 0.868292
Avg Precision: 0.344383
Avg Recall: 1.000000
d_prime: 1.581593
train_loss: 0.115236
valid_loss: 1.105928
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0020295238609094575
Epoch-2 lr: 0.006088571582728373
epoch 2 training time: 17.629
---------------
2023-09-24 01:20:25.688839
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00559	Train Loss 0.0796	
start validation
acc: 0.808612
AUC: 0.866274
Avg Precision: 0.329027
Avg Recall: 1.000000
d_prime: 1.568292
train_loss: 0.094427
valid_loss: 1.093091
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0020295238609094575
Epoch-3 lr: 0.006088571582728373
epoch 3 training time: 15.322
---------------
2023-09-24 01:20:41.011267
current #epochs=4, #steps=120
start validation
acc: 0.856459
AUC: 0.863392
Avg Precision: 0.387205
Avg Recall: 1.000000
d_prime: 1.549538
train_loss: 0.104296
valid_loss: 1.100902
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0020295238609094575
Epoch-4 lr: 0.006088571582728373
epoch 4 training time: 17.615
---------------
2023-09-24 01:20:58.625740
current #epochs=5, #steps=160
start validation
acc: 0.827751
AUC: 0.865493
Avg Precision: 0.356946
Avg Recall: 1.000000
d_prime: 1.563178
train_loss: 0.089181
valid_loss: 1.088827
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0020295238609094575
Epoch-5 lr: 0.006088571582728373
epoch 5 training time: 15.286
---------------
2023-09-24 01:21:13.912226
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03916	Per Sample Data Time 0.03188	Per Sample DNN Time 0.00728	Train Loss 0.0212	
start validation
acc: 0.846890
AUC: 0.855361
Avg Precision: 0.399949
Avg Recall: 1.000000
d_prime: 1.498650
train_loss: 0.089119
valid_loss: 1.096357
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0020295238609094575
Epoch-6 lr: 0.006088571582728373
epoch 6 training time: 15.204
---------------
2023-09-24 01:21:29.116297
current #epochs=7, #steps=240
start validation
acc: 0.846890
AUC: 0.867349
Avg Precision: 0.424398
Avg Recall: 1.000000
d_prime: 1.575356
train_loss: 0.074861
valid_loss: 1.085492
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0020295238609094575
Epoch-7 lr: 0.006088571582728373
epoch 7 training time: 15.872
---------------
2023-09-24 01:21:44.988858
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00714	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00557	Train Loss 0.0904	
start validation
acc: 0.822967
AUC: 0.882535
Avg Precision: 0.394445
Avg Recall: 1.000000
d_prime: 1.679742
train_loss: 0.102436
valid_loss: 1.112791
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0020295238609094575
Epoch-8 lr: 0.006088571582728373
epoch 8 training time: 15.277
---------------
2023-09-24 01:22:00.265837
current #epochs=9, #steps=320
start validation
acc: 0.837321
AUC: 0.882835
Avg Precision: 0.418364
Avg Recall: 1.000000
d_prime: 1.681894
train_loss: 0.127294
valid_loss: 1.097962
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0020295238609094575
Epoch-9 lr: 0.006088571582728373
epoch 9 training time: 15.240
---------------
2023-09-24 01:22:15.506261
current #epochs=10, #steps=360
start validation
acc: 0.837321
AUC: 0.901726
Avg Precision: 0.382921
Avg Recall: 1.000000
d_prime: 1.826388
train_loss: 0.099348
valid_loss: 1.063300
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0014386235662538454
Epoch-10 lr: 0.004315870698761536
epoch 10 training time: 15.288
---------------
2023-09-24 01:22:30.794346
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03820	Per Sample Data Time 0.03065	Per Sample DNN Time 0.00754	Train Loss 0.1101	
start validation
acc: 0.794258
AUC: 0.893436
Avg Precision: 0.363032
Avg Recall: 1.000000
d_prime: 1.760714
train_loss: 0.068913
valid_loss: 1.089658
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0014386235662538454
Epoch-11 lr: 0.004315870698761536
epoch 11 training time: 15.312
---------------
2023-09-24 01:22:46.106131
current #epochs=12, #steps=440
start validation
acc: 0.842105
AUC: 0.902001
Avg Precision: 0.371220
Avg Recall: 1.000000
d_prime: 1.828631
train_loss: 0.090927
valid_loss: 1.076847
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0014386235662538454
Epoch-12 lr: 0.004315870698761536
epoch 12 training time: 15.257
---------------
2023-09-24 01:23:01.363260
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00711	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00554	Train Loss 0.0944	
start validation
acc: 0.832536
AUC: 0.890014
Avg Precision: 0.371332
Avg Recall: 1.000000
d_prime: 1.734677
train_loss: 0.090915
valid_loss: 1.104733
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0014386235662538454
Epoch-13 lr: 0.004315870698761536
epoch 13 training time: 15.260
---------------
2023-09-24 01:23:16.623987
current #epochs=14, #steps=520
start validation
acc: 0.842105
AUC: 0.878379
Avg Precision: 0.413385
Avg Recall: 1.000000
d_prime: 1.650280
train_loss: 0.071691
valid_loss: 1.110087
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0014386235662538454
Epoch-14 lr: 0.004315870698761536
epoch 14 training time: 15.412
---------------
2023-09-24 01:23:32.035928
current #epochs=15, #steps=560
start validation
acc: 0.851675
AUC: 0.883989
Avg Precision: 0.412325
Avg Recall: 1.000000
d_prime: 1.690219
train_loss: 0.074068
valid_loss: 1.097643
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0014386235662538454
Epoch-15 lr: 0.004315870698761536
epoch 15 training time: 15.294
---------------
2023-09-24 01:23:47.329985
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04065	Per Sample Data Time 0.03260	Per Sample DNN Time 0.00805	Train Loss 0.1468	
start validation
acc: 0.851675
AUC: 0.910614
Avg Precision: 0.404051
Avg Recall: 1.000000
d_prime: 1.901479
train_loss: 0.064327
valid_loss: 1.057506
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0014386235662538454
Epoch-16 lr: 0.004315870698761536
epoch 16 training time: 15.357
---------------
2023-09-24 01:24:02.687082
current #epochs=17, #steps=640
start validation
acc: 0.842105
AUC: 0.868429
Avg Precision: 0.395475
Avg Recall: 1.000000
d_prime: 1.582498
train_loss: 0.086536
valid_loss: 1.094737
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0014386235662538454
Epoch-17 lr: 0.004315870698761536
epoch 17 training time: 15.282
---------------
2023-09-24 01:24:17.968600
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00556	Train Loss 0.0547	
start validation
acc: 0.770335
AUC: 0.905488
Avg Precision: 0.379183
Avg Recall: 1.000000
d_prime: 1.857532
train_loss: 0.069293
valid_loss: 1.081342
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0014386235662538454
Epoch-18 lr: 0.004315870698761536
epoch 18 training time: 15.387
---------------
2023-09-24 01:24:33.355950
current #epochs=19, #steps=720
start validation
acc: 0.832536
AUC: 0.899502
Avg Precision: 0.377054
Avg Recall: 1.000000
d_prime: 1.808382
train_loss: 0.098837
valid_loss: 1.083802
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0014386235662538454
Epoch-19 lr: 0.004315870698761536
epoch 19 training time: 15.245
---------------
2023-09-24 01:24:48.600618
current #epochs=20, #steps=760
start validation
acc: 0.822967
AUC: 0.897368
Avg Precision: 0.380898
Avg Recall: 1.000000
d_prime: 1.791375
train_loss: 0.078305
valid_loss: 1.094477
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0010197651800228154
Epoch-20 lr: 0.0030592955400684458
epoch 20 training time: 15.387
---------------
2023-09-24 01:25:03.987919
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03898	Per Sample Data Time 0.03054	Per Sample DNN Time 0.00844	Train Loss 0.1108	
start validation
acc: 0.866029
AUC: 0.879220
Avg Precision: 0.403445
Avg Recall: 1.000000
d_prime: 1.656182
train_loss: 0.100407
valid_loss: 1.101497
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0010197651800228154
Epoch-21 lr: 0.0030592955400684458
epoch 21 training time: 17.904
---------------
2023-09-24 01:25:21.891632
current #epochs=22, #steps=840
start validation
acc: 0.832536
AUC: 0.880143
Avg Precision: 0.388030
Avg Recall: 1.000000
d_prime: 1.662691
train_loss: 0.080601
valid_loss: 1.114526
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0010197651800228154
Epoch-22 lr: 0.0030592955400684458
epoch 22 training time: 17.129
---------------
2023-09-24 01:25:39.021411
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00165	Per Sample DNN Time 0.00554	Train Loss 0.0923	
start validation
[I 2023-09-24 01:25:54,446] Trial 64 finished with value: 0.40047597375507266 and parameters: {'warmup': 'True', 'num_epochs': 23, 'batch_size': 18, 'lr-adaptschedule': 'False', 'lr': 0.0020295238609094575, 'head-lr': 3, 'lr-scheduler-start': 10, 'lr-scheduler-step': 10, 'lr-scheduler-decay': 0.70884782089193}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.861244
AUC: 0.918253
Avg Precision: 0.400476
Avg Recall: 1.000000
d_prime: 1.970592
train_loss: 0.087573
valid_loss: 1.060127
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0010197651800228154
Epoch-23 lr: 0.0030592955400684458
epoch 23 training time: 15.416
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc097f9640>
The learning rate scheduler starts at 10 epoch with decay rate of 0.751 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 01:25:54.486602
current #epochs=1, #steps=0
start validation
acc: 0.832536
AUC: 0.887244
Avg Precision: 0.381934
Avg Recall: 1.000000
d_prime: 1.714025
train_loss: 0.137920
valid_loss: 1.102174
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0022379832364713757
Epoch-1 lr: 0.008951932945885503
epoch 1 training time: 18.961
---------------
2023-09-24 01:26:13.447757
current #epochs=2, #steps=40
start validation
acc: 0.870813
AUC: 0.917009
Avg Precision: 0.421732
Avg Recall: 1.000000
d_prime: 1.959007
train_loss: 0.123276
valid_loss: 1.043296
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0022379832364713757
Epoch-2 lr: 0.008951932945885503
epoch 2 training time: 17.799
---------------
2023-09-24 01:26:31.246597
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00723	Per Sample Data Time 0.00167	Per Sample DNN Time 0.00556	Train Loss 0.0903	
start validation
acc: 0.827751
AUC: 0.896119
Avg Precision: 0.384351
Avg Recall: 1.000000
d_prime: 1.781546
train_loss: 0.098563
valid_loss: 1.109375
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0022379832364713757
Epoch-3 lr: 0.008951932945885503
epoch 3 training time: 16.958
---------------
2023-09-24 01:26:48.204246
current #epochs=4, #steps=120
start validation
acc: 0.842105
AUC: 0.898014
Avg Precision: 0.412166
Avg Recall: 1.000000
d_prime: 1.796501
train_loss: 0.087348
valid_loss: 1.115662
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0022379832364713757
Epoch-4 lr: 0.008951932945885503
epoch 4 training time: 15.284
---------------
2023-09-24 01:27:03.488152
current #epochs=5, #steps=160
start validation
acc: 0.832536
AUC: 0.884711
Avg Precision: 0.412145
Avg Recall: 1.000000
d_prime: 1.695464
train_loss: 0.110108
valid_loss: 1.105429
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0022379832364713757
Epoch-5 lr: 0.008951932945885503
epoch 5 training time: 15.137
---------------
2023-09-24 01:27:18.625089
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03950	Per Sample Data Time 0.03227	Per Sample DNN Time 0.00723	Train Loss 0.0695	
start validation
acc: 0.808612
AUC: 0.858661
Avg Precision: 0.366728
Avg Recall: 1.000000
d_prime: 1.519322
train_loss: 0.175081
valid_loss: 1.128466
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0022379832364713757
Epoch-6 lr: 0.008951932945885503
epoch 6 training time: 15.323
---------------
2023-09-24 01:27:33.948260
current #epochs=7, #steps=240
start validation
acc: 0.736842
AUC: 0.865174
Avg Precision: 0.299398
Avg Recall: 1.000000
d_prime: 1.561101
train_loss: 0.413216
valid_loss: 1.160665
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0022379832364713757
Epoch-7 lr: 0.008951932945885503
epoch 7 training time: 15.588
---------------
2023-09-24 01:27:49.535992
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00715	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00558	Train Loss 0.4059	
start validation
acc: 0.813397
AUC: 0.859943
Avg Precision: 0.319227
Avg Recall: 1.000000
d_prime: 1.527443
train_loss: 0.380707
valid_loss: 1.138528
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0022379832364713757
Epoch-8 lr: 0.008951932945885503
epoch 8 training time: 15.336
---------------
2023-09-24 01:28:04.871877
current #epochs=9, #steps=320
start validation
acc: 0.803828
AUC: 0.866944
Avg Precision: 0.327557
Avg Recall: 1.000000
d_prime: 1.572691
train_loss: 0.274991
valid_loss: 1.128054
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0022379832364713757
Epoch-9 lr: 0.008951932945885503
epoch 9 training time: 15.245
---------------
2023-09-24 01:28:20.117312
current #epochs=10, #steps=360
start validation
acc: 0.832536
AUC: 0.873617
Avg Precision: 0.385708
Avg Recall: 1.000000
d_prime: 1.617376
train_loss: 0.217139
valid_loss: 1.113603
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.001680077602596099
Epoch-10 lr: 0.006720310410384396
epoch 10 training time: 15.835
---------------
2023-09-24 01:28:35.952514
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03801	Per Sample Data Time 0.03051	Per Sample DNN Time 0.00750	Train Loss 0.2137	
start validation
acc: 0.846890
AUC: 0.896046
Avg Precision: 0.433558
Avg Recall: 1.000000
d_prime: 1.780973
train_loss: 0.159094
valid_loss: 1.063849
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.001680077602596099
Epoch-11 lr: 0.006720310410384396
epoch 11 training time: 15.271
---------------
2023-09-24 01:28:51.223601
current #epochs=12, #steps=440
start validation
acc: 0.861244
AUC: 0.908201
Avg Precision: 0.431775
Avg Recall: 1.000000
d_prime: 1.880565
train_loss: 0.167571
valid_loss: 1.072008
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.001680077602596099
Epoch-12 lr: 0.006720310410384396
epoch 12 training time: 15.427
---------------
2023-09-24 01:29:06.651024
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00164	Per Sample DNN Time 0.00554	Train Loss 0.1505	
start validation
acc: 0.808612
AUC: 0.877421
Avg Precision: 0.358388
Avg Recall: 1.000000
d_prime: 1.643586
train_loss: 0.143966
valid_loss: 1.095586
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.001680077602596099
Epoch-13 lr: 0.006720310410384396
epoch 13 training time: 15.310
---------------
2023-09-24 01:29:21.961541
current #epochs=14, #steps=520
start validation
acc: 0.799043
AUC: 0.883330
Avg Precision: 0.371957
Avg Recall: 1.000000
d_prime: 1.685456
train_loss: 0.146332
valid_loss: 1.085733
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.001680077602596099
Epoch-14 lr: 0.006720310410384396
epoch 14 training time: 15.391
---------------
2023-09-24 01:29:37.352820
current #epochs=15, #steps=560
start validation
acc: 0.813397
AUC: 0.896892
Avg Precision: 0.376885
Avg Recall: 1.000000
d_prime: 1.787618
train_loss: 0.143802
valid_loss: 1.074647
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.001680077602596099
Epoch-15 lr: 0.006720310410384396
epoch 15 training time: 15.275
---------------
2023-09-24 01:29:52.627789
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03821	Per Sample Data Time 0.03064	Per Sample DNN Time 0.00758	Train Loss 0.1074	
start validation
acc: 0.856459
AUC: 0.905092
Avg Precision: 0.430131
Avg Recall: 1.000000
d_prime: 1.854205
train_loss: 0.128782
valid_loss: 1.058670
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.001680077602596099
Epoch-16 lr: 0.006720310410384396
epoch 16 training time: 15.297
---------------
2023-09-24 01:30:07.924378
current #epochs=17, #steps=640
start validation
acc: 0.799043
AUC: 0.882648
Avg Precision: 0.376140
Avg Recall: 1.000000
d_prime: 1.680553
train_loss: 0.156914
valid_loss: 1.083195
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.001680077602596099
Epoch-17 lr: 0.006720310410384396
epoch 17 training time: 15.363
---------------
2023-09-24 01:30:23.287880
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00713	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00554	Train Loss 0.1145	
start validation
acc: 0.827751
AUC: 0.891674
Avg Precision: 0.425570
Avg Recall: 1.000000
d_prime: 1.747234
train_loss: 0.123263
valid_loss: 1.078788
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.001680077602596099
Epoch-18 lr: 0.006720310410384396
epoch 18 training time: 15.246
---------------
2023-09-24 01:30:38.533888
current #epochs=19, #steps=720
start validation
acc: 0.842105
AUC: 0.900991
Avg Precision: 0.424546
Avg Recall: 1.000000
d_prime: 1.820401
train_loss: 0.115061
valid_loss: 1.057347
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0012612519632611457
Epoch-19 lr: 0.005045007853044583
epoch 19 training time: 15.275
---------------
2023-09-24 01:30:53.809348
current #epochs=20, #steps=760
start validation
acc: 0.818182
AUC: 0.898921
Avg Precision: 0.416000
Avg Recall: 1.000000
d_prime: 1.803730
train_loss: 0.120595
valid_loss: 1.074566
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0012612519632611457
Epoch-20 lr: 0.005045007853044583
epoch 20 training time: 15.378
---------------
2023-09-24 01:31:09.187806
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03845	Per Sample Data Time 0.03010	Per Sample DNN Time 0.00835	Train Loss 0.1060	
start validation
acc: 0.803828
AUC: 0.906682
Avg Precision: 0.411574
Avg Recall: 1.000000
d_prime: 1.867603
train_loss: 0.107626
valid_loss: 1.072753
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0012612519632611457
Epoch-21 lr: 0.005045007853044583
epoch 21 training time: 15.289
---------------
2023-09-24 01:31:24.476669
current #epochs=22, #steps=840
start validation
acc: 0.822967
AUC: 0.905477
Avg Precision: 0.386625
Avg Recall: 1.000000
d_prime: 1.857441
train_loss: 0.100507
valid_loss: 1.073950
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0012612519632611457
Epoch-22 lr: 0.005045007853044583
epoch 22 training time: 17.136
---------------
2023-09-24 01:31:41.612686
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00723	Per Sample Data Time 0.00164	Per Sample DNN Time 0.00558	Train Loss 0.1117	
start validation
acc: 0.789474
AUC: 0.888884
Avg Precision: 0.386914
Avg Recall: 1.000000
d_prime: 1.726207
train_loss: 0.114746
valid_loss: 1.086712
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0012612519632611457
Epoch-23 lr: 0.005045007853044583
epoch 23 training time: 15.383
---------------
2023-09-24 01:31:56.995479
current #epochs=24, #steps=920
start validation
acc: 0.832536
AUC: 0.888449
Avg Precision: 0.414872
Avg Recall: 1.000000
d_prime: 1.722968
train_loss: 0.097332
valid_loss: 1.068155
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0012612519632611457
Epoch-24 lr: 0.005045007853044583
epoch 24 training time: 15.335
---------------
2023-09-24 01:32:12.331133
current #epochs=25, #steps=960
start validation
acc: 0.832536
AUC: 0.897905
Avg Precision: 0.427476
Avg Recall: 1.000000
d_prime: 1.795636
train_loss: 0.087492
valid_loss: 1.061476
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.0012612519632611457
Epoch-25 lr: 0.005045007853044583
epoch 25 training time: 15.231
---------------
2023-09-24 01:32:27.561592
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.03793	Per Sample Data Time 0.03017	Per Sample DNN Time 0.00776	Train Loss 0.0812	
start validation
acc: 0.799043
AUC: 0.899199
Avg Precision: 0.407125
Avg Recall: 1.000000
d_prime: 1.805954
train_loss: 0.087705
valid_loss: 1.063896
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.0012612519632611457
Epoch-26 lr: 0.005045007853044583
epoch 26 training time: 15.254
---------------
2023-09-24 01:32:42.815949
current #epochs=27, #steps=1040
start validation
acc: 0.755981
AUC: 0.875757
Avg Precision: 0.394238
Avg Recall: 1.000000
d_prime: 1.632055
train_loss: 0.105718
valid_loss: 1.096485
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.0012612519632611457
Epoch-27 lr: 0.005045007853044583
epoch 27 training time: 15.294
---------------
2023-09-24 01:32:58.109888
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00715	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00555	Train Loss 0.0927	
start validation
acc: 0.822967
AUC: 0.900175
Avg Precision: 0.410199
Avg Recall: 1.000000
d_prime: 1.813802
train_loss: 0.101912
valid_loss: 1.070915
validation finished
normal learning rate scheduler step
Epoch-28 lr: 0.0009468351416458481
Epoch-28 lr: 0.0037873405665833923
epoch 28 training time: 16.082
---------------
2023-09-24 01:33:14.191634
current #epochs=29, #steps=1120
start validation
acc: 0.808612
AUC: 0.893680
Avg Precision: 0.382462
Avg Recall: 1.000000
d_prime: 1.762586
train_loss: 0.083548
valid_loss: 1.084335
validation finished
normal learning rate scheduler step
Epoch-29 lr: 0.0009468351416458481
Epoch-29 lr: 0.0037873405665833923
epoch 29 training time: 15.337
---------------
2023-09-24 01:33:29.528581
current #epochs=30, #steps=1160
start validation
[I 2023-09-24 01:33:44,840] Trial 65 finished with value: 0.4029705861337667 and parameters: {'warmup': 'True', 'num_epochs': 30, 'batch_size': 20, 'lr-adaptschedule': 'False', 'lr': 0.0022379832364713757, 'head-lr': 4, 'lr-scheduler-start': 10, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.750710539389506}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.827751
AUC: 0.902980
Avg Precision: 0.402971
Avg Recall: 1.000000
d_prime: 1.836668
train_loss: 0.078262
valid_loss: 1.067304
validation finished
normal learning rate scheduler step
Epoch-30 lr: 0.0009468351416458481
Epoch-30 lr: 0.0037873405665833923
epoch 30 training time: 15.303
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc098201f0>
The learning rate scheduler starts at 9 epoch with decay rate of 0.731 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 01:33:44.877583
current #epochs=1, #steps=0
start validation
acc: 0.808612
AUC: 0.882143
Avg Precision: 0.333666
Avg Recall: 1.000000
d_prime: 1.676930
train_loss: 0.107888
valid_loss: 1.107195
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.001930953360360069
Epoch-1 lr: 0.007723813441440276
epoch 1 training time: 17.982
---------------
2023-09-24 01:34:02.859431
current #epochs=2, #steps=40
start validation
acc: 0.813397
AUC: 0.875863
Avg Precision: 0.374289
Avg Recall: 1.000000
d_prime: 1.632784
train_loss: 0.091815
valid_loss: 1.087134
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.001930953360360069
Epoch-2 lr: 0.007723813441440276
epoch 2 training time: 19.336
---------------
2023-09-24 01:34:22.195424
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00714	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00554	Train Loss 0.1168	
start validation
acc: 0.846890
AUC: 0.884575
Avg Precision: 0.360732
Avg Recall: 1.000000
d_prime: 1.694469
train_loss: 0.110012
valid_loss: 1.088554
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.001930953360360069
Epoch-3 lr: 0.007723813441440276
epoch 3 training time: 17.574
---------------
2023-09-24 01:34:39.769688
current #epochs=4, #steps=120
start validation
acc: 0.813397
AUC: 0.896167
Avg Precision: 0.378190
Avg Recall: 1.000000
d_prime: 1.781924
train_loss: 0.112950
valid_loss: 1.097090
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.001930953360360069
Epoch-4 lr: 0.007723813441440276
epoch 4 training time: 15.258
---------------
2023-09-24 01:34:55.027676
current #epochs=5, #steps=160
start validation
acc: 0.842105
AUC: 0.869342
Avg Precision: 0.413964
Avg Recall: 1.000000
d_prime: 1.588566
train_loss: 0.099121
valid_loss: 1.082217
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.001930953360360069
Epoch-5 lr: 0.007723813441440276
epoch 5 training time: 15.233
---------------
2023-09-24 01:35:10.260298
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03749	Per Sample Data Time 0.02931	Per Sample DNN Time 0.00818	Train Loss 0.0567	
start validation
acc: 0.837321
AUC: 0.882568
Avg Precision: 0.434914
Avg Recall: 1.000000
d_prime: 1.679979
train_loss: 0.087683
valid_loss: 1.080593
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.001930953360360069
Epoch-6 lr: 0.007723813441440276
epoch 6 training time: 15.169
---------------
2023-09-24 01:35:25.429619
current #epochs=7, #steps=240
start validation
acc: 0.846890
AUC: 0.903156
Avg Precision: 0.428961
Avg Recall: 1.000000
d_prime: 1.838115
train_loss: 0.112974
valid_loss: 1.078490
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.001930953360360069
Epoch-7 lr: 0.007723813441440276
epoch 7 training time: 15.442
---------------
2023-09-24 01:35:40.871601
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00711	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00550	Train Loss 0.1469	
start validation
acc: 0.813397
AUC: 0.903890
Avg Precision: 0.414708
Avg Recall: 1.000000
d_prime: 1.844190
train_loss: 0.125572
valid_loss: 1.093637
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.001930953360360069
Epoch-8 lr: 0.007723813441440276
epoch 8 training time: 15.841
---------------
2023-09-24 01:35:56.712100
current #epochs=9, #steps=320
start validation
acc: 0.813397
AUC: 0.882286
Avg Precision: 0.422602
Avg Recall: 1.000000
d_prime: 1.677951
train_loss: 0.082810
valid_loss: 1.116892
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0014106888512220022
Epoch-9 lr: 0.005642755404888009
epoch 9 training time: 15.391
---------------
2023-09-24 01:36:12.103338
current #epochs=10, #steps=360
start validation
acc: 0.837321
AUC: 0.879783
Avg Precision: 0.412376
Avg Recall: 1.000000
d_prime: 1.660148
train_loss: 0.089288
valid_loss: 1.103658
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0014106888512220022
Epoch-10 lr: 0.005642755404888009
epoch 10 training time: 16.452
---------------
2023-09-24 01:36:28.555174
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03762	Per Sample Data Time 0.03011	Per Sample DNN Time 0.00751	Train Loss 0.0457	
start validation
acc: 0.861244
AUC: 0.883733
Avg Precision: 0.413731
Avg Recall: 1.000000
d_prime: 1.688367
train_loss: 0.094142
valid_loss: 1.083204
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0014106888512220022
Epoch-11 lr: 0.005642755404888009
epoch 11 training time: 19.367
---------------
2023-09-24 01:36:47.921805
current #epochs=12, #steps=440
start validation
acc: 0.827751
AUC: 0.888651
Avg Precision: 0.424594
Avg Recall: 1.000000
d_prime: 1.724471
train_loss: 0.081485
valid_loss: 1.090968
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0014106888512220022
Epoch-12 lr: 0.005642755404888009
epoch 12 training time: 15.349
---------------
2023-09-24 01:37:03.270610
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00559	Train Loss 0.0570	
start validation
acc: 0.803828
AUC: 0.886979
Avg Precision: 0.442841
Avg Recall: 1.000000
d_prime: 1.712070
train_loss: 0.073285
valid_loss: 1.093157
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0014106888512220022
Epoch-13 lr: 0.005642755404888009
epoch 13 training time: 15.292
---------------
2023-09-24 01:37:18.562704
current #epochs=14, #steps=520
start validation
acc: 0.846890
AUC: 0.890548
Avg Precision: 0.442059
Avg Recall: 1.000000
d_prime: 1.738698
train_loss: 0.088781
valid_loss: 1.076760
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0014106888512220022
Epoch-14 lr: 0.005642755404888009
epoch 14 training time: 15.204
---------------
2023-09-24 01:37:33.766298
current #epochs=15, #steps=560
start validation
acc: 0.832536
AUC: 0.892475
Avg Precision: 0.383713
Avg Recall: 1.000000
d_prime: 1.753340
train_loss: 0.073545
valid_loss: 1.070961
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0014106888512220022
Epoch-15 lr: 0.005642755404888009
epoch 15 training time: 16.702
---------------
2023-09-24 01:37:50.468382
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03808	Per Sample Data Time 0.02982	Per Sample DNN Time 0.00826	Train Loss 0.0021	
start validation
acc: 0.775120
AUC: 0.878963
Avg Precision: 0.417528
Avg Recall: 1.000000
d_prime: 1.654372
train_loss: 0.076409
valid_loss: 1.093131
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0014106888512220022
Epoch-16 lr: 0.005642755404888009
epoch 16 training time: 15.276
---------------
2023-09-24 01:38:05.744458
current #epochs=17, #steps=640
start validation
acc: 0.808612
AUC: 0.871142
Avg Precision: 0.415458
Avg Recall: 1.000000
d_prime: 1.600615
train_loss: 0.113417
valid_loss: 1.095838
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0014106888512220022
Epoch-17 lr: 0.005642755404888009
epoch 17 training time: 15.287
---------------
2023-09-24 01:38:21.031218
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00725	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00564	Train Loss 0.1051	
start validation
acc: 0.846890
AUC: 0.897543
Avg Precision: 0.420206
Avg Recall: 1.000000
d_prime: 1.792762
train_loss: 0.109037
valid_loss: 1.077350
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.001030601295616464
Epoch-18 lr: 0.004122405182465856
epoch 18 training time: 15.441
---------------
2023-09-24 01:38:36.471645
current #epochs=19, #steps=720
start validation
acc: 0.846890
AUC: 0.889924
Avg Precision: 0.415329
Avg Recall: 1.000000
d_prime: 1.734004
train_loss: 0.064862
valid_loss: 1.070163
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.001030601295616464
Epoch-19 lr: 0.004122405182465856
epoch 19 training time: 15.309
---------------
2023-09-24 01:38:51.781129
current #epochs=20, #steps=760
start validation
acc: 0.846890
AUC: 0.899746
Avg Precision: 0.426997
Avg Recall: 1.000000
d_prime: 1.810342
train_loss: 0.083826
valid_loss: 1.067423
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.001030601295616464
Epoch-20 lr: 0.004122405182465856
epoch 20 training time: 15.448
---------------
2023-09-24 01:39:07.228941
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04311	Per Sample Data Time 0.03276	Per Sample DNN Time 0.01036	Train Loss 0.0961	
start validation
[I 2023-09-24 01:39:24,231] Trial 66 finished with value: 0.41920598211532534 and parameters: {'warmup': 'True', 'num_epochs': 21, 'batch_size': 16, 'lr-adaptschedule': 'False', 'lr': 0.001930953360360069, 'head-lr': 4, 'lr-scheduler-start': 9, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.7305659888952201}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.832536
AUC: 0.898607
Avg Precision: 0.419206
Avg Recall: 1.000000
d_prime: 1.801222
train_loss: 0.070583
valid_loss: 1.049963
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.001030601295616464
Epoch-21 lr: 0.004122405182465856
epoch 21 training time: 16.993
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51df1af0>
The learning rate scheduler starts at 9 epoch with decay rate of 0.677 every 7 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 01:39:24.269516
current #epochs=1, #steps=0
start validation
acc: 0.866029
AUC: 0.910799
Avg Precision: 0.434115
Avg Recall: 1.000000
d_prime: 1.903098
train_loss: 0.092009
valid_loss: 1.051008
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0017484807483073089
Epoch-1 lr: 0.0069939229932292355
epoch 1 training time: 17.849
---------------
2023-09-24 01:39:42.118895
current #epochs=2, #steps=40
start validation
acc: 0.837321
AUC: 0.878179
Avg Precision: 0.381386
Avg Recall: 1.000000
d_prime: 1.648874
train_loss: 0.112072
valid_loss: 1.115306
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0017484807483073089
Epoch-2 lr: 0.0069939229932292355
epoch 2 training time: 15.353
---------------
2023-09-24 01:39:57.472284
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00708	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00552	Train Loss 0.1009	
start validation
acc: 0.794258
AUC: 0.897113
Avg Precision: 0.365338
Avg Recall: 1.000000
d_prime: 1.789367
train_loss: 0.098084
valid_loss: 1.077603
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0017484807483073089
Epoch-3 lr: 0.0069939229932292355
epoch 3 training time: 15.304
---------------
2023-09-24 01:40:12.776483
current #epochs=4, #steps=120
start validation
acc: 0.822967
AUC: 0.911032
Avg Precision: 0.422251
Avg Recall: 1.000000
d_prime: 1.905143
train_loss: 0.113716
valid_loss: 1.095273
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0017484807483073089
Epoch-4 lr: 0.0069939229932292355
epoch 4 training time: 15.198
---------------
2023-09-24 01:40:27.974957
current #epochs=5, #steps=160
start validation
acc: 0.866029
AUC: 0.899135
Avg Precision: 0.465495
Avg Recall: 1.000000
d_prime: 1.805439
train_loss: 0.091119
valid_loss: 1.107193
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0017484807483073089
Epoch-5 lr: 0.0069939229932292355
epoch 5 training time: 15.373
---------------
2023-09-24 01:40:43.348038
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04134	Per Sample Data Time 0.03155	Per Sample DNN Time 0.00980	Train Loss 0.0569	
start validation
acc: 0.846890
AUC: 0.908642
Avg Precision: 0.465838
Avg Recall: 1.000000
d_prime: 1.884354
train_loss: 0.075867
valid_loss: 1.073499
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0017484807483073089
Epoch-6 lr: 0.0069939229932292355
epoch 6 training time: 15.370
---------------
2023-09-24 01:40:58.718443
current #epochs=7, #steps=240
start validation
acc: 0.842105
AUC: 0.909885
Avg Precision: 0.429798
Avg Recall: 1.000000
d_prime: 1.895113
train_loss: 0.110829
valid_loss: 1.072199
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0017484807483073089
Epoch-7 lr: 0.0069939229932292355
epoch 7 training time: 15.321
---------------
2023-09-24 01:41:14.038775
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00567	Train Loss 0.0987	
start validation
acc: 0.832536
AUC: 0.898587
Avg Precision: 0.371659
Avg Recall: 1.000000
d_prime: 1.801057
train_loss: 0.110678
valid_loss: 1.100407
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0017484807483073089
Epoch-8 lr: 0.0069939229932292355
epoch 8 training time: 15.298
---------------
2023-09-24 01:41:29.337154
current #epochs=9, #steps=320
start validation
acc: 0.846890
AUC: 0.892222
Avg Precision: 0.362197
Avg Recall: 1.000000
d_prime: 1.751407
train_loss: 0.123552
valid_loss: 1.099024
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0011836022993500475
Epoch-9 lr: 0.00473440919740019
epoch 9 training time: 15.349
---------------
2023-09-24 01:41:44.686649
current #epochs=10, #steps=360
start validation
acc: 0.870813
AUC: 0.891720
Avg Precision: 0.392406
Avg Recall: 1.000000
d_prime: 1.747580
train_loss: 0.102748
valid_loss: 1.099700
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0011836022993500475
Epoch-10 lr: 0.00473440919740019
epoch 10 training time: 17.995
---------------
2023-09-24 01:42:02.682007
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04085	Per Sample Data Time 0.02976	Per Sample DNN Time 0.01109	Train Loss 0.0668	
start validation
acc: 0.870813
AUC: 0.898103
Avg Precision: 0.459722
Avg Recall: 1.000000
d_prime: 1.797209
train_loss: 0.104974
valid_loss: 1.097627
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0011836022993500475
Epoch-11 lr: 0.00473440919740019
epoch 11 training time: 15.320
---------------
2023-09-24 01:42:18.002152
current #epochs=12, #steps=440
start validation
acc: 0.837321
AUC: 0.902806
Avg Precision: 0.382890
Avg Recall: 1.000000
d_prime: 1.835238
train_loss: 0.096191
valid_loss: 1.095809
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0011836022993500475
Epoch-12 lr: 0.00473440919740019
epoch 12 training time: 15.402
---------------
2023-09-24 01:42:33.404554
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00723	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00566	Train Loss 0.0759	
start validation
acc: 0.837321
AUC: 0.914421
Avg Precision: 0.404069
Avg Recall: 1.000000
d_prime: 1.935341
train_loss: 0.074794
valid_loss: 1.083714
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0011836022993500475
Epoch-13 lr: 0.00473440919740019
epoch 13 training time: 15.244
---------------
2023-09-24 01:42:48.648762
current #epochs=14, #steps=520
start validation
acc: 0.784689
AUC: 0.901751
Avg Precision: 0.381974
Avg Recall: 1.000000
d_prime: 1.826591
train_loss: 0.087663
valid_loss: 1.103972
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0011836022993500475
Epoch-14 lr: 0.00473440919740019
epoch 14 training time: 15.341
---------------
2023-09-24 01:43:03.989137
current #epochs=15, #steps=560
start validation
acc: 0.861244
AUC: 0.916323
Avg Precision: 0.400853
Avg Recall: 1.000000
d_prime: 1.952688
train_loss: 0.085572
valid_loss: 1.076075
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0011836022993500475
Epoch-15 lr: 0.00473440919740019
epoch 15 training time: 15.234
---------------
2023-09-24 01:43:19.223135
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04111	Per Sample Data Time 0.03010	Per Sample DNN Time 0.01101	Train Loss 0.0374	
start validation
acc: 0.818182
AUC: 0.903080
Avg Precision: 0.382781
Avg Recall: 1.000000
d_prime: 1.837491
train_loss: 0.065933
valid_loss: 1.099016
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0008012180885508373
Epoch-16 lr: 0.003204872354203349
epoch 16 training time: 15.517
---------------
2023-09-24 01:43:34.740385
current #epochs=17, #steps=640
start validation
acc: 0.808612
AUC: 0.899392
Avg Precision: 0.398871
Avg Recall: 1.000000
d_prime: 1.807498
train_loss: 0.072636
valid_loss: 1.104213
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0008012180885508373
Epoch-17 lr: 0.003204872354203349
epoch 17 training time: 15.430
---------------
2023-09-24 01:43:50.170131
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00564	Train Loss 0.0690	
start validation
acc: 0.803828
AUC: 0.899312
Avg Precision: 0.399424
Avg Recall: 1.000000
d_prime: 1.806854
train_loss: 0.064410
valid_loss: 1.105634
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0008012180885508373
Epoch-18 lr: 0.003204872354203349
epoch 18 training time: 15.289
---------------
2023-09-24 01:44:05.459354
current #epochs=19, #steps=720
start validation
acc: 0.803828
AUC: 0.898794
Avg Precision: 0.404313
Avg Recall: 1.000000
d_prime: 1.802715
train_loss: 0.083578
valid_loss: 1.095608
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0008012180885508373
Epoch-19 lr: 0.003204872354203349
epoch 19 training time: 15.341
---------------
2023-09-24 01:44:20.800939
current #epochs=20, #steps=760
start validation
acc: 0.818182
AUC: 0.899640
Avg Precision: 0.406494
Avg Recall: 1.000000
d_prime: 1.809490
train_loss: 0.082291
valid_loss: 1.110746
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0008012180885508373
Epoch-20 lr: 0.003204872354203349
epoch 20 training time: 16.513
---------------
2023-09-24 01:44:37.314482
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04122	Per Sample Data Time 0.03024	Per Sample DNN Time 0.01098	Train Loss 0.0017	
start validation
acc: 0.822967
AUC: 0.900416
Avg Precision: 0.410396
Avg Recall: 1.000000
d_prime: 1.815742
train_loss: 0.064702
valid_loss: 1.097562
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0008012180885508373
Epoch-21 lr: 0.003204872354203349
epoch 21 training time: 15.398
---------------
2023-09-24 01:44:52.712405
current #epochs=22, #steps=840
start validation
acc: 0.813397
AUC: 0.895677
Avg Precision: 0.385754
Avg Recall: 1.000000
d_prime: 1.778090
train_loss: 0.071350
valid_loss: 1.109170
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0008012180885508373
Epoch-22 lr: 0.003204872354203349
epoch 22 training time: 15.513
---------------
2023-09-24 01:45:08.225555
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00154	Per Sample DNN Time 0.00563	Train Loss 0.0786	
start validation
acc: 0.851675
AUC: 0.903994
Avg Precision: 0.416719
Avg Recall: 1.000000
d_prime: 1.845052
train_loss: 0.078900
valid_loss: 1.105631
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0005423700391369398
Epoch-23 lr: 0.0021694801565477592
epoch 23 training time: 15.435
---------------
2023-09-24 01:45:23.660526
current #epochs=24, #steps=920
start validation
[I 2023-09-24 01:45:39,104] Trial 67 finished with value: 0.3734479202722973 and parameters: {'warmup': 'True', 'num_epochs': 24, 'batch_size': 13, 'lr-adaptschedule': 'False', 'lr': 0.0017484807483073089, 'head-lr': 4, 'lr-scheduler-start': 9, 'lr-scheduler-step': 7, 'lr-scheduler-decay': 0.6769318452581672}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.851675
AUC: 0.902271
Avg Precision: 0.373448
Avg Recall: 1.000000
d_prime: 1.830838
train_loss: 0.069769
valid_loss: 1.097546
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0005423700391369398
Epoch-24 lr: 0.0021694801565477592
epoch 24 training time: 15.432
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc52630730>
The learning rate scheduler starts at 10 epoch with decay rate of 0.708 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 01:45:39.143201
current #epochs=1, #steps=0
start validation
acc: 0.794258
AUC: 0.891864
Avg Precision: 0.342241
Avg Recall: 1.000000
d_prime: 1.748675
train_loss: 0.122464
valid_loss: 1.121281
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0022710253236416767
Epoch-1 lr: 0.00681307597092503
epoch 1 training time: 18.163
---------------
2023-09-24 01:45:57.306902
current #epochs=2, #steps=40
start validation
acc: 0.866029
AUC: 0.892690
Avg Precision: 0.373686
Avg Recall: 1.000000
d_prime: 1.754988
train_loss: 0.128750
valid_loss: 1.079761
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0022710253236416767
Epoch-2 lr: 0.00681307597092503
epoch 2 training time: 17.835
---------------
2023-09-24 01:46:15.142560
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00166	Per Sample DNN Time 0.00555	Train Loss 0.1056	
start validation
acc: 0.842105
AUC: 0.902364
Avg Precision: 0.444074
Avg Recall: 1.000000
d_prime: 1.831603
train_loss: 0.101218
valid_loss: 1.076599
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0022710253236416767
Epoch-3 lr: 0.00681307597092503
epoch 3 training time: 15.370
---------------
2023-09-24 01:46:30.512084
current #epochs=4, #steps=120
start validation
acc: 0.827751
AUC: 0.907109
Avg Precision: 0.342584
Avg Recall: 1.000000
d_prime: 1.871231
train_loss: 0.122422
valid_loss: 1.094064
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0022710253236416767
Epoch-4 lr: 0.00681307597092503
epoch 4 training time: 15.328
---------------
2023-09-24 01:46:45.840055
current #epochs=5, #steps=160
start validation
acc: 0.846890
AUC: 0.911430
Avg Precision: 0.381433
Avg Recall: 1.000000
d_prime: 1.908638
train_loss: 0.100016
valid_loss: 1.036564
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0022710253236416767
Epoch-5 lr: 0.00681307597092503
epoch 5 training time: 15.392
---------------
2023-09-24 01:47:01.232296
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04083	Per Sample Data Time 0.03096	Per Sample DNN Time 0.00987	Train Loss 0.2432	
start validation
acc: 0.846890
AUC: 0.914483
Avg Precision: 0.407531
Avg Recall: 1.000000
d_prime: 1.935903
train_loss: 0.142865
valid_loss: 1.075193
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0022710253236416767
Epoch-6 lr: 0.00681307597092503
epoch 6 training time: 15.396
---------------
2023-09-24 01:47:16.628225
current #epochs=7, #steps=240
start validation
acc: 0.832536
AUC: 0.896036
Avg Precision: 0.437332
Avg Recall: 1.000000
d_prime: 1.780895
train_loss: 0.119785
valid_loss: 1.096788
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0022710253236416767
Epoch-7 lr: 0.00681307597092503
epoch 7 training time: 15.254
---------------
2023-09-24 01:47:31.882088
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00730	Per Sample Data Time 0.00165	Per Sample DNN Time 0.00565	Train Loss 0.1040	
start validation
acc: 0.794258
AUC: 0.890530
Avg Precision: 0.424385
Avg Recall: 1.000000
d_prime: 1.738563
train_loss: 0.102455
valid_loss: 1.101066
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0022710253236416767
Epoch-8 lr: 0.00681307597092503
epoch 8 training time: 15.401
---------------
2023-09-24 01:47:47.282993
current #epochs=9, #steps=320
start validation
acc: 0.837321
AUC: 0.885934
Avg Precision: 0.438038
Avg Recall: 1.000000
d_prime: 1.704392
train_loss: 0.102613
valid_loss: 1.101864
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0022710253236416767
Epoch-9 lr: 0.00681307597092503
epoch 9 training time: 16.630
---------------
2023-09-24 01:48:03.912870
current #epochs=10, #steps=360
start validation
acc: 0.856459
AUC: 0.884876
Avg Precision: 0.437309
Avg Recall: 1.000000
d_prime: 1.696664
train_loss: 0.104072
valid_loss: 1.097362
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0016074797023167867
Epoch-10 lr: 0.0048224391069503604
epoch 10 training time: 15.315
---------------
2023-09-24 01:48:19.227402
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04145	Per Sample Data Time 0.03112	Per Sample DNN Time 0.01033	Train Loss 0.0786	
start validation
acc: 0.861244
AUC: 0.894468
Avg Precision: 0.445420
Avg Recall: 1.000000
d_prime: 1.768677
train_loss: 0.082466
valid_loss: 1.086535
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0016074797023167867
Epoch-11 lr: 0.0048224391069503604
epoch 11 training time: 15.390
---------------
2023-09-24 01:48:34.617616
current #epochs=12, #steps=440
start validation
acc: 0.875598
AUC: 0.888417
Avg Precision: 0.441153
Avg Recall: 1.000000
d_prime: 1.722726
train_loss: 0.090876
valid_loss: 1.082615
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0016074797023167867
Epoch-12 lr: 0.0048224391069503604
epoch 12 training time: 17.787
---------------
2023-09-24 01:48:52.404774
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00727	Per Sample Data Time 0.00164	Per Sample DNN Time 0.00563	Train Loss 0.0565	
start validation
acc: 0.861244
AUC: 0.878399
Avg Precision: 0.411654
Avg Recall: 1.000000
d_prime: 1.650417
train_loss: 0.063948
valid_loss: 1.081025
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0016074797023167867
Epoch-13 lr: 0.0048224391069503604
epoch 13 training time: 15.364
---------------
2023-09-24 01:49:07.768818
current #epochs=14, #steps=520
start validation
acc: 0.861244
AUC: 0.877709
Avg Precision: 0.426264
Avg Recall: 1.000000
d_prime: 1.645595
train_loss: 0.083573
valid_loss: 1.076107
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0016074797023167867
Epoch-14 lr: 0.0048224391069503604
epoch 14 training time: 15.232
---------------
2023-09-24 01:49:23.000996
current #epochs=15, #steps=560
start validation
acc: 0.856459
AUC: 0.875747
Avg Precision: 0.433582
Avg Recall: 1.000000
d_prime: 1.631983
train_loss: 0.099420
valid_loss: 1.099545
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0016074797023167867
Epoch-15 lr: 0.0048224391069503604
epoch 15 training time: 15.377
---------------
2023-09-24 01:49:38.378484
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03998	Per Sample Data Time 0.03241	Per Sample DNN Time 0.00758	Train Loss 0.1286	
start validation
acc: 0.875598
AUC: 0.883981
Avg Precision: 0.451236
Avg Recall: 1.000000
d_prime: 1.690164
train_loss: 0.085061
valid_loss: 1.075100
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0016074797023167867
Epoch-16 lr: 0.0048224391069503604
epoch 16 training time: 15.347
---------------
2023-09-24 01:49:53.725453
current #epochs=17, #steps=640
start validation
acc: 0.846890
AUC: 0.890858
Avg Precision: 0.444947
Avg Recall: 1.000000
d_prime: 1.741042
train_loss: 0.102027
valid_loss: 1.091091
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0016074797023167867
Epoch-17 lr: 0.0048224391069503604
epoch 17 training time: 15.197
---------------
2023-09-24 01:50:08.922717
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00559	Train Loss 0.1053	
start validation
acc: 0.846890
AUC: 0.882704
Avg Precision: 0.438839
Avg Recall: 1.000000
d_prime: 1.680952
train_loss: 0.102002
valid_loss: 1.118187
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0011378080933139645
Epoch-18 lr: 0.003413424279941894
epoch 18 training time: 15.307
---------------
2023-09-24 01:50:24.229803
current #epochs=19, #steps=720
start validation
[I 2023-09-24 01:50:42,066] Trial 68 finished with value: 0.43720810827462975 and parameters: {'warmup': 'True', 'num_epochs': 19, 'batch_size': 22, 'lr-adaptschedule': 'False', 'lr': 0.0022710253236416767, 'head-lr': 3, 'lr-scheduler-start': 10, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.7078211262475625}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.885167
AUC: 0.896983
Avg Precision: 0.437208
Avg Recall: 1.000000
d_prime: 1.788339
train_loss: 0.087658
valid_loss: 1.088911
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0011378080933139645
Epoch-19 lr: 0.003413424279941894
epoch 19 training time: 17.828
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0983ed90>
The learning rate scheduler starts at 10 epoch with decay rate of 0.705 every 10 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 01:50:42.104840
current #epochs=1, #steps=0
start validation
acc: 0.808612
AUC: 0.884068
Avg Precision: 0.398689
Avg Recall: 1.000000
d_prime: 1.690794
train_loss: 0.209736
valid_loss: 1.116216
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0023960054941466673
Epoch-1 lr: 0.007188016482440001
epoch 1 training time: 17.702
---------------
2023-09-24 01:50:59.807203
current #epochs=2, #steps=40
start validation
acc: 0.842105
AUC: 0.897287
Avg Precision: 0.421063
Avg Recall: 1.000000
d_prime: 1.790742
train_loss: 0.170653
valid_loss: 1.088179
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0023960054941466673
Epoch-2 lr: 0.007188016482440001
epoch 2 training time: 17.738
---------------
2023-09-24 01:51:17.545026
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00168	Per Sample DNN Time 0.00551	Train Loss 0.1082	
start validation
acc: 0.842105
AUC: 0.874334
Avg Precision: 0.430330
Avg Recall: 1.000000
d_prime: 1.622273
train_loss: 0.106811
valid_loss: 1.091503
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0023960054941466673
Epoch-3 lr: 0.007188016482440001
epoch 3 training time: 15.372
---------------
2023-09-24 01:51:32.917427
current #epochs=4, #steps=120
start validation
acc: 0.851675
AUC: 0.889886
Avg Precision: 0.433353
Avg Recall: 1.000000
d_prime: 1.733712
train_loss: 0.093361
valid_loss: 1.073840
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0023960054941466673
Epoch-4 lr: 0.007188016482440001
epoch 4 training time: 18.377
---------------
2023-09-24 01:51:51.294032
current #epochs=5, #steps=160
start validation
acc: 0.827751
AUC: 0.862563
Avg Precision: 0.372073
Avg Recall: 1.000000
d_prime: 1.544189
train_loss: 0.120536
valid_loss: 1.105069
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0023960054941466673
Epoch-5 lr: 0.007188016482440001
epoch 5 training time: 15.217
---------------
2023-09-24 01:52:06.511296
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03732	Per Sample Data Time 0.02975	Per Sample DNN Time 0.00757	Train Loss 0.0722	
start validation
acc: 0.827751
AUC: 0.865484
Avg Precision: 0.361706
Avg Recall: 1.000000
d_prime: 1.563125
train_loss: 0.132715
valid_loss: 1.086605
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0023960054941466673
Epoch-6 lr: 0.007188016482440001
epoch 6 training time: 15.103
---------------
2023-09-24 01:52:21.614594
current #epochs=7, #steps=240
start validation
acc: 0.822967
AUC: 0.903263
Avg Precision: 0.379424
Avg Recall: 1.000000
d_prime: 1.838999
train_loss: 0.167028
valid_loss: 1.090754
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0023960054941466673
Epoch-7 lr: 0.007188016482440001
epoch 7 training time: 15.347
---------------
2023-09-24 01:52:36.961681
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00725	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00563	Train Loss 0.1329	
start validation
acc: 0.799043
AUC: 0.883648
Avg Precision: 0.356203
Avg Recall: 1.000000
d_prime: 1.687757
train_loss: 0.123441
valid_loss: 1.124048
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0023960054941466673
Epoch-8 lr: 0.007188016482440001
epoch 8 training time: 15.314
---------------
2023-09-24 01:52:52.276499
current #epochs=9, #steps=320
start validation
acc: 0.827751
AUC: 0.911374
Avg Precision: 0.368188
Avg Recall: 1.000000
d_prime: 1.908152
train_loss: 0.126151
valid_loss: 1.089491
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0023960054941466673
Epoch-9 lr: 0.007188016482440001
epoch 9 training time: 15.358
---------------
2023-09-24 01:53:07.633931
current #epochs=10, #steps=360
start validation
acc: 0.813397
AUC: 0.879719
Avg Precision: 0.404213
Avg Recall: 1.000000
d_prime: 1.659700
train_loss: 0.106230
valid_loss: 1.090953
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.001688847400978764
Epoch-10 lr: 0.005066542202936291
epoch 10 training time: 15.307
---------------
2023-09-24 01:53:22.940705
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04107	Per Sample Data Time 0.03041	Per Sample DNN Time 0.01065	Train Loss 0.1582	
start validation
acc: 0.794258
AUC: 0.875989
Avg Precision: 0.354931
Avg Recall: 1.000000
d_prime: 1.633652
train_loss: 0.169598
valid_loss: 1.097733
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.001688847400978764
Epoch-11 lr: 0.005066542202936291
epoch 11 training time: 15.371
---------------
2023-09-24 01:53:38.311169
current #epochs=12, #steps=440
start validation
acc: 0.760766
AUC: 0.867074
Avg Precision: 0.330914
Avg Recall: 1.000000
d_prime: 1.573544
train_loss: 0.162750
valid_loss: 1.124622
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.001688847400978764
Epoch-12 lr: 0.005066542202936291
epoch 12 training time: 15.272
---------------
2023-09-24 01:53:53.583831
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00564	Train Loss 0.2119	
start validation
acc: 0.808612
AUC: 0.870704
Avg Precision: 0.367196
Avg Recall: 1.000000
d_prime: 1.597675
train_loss: 0.186582
valid_loss: 1.100506
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.001688847400978764
Epoch-13 lr: 0.005066542202936291
epoch 13 training time: 15.388
---------------
2023-09-24 01:54:08.971900
current #epochs=14, #steps=520
start validation
acc: 0.799043
AUC: 0.870573
Avg Precision: 0.339680
Avg Recall: 1.000000
d_prime: 1.596795
train_loss: 0.140609
valid_loss: 1.105950
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.001688847400978764
Epoch-14 lr: 0.005066542202936291
epoch 14 training time: 15.309
---------------
2023-09-24 01:54:24.280308
current #epochs=15, #steps=560
start validation
acc: 0.803828
AUC: 0.864653
Avg Precision: 0.340606
Avg Recall: 1.000000
d_prime: 1.557707
train_loss: 0.117116
valid_loss: 1.092536
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.001688847400978764
Epoch-15 lr: 0.005066542202936291
epoch 15 training time: 15.280
---------------
2023-09-24 01:54:39.560011
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04028	Per Sample Data Time 0.02976	Per Sample DNN Time 0.01053	Train Loss 0.1160	
start validation
acc: 0.794258
AUC: 0.858100
Avg Precision: 0.353386
Avg Recall: 1.000000
d_prime: 1.515787
train_loss: 0.100119
valid_loss: 1.107485
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.001688847400978764
Epoch-16 lr: 0.005066542202936291
epoch 16 training time: 15.334
---------------
2023-09-24 01:54:54.893851
current #epochs=17, #steps=640
start validation
acc: 0.803828
AUC: 0.861598
Avg Precision: 0.348034
Avg Recall: 1.000000
d_prime: 1.537996
train_loss: 0.115893
valid_loss: 1.100669
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.001688847400978764
Epoch-17 lr: 0.005066542202936291
epoch 17 training time: 15.525
---------------
2023-09-24 01:55:10.419259
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00561	Train Loss 0.0920	
start validation
acc: 0.789474
AUC: 0.854738
Avg Precision: 0.345760
Avg Recall: 1.000000
d_prime: 1.494788
train_loss: 0.096817
valid_loss: 1.114913
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.001688847400978764
Epoch-18 lr: 0.005066542202936291
epoch 18 training time: 15.257
---------------
2023-09-24 01:55:25.676563
current #epochs=19, #steps=720
start validation
[I 2023-09-24 01:55:40,950] Trial 69 finished with value: 0.3505969107840776 and parameters: {'warmup': 'True', 'num_epochs': 19, 'batch_size': 11, 'lr-adaptschedule': 'False', 'lr': 0.0023960054941466673, 'head-lr': 3, 'lr-scheduler-start': 10, 'lr-scheduler-step': 10, 'lr-scheduler-decay': 0.7048595694394447}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.803828
AUC: 0.863281
Avg Precision: 0.350597
Avg Recall: 1.000000
d_prime: 1.548815
train_loss: 0.100646
valid_loss: 1.094445
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.001688847400978764
Epoch-19 lr: 0.005066542202936291
epoch 19 training time: 15.265
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0983e4c0>
The learning rate scheduler starts at 10 epoch with decay rate of 0.679 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 01:55:40.989242
current #epochs=1, #steps=0
start validation
acc: 0.846890
AUC: 0.904882
Avg Precision: 0.379257
Avg Recall: 1.000000
d_prime: 1.852450
train_loss: 0.144487
valid_loss: 1.079452
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.002193029300832013
Epoch-1 lr: 0.006579087902496039
epoch 1 training time: 17.827
---------------
2023-09-24 01:55:58.816637
current #epochs=2, #steps=40
start validation
acc: 0.832536
AUC: 0.889199
Avg Precision: 0.363550
Avg Recall: 1.000000
d_prime: 1.728563
train_loss: 0.153534
valid_loss: 1.090519
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.002193029300832013
Epoch-2 lr: 0.006579087902496039
epoch 2 training time: 15.335
---------------
2023-09-24 01:56:14.151704
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00559	Train Loss 0.1359	
start validation
acc: 0.803828
AUC: 0.876853
Avg Precision: 0.362395
Avg Recall: 1.000000
d_prime: 1.639639
train_loss: 0.142534
valid_loss: 1.110093
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.002193029300832013
Epoch-3 lr: 0.006579087902496039
epoch 3 training time: 15.351
---------------
2023-09-24 01:56:29.502695
current #epochs=4, #steps=120
start validation
acc: 0.856459
AUC: 0.892377
Avg Precision: 0.367496
Avg Recall: 1.000000
d_prime: 1.752590
train_loss: 0.118765
valid_loss: 1.083372
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.002193029300832013
Epoch-4 lr: 0.006579087902496039
epoch 4 training time: 17.754
---------------
2023-09-24 01:56:47.256948
current #epochs=5, #steps=160
start validation
acc: 0.808612
AUC: 0.897500
Avg Precision: 0.350488
Avg Recall: 1.000000
d_prime: 1.792426
train_loss: 0.132008
valid_loss: 1.101740
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.002193029300832013
Epoch-5 lr: 0.006579087902496039
epoch 5 training time: 15.247
---------------
2023-09-24 01:57:02.503825
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03911	Per Sample Data Time 0.02965	Per Sample DNN Time 0.00946	Train Loss 0.1534	
start validation
acc: 0.770335
AUC: 0.841796
Avg Precision: 0.382171
Avg Recall: 1.000000
d_prime: 1.416853
train_loss: 0.129307
valid_loss: 1.127128
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.002193029300832013
Epoch-6 lr: 0.006579087902496039
epoch 6 training time: 15.236
---------------
2023-09-24 01:57:17.740003
current #epochs=7, #steps=240
start validation
acc: 0.775120
AUC: 0.882883
Avg Precision: 0.364469
Avg Recall: 1.000000
d_prime: 1.682238
train_loss: 0.153266
valid_loss: 1.109234
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.002193029300832013
Epoch-7 lr: 0.006579087902496039
epoch 7 training time: 15.421
---------------
2023-09-24 01:57:33.161453
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00714	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00558	Train Loss 0.1072	
start validation
acc: 0.708134
AUC: 0.853323
Avg Precision: 0.326680
Avg Recall: 1.000000
d_prime: 1.486042
train_loss: 0.120263
valid_loss: 1.141440
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.002193029300832013
Epoch-8 lr: 0.006579087902496039
epoch 8 training time: 15.342
---------------
2023-09-24 01:57:48.503435
current #epochs=9, #steps=320
start validation
acc: 0.770335
AUC: 0.850724
Avg Precision: 0.332667
Avg Recall: 1.000000
d_prime: 1.470138
train_loss: 0.135528
valid_loss: 1.118159
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.002193029300832013
Epoch-9 lr: 0.006579087902496039
epoch 9 training time: 15.148
---------------
2023-09-24 01:58:03.651223
current #epochs=10, #steps=360
start validation
acc: 0.813397
AUC: 0.880072
Avg Precision: 0.368090
Avg Recall: 1.000000
d_prime: 1.662193
train_loss: 0.186944
valid_loss: 1.100159
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0014888716453839346
Epoch-10 lr: 0.0044666149361518035
epoch 10 training time: 15.290
---------------
2023-09-24 01:58:18.941662
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04010	Per Sample Data Time 0.02972	Per Sample DNN Time 0.01038	Train Loss 0.1288	
start validation
acc: 0.851675
AUC: 0.896102
Avg Precision: 0.392172
Avg Recall: 1.000000
d_prime: 1.781409
train_loss: 0.116880
valid_loss: 1.072639
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0014888716453839346
Epoch-11 lr: 0.0044666149361518035
epoch 11 training time: 15.369
---------------
2023-09-24 01:58:34.310689
current #epochs=12, #steps=440
start validation
acc: 0.822967
AUC: 0.881595
Avg Precision: 0.336433
Avg Recall: 1.000000
d_prime: 1.673015
train_loss: 0.084441
valid_loss: 1.090410
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0014888716453839346
Epoch-12 lr: 0.0044666149361518035
epoch 12 training time: 15.330
---------------
2023-09-24 01:58:49.640918
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00564	Train Loss 0.1227	
start validation
acc: 0.846890
AUC: 0.893373
Avg Precision: 0.391585
Avg Recall: 1.000000
d_prime: 1.760227
train_loss: 0.113103
valid_loss: 1.083845
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0014888716453839346
Epoch-13 lr: 0.0044666149361518035
epoch 13 training time: 15.328
---------------
2023-09-24 01:59:04.968581
current #epochs=14, #steps=520
start validation
acc: 0.808612
AUC: 0.892477
Avg Precision: 0.381875
Avg Recall: 1.000000
d_prime: 1.753353
train_loss: 0.099759
valid_loss: 1.096198
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0014888716453839346
Epoch-14 lr: 0.0044666149361518035
epoch 14 training time: 15.425
---------------
2023-09-24 01:59:20.393518
current #epochs=15, #steps=560
start validation
acc: 0.861244
AUC: 0.890881
Avg Precision: 0.439481
Avg Recall: 1.000000
d_prime: 1.741216
train_loss: 0.099133
valid_loss: 1.085980
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0014888716453839346
Epoch-15 lr: 0.0044666149361518035
epoch 15 training time: 17.770
---------------
2023-09-24 01:59:38.163228
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04193	Per Sample Data Time 0.03176	Per Sample DNN Time 0.01017	Train Loss 0.2087	
start validation
acc: 0.832536
AUC: 0.870566
Avg Precision: 0.369594
Avg Recall: 1.000000
d_prime: 1.596744
train_loss: 0.097518
valid_loss: 1.095448
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0014888716453839346
Epoch-16 lr: 0.0044666149361518035
epoch 16 training time: 15.348
---------------
2023-09-24 01:59:53.511190
current #epochs=17, #steps=640
start validation
acc: 0.832536
AUC: 0.866585
Avg Precision: 0.365637
Avg Recall: 1.000000
d_prime: 1.570332
train_loss: 0.099674
valid_loss: 1.104455
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0014888716453839346
Epoch-17 lr: 0.0044666149361518035
epoch 17 training time: 15.332
---------------
2023-09-24 02:00:08.843477
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00565	Train Loss 0.0821	
start validation
acc: 0.837321
AUC: 0.867027
Avg Precision: 0.365475
Avg Recall: 1.000000
d_prime: 1.573237
train_loss: 0.093240
valid_loss: 1.104144
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0014888716453839346
Epoch-18 lr: 0.0044666149361518035
epoch 18 training time: 15.293
---------------
2023-09-24 02:00:24.136779
current #epochs=19, #steps=720
start validation
acc: 0.832536
AUC: 0.873205
Avg Precision: 0.364331
Avg Recall: 1.000000
d_prime: 1.614572
train_loss: 0.076929
valid_loss: 1.088848
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.001010811289929987
Epoch-19 lr: 0.0030324338697899607
epoch 19 training time: 15.335
---------------
2023-09-24 02:00:39.471829
current #epochs=20, #steps=760
start validation
acc: 0.822967
AUC: 0.881806
Avg Precision: 0.365507
Avg Recall: 1.000000
d_prime: 1.674516
train_loss: 0.067237
valid_loss: 1.085819
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.001010811289929987
Epoch-20 lr: 0.0030324338697899607
epoch 20 training time: 15.323
---------------
2023-09-24 02:00:54.795105
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04078	Per Sample Data Time 0.03083	Per Sample DNN Time 0.00996	Train Loss 0.0493	
start validation
acc: 0.875598
AUC: 0.883635
Avg Precision: 0.382883
Avg Recall: 1.000000
d_prime: 1.687658
train_loss: 0.060393
valid_loss: 1.077573
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.001010811289929987
Epoch-21 lr: 0.0030324338697899607
epoch 21 training time: 18.190
---------------
2023-09-24 02:01:12.984882
current #epochs=22, #steps=840
start validation
acc: 0.822967
AUC: 0.871985
Avg Precision: 0.355383
Avg Recall: 1.000000
d_prime: 1.606295
train_loss: 0.076415
valid_loss: 1.104676
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.001010811289929987
Epoch-22 lr: 0.0030324338697899607
epoch 22 training time: 15.254
---------------
2023-09-24 02:01:28.239280
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00560	Train Loss 0.0623	
start validation
acc: 0.846890
AUC: 0.883586
Avg Precision: 0.375226
Avg Recall: 1.000000
d_prime: 1.687309
train_loss: 0.073666
valid_loss: 1.065863
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.001010811289929987
Epoch-23 lr: 0.0030324338697899607
epoch 23 training time: 15.286
---------------
2023-09-24 02:01:43.525164
current #epochs=24, #steps=920
start validation
acc: 0.827751
AUC: 0.880735
Avg Precision: 0.374138
Avg Recall: 1.000000
d_prime: 1.666891
train_loss: 0.081107
valid_loss: 1.099652
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.001010811289929987
Epoch-24 lr: 0.0030324338697899607
epoch 24 training time: 15.218
---------------
2023-09-24 02:01:58.743499
current #epochs=25, #steps=960
start validation
acc: 0.851675
AUC: 0.894681
Avg Precision: 0.404591
Avg Recall: 1.000000
d_prime: 1.770327
train_loss: 0.109546
valid_loss: 1.074730
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.001010811289929987
Epoch-25 lr: 0.0030324338697899607
epoch 25 training time: 15.428
---------------
2023-09-24 02:02:14.171716
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.03844	Per Sample Data Time 0.03048	Per Sample DNN Time 0.00796	Train Loss 0.0594	
start validation
acc: 0.837321
AUC: 0.895046
Avg Precision: 0.361763
Avg Recall: 1.000000
d_prime: 1.773164
train_loss: 0.086171
valid_loss: 1.089260
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.001010811289929987
Epoch-26 lr: 0.0030324338697899607
epoch 26 training time: 15.319
---------------
2023-09-24 02:02:29.490689
current #epochs=27, #steps=1040
start validation
acc: 0.851675
AUC: 0.894487
Avg Precision: 0.364417
Avg Recall: 1.000000
d_prime: 1.768830
train_loss: 0.073457
valid_loss: 1.072859
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.001010811289929987
Epoch-27 lr: 0.0030324338697899607
epoch 27 training time: 15.289
---------------
2023-09-24 02:02:44.779480
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00559	Train Loss 0.0698	
start validation
acc: 0.832536
AUC: 0.887324
Avg Precision: 0.349666
Avg Recall: 1.000000
d_prime: 1.714620
train_loss: 0.071006
valid_loss: 1.066675
validation finished
normal learning rate scheduler step
Epoch-28 lr: 0.0006862508712673138
Epoch-28 lr: 0.002058752613801941
epoch 28 training time: 15.300
---------------
2023-09-24 02:03:00.079459
current #epochs=29, #steps=1120
start validation
acc: 0.827751
AUC: 0.889103
Avg Precision: 0.354899
Avg Recall: 1.000000
d_prime: 1.727849
train_loss: 0.067602
valid_loss: 1.079173
validation finished
normal learning rate scheduler step
Epoch-29 lr: 0.0006862508712673138
Epoch-29 lr: 0.002058752613801941
epoch 29 training time: 15.252
---------------
2023-09-24 02:03:15.331574
current #epochs=30, #steps=1160
start validation
acc: 0.846890
AUC: 0.894790
Avg Precision: 0.392286
Avg Recall: 1.000000
d_prime: 1.771174
train_loss: 0.075755
valid_loss: 1.077447
validation finished
normal learning rate scheduler step
Epoch-30 lr: 0.0006862508712673138
Epoch-30 lr: 0.002058752613801941
epoch 30 training time: 15.411
---------------
2023-09-24 02:03:30.742154
current #epochs=31, #steps=1200
Epoch: [31][0/40]	Per Sample Total Time 0.04123	Per Sample Data Time 0.03060	Per Sample DNN Time 0.01063	Train Loss 0.0385	
start validation
acc: 0.842105
AUC: 0.890460
Avg Precision: 0.403142
Avg Recall: 1.000000
d_prime: 1.738040
train_loss: 0.051877
valid_loss: 1.078027
validation finished
normal learning rate scheduler step
Epoch-31 lr: 0.0006862508712673138
Epoch-31 lr: 0.002058752613801941
epoch 31 training time: 15.361
---------------
2023-09-24 02:03:46.102933
current #epochs=32, #steps=1240
start validation
acc: 0.818182
AUC: 0.882413
Avg Precision: 0.379490
Avg Recall: 1.000000
d_prime: 1.678865
train_loss: 0.072273
valid_loss: 1.085549
validation finished
normal learning rate scheduler step
Epoch-32 lr: 0.0006862508712673138
Epoch-32 lr: 0.002058752613801941
epoch 32 training time: 15.337
---------------
2023-09-24 02:04:01.439541
current #epochs=33, #steps=1280
Epoch: [33][20/40]	Per Sample Total Time 0.00726	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00565	Train Loss 0.0696	
start validation
acc: 0.842105
AUC: 0.887250
Avg Precision: 0.414326
Avg Recall: 1.000000
d_prime: 1.714070
train_loss: 0.070447
valid_loss: 1.087480
validation finished
normal learning rate scheduler step
Epoch-33 lr: 0.0006862508712673138
Epoch-33 lr: 0.002058752613801941
epoch 33 training time: 15.341
---------------
2023-09-24 02:04:16.780417
current #epochs=34, #steps=1320
start validation
acc: 0.837321
AUC: 0.891512
Avg Precision: 0.398836
Avg Recall: 1.000000
d_prime: 1.746004
train_loss: 0.070724
valid_loss: 1.096843
validation finished
normal learning rate scheduler step
Epoch-34 lr: 0.0006862508712673138
Epoch-34 lr: 0.002058752613801941
epoch 34 training time: 15.244
---------------
2023-09-24 02:04:32.024314
current #epochs=35, #steps=1360
start validation
acc: 0.861244
AUC: 0.893472
Avg Precision: 0.422935
Avg Recall: 1.000000
d_prime: 1.760986
train_loss: 0.069188
valid_loss: 1.072533
validation finished
normal learning rate scheduler step
Epoch-35 lr: 0.0006862508712673138
Epoch-35 lr: 0.002058752613801941
epoch 35 training time: 15.338
---------------
2023-09-24 02:04:47.362747
current #epochs=36, #steps=1400
Epoch: [36][0/40]	Per Sample Total Time 0.04013	Per Sample Data Time 0.03045	Per Sample DNN Time 0.00968	Train Loss 0.0201	
start validation
acc: 0.842105
AUC: 0.896613
Avg Precision: 0.422248
Avg Recall: 1.000000
d_prime: 1.785423
train_loss: 0.074722
valid_loss: 1.099509
validation finished
normal learning rate scheduler step
Epoch-36 lr: 0.0006862508712673138
Epoch-36 lr: 0.002058752613801941
epoch 36 training time: 16.102
---------------
2023-09-24 02:05:03.464290
current #epochs=37, #steps=1440
start validation
acc: 0.842105
AUC: 0.892796
Avg Precision: 0.362390
Avg Recall: 1.000000
d_prime: 1.755799
train_loss: 0.084163
valid_loss: 1.095375
validation finished
normal learning rate scheduler step
Epoch-37 lr: 0.0004659032432728038
Epoch-37 lr: 0.0013977097298184112
epoch 37 training time: 15.465
---------------
2023-09-24 02:05:18.929665
current #epochs=38, #steps=1480
Epoch: [38][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00561	Train Loss 0.0724	
start validation
acc: 0.866029
AUC: 0.899001
Avg Precision: 0.376166
Avg Recall: 1.000000
d_prime: 1.804370
train_loss: 0.066291
valid_loss: 1.078609
validation finished
normal learning rate scheduler step
Epoch-38 lr: 0.0004659032432728038
Epoch-38 lr: 0.0013977097298184112
epoch 38 training time: 15.255
---------------
2023-09-24 02:05:34.184718
current #epochs=39, #steps=1520
start validation
acc: 0.856459
AUC: 0.889633
Avg Precision: 0.374402
Avg Recall: 1.000000
d_prime: 1.731817
train_loss: 0.066202
valid_loss: 1.082892
validation finished
normal learning rate scheduler step
Epoch-39 lr: 0.0004659032432728038
Epoch-39 lr: 0.0013977097298184112
epoch 39 training time: 15.343
---------------
2023-09-24 02:05:49.528002
current #epochs=40, #steps=1560
start validation
acc: 0.832536
AUC: 0.889161
Avg Precision: 0.354877
Avg Recall: 1.000000
d_prime: 1.728281
train_loss: 0.065312
valid_loss: 1.087205
validation finished
normal learning rate scheduler step
Epoch-40 lr: 0.0004659032432728038
Epoch-40 lr: 0.0013977097298184112
epoch 40 training time: 15.362
---------------
2023-09-24 02:06:04.889968
current #epochs=41, #steps=1600
Epoch: [41][0/40]	Per Sample Total Time 0.04075	Per Sample Data Time 0.03030	Per Sample DNN Time 0.01045	Train Loss 0.0235	
start validation
acc: 0.846890
AUC: 0.894014
Avg Precision: 0.375997
Avg Recall: 1.000000
d_prime: 1.765164
train_loss: 0.077036
valid_loss: 1.086574
validation finished
normal learning rate scheduler step
Epoch-41 lr: 0.0004659032432728038
Epoch-41 lr: 0.0013977097298184112
epoch 41 training time: 15.431
---------------
2023-09-24 02:06:20.321390
current #epochs=42, #steps=1640
start validation
[I 2023-09-24 02:06:35,627] Trial 70 finished with value: 0.3960833823707921 and parameters: {'warmup': 'True', 'num_epochs': 42, 'batch_size': 22, 'lr-adaptschedule': 'False', 'lr': 0.002193029300832013, 'head-lr': 3, 'lr-scheduler-start': 10, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.6789109679560924}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.846890
AUC: 0.888866
Avg Precision: 0.396083
Avg Recall: 1.000000
d_prime: 1.726077
train_loss: 0.072784
valid_loss: 1.079545
validation finished
normal learning rate scheduler step
Epoch-42 lr: 0.0004659032432728038
Epoch-42 lr: 0.0013977097298184112
epoch 42 training time: 15.296
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcbd2c88730>
The learning rate scheduler starts at 9 epoch with decay rate of 0.719 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 02:06:35.665209
current #epochs=1, #steps=0
start validation
acc: 0.846890
AUC: 0.878693
Avg Precision: 0.408723
Avg Recall: 1.000000
d_prime: 1.652478
train_loss: 0.138776
valid_loss: 1.097555
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0019691585230028567
Epoch-1 lr: 0.00590747556900857
epoch 1 training time: 19.102
---------------
2023-09-24 02:06:54.767187
current #epochs=2, #steps=40
start validation
acc: 0.813397
AUC: 0.877584
Avg Precision: 0.337888
Avg Recall: 1.000000
d_prime: 1.644719
train_loss: 0.116679
valid_loss: 1.097261
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0019691585230028567
Epoch-2 lr: 0.00590747556900857
epoch 2 training time: 15.289
---------------
2023-09-24 02:07:10.055712
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00708	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00553	Train Loss 0.1111	
start validation
acc: 0.832536
AUC: 0.872362
Avg Precision: 0.334488
Avg Recall: 1.000000
d_prime: 1.608847
train_loss: 0.097864
valid_loss: 1.101767
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0019691585230028567
Epoch-3 lr: 0.00590747556900857
epoch 3 training time: 15.249
---------------
2023-09-24 02:07:25.304604
current #epochs=4, #steps=120
start validation
acc: 0.822967
AUC: 0.893373
Avg Precision: 0.387755
Avg Recall: 1.000000
d_prime: 1.760228
train_loss: 0.085793
valid_loss: 1.097154
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0019691585230028567
Epoch-4 lr: 0.00590747556900857
epoch 4 training time: 15.248
---------------
2023-09-24 02:07:40.552876
current #epochs=5, #steps=160
start validation
acc: 0.856459
AUC: 0.894100
Avg Precision: 0.360994
Avg Recall: 1.000000
d_prime: 1.765829
train_loss: 0.118886
valid_loss: 1.101350
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0019691585230028567
Epoch-5 lr: 0.00590747556900857
epoch 5 training time: 18.378
---------------
2023-09-24 02:07:58.931305
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03857	Per Sample Data Time 0.02880	Per Sample DNN Time 0.00977	Train Loss 0.2326	
start validation
acc: 0.851675
AUC: 0.884975
Avg Precision: 0.375016
Avg Recall: 1.000000
d_prime: 1.697379
train_loss: 0.103672
valid_loss: 1.087665
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0019691585230028567
Epoch-6 lr: 0.00590747556900857
epoch 6 training time: 15.206
---------------
2023-09-24 02:08:14.137429
current #epochs=7, #steps=240
start validation
acc: 0.799043
AUC: 0.850919
Avg Precision: 0.310244
Avg Recall: 1.000000
d_prime: 1.471323
train_loss: 0.147119
valid_loss: 1.109344
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0019691585230028567
Epoch-7 lr: 0.00590747556900857
epoch 7 training time: 15.321
---------------
2023-09-24 02:08:29.458317
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00558	Train Loss 0.2007	
start validation
acc: 0.770335
AUC: 0.844334
Avg Precision: 0.330756
Avg Recall: 1.000000
d_prime: 1.431795
train_loss: 0.189396
valid_loss: 1.142361
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0019691585230028567
Epoch-8 lr: 0.00590747556900857
epoch 8 training time: 15.320
---------------
2023-09-24 02:08:44.778554
current #epochs=9, #steps=320
start validation
acc: 0.775120
AUC: 0.864287
Avg Precision: 0.318670
Avg Recall: 1.000000
d_prime: 1.555327
train_loss: 0.212094
valid_loss: 1.122883
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0014156156740785825
Epoch-9 lr: 0.004246847022235748
epoch 9 training time: 15.386
---------------
2023-09-24 02:09:00.164795
current #epochs=10, #steps=360
start validation
acc: 0.827751
AUC: 0.873559
Avg Precision: 0.344501
Avg Recall: 1.000000
d_prime: 1.616980
train_loss: 0.207947
valid_loss: 1.118609
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0014156156740785825
Epoch-10 lr: 0.004246847022235748
epoch 10 training time: 15.211
---------------
2023-09-24 02:09:15.376016
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04057	Per Sample Data Time 0.03040	Per Sample DNN Time 0.01017	Train Loss 0.2283	
start validation
acc: 0.842105
AUC: 0.908499
Avg Precision: 0.330033
Avg Recall: 1.000000
d_prime: 1.883126
train_loss: 0.167664
valid_loss: 1.073120
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0014156156740785825
Epoch-11 lr: 0.004246847022235748
epoch 11 training time: 15.395
---------------
2023-09-24 02:09:30.770278
current #epochs=12, #steps=440
start validation
acc: 0.755981
AUC: 0.869176
Avg Precision: 0.319659
Avg Recall: 1.000000
d_prime: 1.587459
train_loss: 0.161798
valid_loss: 1.100146
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0014156156740785825
Epoch-12 lr: 0.004246847022235748
epoch 12 training time: 15.248
---------------
2023-09-24 02:09:46.018693
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00154	Per Sample DNN Time 0.00564	Train Loss 0.1512	
start validation
acc: 0.813397
AUC: 0.889436
Avg Precision: 0.320869
Avg Recall: 1.000000
d_prime: 1.730339
train_loss: 0.131084
valid_loss: 1.081637
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0014156156740785825
Epoch-13 lr: 0.004246847022235748
epoch 13 training time: 15.349
---------------
2023-09-24 02:10:01.367510
current #epochs=14, #steps=520
start validation
acc: 0.784689
AUC: 0.853346
Avg Precision: 0.316526
Avg Recall: 1.000000
d_prime: 1.486185
train_loss: 0.124974
valid_loss: 1.116855
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0014156156740785825
Epoch-14 lr: 0.004246847022235748
epoch 14 training time: 15.276
---------------
2023-09-24 02:10:16.643573
current #epochs=15, #steps=560
start validation
acc: 0.813397
AUC: 0.885574
Avg Precision: 0.324856
Avg Recall: 1.000000
d_prime: 1.701751
train_loss: 0.113054
valid_loss: 1.076176
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0014156156740785825
Epoch-15 lr: 0.004246847022235748
epoch 15 training time: 15.340
---------------
2023-09-24 02:10:31.983500
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04092	Per Sample Data Time 0.03060	Per Sample DNN Time 0.01031	Train Loss 0.0975	
start validation
acc: 0.827751
AUC: 0.891342
Avg Precision: 0.330910
Avg Recall: 1.000000
d_prime: 1.744713
train_loss: 0.102405
valid_loss: 1.075142
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0014156156740785825
Epoch-16 lr: 0.004246847022235748
epoch 16 training time: 15.307
---------------
2023-09-24 02:10:47.290409
current #epochs=17, #steps=640
start validation
acc: 0.822967
AUC: 0.874817
Avg Precision: 0.351593
Avg Recall: 1.000000
d_prime: 1.625584
train_loss: 0.102069
valid_loss: 1.077409
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0010176772023620631
Epoch-17 lr: 0.00305303160708619
epoch 17 training time: 15.501
---------------
2023-09-24 02:11:02.791517
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00730	Per Sample Data Time 0.00164	Per Sample DNN Time 0.00566	Train Loss 0.0720	
start validation
acc: 0.851675
AUC: 0.891300
Avg Precision: 0.352086
Avg Recall: 1.000000
d_prime: 1.744394
train_loss: 0.069178
valid_loss: 1.047729
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0010176772023620631
Epoch-18 lr: 0.00305303160708619
epoch 18 training time: 15.465
---------------
2023-09-24 02:11:18.256406
current #epochs=19, #steps=720
start validation
acc: 0.818182
AUC: 0.880013
Avg Precision: 0.335170
Avg Recall: 1.000000
d_prime: 1.661777
train_loss: 0.079348
valid_loss: 1.067537
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0010176772023620631
Epoch-19 lr: 0.00305303160708619
epoch 19 training time: 15.348
---------------
2023-09-24 02:11:33.603976
current #epochs=20, #steps=760
start validation
acc: 0.842105
AUC: 0.886765
Avg Precision: 0.342264
Avg Recall: 1.000000
d_prime: 1.710497
train_loss: 0.084891
valid_loss: 1.065334
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0010176772023620631
Epoch-20 lr: 0.00305303160708619
epoch 20 training time: 15.343
---------------
2023-09-24 02:11:48.947317
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04093	Per Sample Data Time 0.03058	Per Sample DNN Time 0.01035	Train Loss 0.0426	
start validation
acc: 0.775120
AUC: 0.865979
Avg Precision: 0.342685
Avg Recall: 1.000000
d_prime: 1.566357
train_loss: 0.095960
valid_loss: 1.108187
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0010176772023620631
Epoch-21 lr: 0.00305303160708619
epoch 21 training time: 15.430
---------------
2023-09-24 02:12:04.377922
current #epochs=22, #steps=840
start validation
acc: 0.861244
AUC: 0.892338
Avg Precision: 0.363707
Avg Recall: 1.000000
d_prime: 1.752293
train_loss: 0.082622
valid_loss: 1.061796
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0010176772023620631
Epoch-22 lr: 0.00305303160708619
epoch 22 training time: 18.886
---------------
2023-09-24 02:12:23.263967
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00725	Per Sample Data Time 0.00165	Per Sample DNN Time 0.00560	Train Loss 0.0679	
start validation
acc: 0.861244
AUC: 0.894968
Avg Precision: 0.384463
Avg Recall: 1.000000
d_prime: 1.772558
train_loss: 0.067269
valid_loss: 1.044519
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0010176772023620631
Epoch-23 lr: 0.00305303160708619
epoch 23 training time: 15.457
---------------
2023-09-24 02:12:38.721320
current #epochs=24, #steps=920
start validation
acc: 0.832536
AUC: 0.896693
Avg Precision: 0.356264
Avg Recall: 1.000000
d_prime: 1.786054
train_loss: 0.093168
valid_loss: 1.067770
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0010176772023620631
Epoch-24 lr: 0.00305303160708619
epoch 24 training time: 15.254
---------------
2023-09-24 02:12:53.975399
current #epochs=25, #steps=960
start validation
acc: 0.861244
AUC: 0.892274
Avg Precision: 0.353928
Avg Recall: 1.000000
d_prime: 1.751806
train_loss: 0.069159
valid_loss: 1.069386
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.0007316017385026386
Epoch-25 lr: 0.0021948052155079164
epoch 25 training time: 15.548
---------------
2023-09-24 02:13:09.523250
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.03773	Per Sample Data Time 0.02950	Per Sample DNN Time 0.00823	Train Loss 0.1329	
start validation
acc: 0.885167
AUC: 0.886935
Avg Precision: 0.362490
Avg Recall: 1.000000
d_prime: 1.711747
train_loss: 0.081116
valid_loss: 1.064869
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.0007316017385026386
Epoch-26 lr: 0.0021948052155079164
epoch 26 training time: 17.741
---------------
2023-09-24 02:13:27.264844
current #epochs=27, #steps=1040
start validation
acc: 0.832536
AUC: 0.887515
Avg Precision: 0.348094
Avg Recall: 1.000000
d_prime: 1.716032
train_loss: 0.075799
valid_loss: 1.066206
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.0007316017385026386
Epoch-27 lr: 0.0021948052155079164
epoch 27 training time: 15.305
---------------
2023-09-24 02:13:42.569449
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00558	Train Loss 0.0822	
start validation
acc: 0.870813
AUC: 0.871512
Avg Precision: 0.361399
Avg Recall: 1.000000
d_prime: 1.603109
train_loss: 0.073886
valid_loss: 1.083054
validation finished
normal learning rate scheduler step
Epoch-28 lr: 0.0007316017385026386
Epoch-28 lr: 0.0021948052155079164
epoch 28 training time: 15.315
---------------
2023-09-24 02:13:57.884296
current #epochs=29, #steps=1120
start validation
acc: 0.866029
AUC: 0.875142
Avg Precision: 0.361249
Avg Recall: 1.000000
d_prime: 1.627817
train_loss: 0.074324
valid_loss: 1.078801
validation finished
normal learning rate scheduler step
Epoch-29 lr: 0.0007316017385026386
Epoch-29 lr: 0.0021948052155079164
epoch 29 training time: 15.191
---------------
2023-09-24 02:14:13.075074
current #epochs=30, #steps=1160
start validation
acc: 0.832536
AUC: 0.871086
Avg Precision: 0.355346
Avg Recall: 1.000000
d_prime: 1.600242
train_loss: 0.080402
valid_loss: 1.088080
validation finished
normal learning rate scheduler step
Epoch-30 lr: 0.0007316017385026386
Epoch-30 lr: 0.0021948052155079164
epoch 30 training time: 15.286
---------------
2023-09-24 02:14:28.361056
current #epochs=31, #steps=1200
Epoch: [31][0/40]	Per Sample Total Time 0.03824	Per Sample Data Time 0.03117	Per Sample DNN Time 0.00707	Train Loss 0.0398	
start validation
acc: 0.856459
AUC: 0.895577
Avg Precision: 0.364583
Avg Recall: 1.000000
d_prime: 1.777309
train_loss: 0.082243
valid_loss: 1.065826
validation finished
normal learning rate scheduler step
Epoch-31 lr: 0.0007316017385026386
Epoch-31 lr: 0.0021948052155079164
epoch 31 training time: 15.330
---------------
2023-09-24 02:14:43.691267
current #epochs=32, #steps=1240
start validation
acc: 0.842105
AUC: 0.896314
Avg Precision: 0.354972
Avg Recall: 1.000000
d_prime: 1.783073
train_loss: 0.065981
valid_loss: 1.066558
validation finished
normal learning rate scheduler step
Epoch-32 lr: 0.0007316017385026386
Epoch-32 lr: 0.0021948052155079164
epoch 32 training time: 15.214
---------------
2023-09-24 02:14:58.905476
current #epochs=33, #steps=1280
Epoch: [33][20/40]	Per Sample Total Time 0.00726	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00566	Train Loss 0.0724	
start validation
acc: 0.851675
AUC: 0.906108
Avg Precision: 0.369921
Avg Recall: 1.000000
d_prime: 1.862749
train_loss: 0.070390
valid_loss: 1.061261
validation finished
normal learning rate scheduler step
Epoch-33 lr: 0.0005259438872540041
Epoch-33 lr: 0.0015778316617620126
epoch 33 training time: 15.394
---------------
2023-09-24 02:15:14.299110
current #epochs=34, #steps=1320
start validation
acc: 0.832536
AUC: 0.899162
Avg Precision: 0.357597
Avg Recall: 1.000000
d_prime: 1.805656
train_loss: 0.073664
valid_loss: 1.078541
validation finished
normal learning rate scheduler step
Epoch-34 lr: 0.0005259438872540041
Epoch-34 lr: 0.0015778316617620126
epoch 34 training time: 15.193
---------------
2023-09-24 02:15:29.492188
current #epochs=35, #steps=1360
start validation
acc: 0.856459
AUC: 0.895373
Avg Precision: 0.369468
Avg Recall: 1.000000
d_prime: 1.775716
train_loss: 0.069863
valid_loss: 1.074080
validation finished
normal learning rate scheduler step
Epoch-35 lr: 0.0005259438872540041
Epoch-35 lr: 0.0015778316617620126
epoch 35 training time: 15.231
---------------
2023-09-24 02:15:44.723555
current #epochs=36, #steps=1400
Epoch: [36][0/40]	Per Sample Total Time 0.03840	Per Sample Data Time 0.03018	Per Sample DNN Time 0.00821	Train Loss 0.0769	
start validation
acc: 0.842105
AUC: 0.896343
Avg Precision: 0.359560
Avg Recall: 1.000000
d_prime: 1.783304
train_loss: 0.079965
valid_loss: 1.075693
validation finished
normal learning rate scheduler step
Epoch-36 lr: 0.0005259438872540041
Epoch-36 lr: 0.0015778316617620126
epoch 36 training time: 15.272
---------------
2023-09-24 02:15:59.995955
current #epochs=37, #steps=1440
start validation
acc: 0.856459
AUC: 0.892738
Avg Precision: 0.368943
Avg Recall: 1.000000
d_prime: 1.755353
train_loss: 0.059929
valid_loss: 1.063274
validation finished
normal learning rate scheduler step
Epoch-37 lr: 0.0005259438872540041
Epoch-37 lr: 0.0015778316617620126
epoch 37 training time: 15.284
---------------
2023-09-24 02:16:15.279774
current #epochs=38, #steps=1480
Epoch: [38][20/40]	Per Sample Total Time 0.00725	Per Sample Data Time 0.00165	Per Sample DNN Time 0.00559	Train Loss 0.0520	
start validation
acc: 0.832536
AUC: 0.887218
Avg Precision: 0.361785
Avg Recall: 1.000000
d_prime: 1.713838
train_loss: 0.053531
valid_loss: 1.067245
validation finished
normal learning rate scheduler step
Epoch-38 lr: 0.0005259438872540041
Epoch-38 lr: 0.0015778316617620126
epoch 38 training time: 15.382
---------------
2023-09-24 02:16:30.661441
current #epochs=39, #steps=1520
start validation
acc: 0.851675
AUC: 0.882738
Avg Precision: 0.357262
Avg Recall: 1.000000
d_prime: 1.681197
train_loss: 0.058732
valid_loss: 1.069979
validation finished
normal learning rate scheduler step
Epoch-39 lr: 0.0005259438872540041
Epoch-39 lr: 0.0015778316617620126
epoch 39 training time: 16.628
---------------
2023-09-24 02:16:47.289216
current #epochs=40, #steps=1560
start validation
acc: 0.851675
AUC: 0.874992
Avg Precision: 0.366876
Avg Recall: 1.000000
d_prime: 1.626782
train_loss: 0.058063
valid_loss: 1.067148
validation finished
normal learning rate scheduler step
Epoch-40 lr: 0.0005259438872540041
Epoch-40 lr: 0.0015778316617620126
epoch 40 training time: 15.543
---------------
2023-09-24 02:17:02.832567
current #epochs=41, #steps=1600
Epoch: [41][0/40]	Per Sample Total Time 0.03818	Per Sample Data Time 0.03009	Per Sample DNN Time 0.00809	Train Loss 0.0203	
start validation
acc: 0.851675
AUC: 0.879215
Avg Precision: 0.366088
Avg Recall: 1.000000
d_prime: 1.656144
train_loss: 0.064727
valid_loss: 1.083980
validation finished
normal learning rate scheduler step
Epoch-41 lr: 0.0003780977517986788
Epoch-41 lr: 0.0011342932553960368
epoch 41 training time: 15.276
---------------
2023-09-24 02:17:18.108433
current #epochs=42, #steps=1640
start validation
acc: 0.861244
AUC: 0.881720
Avg Precision: 0.364964
Avg Recall: 1.000000
d_prime: 1.673904
train_loss: 0.062271
valid_loss: 1.081353
validation finished
normal learning rate scheduler step
Epoch-42 lr: 0.0003780977517986788
Epoch-42 lr: 0.0011342932553960368
epoch 42 training time: 15.503
---------------
2023-09-24 02:17:33.611495
current #epochs=43, #steps=1680
Epoch: [43][20/40]	Per Sample Total Time 0.00711	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00556	Train Loss 0.0725	
start validation
acc: 0.866029
AUC: 0.882512
Avg Precision: 0.369957
Avg Recall: 1.000000
d_prime: 1.679573
train_loss: 0.061097
valid_loss: 1.079680
validation finished
normal learning rate scheduler step
Epoch-43 lr: 0.0003780977517986788
Epoch-43 lr: 0.0011342932553960368
epoch 43 training time: 16.350
---------------
2023-09-24 02:17:49.961530
current #epochs=44, #steps=1720
start validation
acc: 0.894737
AUC: 0.882223
Avg Precision: 0.394051
Avg Recall: 1.000000
d_prime: 1.677499
train_loss: 0.080831
valid_loss: 1.075909
validation finished
normal learning rate scheduler step
Epoch-44 lr: 0.0003780977517986788
Epoch-44 lr: 0.0011342932553960368
epoch 44 training time: 17.631
---------------
2023-09-24 02:18:07.592428
current #epochs=45, #steps=1760
start validation
acc: 0.861244
AUC: 0.887292
Avg Precision: 0.379999
Avg Recall: 1.000000
d_prime: 1.714386
train_loss: 0.063539
valid_loss: 1.080388
validation finished
normal learning rate scheduler step
Epoch-45 lr: 0.0003780977517986788
Epoch-45 lr: 0.0011342932553960368
epoch 45 training time: 15.271
---------------
2023-09-24 02:18:22.863386
current #epochs=46, #steps=1800
Epoch: [46][0/40]	Per Sample Total Time 0.03801	Per Sample Data Time 0.03005	Per Sample DNN Time 0.00796	Train Loss 0.0554	
start validation
acc: 0.856459
AUC: 0.886886
Avg Precision: 0.364709
Avg Recall: 1.000000
d_prime: 1.711386
train_loss: 0.051028
valid_loss: 1.083716
validation finished
normal learning rate scheduler step
Epoch-46 lr: 0.0003780977517986788
Epoch-46 lr: 0.0011342932553960368
epoch 46 training time: 15.199
---------------
2023-09-24 02:18:38.063087
current #epochs=47, #steps=1840
start validation
acc: 0.837321
AUC: 0.886505
Avg Precision: 0.359874
Avg Recall: 1.000000
d_prime: 1.708582
train_loss: 0.066627
valid_loss: 1.082433
validation finished
normal learning rate scheduler step
Epoch-47 lr: 0.0003780977517986788
Epoch-47 lr: 0.0011342932553960368
epoch 47 training time: 15.125
---------------
2023-09-24 02:18:53.188594
current #epochs=48, #steps=1880
Epoch: [48][20/40]	Per Sample Total Time 0.00712	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00556	Train Loss 0.0705	
start validation
acc: 0.856459
AUC: 0.887022
Avg Precision: 0.358409
Avg Recall: 1.000000
d_prime: 1.712389
train_loss: 0.079067
valid_loss: 1.077483
validation finished
normal learning rate scheduler step
Epoch-48 lr: 0.0003780977517986788
Epoch-48 lr: 0.0011342932553960368
epoch 48 training time: 15.260
---------------
2023-09-24 02:19:08.448670
current #epochs=49, #steps=1920
start validation
acc: 0.846890
AUC: 0.882178
Avg Precision: 0.352471
Avg Recall: 1.000000
d_prime: 1.677181
train_loss: 0.063837
valid_loss: 1.072239
validation finished
normal learning rate scheduler step
Epoch-49 lr: 0.000271812095129787
Epoch-49 lr: 0.0008154362853893612
epoch 49 training time: 15.256
---------------
2023-09-24 02:19:23.704256
current #epochs=50, #steps=1960
start validation
[I 2023-09-24 02:19:38,931] Trial 71 finished with value: 0.35174057464683084 and parameters: {'warmup': 'True', 'num_epochs': 50, 'batch_size': 26, 'lr-adaptschedule': 'False', 'lr': 0.0019691585230028567, 'head-lr': 3, 'lr-scheduler-start': 9, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.7188937089330156}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.837321
AUC: 0.882272
Avg Precision: 0.351741
Avg Recall: 1.000000
d_prime: 1.677852
train_loss: 0.049565
valid_loss: 1.072693
validation finished
normal learning rate scheduler step
Epoch-50 lr: 0.000271812095129787
Epoch-50 lr: 0.0008154362853893612
epoch 50 training time: 15.218
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc52638a00>
The learning rate scheduler starts at 10 epoch with decay rate of 0.731 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 02:19:38.969404
current #epochs=1, #steps=0
start validation
acc: 0.846890
AUC: 0.863704
Avg Precision: 0.305191
Avg Recall: 1.000000
d_prime: 1.551554
train_loss: 0.101914
valid_loss: 1.084798
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0022368821636234598
Epoch-1 lr: 0.008947528654493839
epoch 1 training time: 17.658
---------------
2023-09-24 02:19:56.627506
current #epochs=2, #steps=40
start validation
acc: 0.822967
AUC: 0.856813
Avg Precision: 0.327649
Avg Recall: 1.000000
d_prime: 1.507705
train_loss: 0.091184
valid_loss: 1.101100
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0022368821636234598
Epoch-2 lr: 0.008947528654493839
epoch 2 training time: 15.262
---------------
2023-09-24 02:20:11.889661
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00709	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00548	Train Loss 0.1146	
start validation
acc: 0.775120
AUC: 0.868305
Avg Precision: 0.303509
Avg Recall: 1.000000
d_prime: 1.581680
train_loss: 0.119264
valid_loss: 1.118631
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0022368821636234598
Epoch-3 lr: 0.008947528654493839
epoch 3 training time: 15.296
---------------
2023-09-24 02:20:27.185557
current #epochs=4, #steps=120
start validation
acc: 0.784689
AUC: 0.851426
Avg Precision: 0.310359
Avg Recall: 1.000000
d_prime: 1.474415
train_loss: 0.157223
valid_loss: 1.117390
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0022368821636234598
Epoch-4 lr: 0.008947528654493839
epoch 4 training time: 15.243
---------------
2023-09-24 02:20:42.428766
current #epochs=5, #steps=160
start validation
acc: 0.856459
AUC: 0.862553
Avg Precision: 0.362012
Avg Recall: 1.000000
d_prime: 1.544128
train_loss: 0.172020
valid_loss: 1.089865
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0022368821636234598
Epoch-5 lr: 0.008947528654493839
epoch 5 training time: 17.647
---------------
2023-09-24 02:21:00.075742
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03822	Per Sample Data Time 0.03022	Per Sample DNN Time 0.00800	Train Loss 0.2269	
start validation
acc: 0.827751
AUC: 0.861551
Avg Precision: 0.337701
Avg Recall: 1.000000
d_prime: 1.537697
train_loss: 0.181541
valid_loss: 1.115655
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0022368821636234598
Epoch-6 lr: 0.008947528654493839
epoch 6 training time: 15.214
---------------
2023-09-24 02:21:15.289108
current #epochs=7, #steps=240
start validation
acc: 0.808612
AUC: 0.852938
Avg Precision: 0.341258
Avg Recall: 1.000000
d_prime: 1.483676
train_loss: 0.117573
valid_loss: 1.109743
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0022368821636234598
Epoch-7 lr: 0.008947528654493839
epoch 7 training time: 15.353
---------------
2023-09-24 02:21:30.642784
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00708	Per Sample Data Time 0.00153	Per Sample DNN Time 0.00555	Train Loss 0.1234	
start validation
acc: 0.846890
AUC: 0.886611
Avg Precision: 0.390202
Avg Recall: 1.000000
d_prime: 1.709358
train_loss: 0.116227
valid_loss: 1.087662
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0022368821636234598
Epoch-8 lr: 0.008947528654493839
epoch 8 training time: 15.143
---------------
2023-09-24 02:21:45.785364
current #epochs=9, #steps=320
start validation
acc: 0.846890
AUC: 0.905291
Avg Precision: 0.413175
Avg Recall: 1.000000
d_prime: 1.855880
train_loss: 0.091750
valid_loss: 1.068608
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0022368821636234598
Epoch-9 lr: 0.008947528654493839
epoch 9 training time: 15.340
---------------
2023-09-24 02:22:01.126114
current #epochs=10, #steps=360
start validation
acc: 0.818182
AUC: 0.900205
Avg Precision: 0.391415
Avg Recall: 1.000000
d_prime: 1.814037
train_loss: 0.099349
valid_loss: 1.095991
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0016341629359134444
Epoch-10 lr: 0.0065366517436537775
epoch 10 training time: 15.291
---------------
2023-09-24 02:22:16.417753
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03761	Per Sample Data Time 0.02946	Per Sample DNN Time 0.00815	Train Loss 0.1416	
start validation
acc: 0.851675
AUC: 0.890120
Avg Precision: 0.437084
Avg Recall: 1.000000
d_prime: 1.735475
train_loss: 0.075026
valid_loss: 1.091069
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0016341629359134444
Epoch-11 lr: 0.0065366517436537775
epoch 11 training time: 15.248
---------------
2023-09-24 02:22:31.665875
current #epochs=12, #steps=440
start validation
acc: 0.837321
AUC: 0.891249
Avg Precision: 0.421343
Avg Recall: 1.000000
d_prime: 1.744005
train_loss: 0.074979
valid_loss: 1.072752
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0016341629359134444
Epoch-12 lr: 0.0065366517436537775
epoch 12 training time: 15.309
---------------
2023-09-24 02:22:46.974683
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00561	Train Loss 0.0666	
start validation
acc: 0.837321
AUC: 0.883984
Avg Precision: 0.375078
Avg Recall: 1.000000
d_prime: 1.690187
train_loss: 0.075125
valid_loss: 1.086018
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0016341629359134444
Epoch-13 lr: 0.0065366517436537775
epoch 13 training time: 15.328
---------------
2023-09-24 02:23:02.302367
current #epochs=14, #steps=520
start validation
acc: 0.822967
AUC: 0.873827
Avg Precision: 0.339542
Avg Recall: 1.000000
d_prime: 1.618808
train_loss: 0.099280
valid_loss: 1.109894
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0016341629359134444
Epoch-14 lr: 0.0065366517436537775
epoch 14 training time: 15.390
---------------
2023-09-24 02:23:17.692746
current #epochs=15, #steps=560
start validation
acc: 0.837321
AUC: 0.889284
Avg Precision: 0.367869
Avg Recall: 1.000000
d_prime: 1.729202
train_loss: 0.099606
valid_loss: 1.104931
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0016341629359134444
Epoch-15 lr: 0.0065366517436537775
epoch 15 training time: 15.287
---------------
2023-09-24 02:23:32.980237
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04059	Per Sample Data Time 0.03057	Per Sample DNN Time 0.01002	Train Loss 0.0911	
start validation
acc: 0.846890
AUC: 0.882390
Avg Precision: 0.399808
Avg Recall: 1.000000
d_prime: 1.678696
train_loss: 0.080237
valid_loss: 1.099384
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0016341629359134444
Epoch-16 lr: 0.0065366517436537775
epoch 16 training time: 15.352
---------------
2023-09-24 02:23:48.332215
current #epochs=17, #steps=640
start validation
acc: 0.856459
AUC: 0.883675
Avg Precision: 0.397444
Avg Recall: 1.000000
d_prime: 1.687952
train_loss: 0.088774
valid_loss: 1.083533
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0016341629359134444
Epoch-17 lr: 0.0065366517436537775
epoch 17 training time: 15.287
---------------
2023-09-24 02:24:03.618985
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00563	Train Loss 0.0853	
start validation
acc: 0.842105
AUC: 0.883158
Avg Precision: 0.393861
Avg Recall: 1.000000
d_prime: 1.684216
train_loss: 0.083765
valid_loss: 1.100024
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.001193844067667562
Epoch-18 lr: 0.004775376270670248
epoch 18 training time: 15.298
---------------
2023-09-24 02:24:18.917062
current #epochs=19, #steps=720
start validation
acc: 0.842105
AUC: 0.892909
Avg Precision: 0.413191
Avg Recall: 1.000000
d_prime: 1.756662
train_loss: 0.076570
valid_loss: 1.077635
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.001193844067667562
Epoch-19 lr: 0.004775376270670248
epoch 19 training time: 16.517
---------------
2023-09-24 02:24:35.434203
current #epochs=20, #steps=760
start validation
acc: 0.861244
AUC: 0.896071
Avg Precision: 0.441767
Avg Recall: 1.000000
d_prime: 1.781168
train_loss: 0.087519
valid_loss: 1.072521
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.001193844067667562
Epoch-20 lr: 0.004775376270670248
epoch 20 training time: 17.834
---------------
2023-09-24 02:24:53.268839
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03941	Per Sample Data Time 0.02967	Per Sample DNN Time 0.00974	Train Loss 0.1855	
start validation
acc: 0.832536
AUC: 0.907026
Avg Precision: 0.396227
Avg Recall: 1.000000
d_prime: 1.870529
train_loss: 0.092750
valid_loss: 1.077702
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.001193844067667562
Epoch-21 lr: 0.004775376270670248
epoch 21 training time: 15.155
---------------
2023-09-24 02:25:08.424062
current #epochs=22, #steps=840
start validation
[I 2023-09-24 02:25:23,630] Trial 72 finished with value: 0.365570875803168 and parameters: {'warmup': 'True', 'num_epochs': 22, 'batch_size': 19, 'lr-adaptschedule': 'False', 'lr': 0.0022368821636234598, 'head-lr': 4, 'lr-scheduler-start': 10, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.7305538765020647}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.803828
AUC: 0.905368
Avg Precision: 0.365571
Avg Recall: 1.000000
d_prime: 1.856524
train_loss: 0.102978
valid_loss: 1.075863
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.001193844067667562
Epoch-22 lr: 0.004775376270670248
epoch 22 training time: 15.196
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc52652580>
The learning rate scheduler starts at 9 epoch with decay rate of 0.743 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 02:25:23.669426
current #epochs=1, #steps=0
start validation
acc: 0.861244
AUC: 0.870703
Avg Precision: 0.364795
Avg Recall: 1.000000
d_prime: 1.597667
train_loss: 0.191178
valid_loss: 1.101218
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.002483272008159485
Epoch-1 lr: 0.0074498160244784555
epoch 1 training time: 17.772
---------------
2023-09-24 02:25:41.441805
current #epochs=2, #steps=40
start validation
acc: 0.842105
AUC: 0.885365
Avg Precision: 0.374065
Avg Recall: 1.000000
d_prime: 1.700223
train_loss: 0.158579
valid_loss: 1.108988
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.002483272008159485
Epoch-2 lr: 0.0074498160244784555
epoch 2 training time: 15.349
---------------
2023-09-24 02:25:56.790560
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00562	Train Loss 0.1045	
start validation
acc: 0.832536
AUC: 0.913668
Avg Precision: 0.370584
Avg Recall: 1.000000
d_prime: 1.928550
train_loss: 0.113648
valid_loss: 1.072128
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.002483272008159485
Epoch-3 lr: 0.0074498160244784555
epoch 3 training time: 16.595
---------------
2023-09-24 02:26:13.386060
current #epochs=4, #steps=120
start validation
acc: 0.779904
AUC: 0.899432
Avg Precision: 0.346534
Avg Recall: 1.000000
d_prime: 1.807818
train_loss: 0.116207
valid_loss: 1.106357
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.002483272008159485
Epoch-4 lr: 0.0074498160244784555
epoch 4 training time: 15.306
---------------
2023-09-24 02:26:28.692104
current #epochs=5, #steps=160
start validation
acc: 0.856459
AUC: 0.895424
Avg Precision: 0.385863
Avg Recall: 1.000000
d_prime: 1.776115
train_loss: 0.121443
valid_loss: 1.091805
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.002483272008159485
Epoch-5 lr: 0.0074498160244784555
epoch 5 training time: 15.309
---------------
2023-09-24 02:26:44.001603
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04041	Per Sample Data Time 0.02987	Per Sample DNN Time 0.01054	Train Loss 0.1526	
start validation
acc: 0.822967
AUC: 0.903167
Avg Precision: 0.339663
Avg Recall: 1.000000
d_prime: 1.838210
train_loss: 0.122138
valid_loss: 1.108632
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.002483272008159485
Epoch-6 lr: 0.0074498160244784555
epoch 6 training time: 15.388
---------------
2023-09-24 02:26:59.388910
current #epochs=7, #steps=240
start validation
acc: 0.818182
AUC: 0.903161
Avg Precision: 0.334162
Avg Recall: 1.000000
d_prime: 1.838159
train_loss: 0.110576
valid_loss: 1.094777
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.002483272008159485
Epoch-7 lr: 0.0074498160244784555
epoch 7 training time: 15.295
---------------
2023-09-24 02:27:14.683703
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00563	Train Loss 0.1445	
start validation
acc: 0.732057
AUC: 0.850596
Avg Precision: 0.296786
Avg Recall: 1.000000
d_prime: 1.469360
train_loss: 0.219222
valid_loss: 1.174376
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.002483272008159485
Epoch-8 lr: 0.0074498160244784555
epoch 8 training time: 15.290
---------------
2023-09-24 02:27:29.973624
current #epochs=9, #steps=320
start validation
acc: 0.794258
AUC: 0.864529
Avg Precision: 0.317294
Avg Recall: 1.000000
d_prime: 1.556904
train_loss: 0.407396
valid_loss: 1.139249
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0018460071109462045
Epoch-9 lr: 0.005538021332838613
epoch 9 training time: 15.349
---------------
2023-09-24 02:27:45.321930
current #epochs=10, #steps=360
start validation
acc: 0.775120
AUC: 0.840719
Avg Precision: 0.323320
Avg Recall: 1.000000
d_prime: 1.410560
train_loss: 0.333514
valid_loss: 1.150812
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0018460071109462045
Epoch-10 lr: 0.005538021332838613
epoch 10 training time: 15.299
---------------
2023-09-24 02:28:00.621030
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04070	Per Sample Data Time 0.03150	Per Sample DNN Time 0.00920	Train Loss 0.2049	
start validation
acc: 0.808612
AUC: 0.867040
Avg Precision: 0.332234
Avg Recall: 1.000000
d_prime: 1.573325
train_loss: 0.232358
valid_loss: 1.114580
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0018460071109462045
Epoch-11 lr: 0.005538021332838613
epoch 11 training time: 15.252
---------------
2023-09-24 02:28:15.872884
current #epochs=12, #steps=440
start validation
acc: 0.822967
AUC: 0.856540
Avg Precision: 0.350354
Avg Recall: 1.000000
d_prime: 1.506000
train_loss: 0.220762
valid_loss: 1.109717
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0018460071109462045
Epoch-12 lr: 0.005538021332838613
epoch 12 training time: 15.238
---------------
2023-09-24 02:28:31.111067
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00728	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00568	Train Loss 0.2024	
start validation
acc: 0.822967
AUC: 0.888480
Avg Precision: 0.356486
Avg Recall: 1.000000
d_prime: 1.723199
train_loss: 0.231868
valid_loss: 1.106725
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0018460071109462045
Epoch-13 lr: 0.005538021332838613
epoch 13 training time: 15.558
---------------
2023-09-24 02:28:46.668845
current #epochs=14, #steps=520
start validation
acc: 0.832536
AUC: 0.899959
Avg Precision: 0.363545
Avg Recall: 1.000000
d_prime: 1.812058
train_loss: 0.150414
valid_loss: 1.082121
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0018460071109462045
Epoch-14 lr: 0.005538021332838613
epoch 14 training time: 15.226
---------------
2023-09-24 02:29:01.894469
current #epochs=15, #steps=560
start validation
[I 2023-09-24 02:29:17,168] Trial 73 finished with value: 0.3443204104399854 and parameters: {'warmup': 'True', 'num_epochs': 15, 'batch_size': 24, 'lr-adaptschedule': 'False', 'lr': 0.002483272008159485, 'head-lr': 3, 'lr-scheduler-start': 9, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.7433769256370754}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.813397
AUC: 0.878956
Avg Precision: 0.344320
Avg Recall: 1.000000
d_prime: 1.654322
train_loss: 0.142446
valid_loss: 1.097423
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0018460071109462045
Epoch-15 lr: 0.005538021332838613
epoch 15 training time: 15.263
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcbd2c9ffa0>
The learning rate scheduler starts at 10 epoch with decay rate of 0.762 every 7 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 02:29:17.207050
current #epochs=1, #steps=0
start validation
acc: 0.846890
AUC: 0.861190
Avg Precision: 0.350916
Avg Recall: 1.000000
d_prime: 1.535384
train_loss: 0.150597
valid_loss: 1.101221
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0017699596023450436
Epoch-1 lr: 0.0070798384093801745
epoch 1 training time: 18.966
---------------
2023-09-24 02:29:36.173803
current #epochs=2, #steps=40
start validation
acc: 0.861244
AUC: 0.882218
Avg Precision: 0.361340
Avg Recall: 1.000000
d_prime: 1.677467
train_loss: 0.114008
valid_loss: 1.059527
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0017699596023450436
Epoch-2 lr: 0.0070798384093801745
epoch 2 training time: 18.075
---------------
2023-09-24 02:29:54.249189
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00711	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00555	Train Loss 0.1269	
start validation
acc: 0.856459
AUC: 0.878093
Avg Precision: 0.358650
Avg Recall: 1.000000
d_prime: 1.648273
train_loss: 0.125505
valid_loss: 1.086008
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0017699596023450436
Epoch-3 lr: 0.0070798384093801745
epoch 3 training time: 15.246
---------------
2023-09-24 02:30:09.495028
current #epochs=4, #steps=120
start validation
acc: 0.875598
AUC: 0.884544
Avg Precision: 0.436275
Avg Recall: 1.000000
d_prime: 1.694247
train_loss: 0.092956
valid_loss: 1.064955
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0017699596023450436
Epoch-4 lr: 0.0070798384093801745
epoch 4 training time: 17.610
---------------
2023-09-24 02:30:27.104748
current #epochs=5, #steps=160
start validation
acc: 0.856459
AUC: 0.889082
Avg Precision: 0.363935
Avg Recall: 1.000000
d_prime: 1.727690
train_loss: 0.144403
valid_loss: 1.056229
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0017699596023450436
Epoch-5 lr: 0.0070798384093801745
epoch 5 training time: 15.318
---------------
2023-09-24 02:30:42.422953
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03911	Per Sample Data Time 0.02844	Per Sample DNN Time 0.01067	Train Loss 0.0312	
start validation
acc: 0.818182
AUC: 0.886361
Avg Precision: 0.384520
Avg Recall: 1.000000
d_prime: 1.707521
train_loss: 0.095131
valid_loss: 1.080201
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0017699596023450436
Epoch-6 lr: 0.0070798384093801745
epoch 6 training time: 15.136
---------------
2023-09-24 02:30:57.558748
current #epochs=7, #steps=240
start validation
acc: 0.794258
AUC: 0.873237
Avg Precision: 0.334993
Avg Recall: 1.000000
d_prime: 1.614786
train_loss: 0.114589
valid_loss: 1.096177
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0017699596023450436
Epoch-7 lr: 0.0070798384093801745
epoch 7 training time: 15.325
---------------
2023-09-24 02:31:12.883902
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00711	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00556	Train Loss 0.1424	
start validation
acc: 0.870813
AUC: 0.877220
Avg Precision: 0.386147
Avg Recall: 1.000000
d_prime: 1.642190
train_loss: 0.128740
valid_loss: 1.071612
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0017699596023450436
Epoch-8 lr: 0.0070798384093801745
epoch 8 training time: 15.315
---------------
2023-09-24 02:31:28.199090
current #epochs=9, #steps=320
start validation
acc: 0.875598
AUC: 0.895143
Avg Precision: 0.423587
Avg Recall: 1.000000
d_prime: 1.773920
train_loss: 0.168722
valid_loss: 1.065021
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0017699596023450436
Epoch-9 lr: 0.0070798384093801745
epoch 9 training time: 15.226
---------------
2023-09-24 02:31:43.425409
current #epochs=10, #steps=360
start validation
acc: 0.866029
AUC: 0.904762
Avg Precision: 0.356446
Avg Recall: 1.000000
d_prime: 1.851446
train_loss: 0.205375
valid_loss: 1.076240
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.001348894341563711
Epoch-10 lr: 0.005395577366254844
epoch 10 training time: 15.312
---------------
2023-09-24 02:31:58.737487
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04132	Per Sample Data Time 0.03179	Per Sample DNN Time 0.00954	Train Loss 0.0722	
start validation
acc: 0.861244
AUC: 0.902286
Avg Precision: 0.366885
Avg Recall: 1.000000
d_prime: 1.830967
train_loss: 0.160819
valid_loss: 1.076784
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.001348894341563711
Epoch-11 lr: 0.005395577366254844
epoch 11 training time: 15.346
---------------
2023-09-24 02:32:14.083505
current #epochs=12, #steps=440
start validation
acc: 0.827751
AUC: 0.897326
Avg Precision: 0.405421
Avg Recall: 1.000000
d_prime: 1.791046
train_loss: 0.123327
valid_loss: 1.074498
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.001348894341563711
Epoch-12 lr: 0.005395577366254844
epoch 12 training time: 15.410
---------------
2023-09-24 02:32:29.494038
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00154	Per Sample DNN Time 0.00564	Train Loss 0.1322	
start validation
acc: 0.870813
AUC: 0.893576
Avg Precision: 0.406999
Avg Recall: 1.000000
d_prime: 1.761788
train_loss: 0.122221
valid_loss: 1.063930
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.001348894341563711
Epoch-13 lr: 0.005395577366254844
epoch 13 training time: 15.267
---------------
2023-09-24 02:32:44.760759
current #epochs=14, #steps=520
start validation
acc: 0.837321
AUC: 0.897066
Avg Precision: 0.407369
Avg Recall: 1.000000
d_prime: 1.788992
train_loss: 0.122816
valid_loss: 1.057525
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.001348894341563711
Epoch-14 lr: 0.005395577366254844
epoch 14 training time: 15.375
---------------
2023-09-24 02:33:00.135529
current #epochs=15, #steps=560
start validation
acc: 0.885167
AUC: 0.890253
Avg Precision: 0.407515
Avg Recall: 1.000000
d_prime: 1.736477
train_loss: 0.107904
valid_loss: 1.065614
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.001348894341563711
Epoch-15 lr: 0.005395577366254844
epoch 15 training time: 18.987
---------------
2023-09-24 02:33:19.122418
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04117	Per Sample Data Time 0.03012	Per Sample DNN Time 0.01105	Train Loss 0.3445	
start validation
acc: 0.832536
AUC: 0.900716
Avg Precision: 0.381798
Avg Recall: 1.000000
d_prime: 1.818173
train_loss: 0.155693
valid_loss: 1.085835
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.001348894341563711
Epoch-16 lr: 0.005395577366254844
epoch 16 training time: 15.242
---------------
2023-09-24 02:33:34.364446
current #epochs=17, #steps=640
start validation
acc: 0.866029
AUC: 0.899385
Avg Precision: 0.403352
Avg Recall: 1.000000
d_prime: 1.807446
train_loss: 0.117640
valid_loss: 1.064611
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0010279985725617103
Epoch-17 lr: 0.004111994290246841
epoch 17 training time: 15.230
---------------
2023-09-24 02:33:49.594890
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00563	Train Loss 0.1338	
start validation
[I 2023-09-24 02:34:04,923] Trial 74 finished with value: 0.39064836657233354 and parameters: {'warmup': 'True', 'num_epochs': 18, 'batch_size': 21, 'lr-adaptschedule': 'False', 'lr': 0.0017699596023450436, 'head-lr': 4, 'lr-scheduler-start': 10, 'lr-scheduler-step': 7, 'lr-scheduler-decay': 0.7621045925435487}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.822967
AUC: 0.893835
Avg Precision: 0.390648
Avg Recall: 1.000000
d_prime: 1.763784
train_loss: 0.126393
valid_loss: 1.098090
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0010279985725617103
Epoch-18 lr: 0.004111994290246841
epoch 18 training time: 15.317
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51d88a30>
The learning rate scheduler starts at 8 epoch with decay rate of 0.699 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 02:34:04.962020
current #epochs=1, #steps=0
start validation
acc: 0.818182
AUC: 0.892586
Avg Precision: 0.369765
Avg Recall: 1.000000
d_prime: 1.754191
train_loss: 0.184208
valid_loss: 1.120238
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0027388019119314556
Epoch-1 lr: 0.008216405735794366
epoch 1 training time: 17.716
---------------
2023-09-24 02:34:22.678997
current #epochs=2, #steps=40
start validation
acc: 0.837321
AUC: 0.876742
Avg Precision: 0.355641
Avg Recall: 1.000000
d_prime: 1.638863
train_loss: 0.122397
valid_loss: 1.090605
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0027388019119314556
Epoch-2 lr: 0.008216405735794366
epoch 2 training time: 18.696
---------------
2023-09-24 02:34:41.375308
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00712	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00556	Train Loss 0.1121	
start validation
acc: 0.827751
AUC: 0.870225
Avg Precision: 0.351986
Avg Recall: 1.000000
d_prime: 1.594463
train_loss: 0.108227
valid_loss: 1.107272
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0027388019119314556
Epoch-3 lr: 0.008216405735794366
epoch 3 training time: 15.275
---------------
2023-09-24 02:34:56.650376
current #epochs=4, #steps=120
start validation
acc: 0.813397
AUC: 0.878825
Avg Precision: 0.378906
Avg Recall: 1.000000
d_prime: 1.653404
train_loss: 0.162818
valid_loss: 1.110034
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0027388019119314556
Epoch-4 lr: 0.008216405735794366
epoch 4 training time: 15.252
---------------
2023-09-24 02:35:11.901914
current #epochs=5, #steps=160
start validation
acc: 0.885167
AUC: 0.912126
Avg Precision: 0.396364
Avg Recall: 1.000000
d_prime: 1.914795
train_loss: 0.162215
valid_loss: 1.070364
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0027388019119314556
Epoch-5 lr: 0.008216405735794366
epoch 5 training time: 17.707
---------------
2023-09-24 02:35:29.609339
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03919	Per Sample Data Time 0.03078	Per Sample DNN Time 0.00841	Train Loss 0.1832	
start validation
acc: 0.832536
AUC: 0.883810
Avg Precision: 0.401302
Avg Recall: 1.000000
d_prime: 1.688928
train_loss: 0.128142
valid_loss: 1.093745
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0027388019119314556
Epoch-6 lr: 0.008216405735794366
epoch 6 training time: 15.315
---------------
2023-09-24 02:35:44.924670
current #epochs=7, #steps=240
start validation
acc: 0.789474
AUC: 0.906042
Avg Precision: 0.324616
Avg Recall: 1.000000
d_prime: 1.862196
train_loss: 0.120119
valid_loss: 1.114546
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0027388019119314556
Epoch-7 lr: 0.008216405735794366
epoch 7 training time: 15.212
---------------
2023-09-24 02:36:00.136193
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00715	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00556	Train Loss 0.1456	
start validation
acc: 0.832536
AUC: 0.894489
Avg Precision: 0.357699
Avg Recall: 1.000000
d_prime: 1.768845
train_loss: 0.153750
valid_loss: 1.094797
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0019152205474514577
Epoch-8 lr: 0.005745661642354372
epoch 8 training time: 15.219
---------------
2023-09-24 02:36:15.355227
current #epochs=9, #steps=320
start validation
acc: 0.808612
AUC: 0.882964
Avg Precision: 0.368760
Avg Recall: 1.000000
d_prime: 1.682825
train_loss: 0.142618
valid_loss: 1.085866
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0019152205474514577
Epoch-9 lr: 0.005745661642354372
epoch 9 training time: 16.863
---------------
2023-09-24 02:36:32.218320
current #epochs=10, #steps=360
start validation
acc: 0.784689
AUC: 0.891625
Avg Precision: 0.347165
Avg Recall: 1.000000
d_prime: 1.746859
train_loss: 0.104130
valid_loss: 1.096633
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0019152205474514577
Epoch-10 lr: 0.005745661642354372
epoch 10 training time: 15.331
---------------
2023-09-24 02:36:47.548906
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03886	Per Sample Data Time 0.03125	Per Sample DNN Time 0.00761	Train Loss 0.1269	
start validation
acc: 0.842105
AUC: 0.887195
Avg Precision: 0.418213
Avg Recall: 1.000000
d_prime: 1.713663
train_loss: 0.095091
valid_loss: 1.086539
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0019152205474514577
Epoch-11 lr: 0.005745661642354372
epoch 11 training time: 15.216
---------------
2023-09-24 02:37:02.764514
current #epochs=12, #steps=440
start validation
acc: 0.799043
AUC: 0.874072
Avg Precision: 0.373313
Avg Recall: 1.000000
d_prime: 1.620483
train_loss: 0.082166
valid_loss: 1.107282
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0019152205474514577
Epoch-12 lr: 0.005745661642354372
epoch 12 training time: 15.365
---------------
2023-09-24 02:37:18.129565
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00725	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00564	Train Loss 0.1040	
start validation
acc: 0.827751
AUC: 0.912576
Avg Precision: 0.404519
Avg Recall: 1.000000
d_prime: 1.918793
train_loss: 0.093453
valid_loss: 1.074686
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0019152205474514577
Epoch-13 lr: 0.005745661642354372
epoch 13 training time: 15.320
---------------
2023-09-24 02:37:33.449958
current #epochs=14, #steps=520
start validation
acc: 0.813397
AUC: 0.904305
Avg Precision: 0.379295
Avg Recall: 1.000000
d_prime: 1.847643
train_loss: 0.112926
valid_loss: 1.075886
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0019152205474514577
Epoch-14 lr: 0.005745661642354372
epoch 14 training time: 15.359
---------------
2023-09-24 02:37:48.808780
current #epochs=15, #steps=560
start validation
acc: 0.808612
AUC: 0.906345
Avg Precision: 0.404387
Avg Recall: 1.000000
d_prime: 1.864751
train_loss: 0.148942
valid_loss: 1.094950
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0019152205474514577
Epoch-15 lr: 0.005745661642354372
epoch 15 training time: 17.952
---------------
2023-09-24 02:38:06.760880
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04056	Per Sample Data Time 0.02976	Per Sample DNN Time 0.01080	Train Loss 0.3176	
start validation
acc: 0.832536
AUC: 0.902643
Avg Precision: 0.420613
Avg Recall: 1.000000
d_prime: 1.833894
train_loss: 0.147995
valid_loss: 1.075836
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0013392972048838201
Epoch-16 lr: 0.00401789161465146
epoch 16 training time: 15.377
---------------
2023-09-24 02:38:22.138356
current #epochs=17, #steps=640
start validation
acc: 0.832536
AUC: 0.906954
Avg Precision: 0.400807
Avg Recall: 1.000000
d_prime: 1.869910
train_loss: 0.114993
valid_loss: 1.087310
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0013392972048838201
Epoch-17 lr: 0.00401789161465146
epoch 17 training time: 15.232
---------------
2023-09-24 02:38:37.370323
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00723	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00562	Train Loss 0.1192	
start validation
acc: 0.842105
AUC: 0.914624
Avg Precision: 0.412789
Avg Recall: 1.000000
d_prime: 1.937174
train_loss: 0.102800
valid_loss: 1.067086
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0013392972048838201
Epoch-18 lr: 0.00401789161465146
epoch 18 training time: 15.586
---------------
2023-09-24 02:38:52.956047
current #epochs=19, #steps=720
start validation
acc: 0.827751
AUC: 0.910402
Avg Precision: 0.363544
Avg Recall: 1.000000
d_prime: 1.899623
train_loss: 0.098813
valid_loss: 1.069399
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0013392972048838201
Epoch-19 lr: 0.00401789161465146
epoch 19 training time: 15.263
---------------
2023-09-24 02:39:08.219213
current #epochs=20, #steps=760
start validation
[I 2023-09-24 02:39:23,467] Trial 75 finished with value: 0.39651198499127355 and parameters: {'warmup': 'True', 'num_epochs': 20, 'batch_size': 27, 'lr-adaptschedule': 'False', 'lr': 0.0027388019119314556, 'head-lr': 3, 'lr-scheduler-start': 8, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.6992913722996518}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.866029
AUC: 0.912504
Avg Precision: 0.396512
Avg Recall: 1.000000
d_prime: 1.918150
train_loss: 0.097005
valid_loss: 1.045190
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0013392972048838201
Epoch-20 lr: 0.00401789161465146
epoch 20 training time: 15.239
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0a698d30>
The learning rate scheduler starts at 10 epoch with decay rate of 0.728 every 6 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 02:39:23.505795
current #epochs=1, #steps=0
start validation
acc: 0.827751
AUC: 0.899831
Avg Precision: 0.347248
Avg Recall: 1.000000
d_prime: 1.811025
train_loss: 0.142863
valid_loss: 1.082860
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0020118320473623244
Epoch-1 lr: 0.008047328189449298
epoch 1 training time: 19.038
---------------
2023-09-24 02:39:42.544442
current #epochs=2, #steps=40
start validation
acc: 0.832536
AUC: 0.876076
Avg Precision: 0.387499
Avg Recall: 1.000000
d_prime: 1.634255
train_loss: 0.106677
valid_loss: 1.079565
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0020118320473623244
Epoch-2 lr: 0.008047328189449298
epoch 2 training time: 17.637
---------------
2023-09-24 02:40:00.181418
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00715	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00553	Train Loss 0.1068	
start validation
acc: 0.779904
AUC: 0.891543
Avg Precision: 0.333768
Avg Recall: 1.000000
d_prime: 1.746237
train_loss: 0.102037
valid_loss: 1.115729
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0020118320473623244
Epoch-3 lr: 0.008047328189449298
epoch 3 training time: 15.207
---------------
2023-09-24 02:40:15.387990
current #epochs=4, #steps=120
start validation
acc: 0.856459
AUC: 0.907374
Avg Precision: 0.415790
Avg Recall: 1.000000
d_prime: 1.873486
train_loss: 0.122096
valid_loss: 1.070315
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0020118320473623244
Epoch-4 lr: 0.008047328189449298
epoch 4 training time: 18.636
---------------
2023-09-24 02:40:34.024357
current #epochs=5, #steps=160
start validation
acc: 0.832536
AUC: 0.891747
Avg Precision: 0.406893
Avg Recall: 1.000000
d_prime: 1.747784
train_loss: 0.114463
valid_loss: 1.072226
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0020118320473623244
Epoch-5 lr: 0.008047328189449298
epoch 5 training time: 15.302
---------------
2023-09-24 02:40:49.325991
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03973	Per Sample Data Time 0.02921	Per Sample DNN Time 0.01052	Train Loss 0.1140	
start validation
acc: 0.856459
AUC: 0.892913
Avg Precision: 0.424144
Avg Recall: 1.000000
d_prime: 1.756693
train_loss: 0.112263
valid_loss: 1.072272
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0020118320473623244
Epoch-6 lr: 0.008047328189449298
epoch 6 training time: 15.251
---------------
2023-09-24 02:41:04.576829
current #epochs=7, #steps=240
start validation
acc: 0.866029
AUC: 0.891059
Avg Precision: 0.407521
Avg Recall: 1.000000
d_prime: 1.742562
train_loss: 0.126832
valid_loss: 1.073360
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0020118320473623244
Epoch-7 lr: 0.008047328189449298
epoch 7 training time: 17.846
---------------
2023-09-24 02:41:22.422624
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00710	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00549	Train Loss 0.0882	
start validation
acc: 0.837321
AUC: 0.880936
Avg Precision: 0.332222
Avg Recall: 1.000000
d_prime: 1.668318
train_loss: 0.082237
valid_loss: 1.077525
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0020118320473623244
Epoch-8 lr: 0.008047328189449298
epoch 8 training time: 15.097
---------------
2023-09-24 02:41:37.519987
current #epochs=9, #steps=320
start validation
acc: 0.846890
AUC: 0.863494
Avg Precision: 0.323212
Avg Recall: 1.000000
d_prime: 1.550193
train_loss: 0.095832
valid_loss: 1.097369
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0020118320473623244
Epoch-9 lr: 0.008047328189449298
epoch 9 training time: 15.385
---------------
2023-09-24 02:41:52.904629
current #epochs=10, #steps=360
start validation
acc: 0.827751
AUC: 0.889657
Avg Precision: 0.312349
Avg Recall: 1.000000
d_prime: 1.731994
train_loss: 0.094331
valid_loss: 1.082527
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.001465423863258052
Epoch-10 lr: 0.005861695453032208
epoch 10 training time: 15.294
---------------
2023-09-24 02:42:08.198847
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04078	Per Sample Data Time 0.03036	Per Sample DNN Time 0.01042	Train Loss 0.0705	
start validation
acc: 0.851675
AUC: 0.870226
Avg Precision: 0.329971
Avg Recall: 1.000000
d_prime: 1.594472
train_loss: 0.115244
valid_loss: 1.095330
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.001465423863258052
Epoch-11 lr: 0.005861695453032208
epoch 11 training time: 15.674
---------------
2023-09-24 02:42:23.873608
current #epochs=12, #steps=440
start validation
acc: 0.894737
AUC: 0.900360
Avg Precision: 0.362977
Avg Recall: 1.000000
d_prime: 1.815294
train_loss: 0.080406
valid_loss: 1.050490
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.001465423863258052
Epoch-12 lr: 0.005861695453032208
epoch 12 training time: 17.688
---------------
2023-09-24 02:42:41.561709
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00714	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00554	Train Loss 0.0767	
start validation
acc: 0.851675
AUC: 0.881370
Avg Precision: 0.363963
Avg Recall: 1.000000
d_prime: 1.671404
train_loss: 0.085840
valid_loss: 1.071750
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.001465423863258052
Epoch-13 lr: 0.005861695453032208
epoch 13 training time: 15.281
---------------
2023-09-24 02:42:56.842680
current #epochs=14, #steps=520
start validation
acc: 0.842105
AUC: 0.878865
Avg Precision: 0.345976
Avg Recall: 1.000000
d_prime: 1.653684
train_loss: 0.091121
valid_loss: 1.076441
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.001465423863258052
Epoch-14 lr: 0.005861695453032208
epoch 14 training time: 15.236
---------------
2023-09-24 02:43:12.078420
current #epochs=15, #steps=560
start validation
acc: 0.851675
AUC: 0.867404
Avg Precision: 0.360290
Avg Recall: 1.000000
d_prime: 1.575720
train_loss: 0.077407
valid_loss: 1.074123
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.001465423863258052
Epoch-15 lr: 0.005861695453032208
epoch 15 training time: 15.316
---------------
2023-09-24 02:43:27.394578
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03929	Per Sample Data Time 0.03177	Per Sample DNN Time 0.00752	Train Loss 0.0808	
start validation
acc: 0.846890
AUC: 0.875276
Avg Precision: 0.350976
Avg Recall: 1.000000
d_prime: 1.628734
train_loss: 0.088621
valid_loss: 1.084394
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0010674186753420387
Epoch-16 lr: 0.004269674701368155
epoch 16 training time: 15.387
---------------
2023-09-24 02:43:42.781659
current #epochs=17, #steps=640
start validation
acc: 0.851675
AUC: 0.893340
Avg Precision: 0.407485
Avg Recall: 1.000000
d_prime: 1.759972
train_loss: 0.077577
valid_loss: 1.069989
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0010674186753420387
Epoch-17 lr: 0.004269674701368155
epoch 17 training time: 15.201
---------------
2023-09-24 02:43:57.982637
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00564	Train Loss 0.0707	
start validation
acc: 0.846890
AUC: 0.892038
Avg Precision: 0.372191
Avg Recall: 1.000000
d_prime: 1.750007
train_loss: 0.073342
valid_loss: 1.066278
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0010674186753420387
Epoch-18 lr: 0.004269674701368155
epoch 18 training time: 15.331
---------------
2023-09-24 02:44:13.313675
current #epochs=19, #steps=720
start validation
acc: 0.861244
AUC: 0.897342
Avg Precision: 0.390597
Avg Recall: 1.000000
d_prime: 1.791177
train_loss: 0.071181
valid_loss: 1.074463
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0010674186753420387
Epoch-19 lr: 0.004269674701368155
epoch 19 training time: 15.321
---------------
2023-09-24 02:44:28.635379
current #epochs=20, #steps=760
start validation
acc: 0.866029
AUC: 0.878063
Avg Precision: 0.360633
Avg Recall: 1.000000
d_prime: 1.648063
train_loss: 0.073451
valid_loss: 1.076772
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0010674186753420387
Epoch-20 lr: 0.004269674701368155
epoch 20 training time: 15.361
---------------
2023-09-24 02:44:43.996042
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03987	Per Sample Data Time 0.02967	Per Sample DNN Time 0.01019	Train Loss 0.0880	
start validation
acc: 0.861244
AUC: 0.893418
Avg Precision: 0.409352
Avg Recall: 1.000000
d_prime: 1.760569
train_loss: 0.061461
valid_loss: 1.066273
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0010674186753420387
Epoch-21 lr: 0.004269674701368155
epoch 21 training time: 15.318
---------------
2023-09-24 02:44:59.314349
current #epochs=22, #steps=840
start validation
acc: 0.813397
AUC: 0.891097
Avg Precision: 0.377251
Avg Recall: 1.000000
d_prime: 1.742849
train_loss: 0.064893
valid_loss: 1.097238
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0007775106281781045
Epoch-22 lr: 0.003110042512712418
epoch 22 training time: 16.543
---------------
2023-09-24 02:45:15.857467
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00153	Per Sample DNN Time 0.00563	Train Loss 0.0630	
start validation
acc: 0.866029
AUC: 0.891309
Avg Precision: 0.381605
Avg Recall: 1.000000
d_prime: 1.744463
train_loss: 0.063790
valid_loss: 1.061155
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0007775106281781045
Epoch-23 lr: 0.003110042512712418
epoch 23 training time: 15.307
---------------
2023-09-24 02:45:31.164435
current #epochs=24, #steps=920
start validation
acc: 0.861244
AUC: 0.885502
Avg Precision: 0.382989
Avg Recall: 1.000000
d_prime: 1.701229
train_loss: 0.075337
valid_loss: 1.077471
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0007775106281781045
Epoch-24 lr: 0.003110042512712418
epoch 24 training time: 15.304
---------------
2023-09-24 02:45:46.468461
current #epochs=25, #steps=960
start validation
acc: 0.842105
AUC: 0.897895
Avg Precision: 0.356538
Avg Recall: 1.000000
d_prime: 1.795552
train_loss: 0.056089
valid_loss: 1.073276
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.0007775106281781045
Epoch-25 lr: 0.003110042512712418
epoch 25 training time: 15.385
---------------
2023-09-24 02:46:01.853694
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.04022	Per Sample Data Time 0.03007	Per Sample DNN Time 0.01016	Train Loss 0.1137	
start validation
acc: 0.861244
AUC: 0.894657
Avg Precision: 0.346032
Avg Recall: 1.000000
d_prime: 1.770148
train_loss: 0.072346
valid_loss: 1.062209
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.0007775106281781045
Epoch-26 lr: 0.003110042512712418
epoch 26 training time: 15.375
---------------
2023-09-24 02:46:17.229281
current #epochs=27, #steps=1040
start validation
acc: 0.851675
AUC: 0.888098
Avg Precision: 0.331824
Avg Recall: 1.000000
d_prime: 1.720355
train_loss: 0.061110
valid_loss: 1.064184
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.0007775106281781045
Epoch-27 lr: 0.003110042512712418
epoch 27 training time: 15.399
---------------
2023-09-24 02:46:32.628443
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00563	Train Loss 0.0448	
start validation
[I 2023-09-24 02:46:49,240] Trial 76 finished with value: 0.37226791574352214 and parameters: {'warmup': 'True', 'num_epochs': 28, 'batch_size': 17, 'lr-adaptschedule': 'False', 'lr': 0.0020118320473623244, 'head-lr': 4, 'lr-scheduler-start': 10, 'lr-scheduler-step': 6, 'lr-scheduler-decay': 0.7284026841004656}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.861244
AUC: 0.896437
Avg Precision: 0.372268
Avg Recall: 1.000000
d_prime: 1.784043
train_loss: 0.063007
valid_loss: 1.050545
validation finished
normal learning rate scheduler step
Epoch-28 lr: 0.0005663408284815704
Epoch-28 lr: 0.0022653633139262815
epoch 28 training time: 16.601
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcbd2c888e0>
The learning rate scheduler starts at 9 epoch with decay rate of 0.711 every 10 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 02:46:49.279737
current #epochs=1, #steps=0
start validation
acc: 0.851675
AUC: 0.880060
Avg Precision: 0.365333
Avg Recall: 1.000000
d_prime: 1.662109
train_loss: 0.121898
valid_loss: 1.087286
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0015726223876324763
Epoch-1 lr: 0.006290489550529905
epoch 1 training time: 17.828
---------------
2023-09-24 02:47:07.107900
current #epochs=2, #steps=40
start validation
acc: 0.851675
AUC: 0.910990
Avg Precision: 0.381656
Avg Recall: 1.000000
d_prime: 1.904768
train_loss: 0.111158
valid_loss: 1.069607
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0015726223876324763
Epoch-2 lr: 0.006290489550529905
epoch 2 training time: 15.178
---------------
2023-09-24 02:47:22.285676
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00710	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00554	Train Loss 0.1041	
start validation
acc: 0.832536
AUC: 0.896784
Avg Precision: 0.368006
Avg Recall: 1.000000
d_prime: 1.786768
train_loss: 0.122467
valid_loss: 1.068476
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0015726223876324763
Epoch-3 lr: 0.006290489550529905
epoch 3 training time: 15.270
---------------
2023-09-24 02:47:37.556127
current #epochs=4, #steps=120
start validation
acc: 0.861244
AUC: 0.887508
Avg Precision: 0.389064
Avg Recall: 1.000000
d_prime: 1.715978
train_loss: 0.116815
valid_loss: 1.057022
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0015726223876324763
Epoch-4 lr: 0.006290489550529905
epoch 4 training time: 17.653
---------------
2023-09-24 02:47:55.209786
current #epochs=5, #steps=160
start validation
acc: 0.837321
AUC: 0.882409
Avg Precision: 0.398691
Avg Recall: 1.000000
d_prime: 1.678834
train_loss: 0.092322
valid_loss: 1.069057
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0015726223876324763
Epoch-5 lr: 0.006290489550529905
epoch 5 training time: 15.341
---------------
2023-09-24 02:48:10.550458
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04020	Per Sample Data Time 0.03092	Per Sample DNN Time 0.00928	Train Loss 0.1024	
start validation
acc: 0.851675
AUC: 0.917709
Avg Precision: 0.390192
Avg Recall: 1.000000
d_prime: 1.965509
train_loss: 0.075918
valid_loss: 1.042017
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0015726223876324763
Epoch-6 lr: 0.006290489550529905
epoch 6 training time: 15.228
---------------
2023-09-24 02:48:25.778633
current #epochs=7, #steps=240
start validation
acc: 0.889952
AUC: 0.887684
Avg Precision: 0.445649
Avg Recall: 1.000000
d_prime: 1.717288
train_loss: 0.089769
valid_loss: 1.076458
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0015726223876324763
Epoch-7 lr: 0.006290489550529905
epoch 7 training time: 17.635
---------------
2023-09-24 02:48:43.413813
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00710	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00552	Train Loss 0.0889	
start validation
acc: 0.842105
AUC: 0.879746
Avg Precision: 0.403120
Avg Recall: 1.000000
d_prime: 1.659886
train_loss: 0.084227
valid_loss: 1.074576
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0015726223876324763
Epoch-8 lr: 0.006290489550529905
epoch 8 training time: 15.188
---------------
2023-09-24 02:48:58.601805
current #epochs=9, #steps=320
start validation
acc: 0.818182
AUC: 0.899580
Avg Precision: 0.388527
Avg Recall: 1.000000
d_prime: 1.809008
train_loss: 0.078618
valid_loss: 1.077240
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.001117478367009667
Epoch-9 lr: 0.004469913468038668
epoch 9 training time: 15.369
---------------
2023-09-24 02:49:13.971051
current #epochs=10, #steps=360
start validation
acc: 0.813397
AUC: 0.902034
Avg Precision: 0.384067
Avg Recall: 1.000000
d_prime: 1.828901
train_loss: 0.074688
valid_loss: 1.085099
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.001117478367009667
Epoch-10 lr: 0.004469913468038668
epoch 10 training time: 15.225
---------------
2023-09-24 02:49:29.195821
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04092	Per Sample Data Time 0.03004	Per Sample DNN Time 0.01088	Train Loss 0.0214	
start validation
acc: 0.842105
AUC: 0.907949
Avg Precision: 0.382183
Avg Recall: 1.000000
d_prime: 1.878403
train_loss: 0.064244
valid_loss: 1.070423
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.001117478367009667
Epoch-11 lr: 0.004469913468038668
epoch 11 training time: 15.393
---------------
2023-09-24 02:49:44.588570
current #epochs=12, #steps=440
start validation
acc: 0.846890
AUC: 0.905179
Avg Precision: 0.399308
Avg Recall: 1.000000
d_prime: 1.854940
train_loss: 0.068735
valid_loss: 1.068423
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.001117478367009667
Epoch-12 lr: 0.004469913468038668
epoch 12 training time: 15.328
---------------
2023-09-24 02:49:59.916377
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00565	Train Loss 0.0735	
start validation
acc: 0.856459
AUC: 0.890274
Avg Precision: 0.389026
Avg Recall: 1.000000
d_prime: 1.736637
train_loss: 0.082109
valid_loss: 1.075437
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.001117478367009667
Epoch-13 lr: 0.004469913468038668
epoch 13 training time: 15.253
---------------
2023-09-24 02:50:15.169167
current #epochs=14, #steps=520
start validation
acc: 0.822967
AUC: 0.900975
Avg Precision: 0.407220
Avg Recall: 1.000000
d_prime: 1.820272
train_loss: 0.069853
valid_loss: 1.071142
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.001117478367009667
Epoch-14 lr: 0.004469913468038668
epoch 14 training time: 15.690
---------------
2023-09-24 02:50:30.859395
current #epochs=15, #steps=560
start validation
acc: 0.861244
AUC: 0.895783
Avg Precision: 0.408276
Avg Recall: 1.000000
d_prime: 1.778916
train_loss: 0.067553
valid_loss: 1.071597
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.001117478367009667
Epoch-15 lr: 0.004469913468038668
epoch 15 training time: 15.322
---------------
2023-09-24 02:50:46.181426
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04118	Per Sample Data Time 0.03227	Per Sample DNN Time 0.00890	Train Loss 0.1276	
start validation
acc: 0.822967
AUC: 0.879650
Avg Precision: 0.376221
Avg Recall: 1.000000
d_prime: 1.659209
train_loss: 0.120498
valid_loss: 1.118266
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.001117478367009667
Epoch-16 lr: 0.004469913468038668
epoch 16 training time: 15.324
---------------
2023-09-24 02:51:01.504720
current #epochs=17, #steps=640
start validation
acc: 0.818182
AUC: 0.868843
Avg Precision: 0.384851
Avg Recall: 1.000000
d_prime: 1.585244
train_loss: 0.119189
valid_loss: 1.109831
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.001117478367009667
Epoch-17 lr: 0.004469913468038668
epoch 17 training time: 15.306
---------------
2023-09-24 02:51:16.810692
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00154	Per Sample DNN Time 0.00562	Train Loss 0.0770	
start validation
acc: 0.822967
AUC: 0.895693
Avg Precision: 0.416872
Avg Recall: 1.000000
d_prime: 1.778209
train_loss: 0.078982
valid_loss: 1.072329
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.001117478367009667
Epoch-18 lr: 0.004469913468038668
epoch 18 training time: 15.246
---------------
2023-09-24 02:51:32.057100
current #epochs=19, #steps=720
start validation
acc: 0.799043
AUC: 0.888004
Avg Precision: 0.390210
Avg Recall: 1.000000
d_prime: 1.719658
train_loss: 0.080666
valid_loss: 1.098383
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0007940608696373388
Epoch-19 lr: 0.003176243478549355
epoch 19 training time: 15.334
---------------
2023-09-24 02:51:47.391540
current #epochs=20, #steps=760
start validation
acc: 0.799043
AUC: 0.888193
Avg Precision: 0.385618
Avg Recall: 1.000000
d_prime: 1.721065
train_loss: 0.063542
valid_loss: 1.070594
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0007940608696373388
Epoch-20 lr: 0.003176243478549355
epoch 20 training time: 15.281
---------------
2023-09-24 02:52:02.672266
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04182	Per Sample Data Time 0.03197	Per Sample DNN Time 0.00984	Train Loss 0.0335	
start validation
acc: 0.808612
AUC: 0.880626
Avg Precision: 0.372589
Avg Recall: 1.000000
d_prime: 1.666118
train_loss: 0.093403
valid_loss: 1.084628
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0007940608696373388
Epoch-21 lr: 0.003176243478549355
epoch 21 training time: 15.421
---------------
2023-09-24 02:52:18.093627
current #epochs=22, #steps=840
start validation
[I 2023-09-24 02:52:33,415] Trial 77 finished with value: 0.3791774922328332 and parameters: {'warmup': 'True', 'num_epochs': 22, 'batch_size': 23, 'lr-adaptschedule': 'False', 'lr': 0.0015726223876324763, 'head-lr': 4, 'lr-scheduler-start': 9, 'lr-scheduler-step': 10, 'lr-scheduler-decay': 0.7105827665928046}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.813397
AUC: 0.872204
Avg Precision: 0.379177
Avg Recall: 1.000000
d_prime: 1.607781
train_loss: 0.075473
valid_loss: 1.072943
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0007940608696373388
Epoch-22 lr: 0.003176243478549355
epoch 22 training time: 15.309
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc098301c0>
The learning rate scheduler starts at 10 epoch with decay rate of 0.743 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 02:52:33.454822
current #epochs=1, #steps=0
start validation
acc: 0.808612
AUC: 0.852328
Avg Precision: 0.302339
Avg Recall: 1.000000
d_prime: 1.479933
train_loss: 0.101425
valid_loss: 1.108476
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0018294401416683369
Epoch-1 lr: 0.005488320425005011
epoch 1 training time: 18.020
---------------
2023-09-24 02:52:51.475472
current #epochs=2, #steps=40
start validation
acc: 0.784689
AUC: 0.903204
Avg Precision: 0.385359
Avg Recall: 1.000000
d_prime: 1.838518
train_loss: 0.122721
valid_loss: 1.078804
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0018294401416683369
Epoch-2 lr: 0.005488320425005011
epoch 2 training time: 15.172
---------------
2023-09-24 02:53:06.647040
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00558	Train Loss 0.0939	
start validation
acc: 0.837321
AUC: 0.902967
Avg Precision: 0.417317
Avg Recall: 1.000000
d_prime: 1.836563
train_loss: 0.083796
valid_loss: 1.083698
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0018294401416683369
Epoch-3 lr: 0.005488320425005011
epoch 3 training time: 17.702
---------------
2023-09-24 02:53:24.348868
current #epochs=4, #steps=120
start validation
acc: 0.842105
AUC: 0.879978
Avg Precision: 0.403482
Avg Recall: 1.000000
d_prime: 1.661524
train_loss: 0.102476
valid_loss: 1.079747
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0018294401416683369
Epoch-4 lr: 0.005488320425005011
epoch 4 training time: 17.718
---------------
2023-09-24 02:53:42.067215
current #epochs=5, #steps=160
start validation
acc: 0.808612
AUC: 0.904473
Avg Precision: 0.356316
Avg Recall: 1.000000
d_prime: 1.849042
train_loss: 0.132351
valid_loss: 1.099080
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0018294401416683369
Epoch-5 lr: 0.005488320425005011
epoch 5 training time: 15.304
---------------
2023-09-24 02:53:57.371607
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03844	Per Sample Data Time 0.03055	Per Sample DNN Time 0.00790	Train Loss 0.1855	
start validation
acc: 0.813397
AUC: 0.908376
Avg Precision: 0.402272
Avg Recall: 1.000000
d_prime: 1.882063
train_loss: 0.110420
valid_loss: 1.076794
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0018294401416683369
Epoch-6 lr: 0.005488320425005011
epoch 6 training time: 15.333
---------------
2023-09-24 02:54:12.704782
current #epochs=7, #steps=240
start validation
acc: 0.827751
AUC: 0.902383
Avg Precision: 0.404486
Avg Recall: 1.000000
d_prime: 1.831764
train_loss: 0.111235
valid_loss: 1.081661
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0018294401416683369
Epoch-7 lr: 0.005488320425005011
epoch 7 training time: 15.548
---------------
2023-09-24 02:54:28.252772
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00165	Per Sample DNN Time 0.00554	Train Loss 0.0967	
start validation
acc: 0.889952
AUC: 0.911281
Avg Precision: 0.390114
Avg Recall: 1.000000
d_prime: 1.907326
train_loss: 0.098387
valid_loss: 1.060874
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0018294401416683369
Epoch-8 lr: 0.005488320425005011
epoch 8 training time: 17.971
---------------
2023-09-24 02:54:46.223685
current #epochs=9, #steps=320
start validation
acc: 0.827751
AUC: 0.905826
Avg Precision: 0.388948
Avg Recall: 1.000000
d_prime: 1.860373
train_loss: 0.098717
valid_loss: 1.085805
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0018294401416683369
Epoch-9 lr: 0.005488320425005011
epoch 9 training time: 15.253
---------------
2023-09-24 02:55:01.476555
current #epochs=10, #steps=360
start validation
acc: 0.861244
AUC: 0.904793
Avg Precision: 0.412450
Avg Recall: 1.000000
d_prime: 1.851706
train_loss: 0.085030
valid_loss: 1.069190
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0013594884630261223
Epoch-10 lr: 0.0040784653890783675
epoch 10 training time: 15.291
---------------
2023-09-24 02:55:16.767292
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03729	Per Sample Data Time 0.03059	Per Sample DNN Time 0.00670	Train Loss 0.0188	
start validation
acc: 0.837321
AUC: 0.915074
Avg Precision: 0.397016
Avg Recall: 1.000000
d_prime: 1.941260
train_loss: 0.062559
valid_loss: 1.066599
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0013594884630261223
Epoch-11 lr: 0.0040784653890783675
epoch 11 training time: 15.198
---------------
2023-09-24 02:55:31.964751
current #epochs=12, #steps=440
start validation
acc: 0.794258
AUC: 0.907356
Avg Precision: 0.378612
Avg Recall: 1.000000
d_prime: 1.873335
train_loss: 0.086315
valid_loss: 1.088602
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0013594884630261223
Epoch-12 lr: 0.0040784653890783675
epoch 12 training time: 15.287
---------------
2023-09-24 02:55:47.252522
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00711	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00556	Train Loss 0.0648	
start validation
acc: 0.837321
AUC: 0.887224
Avg Precision: 0.340668
Avg Recall: 1.000000
d_prime: 1.713879
train_loss: 0.066554
valid_loss: 1.078010
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0013594884630261223
Epoch-13 lr: 0.0040784653890783675
epoch 13 training time: 15.282
---------------
2023-09-24 02:56:02.534577
current #epochs=14, #steps=520
start validation
acc: 0.846890
AUC: 0.908476
Avg Precision: 0.378972
Avg Recall: 1.000000
d_prime: 1.882927
train_loss: 0.070964
valid_loss: 1.078610
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0013594884630261223
Epoch-14 lr: 0.0040784653890783675
epoch 14 training time: 15.164
---------------
2023-09-24 02:56:17.698745
current #epochs=15, #steps=560
start validation
acc: 0.837321
AUC: 0.904076
Avg Precision: 0.354283
Avg Recall: 1.000000
d_prime: 1.845739
train_loss: 0.074323
valid_loss: 1.058186
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0013594884630261223
Epoch-15 lr: 0.0040784653890783675
epoch 15 training time: 15.400
---------------
2023-09-24 02:56:33.099394
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04085	Per Sample Data Time 0.03195	Per Sample DNN Time 0.00891	Train Loss 0.0334	
start validation
acc: 0.799043
AUC: 0.915214
Avg Precision: 0.381204
Avg Recall: 1.000000
d_prime: 1.942537
train_loss: 0.075283
valid_loss: 1.074447
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0013594884630261223
Epoch-16 lr: 0.0040784653890783675
epoch 16 training time: 15.277
---------------
2023-09-24 02:56:48.376281
current #epochs=17, #steps=640
start validation
[I 2023-09-24 02:57:04,848] Trial 78 finished with value: 0.40711064586356865 and parameters: {'warmup': 'True', 'num_epochs': 17, 'batch_size': 13, 'lr-adaptschedule': 'False', 'lr': 0.0018294401416683369, 'head-lr': 3, 'lr-scheduler-start': 10, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.7431172149673902}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.861244
AUC: 0.916301
Avg Precision: 0.407111
Avg Recall: 1.000000
d_prime: 1.952480
train_loss: 0.081975
valid_loss: 1.067306
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0013594884630261223
Epoch-17 lr: 0.0040784653890783675
epoch 17 training time: 16.460
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 5 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0983e370>
The learning rate scheduler starts at 9 epoch with decay rate of 0.720 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 02:57:04.887825
current #epochs=1, #steps=0
start validation
acc: 0.803828
AUC: 0.911077
Avg Precision: 0.392487
Avg Recall: 1.000000
d_prime: 1.905539
train_loss: 0.180148
valid_loss: 1.109425
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0021417855409620636
Epoch-1 lr: 0.010708927704810318
epoch 1 training time: 17.680
---------------
2023-09-24 02:57:22.568574
current #epochs=2, #steps=40
start validation
acc: 0.851675
AUC: 0.887311
Avg Precision: 0.424712
Avg Recall: 1.000000
d_prime: 1.714524
train_loss: 0.120596
valid_loss: 1.077751
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0021417855409620636
Epoch-2 lr: 0.010708927704810318
epoch 2 training time: 17.699
---------------
2023-09-24 02:57:40.267229
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00712	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00557	Train Loss 0.0961	
start validation
acc: 0.803828
AUC: 0.894568
Avg Precision: 0.342763
Avg Recall: 1.000000
d_prime: 1.769453
train_loss: 0.098005
valid_loss: 1.091391
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0021417855409620636
Epoch-3 lr: 0.010708927704810318
epoch 3 training time: 15.203
---------------
2023-09-24 02:57:55.470278
current #epochs=4, #steps=120
start validation
acc: 0.822967
AUC: 0.881237
Avg Precision: 0.358285
Avg Recall: 1.000000
d_prime: 1.670456
train_loss: 0.115391
valid_loss: 1.095196
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0021417855409620636
Epoch-4 lr: 0.010708927704810318
epoch 4 training time: 15.397
---------------
2023-09-24 02:58:10.867763
current #epochs=5, #steps=160
start validation
acc: 0.808612
AUC: 0.885626
Avg Precision: 0.369783
Avg Recall: 1.000000
d_prime: 1.702136
train_loss: 0.160272
valid_loss: 1.104673
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0021417855409620636
Epoch-5 lr: 0.010708927704810318
epoch 5 training time: 15.313
---------------
2023-09-24 02:58:26.180396
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03979	Per Sample Data Time 0.02963	Per Sample DNN Time 0.01016	Train Loss 0.0656	
start validation
acc: 0.818182
AUC: 0.896759
Avg Precision: 0.383717
Avg Recall: 1.000000
d_prime: 1.786570
train_loss: 0.164840
valid_loss: 1.099038
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0021417855409620636
Epoch-6 lr: 0.010708927704810318
epoch 6 training time: 15.503
---------------
2023-09-24 02:58:41.683684
current #epochs=7, #steps=240
start validation
acc: 0.818182
AUC: 0.899374
Avg Precision: 0.335169
Avg Recall: 1.000000
d_prime: 1.807352
train_loss: 0.171696
valid_loss: 1.094534
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0021417855409620636
Epoch-7 lr: 0.010708927704810318
epoch 7 training time: 15.338
---------------
2023-09-24 02:58:57.021744
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00562	Train Loss 0.1048	
start validation
acc: 0.846890
AUC: 0.904237
Avg Precision: 0.409293
Avg Recall: 1.000000
d_prime: 1.847075
train_loss: 0.121356
valid_loss: 1.071570
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0021417855409620636
Epoch-8 lr: 0.010708927704810318
epoch 8 training time: 15.296
---------------
2023-09-24 02:59:12.317683
current #epochs=9, #steps=320
start validation
acc: 0.818182
AUC: 0.873982
Avg Precision: 0.354671
Avg Recall: 1.000000
d_prime: 1.619867
train_loss: 0.150331
valid_loss: 1.102301
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.001541514945224393
Epoch-9 lr: 0.0077075747261219655
epoch 9 training time: 15.224
---------------
2023-09-24 02:59:27.542297
current #epochs=10, #steps=360
start validation
acc: 0.846890
AUC: 0.881720
Avg Precision: 0.407362
Avg Recall: 1.000000
d_prime: 1.673903
train_loss: 0.136541
valid_loss: 1.093697
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.001541514945224393
Epoch-10 lr: 0.0077075747261219655
epoch 10 training time: 15.404
---------------
2023-09-24 02:59:42.946801
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04069	Per Sample Data Time 0.03068	Per Sample DNN Time 0.01001	Train Loss 0.0525	
start validation
acc: 0.846890
AUC: 0.872810
Avg Precision: 0.389670
Avg Recall: 1.000000
d_prime: 1.611887
train_loss: 0.167226
valid_loss: 1.105157
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.001541514945224393
Epoch-11 lr: 0.0077075747261219655
epoch 11 training time: 15.385
---------------
2023-09-24 02:59:58.331598
current #epochs=12, #steps=440
start validation
acc: 0.813397
AUC: 0.893394
Avg Precision: 0.377793
Avg Recall: 1.000000
d_prime: 1.760389
train_loss: 0.131175
valid_loss: 1.097136
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.001541514945224393
Epoch-12 lr: 0.0077075747261219655
epoch 12 training time: 16.187
---------------
2023-09-24 03:00:14.518288
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00727	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00569	Train Loss 0.1431	
start validation
acc: 0.770335
AUC: 0.869507
Avg Precision: 0.349211
Avg Recall: 1.000000
d_prime: 1.589668
train_loss: 0.139271
valid_loss: 1.145507
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.001541514945224393
Epoch-13 lr: 0.0077075747261219655
epoch 13 training time: 15.453
---------------
2023-09-24 03:00:29.971229
current #epochs=14, #steps=520
start validation
acc: 0.741627
AUC: 0.797012
Avg Precision: 0.302020
Avg Recall: 1.000000
d_prime: 1.175203
train_loss: 0.181338
valid_loss: 1.167445
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.001541514945224393
Epoch-14 lr: 0.0077075747261219655
epoch 14 training time: 15.397
---------------
2023-09-24 03:00:45.368696
current #epochs=15, #steps=560
start validation
acc: 0.779904
AUC: 0.853071
Avg Precision: 0.319612
Avg Recall: 1.000000
d_prime: 1.484495
train_loss: 0.266907
valid_loss: 1.128585
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.001541514945224393
Epoch-15 lr: 0.0077075747261219655
epoch 15 training time: 15.386
---------------
2023-09-24 03:01:00.754807
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03916	Per Sample Data Time 0.02942	Per Sample DNN Time 0.00973	Train Loss 0.4244	
start validation
acc: 0.846890
AUC: 0.881662
Avg Precision: 0.350913
Avg Recall: 1.000000
d_prime: 1.673490
train_loss: 0.199325
valid_loss: 1.077098
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.001541514945224393
Epoch-16 lr: 0.0077075747261219655
epoch 16 training time: 15.180
---------------
2023-09-24 03:01:15.934601
current #epochs=17, #steps=640
start validation
acc: 0.789474
AUC: 0.890091
Avg Precision: 0.334853
Avg Recall: 1.000000
d_prime: 1.735258
train_loss: 0.245124
valid_loss: 1.139236
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.001541514945224393
Epoch-17 lr: 0.0077075747261219655
epoch 17 training time: 15.362
---------------
2023-09-24 03:01:31.296304
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00735	Per Sample Data Time 0.00167	Per Sample DNN Time 0.00568	Train Loss 0.2239	
start validation
acc: 0.760766
AUC: 0.867092
Avg Precision: 0.322736
Avg Recall: 1.000000
d_prime: 1.573667
train_loss: 0.229177
valid_loss: 1.128466
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0011094800487273684
Epoch-18 lr: 0.0055474002436368425
epoch 18 training time: 15.473
---------------
2023-09-24 03:01:46.769966
current #epochs=19, #steps=720
start validation
acc: 0.813397
AUC: 0.860189
Avg Precision: 0.325667
Avg Recall: 1.000000
d_prime: 1.529001
train_loss: 0.255315
valid_loss: 1.107780
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0011094800487273684
Epoch-19 lr: 0.0055474002436368425
epoch 19 training time: 15.406
---------------
2023-09-24 03:02:02.176222
current #epochs=20, #steps=760
start validation
acc: 0.770335
AUC: 0.860964
Avg Precision: 0.338297
Avg Recall: 1.000000
d_prime: 1.533939
train_loss: 0.195496
valid_loss: 1.114048
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0011094800487273684
Epoch-20 lr: 0.0055474002436368425
epoch 20 training time: 15.377
---------------
2023-09-24 03:02:17.552815
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03987	Per Sample Data Time 0.03001	Per Sample DNN Time 0.00986	Train Loss 0.1353	
start validation
acc: 0.818182
AUC: 0.891365
Avg Precision: 0.378972
Avg Recall: 1.000000
d_prime: 1.744888
train_loss: 0.197913
valid_loss: 1.083060
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0011094800487273684
Epoch-21 lr: 0.0055474002436368425
epoch 21 training time: 15.295
---------------
2023-09-24 03:02:32.848559
current #epochs=22, #steps=840
start validation
acc: 0.770335
AUC: 0.880375
Avg Precision: 0.347412
Avg Recall: 1.000000
d_prime: 1.664339
train_loss: 0.172865
valid_loss: 1.087518
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0011094800487273684
Epoch-22 lr: 0.0055474002436368425
epoch 22 training time: 15.398
---------------
2023-09-24 03:02:48.246949
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00562	Train Loss 0.1667	
start validation
acc: 0.808612
AUC: 0.869247
Avg Precision: 0.353495
Avg Recall: 1.000000
d_prime: 1.587933
train_loss: 0.158709
valid_loss: 1.099703
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0011094800487273684
Epoch-23 lr: 0.0055474002436368425
epoch 23 training time: 15.257
---------------
2023-09-24 03:03:03.504031
current #epochs=24, #steps=920
start validation
acc: 0.779904
AUC: 0.867034
Avg Precision: 0.336007
Avg Recall: 1.000000
d_prime: 1.573287
train_loss: 0.150237
valid_loss: 1.096951
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0011094800487273684
Epoch-24 lr: 0.0055474002436368425
epoch 24 training time: 15.876
---------------
2023-09-24 03:03:19.379605
current #epochs=25, #steps=960
start validation
[I 2023-09-24 03:03:34,739] Trial 79 finished with value: 0.3499582548063443 and parameters: {'warmup': 'True', 'num_epochs': 25, 'batch_size': 15, 'lr-adaptschedule': 'False', 'lr': 0.0021417855409620636, 'head-lr': 5, 'lr-scheduler-start': 9, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.7197335661029646}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.827751
AUC: 0.887504
Avg Precision: 0.349958
Avg Recall: 1.000000
d_prime: 1.715954
train_loss: 0.152148
valid_loss: 1.076825
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.0011094800487273684
Epoch-25 lr: 0.0055474002436368425
epoch 25 training time: 15.350
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 2 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51d88a60>
The learning rate scheduler starts at 9 epoch with decay rate of 0.734 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 03:03:34.779212
current #epochs=1, #steps=0
start validation
acc: 0.813397
AUC: 0.872514
Avg Precision: 0.336623
Avg Recall: 1.000000
d_prime: 1.609875
train_loss: 0.195916
valid_loss: 1.110421
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.002477956888180563
Epoch-1 lr: 0.004955913776361126
epoch 1 training time: 17.680
---------------
2023-09-24 03:03:52.459249
current #epochs=2, #steps=40
start validation
acc: 0.818182
AUC: 0.851545
Avg Precision: 0.358023
Avg Recall: 1.000000
d_prime: 1.475144
train_loss: 0.201818
valid_loss: 1.118107
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.002477956888180563
Epoch-2 lr: 0.004955913776361126
epoch 2 training time: 17.579
---------------
2023-09-24 03:04:10.038682
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00559	Train Loss 0.1589	
start validation
acc: 0.770335
AUC: 0.861145
Avg Precision: 0.335139
Avg Recall: 1.000000
d_prime: 1.535100
train_loss: 0.152394
valid_loss: 1.117216
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.002477956888180563
Epoch-3 lr: 0.004955913776361126
epoch 3 training time: 15.265
---------------
2023-09-24 03:04:25.303696
current #epochs=4, #steps=120
start validation
acc: 0.803828
AUC: 0.860488
Avg Precision: 0.364506
Avg Recall: 1.000000
d_prime: 1.530908
train_loss: 0.189515
valid_loss: 1.124073
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.002477956888180563
Epoch-4 lr: 0.004955913776361126
epoch 4 training time: 15.398
---------------
2023-09-24 03:04:40.701302
current #epochs=5, #steps=160
start validation
acc: 0.875598
AUC: 0.863423
Avg Precision: 0.315444
Avg Recall: 1.000000
d_prime: 1.549732
train_loss: 0.242647
valid_loss: 1.112795
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.002477956888180563
Epoch-5 lr: 0.004955913776361126
epoch 5 training time: 17.720
---------------
2023-09-24 03:04:58.421715
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04105	Per Sample Data Time 0.03038	Per Sample DNN Time 0.01068	Train Loss 0.1880	
start validation
acc: 0.770335
AUC: 0.860874
Avg Precision: 0.366424
Avg Recall: 1.000000
d_prime: 1.533367
train_loss: 0.188544
valid_loss: 1.126391
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.002477956888180563
Epoch-6 lr: 0.004955913776361126
epoch 6 training time: 15.358
---------------
2023-09-24 03:05:13.780071
current #epochs=7, #steps=240
start validation
acc: 0.765550
AUC: 0.839961
Avg Precision: 0.324418
Avg Recall: 1.000000
d_prime: 1.406147
train_loss: 0.175711
valid_loss: 1.138410
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.002477956888180563
Epoch-7 lr: 0.004955913776361126
epoch 7 training time: 15.224
---------------
2023-09-24 03:05:29.004271
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00155	Per Sample DNN Time 0.00561	Train Loss 0.2225	
start validation
acc: 0.765550
AUC: 0.889249
Avg Precision: 0.335745
Avg Recall: 1.000000
d_prime: 1.728935
train_loss: 0.220522
valid_loss: 1.093570
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.002477956888180563
Epoch-8 lr: 0.004955913776361126
epoch 8 training time: 16.145
---------------
2023-09-24 03:05:45.149311
current #epochs=9, #steps=320
start validation
acc: 0.779904
AUC: 0.855244
Avg Precision: 0.338917
Avg Recall: 1.000000
d_prime: 1.497925
train_loss: 0.294076
valid_loss: 1.119810
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.001818964931189936
Epoch-9 lr: 0.003637929862379872
epoch 9 training time: 15.387
---------------
2023-09-24 03:06:00.536527
current #epochs=10, #steps=360
start validation
acc: 0.760766
AUC: 0.876997
Avg Precision: 0.351714
Avg Recall: 1.000000
d_prime: 1.640634
train_loss: 0.305756
valid_loss: 1.109950
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.001818964931189936
Epoch-10 lr: 0.003637929862379872
epoch 10 training time: 15.162
---------------
2023-09-24 03:06:15.698426
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04168	Per Sample Data Time 0.03204	Per Sample DNN Time 0.00964	Train Loss 0.3696	
start validation
acc: 0.789474
AUC: 0.860469
Avg Precision: 0.318467
Avg Recall: 1.000000
d_prime: 1.530784
train_loss: 0.303287
valid_loss: 1.102037
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.001818964931189936
Epoch-11 lr: 0.003637929862379872
epoch 11 training time: 15.401
---------------
2023-09-24 03:06:31.099642
current #epochs=12, #steps=440
start validation
acc: 0.698565
AUC: 0.841923
Avg Precision: 0.318738
Avg Recall: 1.000000
d_prime: 1.417597
train_loss: 0.283414
valid_loss: 1.150928
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.001818964931189936
Epoch-12 lr: 0.003637929862379872
epoch 12 training time: 15.333
---------------
2023-09-24 03:06:46.432488
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00153	Per Sample DNN Time 0.00563	Train Loss 0.3238	
start validation
acc: 0.751196
AUC: 0.821392
Avg Precision: 0.325972
Avg Recall: 1.000000
d_prime: 1.302045
train_loss: 0.370652
valid_loss: 1.168196
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.001818964931189936
Epoch-13 lr: 0.003637929862379872
epoch 13 training time: 15.328
---------------
2023-09-24 03:07:01.760722
current #epochs=14, #steps=520
start validation
acc: 0.784689
AUC: 0.870094
Avg Precision: 0.323365
Avg Recall: 1.000000
d_prime: 1.593587
train_loss: 0.391875
valid_loss: 1.125832
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.001818964931189936
Epoch-14 lr: 0.003637929862379872
epoch 14 training time: 15.429
---------------
2023-09-24 03:07:17.189706
current #epochs=15, #steps=560
start validation
acc: 0.755981
AUC: 0.840780
Avg Precision: 0.318022
Avg Recall: 1.000000
d_prime: 1.410918
train_loss: 0.301507
valid_loss: 1.137836
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.001818964931189936
Epoch-15 lr: 0.003637929862379872
epoch 15 training time: 16.508
---------------
2023-09-24 03:07:33.697231
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03972	Per Sample Data Time 0.02906	Per Sample DNN Time 0.01066	Train Loss 0.3989	
start validation
acc: 0.779904
AUC: 0.857711
Avg Precision: 0.331389
Avg Recall: 1.000000
d_prime: 1.513338
train_loss: 0.321806
valid_loss: 1.124914
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.001818964931189936
Epoch-16 lr: 0.003637929862379872
epoch 16 training time: 15.224
---------------
2023-09-24 03:07:48.921267
current #epochs=17, #steps=640
start validation
acc: 0.789474
AUC: 0.839209
Avg Precision: 0.326566
Avg Recall: 1.000000
d_prime: 1.401786
train_loss: 0.357596
valid_loss: 1.143603
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0013352263861733968
Epoch-17 lr: 0.0026704527723467935
epoch 17 training time: 15.303
---------------
2023-09-24 03:08:04.224048
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00562	Train Loss 0.4057	
start validation
acc: 0.789474
AUC: 0.815621
Avg Precision: 0.300381
Avg Recall: 1.000000
d_prime: 1.271098
train_loss: 0.388238
valid_loss: 1.185334
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0013352263861733968
Epoch-18 lr: 0.0026704527723467935
epoch 18 training time: 15.284
---------------
2023-09-24 03:08:19.508048
current #epochs=19, #steps=720
start validation
acc: 0.784689
AUC: 0.845443
Avg Precision: 0.301084
Avg Recall: 1.000000
d_prime: 1.438375
train_loss: 0.280091
valid_loss: 1.137142
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0013352263861733968
Epoch-19 lr: 0.0026704527723467935
epoch 19 training time: 15.333
---------------
2023-09-24 03:08:34.840897
current #epochs=20, #steps=760
start validation
acc: 0.808612
AUC: 0.855227
Avg Precision: 0.305487
Avg Recall: 1.000000
d_prime: 1.497820
train_loss: 0.275728
valid_loss: 1.119787
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0013352263861733968
Epoch-20 lr: 0.0026704527723467935
epoch 20 training time: 15.393
---------------
2023-09-24 03:08:50.233889
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04048	Per Sample Data Time 0.03000	Per Sample DNN Time 0.01048	Train Loss 0.1606	
start validation
[I 2023-09-24 03:09:05,581] Trial 80 finished with value: 0.30994305306293063 and parameters: {'warmup': 'True', 'num_epochs': 21, 'batch_size': 9, 'lr-adaptschedule': 'False', 'lr': 0.002477956888180563, 'head-lr': 2, 'lr-scheduler-start': 9, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.7340583445442866}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.827751
AUC: 0.864163
Avg Precision: 0.309943
Avg Recall: 1.000000
d_prime: 1.554527
train_loss: 0.253881
valid_loss: 1.116168
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0013352263861733968
Epoch-21 lr: 0.0026704527723467935
epoch 21 training time: 15.336
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51df1880>
The learning rate scheduler starts at 9 epoch with decay rate of 0.702 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 03:09:05.619926
current #epochs=1, #steps=0
start validation
acc: 0.775120
AUC: 0.831150
Avg Precision: 0.313382
Avg Recall: 1.000000
d_prime: 1.355837
train_loss: 0.269341
valid_loss: 1.148083
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0015176571913769644
Epoch-1 lr: 0.006070628765507857
epoch 1 training time: 18.112
---------------
2023-09-24 03:09:23.732817
current #epochs=2, #steps=40
start validation
acc: 0.784689
AUC: 0.860575
Avg Precision: 0.321739
Avg Recall: 1.000000
d_prime: 1.531459
train_loss: 0.230101
valid_loss: 1.118836
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0015176571913769644
Epoch-2 lr: 0.006070628765507857
epoch 2 training time: 19.332
---------------
2023-09-24 03:09:43.067011
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00712	Per Sample Data Time 0.00154	Per Sample DNN Time 0.00559	Train Loss 0.2654	
start validation
acc: 0.789474
AUC: 0.834865
Avg Precision: 0.322387
Avg Recall: 1.000000
d_prime: 1.376838
train_loss: 0.254656
valid_loss: 1.132333
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0015176571913769644
Epoch-3 lr: 0.006070628765507857
epoch 3 training time: 17.696
---------------
2023-09-24 03:10:00.760854
current #epochs=4, #steps=120
start validation
acc: 0.794258
AUC: 0.836382
Avg Precision: 0.327406
Avg Recall: 1.000000
d_prime: 1.385501
train_loss: 0.223632
valid_loss: 1.126720
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0015176571913769644
Epoch-4 lr: 0.006070628765507857
epoch 4 training time: 17.716
---------------
2023-09-24 03:10:18.476575
current #epochs=5, #steps=160
start validation
acc: 0.712919
AUC: 0.831972
Avg Precision: 0.320160
Avg Recall: 1.000000
d_prime: 1.360456
train_loss: 0.205681
valid_loss: 1.138427
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0015176571913769644
Epoch-5 lr: 0.006070628765507857
epoch 5 training time: 15.279
---------------
2023-09-24 03:10:33.755694
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03848	Per Sample Data Time 0.03126	Per Sample DNN Time 0.00722	Train Loss 0.2454	
start validation
acc: 0.794258
AUC: 0.862621
Avg Precision: 0.344533
Avg Recall: 1.000000
d_prime: 1.544563
train_loss: 0.213089
valid_loss: 1.110918
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0015176571913769644
Epoch-6 lr: 0.006070628765507857
epoch 6 training time: 15.326
---------------
2023-09-24 03:10:49.082069
current #epochs=7, #steps=240
start validation
acc: 0.799043
AUC: 0.879399
Avg Precision: 0.350173
Avg Recall: 1.000000
d_prime: 1.657444
train_loss: 0.232922
valid_loss: 1.104730
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0015176571913769644
Epoch-7 lr: 0.006070628765507857
epoch 7 training time: 18.990
---------------
2023-09-24 03:11:08.071851
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00561	Train Loss 0.2439	
start validation
acc: 0.751196
AUC: 0.834970
Avg Precision: 0.316309
Avg Recall: 1.000000
d_prime: 1.377434
train_loss: 0.251512
valid_loss: 1.137770
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0015176571913769644
Epoch-8 lr: 0.006070628765507857
epoch 8 training time: 16.426
---------------
2023-09-24 03:11:24.497975
current #epochs=9, #steps=320
start validation
acc: 0.808612
AUC: 0.830776
Avg Precision: 0.311987
Avg Recall: 1.000000
d_prime: 1.353735
train_loss: 0.307038
valid_loss: 1.153011
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0010657742818208174
Epoch-9 lr: 0.004263097127283269
epoch 9 training time: 17.719
---------------
2023-09-24 03:11:42.216949
current #epochs=10, #steps=360
start validation
acc: 0.741627
AUC: 0.813085
Avg Precision: 0.300148
Avg Recall: 1.000000
d_prime: 1.257694
train_loss: 0.276785
valid_loss: 1.181317
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0010657742818208174
Epoch-10 lr: 0.004263097127283269
epoch 10 training time: 15.493
---------------
2023-09-24 03:11:57.710347
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03733	Per Sample Data Time 0.03000	Per Sample DNN Time 0.00732	Train Loss 0.3995	
start validation
acc: 0.732057
AUC: 0.775372
Avg Precision: 0.307629
Avg Recall: 1.000000
d_prime: 1.070072
train_loss: 0.451258
valid_loss: 1.221312
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0010657742818208174
Epoch-11 lr: 0.004263097127283269
epoch 11 training time: 15.192
---------------
2023-09-24 03:12:12.902126
current #epochs=12, #steps=440
start validation
acc: 0.732057
AUC: 0.820260
Avg Precision: 0.302734
Avg Recall: 1.000000
d_prime: 1.295923
train_loss: 0.442383
valid_loss: 1.188171
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0010657742818208174
Epoch-12 lr: 0.004263097127283269
epoch 12 training time: 15.422
---------------
2023-09-24 03:12:28.324093
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00725	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00565	Train Loss 0.3877	
start validation
acc: 0.760766
AUC: 0.805144
Avg Precision: 0.316009
Avg Recall: 1.000000
d_prime: 1.216423
train_loss: 0.408056
valid_loss: 1.193602
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0010657742818208174
Epoch-13 lr: 0.004263097127283269
epoch 13 training time: 15.402
---------------
2023-09-24 03:12:43.726050
current #epochs=14, #steps=520
start validation
acc: 0.655502
AUC: 0.809834
Avg Precision: 0.309996
Avg Recall: 1.000000
d_prime: 1.240669
train_loss: 0.402930
valid_loss: 1.203319
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0010657742818208174
Epoch-14 lr: 0.004263097127283269
epoch 14 training time: 15.871
---------------
2023-09-24 03:12:59.597594
current #epochs=15, #steps=560
start validation
acc: 0.755981
AUC: 0.810130
Avg Precision: 0.308067
Avg Recall: 1.000000
d_prime: 1.242210
train_loss: 0.371325
valid_loss: 1.196281
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0010657742818208174
Epoch-15 lr: 0.004263097127283269
epoch 15 training time: 15.412
---------------
2023-09-24 03:13:15.009060
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04195	Per Sample Data Time 0.03223	Per Sample DNN Time 0.00972	Train Loss 0.3538	
start validation
[I 2023-09-24 03:13:30,416] Trial 81 finished with value: 0.30129095799294675 and parameters: {'warmup': 'True', 'num_epochs': 16, 'batch_size': 25, 'lr-adaptschedule': 'False', 'lr': 0.0015176571913769644, 'head-lr': 4, 'lr-scheduler-start': 9, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.7022496831803264}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.770335
AUC: 0.839381
Avg Precision: 0.301291
Avg Recall: 1.000000
d_prime: 1.402781
train_loss: 0.363584
valid_loss: 1.162784
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0010657742818208174
Epoch-16 lr: 0.004263097127283269
epoch 16 training time: 15.398
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51df1e50>
The learning rate scheduler starts at 8 epoch with decay rate of 0.659 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 03:13:30.456594
current #epochs=1, #steps=0
start validation
acc: 0.755981
AUC: 0.805649
Avg Precision: 0.291050
Avg Recall: 1.000000
d_prime: 1.219013
train_loss: 0.408736
valid_loss: 1.192142
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0016617052492723943
Epoch-1 lr: 0.006646820997089577
epoch 1 training time: 18.566
---------------
2023-09-24 03:13:49.022695
current #epochs=2, #steps=40
start validation
acc: 0.794258
AUC: 0.823323
Avg Precision: 0.308365
Avg Recall: 1.000000
d_prime: 1.312534
train_loss: 0.393734
valid_loss: 1.172522
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0016617052492723943
Epoch-2 lr: 0.006646820997089577
epoch 2 training time: 17.807
---------------
2023-09-24 03:14:06.829937
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00559	Train Loss 0.4387	
start validation
acc: 0.794258
AUC: 0.819562
Avg Precision: 0.317036
Avg Recall: 1.000000
d_prime: 1.292166
train_loss: 0.406899
valid_loss: 1.178479
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0016617052492723943
Epoch-3 lr: 0.006646820997089577
epoch 3 training time: 16.881
---------------
2023-09-24 03:14:23.710798
current #epochs=4, #steps=120
start validation
acc: 0.760766
AUC: 0.806296
Avg Precision: 0.315933
Avg Recall: 1.000000
d_prime: 1.222343
train_loss: 0.331032
valid_loss: 1.187169
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0016617052492723943
Epoch-4 lr: 0.006646820997089577
epoch 4 training time: 15.305
---------------
2023-09-24 03:14:39.016355
current #epochs=5, #steps=160
start validation
acc: 0.803828
AUC: 0.854755
Avg Precision: 0.323164
Avg Recall: 1.000000
d_prime: 1.494893
train_loss: 0.316166
valid_loss: 1.128016
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0016617052492723943
Epoch-5 lr: 0.006646820997089577
epoch 5 training time: 17.657
---------------
2023-09-24 03:14:56.673178
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03878	Per Sample Data Time 0.02920	Per Sample DNN Time 0.00958	Train Loss 0.1517	
start validation
acc: 0.760766
AUC: 0.810585
Avg Precision: 0.330463
Avg Recall: 1.000000
d_prime: 1.244586
train_loss: 0.302147
valid_loss: 1.172334
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0016617052492723943
Epoch-6 lr: 0.006646820997089577
epoch 6 training time: 15.172
---------------
2023-09-24 03:15:11.845227
current #epochs=7, #steps=240
start validation
acc: 0.808612
AUC: 0.842674
Avg Precision: 0.346930
Avg Recall: 1.000000
d_prime: 1.422002
train_loss: 0.275904
valid_loss: 1.132415
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0016617052492723943
Epoch-7 lr: 0.006646820997089577
epoch 7 training time: 17.710
---------------
2023-09-24 03:15:29.555224
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00715	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00559	Train Loss 0.2522	
start validation
acc: 0.770335
AUC: 0.799759
Avg Precision: 0.338036
Avg Recall: 1.000000
d_prime: 1.189014
train_loss: 0.285886
valid_loss: 1.170513
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0010953591728374216
Epoch-8 lr: 0.0043814366913496865
epoch 8 training time: 15.359
---------------
2023-09-24 03:15:44.914022
current #epochs=9, #steps=320
start validation
acc: 0.779904
AUC: 0.825889
Avg Precision: 0.333386
Avg Recall: 1.000000
d_prime: 1.326594
train_loss: 0.347865
valid_loss: 1.141485
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0010953591728374216
Epoch-9 lr: 0.0043814366913496865
epoch 9 training time: 15.355
---------------
2023-09-24 03:16:00.268843
current #epochs=10, #steps=360
start validation
acc: 0.760766
AUC: 0.821871
Avg Precision: 0.318390
Avg Recall: 1.000000
d_prime: 1.304638
train_loss: 0.311752
valid_loss: 1.160446
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0010953591728374216
Epoch-10 lr: 0.0043814366913496865
epoch 10 training time: 15.414
---------------
2023-09-24 03:16:15.683144
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03962	Per Sample Data Time 0.02966	Per Sample DNN Time 0.00995	Train Loss 0.2684	
start validation
acc: 0.794258
AUC: 0.824654
Avg Precision: 0.320488
Avg Recall: 1.000000
d_prime: 1.319812
train_loss: 0.306050
valid_loss: 1.151093
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0010953591728374216
Epoch-11 lr: 0.0043814366913496865
epoch 11 training time: 15.320
---------------
2023-09-24 03:16:31.003138
current #epochs=12, #steps=440
start validation
acc: 0.775120
AUC: 0.841146
Avg Precision: 0.322138
Avg Recall: 1.000000
d_prime: 1.413051
train_loss: 0.237498
valid_loss: 1.131487
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0010953591728374216
Epoch-12 lr: 0.0043814366913496865
epoch 12 training time: 15.401
---------------
2023-09-24 03:16:46.403724
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00563	Train Loss 0.2091	
start validation
acc: 0.784689
AUC: 0.819115
Avg Precision: 0.332088
Avg Recall: 1.000000
d_prime: 1.289762
train_loss: 0.245268
valid_loss: 1.159077
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0010953591728374216
Epoch-13 lr: 0.0043814366913496865
epoch 13 training time: 15.469
---------------
2023-09-24 03:17:01.872441
current #epochs=14, #steps=520
start validation
[I 2023-09-24 03:17:17,244] Trial 82 finished with value: 0.3352462730123334 and parameters: {'warmup': 'True', 'num_epochs': 14, 'batch_size': 17, 'lr-adaptschedule': 'False', 'lr': 0.0016617052492723943, 'head-lr': 4, 'lr-scheduler-start': 8, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.6591777773567503}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.775120
AUC: 0.816870
Avg Precision: 0.335246
Avg Recall: 1.000000
d_prime: 1.277741
train_loss: 0.263191
valid_loss: 1.166139
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0010953591728374216
Epoch-14 lr: 0.0043814366913496865
epoch 14 training time: 15.361
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51dc5cd0>
The learning rate scheduler starts at 9 epoch with decay rate of 0.694 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 03:17:17.284580
current #epochs=1, #steps=0
start validation
acc: 0.784689
AUC: 0.828161
Avg Precision: 0.330623
Avg Recall: 1.000000
d_prime: 1.339151
train_loss: 0.327749
valid_loss: 1.163295
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.002052411852962124
Epoch-1 lr: 0.008209647411848497
epoch 1 training time: 19.475
---------------
2023-09-24 03:17:36.759556
current #epochs=2, #steps=40
start validation
acc: 0.741627
AUC: 0.800778
Avg Precision: 0.319223
Avg Recall: 1.000000
d_prime: 1.194167
train_loss: 0.272961
valid_loss: 1.167587
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.002052411852962124
Epoch-2 lr: 0.008209647411848497
epoch 2 training time: 15.204
---------------
2023-09-24 03:17:51.963316
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00556	Train Loss 0.2520	
start validation
acc: 0.775120
AUC: 0.830091
Avg Precision: 0.332174
Avg Recall: 1.000000
d_prime: 1.349904
train_loss: 0.251597
valid_loss: 1.137456
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.002052411852962124
Epoch-3 lr: 0.008209647411848497
epoch 3 training time: 16.498
---------------
2023-09-24 03:18:08.461614
current #epochs=4, #steps=120
start validation
acc: 0.732057
AUC: 0.816013
Avg Precision: 0.324839
Avg Recall: 1.000000
d_prime: 1.273180
train_loss: 0.250630
valid_loss: 1.159482
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.002052411852962124
Epoch-4 lr: 0.008209647411848497
epoch 4 training time: 15.254
---------------
2023-09-24 03:18:23.715860
current #epochs=5, #steps=160
start validation
acc: 0.799043
AUC: 0.832290
Avg Precision: 0.329400
Avg Recall: 1.000000
d_prime: 1.362245
train_loss: 0.257817
valid_loss: 1.138666
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.002052411852962124
Epoch-5 lr: 0.008209647411848497
epoch 5 training time: 17.721
---------------
2023-09-24 03:18:41.436709
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04200	Per Sample Data Time 0.03079	Per Sample DNN Time 0.01121	Train Loss 0.2109	
start validation
acc: 0.755981
AUC: 0.867655
Avg Precision: 0.346292
Avg Recall: 1.000000
d_prime: 1.577380
train_loss: 0.233311
valid_loss: 1.124873
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.002052411852962124
Epoch-6 lr: 0.008209647411848497
epoch 6 training time: 15.374
---------------
2023-09-24 03:18:56.810829
current #epochs=7, #steps=240
start validation
acc: 0.741627
AUC: 0.806277
Avg Precision: 0.319188
Avg Recall: 1.000000
d_prime: 1.222248
train_loss: 0.235250
valid_loss: 1.174273
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.002052411852962124
Epoch-7 lr: 0.008209647411848497
epoch 7 training time: 15.276
---------------
2023-09-24 03:19:12.087027
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00730	Per Sample Data Time 0.00166	Per Sample DNN Time 0.00564	Train Loss 0.2934	
start validation
acc: 0.679426
AUC: 0.847739
Avg Precision: 0.346413
Avg Recall: 1.000000
d_prime: 1.452090
train_loss: 0.276875
valid_loss: 1.149319
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.002052411852962124
Epoch-8 lr: 0.008209647411848497
epoch 8 training time: 16.132
---------------
2023-09-24 03:19:28.219025
current #epochs=9, #steps=320
start validation
acc: 0.832536
AUC: 0.885426
Avg Precision: 0.392252
Avg Recall: 1.000000
d_prime: 1.700673
train_loss: 0.271551
valid_loss: 1.097426
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0014241417905844912
Epoch-9 lr: 0.005696567162337965
epoch 9 training time: 17.819
---------------
2023-09-24 03:19:46.037653
current #epochs=10, #steps=360
start validation
acc: 0.784689
AUC: 0.874499
Avg Precision: 0.344885
Avg Recall: 1.000000
d_prime: 1.623400
train_loss: 0.239956
valid_loss: 1.129331
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0014241417905844912
Epoch-10 lr: 0.005696567162337965
epoch 10 training time: 15.299
---------------
2023-09-24 03:20:01.336817
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03759	Per Sample Data Time 0.02929	Per Sample DNN Time 0.00831	Train Loss 0.1447	
start validation
acc: 0.645933
AUC: 0.845519
Avg Precision: 0.327395
Avg Recall: 1.000000
d_prime: 1.438824
train_loss: 0.243018
valid_loss: 1.136843
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0014241417905844912
Epoch-11 lr: 0.005696567162337965
epoch 11 training time: 15.248
---------------
2023-09-24 03:20:16.584884
current #epochs=12, #steps=440
start validation
acc: 0.813397
AUC: 0.894725
Avg Precision: 0.420995
Avg Recall: 1.000000
d_prime: 1.770671
train_loss: 0.272511
valid_loss: 1.098901
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0014241417905844912
Epoch-12 lr: 0.005696567162337965
epoch 12 training time: 16.374
---------------
2023-09-24 03:20:32.959100
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00563	Train Loss 0.2772	
start validation
acc: 0.813397
AUC: 0.856180
Avg Precision: 0.335712
Avg Recall: 1.000000
d_prime: 1.503753
train_loss: 0.267693
valid_loss: 1.136768
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0014241417905844912
Epoch-13 lr: 0.005696567162337965
epoch 13 training time: 15.340
---------------
2023-09-24 03:20:48.299122
current #epochs=14, #steps=520
start validation
acc: 0.727273
AUC: 0.823011
Avg Precision: 0.323908
Avg Recall: 1.000000
d_prime: 1.310834
train_loss: 0.297396
valid_loss: 1.165446
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0014241417905844912
Epoch-14 lr: 0.005696567162337965
epoch 14 training time: 16.562
---------------
2023-09-24 03:21:04.861528
current #epochs=15, #steps=560
start validation
acc: 0.803828
AUC: 0.858454
Avg Precision: 0.329965
Avg Recall: 1.000000
d_prime: 1.518016
train_loss: 0.235238
valid_loss: 1.114854
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0014241417905844912
Epoch-15 lr: 0.005696567162337965
epoch 15 training time: 15.252
---------------
2023-09-24 03:21:20.113631
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03984	Per Sample Data Time 0.03009	Per Sample DNN Time 0.00975	Train Loss 0.0827	
start validation
acc: 0.832536
AUC: 0.870038
Avg Precision: 0.341163
Avg Recall: 1.000000
d_prime: 1.593212
train_loss: 0.232275
valid_loss: 1.120917
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0014241417905844912
Epoch-16 lr: 0.005696567162337965
epoch 16 training time: 15.257
---------------
2023-09-24 03:21:35.370947
current #epochs=17, #steps=640
start validation
acc: 0.842105
AUC: 0.879234
Avg Precision: 0.380570
Avg Recall: 1.000000
d_prime: 1.656280
train_loss: 0.194552
valid_loss: 1.089953
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0009881933963507613
Epoch-17 lr: 0.003952773585403045
epoch 17 training time: 17.795
---------------
2023-09-24 03:21:53.165864
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00727	Per Sample Data Time 0.00164	Per Sample DNN Time 0.00563	Train Loss 0.1778	
start validation
[I 2023-09-24 03:22:08,537] Trial 83 finished with value: 0.35348314695139993 and parameters: {'warmup': 'True', 'num_epochs': 18, 'batch_size': 21, 'lr-adaptschedule': 'False', 'lr': 0.002052411852962124, 'head-lr': 4, 'lr-scheduler-start': 9, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.693886945024758}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.818182
AUC: 0.875942
Avg Precision: 0.353483
Avg Recall: 1.000000
d_prime: 1.633326
train_loss: 0.181752
valid_loss: 1.098453
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0009881933963507613
Epoch-18 lr: 0.003952773585403045
epoch 18 training time: 15.362
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc52634df0>
The learning rate scheduler starts at 10 epoch with decay rate of 0.687 every 7 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 03:22:08.577589
current #epochs=1, #steps=0
start validation
acc: 0.899522
AUC: 0.899589
Avg Precision: 0.406340
Avg Recall: 1.000000
d_prime: 1.809084
train_loss: 0.246654
valid_loss: 1.087205
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0018332394474485777
Epoch-1 lr: 0.007332957789794311
epoch 1 training time: 18.869
---------------
2023-09-24 03:22:27.446610
current #epochs=2, #steps=40
start validation
acc: 0.650718
AUC: 0.833194
Avg Precision: 0.324892
Avg Recall: 1.000000
d_prime: 1.367353
train_loss: 0.258033
valid_loss: 1.145121
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0018332394474485777
Epoch-2 lr: 0.007332957789794311
epoch 2 training time: 15.445
---------------
2023-09-24 03:22:42.891747
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00727	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00571	Train Loss 0.2680	
start validation
acc: 0.794258
AUC: 0.871054
Avg Precision: 0.329948
Avg Recall: 1.000000
d_prime: 1.600026
train_loss: 0.259232
valid_loss: 1.110551
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0018332394474485777
Epoch-3 lr: 0.007332957789794311
epoch 3 training time: 15.399
---------------
2023-09-24 03:22:58.290668
current #epochs=4, #steps=120
start validation
acc: 0.822967
AUC: 0.889435
Avg Precision: 0.348372
Avg Recall: 1.000000
d_prime: 1.730334
train_loss: 0.187060
valid_loss: 1.076142
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0018332394474485777
Epoch-4 lr: 0.007332957789794311
epoch 4 training time: 15.342
---------------
2023-09-24 03:23:13.632607
current #epochs=5, #steps=160
start validation
acc: 0.794258
AUC: 0.868267
Avg Precision: 0.346992
Avg Recall: 1.000000
d_prime: 1.581424
train_loss: 0.220655
valid_loss: 1.103621
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0018332394474485777
Epoch-5 lr: 0.007332957789794311
epoch 5 training time: 15.266
---------------
2023-09-24 03:23:28.898704
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03971	Per Sample Data Time 0.02980	Per Sample DNN Time 0.00991	Train Loss 0.2334	
start validation
acc: 0.827751
AUC: 0.878574
Avg Precision: 0.383312
Avg Recall: 1.000000
d_prime: 1.651641
train_loss: 0.247374
valid_loss: 1.113866
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0018332394474485777
Epoch-6 lr: 0.007332957789794311
epoch 6 training time: 15.295
---------------
2023-09-24 03:23:44.193885
current #epochs=7, #steps=240
start validation
acc: 0.732057
AUC: 0.848217
Avg Precision: 0.324739
Avg Recall: 1.000000
d_prime: 1.454964
train_loss: 0.208434
valid_loss: 1.131051
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0018332394474485777
Epoch-7 lr: 0.007332957789794311
epoch 7 training time: 15.264
---------------
2023-09-24 03:23:59.457650
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00563	Train Loss 0.2308	
start validation
acc: 0.861244
AUC: 0.895158
Avg Precision: 0.382115
Avg Recall: 1.000000
d_prime: 1.774042
train_loss: 0.206600
valid_loss: 1.104959
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0018332394474485777
Epoch-8 lr: 0.007332957789794311
epoch 8 training time: 15.295
---------------
2023-09-24 03:24:14.753101
current #epochs=9, #steps=320
start validation
acc: 0.875598
AUC: 0.914574
Avg Precision: 0.417064
Avg Recall: 1.000000
d_prime: 1.936727
train_loss: 0.171333
valid_loss: 1.078918
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0018332394474485777
Epoch-9 lr: 0.007332957789794311
epoch 9 training time: 15.290
---------------
2023-09-24 03:24:30.043337
current #epochs=10, #steps=360
start validation
acc: 0.851675
AUC: 0.895978
Avg Precision: 0.359538
Avg Recall: 1.000000
d_prime: 1.780445
train_loss: 0.176386
valid_loss: 1.095299
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.001259393017565588
Epoch-10 lr: 0.005037572070262352
epoch 10 training time: 15.326
---------------
2023-09-24 03:24:45.368784
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04228	Per Sample Data Time 0.03223	Per Sample DNN Time 0.01005	Train Loss 0.0989	
start validation
acc: 0.808612
AUC: 0.908693
Avg Precision: 0.399038
Avg Recall: 1.000000
d_prime: 1.884794
train_loss: 0.169270
valid_loss: 1.092021
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.001259393017565588
Epoch-11 lr: 0.005037572070262352
epoch 11 training time: 15.538
---------------
2023-09-24 03:25:00.906477
current #epochs=12, #steps=440
start validation
acc: 0.818182
AUC: 0.909714
Avg Precision: 0.404868
Avg Recall: 1.000000
d_prime: 1.893629
train_loss: 0.164399
valid_loss: 1.074393
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.001259393017565588
Epoch-12 lr: 0.005037572070262352
epoch 12 training time: 15.358
---------------
2023-09-24 03:25:16.264675
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00726	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00564	Train Loss 0.1400	
start validation
acc: 0.856459
AUC: 0.890510
Avg Precision: 0.405815
Avg Recall: 1.000000
d_prime: 1.738413
train_loss: 0.149546
valid_loss: 1.081398
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.001259393017565588
Epoch-13 lr: 0.005037572070262352
epoch 13 training time: 15.656
---------------
2023-09-24 03:25:31.920738
current #epochs=14, #steps=520
start validation
acc: 0.870813
AUC: 0.881359
Avg Precision: 0.409252
Avg Recall: 1.000000
d_prime: 1.671328
train_loss: 0.179744
valid_loss: 1.076857
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.001259393017565588
Epoch-14 lr: 0.005037572070262352
epoch 14 training time: 15.458
---------------
2023-09-24 03:25:47.378805
current #epochs=15, #steps=560
start validation
acc: 0.813397
AUC: 0.889203
Avg Precision: 0.378882
Avg Recall: 1.000000
d_prime: 1.728591
train_loss: 0.194511
valid_loss: 1.092718
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.001259393017565588
Epoch-15 lr: 0.005037572070262352
epoch 15 training time: 15.405
---------------
2023-09-24 03:26:02.783755
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03993	Per Sample Data Time 0.02975	Per Sample DNN Time 0.01018	Train Loss 0.2381	
start validation
[I 2023-09-24 03:26:18,093] Trial 84 finished with value: 0.3782076485959981 and parameters: {'warmup': 'True', 'num_epochs': 16, 'batch_size': 19, 'lr-adaptschedule': 'False', 'lr': 0.0018332394474485777, 'head-lr': 4, 'lr-scheduler-start': 10, 'lr-scheduler-step': 7, 'lr-scheduler-decay': 0.6869768263596749}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.851675
AUC: 0.889613
Avg Precision: 0.378208
Avg Recall: 1.000000
d_prime: 1.731669
train_loss: 0.175445
valid_loss: 1.083915
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.001259393017565588
Epoch-16 lr: 0.005037572070262352
epoch 16 training time: 15.300
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 5 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc52630e50>
The learning rate scheduler starts at 9 epoch with decay rate of 0.681 every 10 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 03:26:18.133135
current #epochs=1, #steps=0
start validation
acc: 0.851675
AUC: 0.906823
Avg Precision: 0.396733
Avg Recall: 1.000000
d_prime: 1.868803
train_loss: 0.207971
valid_loss: 1.074708
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0014344528068790552
Epoch-1 lr: 0.007172264034395276
epoch 1 training time: 18.286
---------------
2023-09-24 03:26:36.418922
current #epochs=2, #steps=40
start validation
acc: 0.832536
AUC: 0.882555
Avg Precision: 0.381116
Avg Recall: 1.000000
d_prime: 1.679881
train_loss: 0.187155
valid_loss: 1.096887
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0014344528068790552
Epoch-2 lr: 0.007172264034395276
epoch 2 training time: 15.230
---------------
2023-09-24 03:26:51.648819
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00709	Per Sample Data Time 0.00154	Per Sample DNN Time 0.00556	Train Loss 0.1440	
start validation
acc: 0.870813
AUC: 0.879324
Avg Precision: 0.397943
Avg Recall: 1.000000
d_prime: 1.656912
train_loss: 0.152502
valid_loss: 1.080545
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0014344528068790552
Epoch-3 lr: 0.007172264034395276
epoch 3 training time: 17.623
---------------
2023-09-24 03:27:09.271476
current #epochs=4, #steps=120
start validation
acc: 0.842105
AUC: 0.901237
Avg Precision: 0.392302
Avg Recall: 1.000000
d_prime: 1.822402
train_loss: 0.163924
valid_loss: 1.091406
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0014344528068790552
Epoch-4 lr: 0.007172264034395276
epoch 4 training time: 15.275
---------------
2023-09-24 03:27:24.546609
current #epochs=5, #steps=160
start validation
acc: 0.842105
AUC: 0.887778
Avg Precision: 0.383664
Avg Recall: 1.000000
d_prime: 1.717981
train_loss: 0.144774
valid_loss: 1.076218
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0014344528068790552
Epoch-5 lr: 0.007172264034395276
epoch 5 training time: 15.372
---------------
2023-09-24 03:27:39.918156
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03693	Per Sample Data Time 0.02971	Per Sample DNN Time 0.00722	Train Loss 0.2450	
start validation
acc: 0.837321
AUC: 0.885711
Avg Precision: 0.363770
Avg Recall: 1.000000
d_prime: 1.702753
train_loss: 0.140643
valid_loss: 1.081263
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0014344528068790552
Epoch-6 lr: 0.007172264034395276
epoch 6 training time: 15.138
---------------
2023-09-24 03:27:55.055865
current #epochs=7, #steps=240
start validation
acc: 0.813397
AUC: 0.882928
Avg Precision: 0.363376
Avg Recall: 1.000000
d_prime: 1.682563
train_loss: 0.171421
valid_loss: 1.101539
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0014344528068790552
Epoch-7 lr: 0.007172264034395276
epoch 7 training time: 15.337
---------------
2023-09-24 03:28:10.393027
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00713	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00558	Train Loss 0.2828	
start validation
acc: 0.803828
AUC: 0.872093
Avg Precision: 0.369809
Avg Recall: 1.000000
d_prime: 1.607026
train_loss: 0.276656
valid_loss: 1.118474
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0014344528068790552
Epoch-8 lr: 0.007172264034395276
epoch 8 training time: 15.196
---------------
2023-09-24 03:28:25.588599
current #epochs=9, #steps=320
start validation
acc: 0.822967
AUC: 0.885052
Avg Precision: 0.376459
Avg Recall: 1.000000
d_prime: 1.697945
train_loss: 0.252956
valid_loss: 1.108374
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0009762694423764705
Epoch-9 lr: 0.004881347211882352
epoch 9 training time: 15.175
---------------
2023-09-24 03:28:40.764011
current #epochs=10, #steps=360
start validation
acc: 0.822967
AUC: 0.891530
Avg Precision: 0.367310
Avg Recall: 1.000000
d_prime: 1.746135
train_loss: 0.219933
valid_loss: 1.090361
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0009762694423764705
Epoch-10 lr: 0.004881347211882352
epoch 10 training time: 15.280
---------------
2023-09-24 03:28:56.044123
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04107	Per Sample Data Time 0.03147	Per Sample DNN Time 0.00960	Train Loss 0.1480	
start validation
acc: 0.832536
AUC: 0.859786
Avg Precision: 0.344598
Avg Recall: 1.000000
d_prime: 1.526441
train_loss: 0.203316
valid_loss: 1.111348
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0009762694423764705
Epoch-11 lr: 0.004881347211882352
epoch 11 training time: 15.397
---------------
2023-09-24 03:29:11.440892
current #epochs=12, #steps=440
start validation
acc: 0.822967
AUC: 0.887832
Avg Precision: 0.354310
Avg Recall: 1.000000
d_prime: 1.718380
train_loss: 0.171419
valid_loss: 1.075906
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0009762694423764705
Epoch-12 lr: 0.004881347211882352
epoch 12 training time: 15.342
---------------
2023-09-24 03:29:26.783303
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00731	Per Sample Data Time 0.00164	Per Sample DNN Time 0.00567	Train Loss 0.1491	
start validation
acc: 0.832536
AUC: 0.872470
Avg Precision: 0.388385
Avg Recall: 1.000000
d_prime: 1.609579
train_loss: 0.153821
valid_loss: 1.097001
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0009762694423764705
Epoch-13 lr: 0.004881347211882352
epoch 13 training time: 15.373
---------------
2023-09-24 03:29:42.156580
current #epochs=14, #steps=520
start validation
acc: 0.813397
AUC: 0.882688
Avg Precision: 0.403167
Avg Recall: 1.000000
d_prime: 1.680839
train_loss: 0.147516
valid_loss: 1.091839
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0009762694423764705
Epoch-14 lr: 0.004881347211882352
epoch 14 training time: 15.268
---------------
2023-09-24 03:29:57.424268
current #epochs=15, #steps=560
start validation
acc: 0.832536
AUC: 0.873841
Avg Precision: 0.370112
Avg Recall: 1.000000
d_prime: 1.618900
train_loss: 0.140950
valid_loss: 1.091429
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0009762694423764705
Epoch-15 lr: 0.004881347211882352
epoch 15 training time: 15.393
---------------
2023-09-24 03:30:12.817334
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04003	Per Sample Data Time 0.03057	Per Sample DNN Time 0.00946	Train Loss 0.1235	
start validation
acc: 0.822967
AUC: 0.890555
Avg Precision: 0.428794
Avg Recall: 1.000000
d_prime: 1.738753
train_loss: 0.149977
valid_loss: 1.087100
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0009762694423764705
Epoch-16 lr: 0.004881347211882352
epoch 16 training time: 15.260
---------------
2023-09-24 03:30:28.077297
current #epochs=17, #steps=640
start validation
acc: 0.846890
AUC: 0.903661
Avg Precision: 0.413464
Avg Recall: 1.000000
d_prime: 1.842292
train_loss: 0.193865
valid_loss: 1.079725
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0009762694423764705
Epoch-17 lr: 0.004881347211882352
epoch 17 training time: 15.327
---------------
2023-09-24 03:30:43.404219
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00723	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00564	Train Loss 0.1856	
start validation
acc: 0.803828
AUC: 0.930868
Avg Precision: 0.398925
Avg Recall: 1.000000
d_prime: 2.096274
train_loss: 0.174443
valid_loss: 1.090956
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0009762694423764705
Epoch-18 lr: 0.004881347211882352
epoch 18 training time: 15.308
---------------
2023-09-24 03:30:58.712862
current #epochs=19, #steps=720
start validation
acc: 0.837321
AUC: 0.913145
Avg Precision: 0.431309
Avg Recall: 1.000000
d_prime: 1.923871
train_loss: 0.148528
valid_loss: 1.062510
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0006644359574238853
Epoch-19 lr: 0.0033221797871194263
epoch 19 training time: 15.261
---------------
2023-09-24 03:31:13.974130
current #epochs=20, #steps=760
start validation
acc: 0.842105
AUC: 0.921972
Avg Precision: 0.408746
Avg Recall: 1.000000
d_prime: 2.006008
train_loss: 0.136428
valid_loss: 1.059138
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0006644359574238853
Epoch-20 lr: 0.0033221797871194263
epoch 20 training time: 15.255
---------------
2023-09-24 03:31:29.229443
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04190	Per Sample Data Time 0.03151	Per Sample DNN Time 0.01039	Train Loss 0.2702	
start validation
acc: 0.808612
AUC: 0.907378
Avg Precision: 0.396195
Avg Recall: 1.000000
d_prime: 1.873525
train_loss: 0.123696
valid_loss: 1.071449
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0006644359574238853
Epoch-21 lr: 0.0033221797871194263
epoch 21 training time: 15.477
---------------
2023-09-24 03:31:44.706630
current #epochs=22, #steps=840
start validation
acc: 0.837321
AUC: 0.916706
Avg Precision: 0.412949
Avg Recall: 1.000000
d_prime: 1.956211
train_loss: 0.126608
valid_loss: 1.062256
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0006644359574238853
Epoch-22 lr: 0.0033221797871194263
epoch 22 training time: 15.359
---------------
2023-09-24 03:32:00.065475
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00563	Train Loss 0.1424	
start validation
[I 2023-09-24 03:32:15,421] Trial 85 finished with value: 0.4151998260940051 and parameters: {'warmup': 'True', 'num_epochs': 23, 'batch_size': 24, 'lr-adaptschedule': 'False', 'lr': 0.0014344528068790552, 'head-lr': 5, 'lr-scheduler-start': 9, 'lr-scheduler-step': 10, 'lr-scheduler-decay': 0.6805866583373655}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.846890
AUC: 0.887023
Avg Precision: 0.415200
Avg Recall: 1.000000
d_prime: 1.712399
train_loss: 0.135658
valid_loss: 1.098642
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0006644359574238853
Epoch-23 lr: 0.0033221797871194263
epoch 23 training time: 15.346
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51de1850>
The learning rate scheduler starts at 8 epoch with decay rate of 0.712 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 03:32:15.461423
current #epochs=1, #steps=0
start validation
acc: 0.875598
AUC: 0.907993
Avg Precision: 0.361159
Avg Recall: 1.000000
d_prime: 1.878782
train_loss: 0.171746
valid_loss: 1.077983
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0016210242777629131
Epoch-1 lr: 0.0064840971110516525
epoch 1 training time: 18.813
---------------
2023-09-24 03:32:34.275229
current #epochs=2, #steps=40
start validation
[I 2023-09-24 03:32:50,642] Trial 86 finished with value: 0.3299214662397749 and parameters: {'warmup': 'True', 'num_epochs': 2, 'batch_size': 27, 'lr-adaptschedule': 'False', 'lr': 0.0016210242777629131, 'head-lr': 4, 'lr-scheduler-start': 8, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.7122897428704935}. Best is trial 0 with value: 0.44491567769157475.
acc: 0.827751
AUC: 0.880614
Avg Precision: 0.329921
Avg Recall: 1.000000
d_prime: 1.666029
train_loss: 0.200912
valid_loss: 1.087656
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0016210242777629131
Epoch-2 lr: 0.0064840971110516525
epoch 2 training time: 16.357
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0a68bdc0>
The learning rate scheduler starts at 10 epoch with decay rate of 0.726 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 03:32:50.682324
current #epochs=1, #steps=0
start validation
acc: 0.789474
AUC: 0.851569
Avg Precision: 0.336649
Avg Recall: 1.000000
d_prime: 1.475290
train_loss: 0.231008
valid_loss: 1.127699
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.002290650550498399
Epoch-1 lr: 0.0068719516514951975
epoch 1 training time: 18.015
---------------
2023-09-24 03:33:08.698060
current #epochs=2, #steps=40
start validation
acc: 0.803828
AUC: 0.864542
Avg Precision: 0.362775
Avg Recall: 1.000000
d_prime: 1.556986
train_loss: 0.200772
valid_loss: 1.100099
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.002290650550498399
Epoch-2 lr: 0.0068719516514951975
epoch 2 training time: 17.820
---------------
2023-09-24 03:33:26.518099
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00561	Train Loss 0.1688	
start validation
acc: 0.770335
AUC: 0.870474
Avg Precision: 0.361210
Avg Recall: 1.000000
d_prime: 1.596129
train_loss: 0.179043
valid_loss: 1.127960
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.002290650550498399
Epoch-3 lr: 0.0068719516514951975
epoch 3 training time: 15.314
---------------
2023-09-24 03:33:41.832646
current #epochs=4, #steps=120
start validation
acc: 0.799043
AUC: 0.849815
Avg Precision: 0.401117
Avg Recall: 1.000000
d_prime: 1.464617
train_loss: 0.180687
valid_loss: 1.135841
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.002290650550498399
Epoch-4 lr: 0.0068719516514951975
epoch 4 training time: 15.196
---------------
2023-09-24 03:33:57.028641
current #epochs=5, #steps=160
start validation
acc: 0.832536
AUC: 0.870673
Avg Precision: 0.399172
Avg Recall: 1.000000
d_prime: 1.597462
train_loss: 0.133701
valid_loss: 1.105147
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.002290650550498399
Epoch-5 lr: 0.0068719516514951975
epoch 5 training time: 17.640
---------------
2023-09-24 03:34:14.668488
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03982	Per Sample Data Time 0.03148	Per Sample DNN Time 0.00834	Train Loss 0.0891	
start validation
acc: 0.822967
AUC: 0.895584
Avg Precision: 0.349025
Avg Recall: 1.000000
d_prime: 1.777363
train_loss: 0.153677
valid_loss: 1.107043
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.002290650550498399
Epoch-6 lr: 0.0068719516514951975
epoch 6 training time: 15.414
---------------
2023-09-24 03:34:30.082516
current #epochs=7, #steps=240
start validation
acc: 0.832536
AUC: 0.900255
Avg Precision: 0.429830
Avg Recall: 1.000000
d_prime: 1.814442
train_loss: 0.162826
valid_loss: 1.091697
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.002290650550498399
Epoch-7 lr: 0.0068719516514951975
epoch 7 training time: 15.312
---------------
2023-09-24 03:34:45.394555
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00166	Per Sample DNN Time 0.00552	Train Loss 0.1485	
start validation
acc: 0.875598
AUC: 0.926939
Avg Precision: 0.473908
Avg Recall: 1.000000
d_prime: 2.055369
train_loss: 0.166602
valid_loss: 1.076278
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.002290650550498399
Epoch-8 lr: 0.0068719516514951975
epoch 8 training time: 17.679
---------------
2023-09-24 03:35:03.073618
current #epochs=9, #steps=320
start validation
acc: 0.822967
AUC: 0.914406
Avg Precision: 0.433505
Avg Recall: 1.000000
d_prime: 1.935209
train_loss: 0.133408
valid_loss: 1.088362
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.002290650550498399
Epoch-9 lr: 0.0068719516514951975
epoch 9 training time: 15.463
---------------
2023-09-24 03:35:18.536664
current #epochs=10, #steps=360
start validation
acc: 0.832536
AUC: 0.874656
Avg Precision: 0.433075
Avg Recall: 1.000000
d_prime: 1.624477
train_loss: 0.183457
valid_loss: 1.128070
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0016626703040701354
Epoch-10 lr: 0.004988010912210406
epoch 10 training time: 15.167
---------------
2023-09-24 03:35:33.704037
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04064	Per Sample Data Time 0.03083	Per Sample DNN Time 0.00981	Train Loss 0.3210	
start validation
acc: 0.827751
AUC: 0.871819
Avg Precision: 0.433392
Avg Recall: 1.000000
d_prime: 1.605176
train_loss: 0.143623
valid_loss: 1.104844
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0016626703040701354
Epoch-11 lr: 0.004988010912210406
epoch 11 training time: 15.274
---------------
2023-09-24 03:35:48.977974
current #epochs=12, #steps=440
start validation
acc: 0.808612
AUC: 0.902109
Avg Precision: 0.351838
Avg Recall: 1.000000
d_prime: 1.829514
train_loss: 0.156587
valid_loss: 1.116243
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0016626703040701354
Epoch-12 lr: 0.004988010912210406
epoch 12 training time: 15.440
---------------
2023-09-24 03:36:04.417700
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00564	Train Loss 0.1461	
start validation
acc: 0.837321
AUC: 0.870658
Avg Precision: 0.418044
Avg Recall: 1.000000
d_prime: 1.597361
train_loss: 0.142819
valid_loss: 1.108710
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0016626703040701354
Epoch-13 lr: 0.004988010912210406
epoch 13 training time: 15.325
---------------
2023-09-24 03:36:19.742205
current #epochs=14, #steps=520
start validation
acc: 0.832536
AUC: 0.857401
Avg Precision: 0.391832
Avg Recall: 1.000000
d_prime: 1.511390
train_loss: 0.150472
valid_loss: 1.110415
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0016626703040701354
Epoch-14 lr: 0.004988010912210406
epoch 14 training time: 15.237
---------------
2023-09-24 03:36:34.979427
current #epochs=15, #steps=560
start validation
acc: 0.861244
AUC: 0.872096
Avg Precision: 0.439082
Avg Recall: 1.000000
d_prime: 1.607051
train_loss: 0.146831
valid_loss: 1.091629
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0016626703040701354
Epoch-15 lr: 0.004988010912210406
epoch 15 training time: 15.450
---------------
2023-09-24 03:36:50.429429
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04125	Per Sample Data Time 0.03158	Per Sample DNN Time 0.00967	Train Loss 0.1089	
start validation
acc: 0.870813
AUC: 0.897325
Avg Precision: 0.449827
Avg Recall: 1.000000
d_prime: 1.791038
train_loss: 0.134216
valid_loss: 1.066438
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0016626703040701354
Epoch-16 lr: 0.004988010912210406
epoch 16 training time: 15.335
---------------
2023-09-24 03:37:05.763961
current #epochs=17, #steps=640
start validation
acc: 0.832536
AUC: 0.870783
Avg Precision: 0.396095
Avg Recall: 1.000000
d_prime: 1.598206
train_loss: 0.140115
valid_loss: 1.110309
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0016626703040701354
Epoch-17 lr: 0.004988010912210406
epoch 17 training time: 15.308
---------------
2023-09-24 03:37:21.071705
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00727	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00567	Train Loss 0.1460	
start validation
acc: 0.818182
AUC: 0.916337
Avg Precision: 0.421729
Avg Recall: 1.000000
d_prime: 1.952808
train_loss: 0.147398
valid_loss: 1.094422
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.001206850403015503
Epoch-18 lr: 0.003620551209046509
epoch 18 training time: 15.350
---------------
2023-09-24 03:37:36.421731
current #epochs=19, #steps=720
start validation
acc: 0.803828
AUC: 0.902353
Avg Precision: 0.404631
Avg Recall: 1.000000
d_prime: 1.831516
train_loss: 0.133880
valid_loss: 1.093700
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.001206850403015503
Epoch-19 lr: 0.003620551209046509
epoch 19 training time: 15.467
---------------
2023-09-24 03:37:51.888577
current #epochs=20, #steps=760
start validation
[I 2023-09-24 03:38:09,706] Trial 87 finished with value: 0.45521598372193306 and parameters: {'warmup': 'True', 'num_epochs': 20, 'batch_size': 18, 'lr-adaptschedule': 'False', 'lr': 0.002290650550498399, 'head-lr': 3, 'lr-scheduler-start': 10, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.7258506993606564}. Best is trial 87 with value: 0.45521598372193306.
acc: 0.904306
AUC: 0.919611
Avg Precision: 0.455216
Avg Recall: 1.000000
d_prime: 1.983375
train_loss: 0.115634
valid_loss: 1.043177
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.001206850403015503
Epoch-20 lr: 0.003620551209046509
epoch 20 training time: 17.806
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0983e5e0>
The learning rate scheduler starts at 10 epoch with decay rate of 0.761 every 7 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 03:38:09.746843
current #epochs=1, #steps=0
start validation
acc: 0.813397
AUC: 0.909644
Avg Precision: 0.380010
Avg Recall: 1.000000
d_prime: 1.893015
train_loss: 0.185756
valid_loss: 1.059117
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.002307983186765048
Epoch-1 lr: 0.006923949560295144
epoch 1 training time: 18.556
---------------
2023-09-24 03:38:28.303061
current #epochs=2, #steps=40
start validation
acc: 0.875598
AUC: 0.910832
Avg Precision: 0.451516
Avg Recall: 1.000000
d_prime: 1.903385
train_loss: 0.153387
valid_loss: 1.055727
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.002307983186765048
Epoch-2 lr: 0.006923949560295144
epoch 2 training time: 17.782
---------------
2023-09-24 03:38:46.084819
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00714	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00552	Train Loss 0.1207	
start validation
acc: 0.885167
AUC: 0.901700
Avg Precision: 0.420637
Avg Recall: 1.000000
d_prime: 1.826176
train_loss: 0.123067
valid_loss: 1.070047
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.002307983186765048
Epoch-3 lr: 0.006923949560295144
epoch 3 training time: 18.008
---------------
2023-09-24 03:39:04.093084
current #epochs=4, #steps=120
start validation
acc: 0.837321
AUC: 0.897605
Avg Precision: 0.382988
Avg Recall: 1.000000
d_prime: 1.793257
train_loss: 0.122270
valid_loss: 1.075608
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.002307983186765048
Epoch-4 lr: 0.006923949560295144
epoch 4 training time: 15.394
---------------
2023-09-24 03:39:19.486827
current #epochs=5, #steps=160
start validation
acc: 0.870813
AUC: 0.901465
Avg Precision: 0.393211
Avg Recall: 1.000000
d_prime: 1.824256
train_loss: 0.138356
valid_loss: 1.059779
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.002307983186765048
Epoch-5 lr: 0.006923949560295144
epoch 5 training time: 15.207
---------------
2023-09-24 03:39:34.693773
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03760	Per Sample Data Time 0.03076	Per Sample DNN Time 0.00684	Train Loss 0.1389	
start validation
acc: 0.808612
AUC: 0.882001
Avg Precision: 0.358895
Avg Recall: 1.000000
d_prime: 1.675912
train_loss: 0.135341
valid_loss: 1.099021
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.002307983186765048
Epoch-6 lr: 0.006923949560295144
epoch 6 training time: 15.287
---------------
2023-09-24 03:39:49.980691
current #epochs=7, #steps=240
start validation
acc: 0.856459
AUC: 0.908429
Avg Precision: 0.390341
Avg Recall: 1.000000
d_prime: 1.882521
train_loss: 0.120841
valid_loss: 1.060915
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.002307983186765048
Epoch-7 lr: 0.006923949560295144
epoch 7 training time: 15.332
---------------
2023-09-24 03:40:05.313038
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00723	Per Sample Data Time 0.00166	Per Sample DNN Time 0.00557	Train Loss 0.1362	
start validation
acc: 0.837321
AUC: 0.925030
Avg Precision: 0.400074
Avg Recall: 1.000000
d_prime: 2.036105
train_loss: 0.133647
valid_loss: 1.050430
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.002307983186765048
Epoch-8 lr: 0.006923949560295144
epoch 8 training time: 15.460
---------------
2023-09-24 03:40:20.772987
current #epochs=9, #steps=320
start validation
acc: 0.842105
AUC: 0.906020
Avg Precision: 0.377362
Avg Recall: 1.000000
d_prime: 1.862008
train_loss: 0.137949
valid_loss: 1.068432
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.002307983186765048
Epoch-9 lr: 0.006923949560295144
epoch 9 training time: 15.545
---------------
2023-09-24 03:40:36.318214
current #epochs=10, #steps=360
start validation
acc: 0.846890
AUC: 0.912080
Avg Precision: 0.428928
Avg Recall: 1.000000
d_prime: 1.914385
train_loss: 0.124337
valid_loss: 1.053310
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0017553363764906404
Epoch-10 lr: 0.005266009129471921
epoch 10 training time: 15.268
---------------
2023-09-24 03:40:51.585692
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03630	Per Sample Data Time 0.02902	Per Sample DNN Time 0.00728	Train Loss 0.0766	
start validation
acc: 0.856459
AUC: 0.902842
Avg Precision: 0.430560
Avg Recall: 1.000000
d_prime: 1.835533
train_loss: 0.112979
valid_loss: 1.049242
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0017553363764906404
Epoch-11 lr: 0.005266009129471921
epoch 11 training time: 15.197
---------------
2023-09-24 03:41:06.782729
current #epochs=12, #steps=440
start validation
acc: 0.827751
AUC: 0.896928
Avg Precision: 0.405286
Avg Recall: 1.000000
d_prime: 1.787905
train_loss: 0.108048
valid_loss: 1.069772
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0017553363764906404
Epoch-12 lr: 0.005266009129471921
epoch 12 training time: 15.311
---------------
2023-09-24 03:41:22.093679
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00553	Train Loss 0.0918	
start validation
acc: 0.870813
AUC: 0.917005
Avg Precision: 0.410226
Avg Recall: 1.000000
d_prime: 1.958976
train_loss: 0.091726
valid_loss: 1.032668
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0017553363764906404
Epoch-13 lr: 0.005266009129471921
epoch 13 training time: 16.186
---------------
2023-09-24 03:41:38.280053
current #epochs=14, #steps=520
start validation
acc: 0.842105
AUC: 0.930515
Avg Precision: 0.409941
Avg Recall: 1.000000
d_prime: 2.092525
train_loss: 0.113619
valid_loss: 1.050244
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0017553363764906404
Epoch-14 lr: 0.005266009129471921
epoch 14 training time: 15.398
---------------
2023-09-24 03:41:53.678150
current #epochs=15, #steps=560
start validation
acc: 0.880383
AUC: 0.895977
Avg Precision: 0.401671
Avg Recall: 1.000000
d_prime: 1.780435
train_loss: 0.147411
valid_loss: 1.068969
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0017553363764906404
Epoch-15 lr: 0.005266009129471921
epoch 15 training time: 15.336
---------------
2023-09-24 03:42:09.013663
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03799	Per Sample Data Time 0.03006	Per Sample DNN Time 0.00793	Train Loss 0.0931	
start validation
acc: 0.851675
AUC: 0.900913
Avg Precision: 0.420623
Avg Recall: 1.000000
d_prime: 1.819769
train_loss: 0.112013
valid_loss: 1.061260
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0017553363764906404
Epoch-16 lr: 0.005266009129471921
epoch 16 training time: 15.254
---------------
2023-09-24 03:42:24.267390
current #epochs=17, #steps=640
start validation
acc: 0.866029
AUC: 0.915732
Avg Precision: 0.447527
Avg Recall: 1.000000
d_prime: 1.947263
train_loss: 0.098658
valid_loss: 1.044192
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.001335020901495396
Epoch-17 lr: 0.004005062704486188
epoch 17 training time: 15.249
---------------
2023-09-24 03:42:39.516021
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00154	Per Sample DNN Time 0.00562	Train Loss 0.0906	
start validation
acc: 0.842105
AUC: 0.894789
Avg Precision: 0.397495
Avg Recall: 1.000000
d_prime: 1.771172
train_loss: 0.097848
valid_loss: 1.062281
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.001335020901495396
Epoch-18 lr: 0.004005062704486188
epoch 18 training time: 15.294
---------------
2023-09-24 03:42:54.809571
current #epochs=19, #steps=720
start validation
acc: 0.856459
AUC: 0.885604
Avg Precision: 0.460985
Avg Recall: 1.000000
d_prime: 1.701971
train_loss: 0.116623
valid_loss: 1.056422
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.001335020901495396
Epoch-19 lr: 0.004005062704486188
epoch 19 training time: 15.267
---------------
2023-09-24 03:43:10.076677
current #epochs=20, #steps=760
start validation
[I 2023-09-24 03:43:25,385] Trial 88 finished with value: 0.41376067463551175 and parameters: {'warmup': 'True', 'num_epochs': 20, 'batch_size': 14, 'lr-adaptschedule': 'False', 'lr': 0.002307983186765048, 'head-lr': 3, 'lr-scheduler-start': 10, 'lr-scheduler-step': 7, 'lr-scheduler-decay': 0.7605498976580427}. Best is trial 87 with value: 0.45521598372193306.
acc: 0.832536
AUC: 0.881034
Avg Precision: 0.413761
Avg Recall: 1.000000
d_prime: 1.669016
train_loss: 0.099646
valid_loss: 1.075003
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.001335020901495396
Epoch-20 lr: 0.004005062704486188
epoch 20 training time: 15.297
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcbd1460a90>
The learning rate scheduler starts at 10 epoch with decay rate of 0.748 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 03:43:25.424880
current #epochs=1, #steps=0
start validation
acc: 0.818182
AUC: 0.857476
Avg Precision: 0.343624
Avg Recall: 1.000000
d_prime: 1.511861
train_loss: 0.158655
valid_loss: 1.118431
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.002584176912202118
Epoch-1 lr: 0.007752530736606355
epoch 1 training time: 17.789
---------------
2023-09-24 03:43:43.214217
current #epochs=2, #steps=40
start validation
acc: 0.813397
AUC: 0.929346
Avg Precision: 0.373552
Avg Recall: 1.000000
d_prime: 2.080223
train_loss: 0.139639
valid_loss: 1.044689
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.002584176912202118
Epoch-2 lr: 0.007752530736606355
epoch 2 training time: 15.353
---------------
2023-09-24 03:43:58.567405
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00709	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00550	Train Loss 0.1271	
start validation
acc: 0.760766
AUC: 0.901153
Avg Precision: 0.356531
Avg Recall: 1.000000
d_prime: 1.821719
train_loss: 0.130857
valid_loss: 1.100076
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.002584176912202118
Epoch-3 lr: 0.007752530736606355
epoch 3 training time: 16.557
---------------
2023-09-24 03:44:15.124352
current #epochs=4, #steps=120
start validation
acc: 0.842105
AUC: 0.909700
Avg Precision: 0.415278
Avg Recall: 1.000000
d_prime: 1.893505
train_loss: 0.151314
valid_loss: 1.069049
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.002584176912202118
Epoch-4 lr: 0.007752530736606355
epoch 4 training time: 17.796
---------------
2023-09-24 03:44:32.920598
current #epochs=5, #steps=160
start validation
acc: 0.846890
AUC: 0.922139
Avg Precision: 0.469524
Avg Recall: 1.000000
d_prime: 2.007629
train_loss: 0.148895
valid_loss: 1.069551
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.002584176912202118
Epoch-5 lr: 0.007752530736606355
epoch 5 training time: 17.816
---------------
2023-09-24 03:44:50.736637
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03782	Per Sample Data Time 0.03027	Per Sample DNN Time 0.00755	Train Loss 0.1481	
start validation
acc: 0.765550
AUC: 0.873268
Avg Precision: 0.345021
Avg Recall: 1.000000
d_prime: 1.614997
train_loss: 0.118529
valid_loss: 1.130834
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.002584176912202118
Epoch-6 lr: 0.007752530736606355
epoch 6 training time: 15.243
---------------
2023-09-24 03:45:05.979966
current #epochs=7, #steps=240
start validation
acc: 0.799043
AUC: 0.870122
Avg Precision: 0.377840
Avg Recall: 1.000000
d_prime: 1.593773
train_loss: 0.149502
valid_loss: 1.123931
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.002584176912202118
Epoch-7 lr: 0.007752530736606355
epoch 7 training time: 15.380
---------------
2023-09-24 03:45:21.360353
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00561	Train Loss 0.1866	
start validation
acc: 0.784689
AUC: 0.872361
Avg Precision: 0.369079
Avg Recall: 1.000000
d_prime: 1.608839
train_loss: 0.194629
valid_loss: 1.129224
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.002584176912202118
Epoch-8 lr: 0.007752530736606355
epoch 8 training time: 15.260
---------------
2023-09-24 03:45:36.620021
current #epochs=9, #steps=320
start validation
acc: 0.818182
AUC: 0.917168
Avg Precision: 0.432629
Avg Recall: 1.000000
d_prime: 1.960482
train_loss: 0.149407
valid_loss: 1.078306
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.002584176912202118
Epoch-9 lr: 0.007752530736606355
epoch 9 training time: 16.545
---------------
2023-09-24 03:45:53.165021
current #epochs=10, #steps=360
start validation
acc: 0.851675
AUC: 0.917299
Avg Precision: 0.433635
Avg Recall: 1.000000
d_prime: 1.961697
train_loss: 0.116767
valid_loss: 1.068036
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0019325066012662753
Epoch-10 lr: 0.005797519803798826
epoch 10 training time: 17.802
---------------
2023-09-24 03:46:10.967516
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03802	Per Sample Data Time 0.02949	Per Sample DNN Time 0.00853	Train Loss 0.0119	
start validation
acc: 0.851675
AUC: 0.903750
Avg Precision: 0.414398
Avg Recall: 1.000000
d_prime: 1.843029
train_loss: 0.113208
valid_loss: 1.076892
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0019325066012662753
Epoch-11 lr: 0.005797519803798826
epoch 11 training time: 15.235
---------------
2023-09-24 03:46:26.202359
current #epochs=12, #steps=440
start validation
acc: 0.808612
AUC: 0.896915
Avg Precision: 0.399623
Avg Recall: 1.000000
d_prime: 1.787799
train_loss: 0.105291
valid_loss: 1.080559
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0019325066012662753
Epoch-12 lr: 0.005797519803798826
epoch 12 training time: 15.352
---------------
2023-09-24 03:46:41.555020
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00557	Train Loss 0.0745	
start validation
acc: 0.789474
AUC: 0.873652
Avg Precision: 0.376584
Avg Recall: 1.000000
d_prime: 1.617613
train_loss: 0.085816
valid_loss: 1.105364
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0019325066012662753
Epoch-13 lr: 0.005797519803798826
epoch 13 training time: 15.323
---------------
2023-09-24 03:46:56.878362
current #epochs=14, #steps=520
start validation
acc: 0.818182
AUC: 0.914553
Avg Precision: 0.401630
Avg Recall: 1.000000
d_prime: 1.936537
train_loss: 0.120586
valid_loss: 1.065539
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0019325066012662753
Epoch-14 lr: 0.005797519803798826
epoch 14 training time: 15.325
---------------
2023-09-24 03:47:12.203217
current #epochs=15, #steps=560
start validation
acc: 0.866029
AUC: 0.913052
Avg Precision: 0.412514
Avg Recall: 1.000000
d_prime: 1.923035
train_loss: 0.153876
valid_loss: 1.072866
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0019325066012662753
Epoch-15 lr: 0.005797519803798826
epoch 15 training time: 17.783
---------------
2023-09-24 03:47:29.986423
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03840	Per Sample Data Time 0.03093	Per Sample DNN Time 0.00748	Train Loss 0.1271	
start validation
acc: 0.851675
AUC: 0.917662
Avg Precision: 0.373498
Avg Recall: 1.000000
d_prime: 1.965075
train_loss: 0.132524
valid_loss: 1.044950
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0019325066012662753
Epoch-16 lr: 0.005797519803798826
epoch 16 training time: 15.288
---------------
2023-09-24 03:47:45.274248
current #epochs=17, #steps=640
start validation
acc: 0.870813
AUC: 0.891140
Avg Precision: 0.385237
Avg Recall: 1.000000
d_prime: 1.743182
train_loss: 0.181180
valid_loss: 1.082987
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0019325066012662753
Epoch-17 lr: 0.005797519803798826
epoch 17 training time: 17.629
---------------
2023-09-24 03:48:02.903035
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00558	Train Loss 0.1777	
start validation
acc: 0.861244
AUC: 0.901886
Avg Precision: 0.406558
Avg Recall: 1.000000
d_prime: 1.827688
train_loss: 0.158718
valid_loss: 1.070931
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0019325066012662753
Epoch-18 lr: 0.005797519803798826
epoch 18 training time: 15.270
---------------
2023-09-24 03:48:18.173317
current #epochs=19, #steps=720
start validation
acc: 0.837321
AUC: 0.921900
Avg Precision: 0.417978
Avg Recall: 1.000000
d_prime: 2.005306
train_loss: 0.133820
valid_loss: 1.044465
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.001445172637486065
Epoch-19 lr: 0.0043355179124581955
epoch 19 training time: 15.276
---------------
2023-09-24 03:48:33.448960
current #epochs=20, #steps=760
start validation
acc: 0.803828
AUC: 0.903830
Avg Precision: 0.411027
Avg Recall: 1.000000
d_prime: 1.843689
train_loss: 0.127284
valid_loss: 1.085023
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.001445172637486065
Epoch-20 lr: 0.0043355179124581955
epoch 20 training time: 16.345
---------------
2023-09-24 03:48:49.794189
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03926	Per Sample Data Time 0.03061	Per Sample DNN Time 0.00865	Train Loss 0.0880	
start validation
acc: 0.837321
AUC: 0.909781
Avg Precision: 0.429832
Avg Recall: 1.000000
d_prime: 1.894207
train_loss: 0.145204
valid_loss: 1.088386
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.001445172637486065
Epoch-21 lr: 0.0043355179124581955
epoch 21 training time: 15.397
---------------
2023-09-24 03:49:05.191079
current #epochs=22, #steps=840
start validation
acc: 0.880383
AUC: 0.924729
Avg Precision: 0.398581
Avg Recall: 1.000000
d_prime: 2.033101
train_loss: 0.112242
valid_loss: 1.065798
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.001445172637486065
Epoch-22 lr: 0.0043355179124581955
epoch 22 training time: 18.741
---------------
2023-09-24 03:49:23.932320
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00556	Train Loss 0.1107	
start validation
acc: 0.866029
AUC: 0.906636
Avg Precision: 0.426918
Avg Recall: 1.000000
d_prime: 1.867214
train_loss: 0.120705
valid_loss: 1.064964
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.001445172637486065
Epoch-23 lr: 0.0043355179124581955
epoch 23 training time: 15.233
---------------
2023-09-24 03:49:39.165431
current #epochs=24, #steps=920
start validation
[I 2023-09-24 03:49:54,437] Trial 89 finished with value: 0.41413872058509343 and parameters: {'warmup': 'True', 'num_epochs': 24, 'batch_size': 18, 'lr-adaptschedule': 'False', 'lr': 0.002584176912202118, 'head-lr': 3, 'lr-scheduler-start': 10, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.7478228723974942}. Best is trial 87 with value: 0.45521598372193306.
acc: 0.813397
AUC: 0.906016
Avg Precision: 0.414139
Avg Recall: 1.000000
d_prime: 1.861977
train_loss: 0.135993
valid_loss: 1.074852
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.001445172637486065
Epoch-24 lr: 0.0043355179124581955
epoch 24 training time: 15.261
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51de1c40>
The learning rate scheduler starts at 10 epoch with decay rate of 0.727 every 10 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 03:49:54.478366
current #epochs=1, #steps=0
start validation
acc: 0.842105
AUC: 0.891518
Avg Precision: 0.387216
Avg Recall: 1.000000
d_prime: 1.746048
train_loss: 0.191358
valid_loss: 1.084433
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0021104120243195875
Epoch-1 lr: 0.006331236072958763
epoch 1 training time: 17.682
---------------
2023-09-24 03:50:12.160615
current #epochs=2, #steps=40
start validation
acc: 0.746411
AUC: 0.873432
Avg Precision: 0.330864
Avg Recall: 1.000000
d_prime: 1.616111
train_loss: 0.136460
valid_loss: 1.106560
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0021104120243195875
Epoch-2 lr: 0.006331236072958763
epoch 2 training time: 15.228
---------------
2023-09-24 03:50:27.388726
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00714	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00554	Train Loss 0.1297	
start validation
acc: 0.803828
AUC: 0.893078
Avg Precision: 0.374295
Avg Recall: 1.000000
d_prime: 1.757961
train_loss: 0.151954
valid_loss: 1.114070
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0021104120243195875
Epoch-3 lr: 0.006331236072958763
epoch 3 training time: 15.372
---------------
2023-09-24 03:50:42.761340
current #epochs=4, #steps=120
start validation
acc: 0.765550
AUC: 0.857455
Avg Precision: 0.320158
Avg Recall: 1.000000
d_prime: 1.511728
train_loss: 0.161336
valid_loss: 1.136525
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0021104120243195875
Epoch-4 lr: 0.006331236072958763
epoch 4 training time: 16.439
---------------
2023-09-24 03:50:59.199901
current #epochs=5, #steps=160
start validation
acc: 0.822967
AUC: 0.905627
Avg Precision: 0.378308
Avg Recall: 1.000000
d_prime: 1.858695
train_loss: 0.141760
valid_loss: 1.076178
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0021104120243195875
Epoch-5 lr: 0.006331236072958763
epoch 5 training time: 15.272
---------------
2023-09-24 03:51:14.471593
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03914	Per Sample Data Time 0.03151	Per Sample DNN Time 0.00763	Train Loss 0.2274	
start validation
acc: 0.851675
AUC: 0.893130
Avg Precision: 0.344768
Avg Recall: 1.000000
d_prime: 1.758357
train_loss: 0.194355
valid_loss: 1.107765
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0021104120243195875
Epoch-6 lr: 0.006331236072958763
epoch 6 training time: 17.894
---------------
2023-09-24 03:51:32.365899
current #epochs=7, #steps=240
start validation
acc: 0.822967
AUC: 0.877814
Avg Precision: 0.360935
Avg Recall: 1.000000
d_prime: 1.646329
train_loss: 0.239430
valid_loss: 1.108462
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0021104120243195875
Epoch-7 lr: 0.006331236072958763
epoch 7 training time: 15.429
---------------
2023-09-24 03:51:47.795362
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00557	Train Loss 0.1981	
start validation
acc: 0.861244
AUC: 0.906853
Avg Precision: 0.388554
Avg Recall: 1.000000
d_prime: 1.869054
train_loss: 0.200654
valid_loss: 1.084512
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0021104120243195875
Epoch-8 lr: 0.006331236072958763
epoch 8 training time: 17.975
---------------
2023-09-24 03:52:05.770459
current #epochs=9, #steps=320
start validation
acc: 0.846890
AUC: 0.895486
Avg Precision: 0.374967
Avg Recall: 1.000000
d_prime: 1.776594
train_loss: 0.164933
valid_loss: 1.108652
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0021104120243195875
Epoch-9 lr: 0.006331236072958763
epoch 9 training time: 15.279
---------------
2023-09-24 03:52:21.049736
current #epochs=10, #steps=360
start validation
acc: 0.861244
AUC: 0.896858
Avg Precision: 0.360073
Avg Recall: 1.000000
d_prime: 1.787356
train_loss: 0.161971
valid_loss: 1.081778
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0015340105408289083
Epoch-10 lr: 0.004602031622486725
epoch 10 training time: 15.239
---------------
2023-09-24 03:52:36.289044
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03853	Per Sample Data Time 0.03003	Per Sample DNN Time 0.00850	Train Loss 0.0669	
start validation
acc: 0.837321
AUC: 0.895778
Avg Precision: 0.403043
Avg Recall: 1.000000
d_prime: 1.778873
train_loss: 0.133531
valid_loss: 1.074409
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0015340105408289083
Epoch-11 lr: 0.004602031622486725
epoch 11 training time: 15.347
---------------
2023-09-24 03:52:51.635748
current #epochs=12, #steps=440
start validation
acc: 0.794258
AUC: 0.879218
Avg Precision: 0.363772
Avg Recall: 1.000000
d_prime: 1.656168
train_loss: 0.119925
valid_loss: 1.090213
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0015340105408289083
Epoch-12 lr: 0.004602031622486725
epoch 12 training time: 15.295
---------------
2023-09-24 03:53:06.930517
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00714	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00551	Train Loss 0.1158	
start validation
acc: 0.880383
AUC: 0.897662
Avg Precision: 0.437629
Avg Recall: 1.000000
d_prime: 1.793709
train_loss: 0.123798
valid_loss: 1.059675
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0015340105408289083
Epoch-13 lr: 0.004602031622486725
epoch 13 training time: 17.691
---------------
2023-09-24 03:53:24.621690
current #epochs=14, #steps=520
start validation
acc: 0.842105
AUC: 0.908817
Avg Precision: 0.399901
Avg Recall: 1.000000
d_prime: 1.885865
train_loss: 0.122707
valid_loss: 1.055566
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0015340105408289083
Epoch-14 lr: 0.004602031622486725
epoch 14 training time: 16.442
---------------
2023-09-24 03:53:41.063367
current #epochs=15, #steps=560
start validation
acc: 0.813397
AUC: 0.905375
Avg Precision: 0.388401
Avg Recall: 1.000000
d_prime: 1.856580
train_loss: 0.127612
valid_loss: 1.081156
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0015340105408289083
Epoch-15 lr: 0.004602031622486725
epoch 15 training time: 15.223
---------------
2023-09-24 03:53:56.286575
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03849	Per Sample Data Time 0.03090	Per Sample DNN Time 0.00760	Train Loss 0.2081	
start validation
acc: 0.846890
AUC: 0.887518
Avg Precision: 0.379084
Avg Recall: 1.000000
d_prime: 1.716052
train_loss: 0.145061
valid_loss: 1.092276
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0015340105408289083
Epoch-16 lr: 0.004602031622486725
epoch 16 training time: 15.333
---------------
2023-09-24 03:54:11.619602
current #epochs=17, #steps=640
start validation
acc: 0.822967
AUC: 0.910529
Avg Precision: 0.382924
Avg Recall: 1.000000
d_prime: 1.900734
train_loss: 0.127414
valid_loss: 1.075099
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0015340105408289083
Epoch-17 lr: 0.004602031622486725
epoch 17 training time: 15.338
---------------
2023-09-24 03:54:26.958243
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00709	Per Sample Data Time 0.00152	Per Sample DNN Time 0.00558	Train Loss 0.1278	
start validation
acc: 0.846890
AUC: 0.875413
Avg Precision: 0.418625
Avg Recall: 1.000000
d_prime: 1.629679
train_loss: 0.130509
valid_loss: 1.105882
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0015340105408289083
Epoch-18 lr: 0.004602031622486725
epoch 18 training time: 16.359
---------------
2023-09-24 03:54:43.317182
current #epochs=19, #steps=720
start validation
[I 2023-09-24 03:54:58,652] Trial 90 finished with value: 0.3776393165504656 and parameters: {'warmup': 'True', 'num_epochs': 19, 'batch_size': 23, 'lr-adaptschedule': 'False', 'lr': 0.0021104120243195875, 'head-lr': 3, 'lr-scheduler-start': 10, 'lr-scheduler-step': 10, 'lr-scheduler-decay': 0.7268772747461409}. Best is trial 87 with value: 0.45521598372193306.
acc: 0.818182
AUC: 0.896225
Avg Precision: 0.377639
Avg Recall: 1.000000
d_prime: 1.782376
train_loss: 0.100583
valid_loss: 1.076934
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0015340105408289083
Epoch-19 lr: 0.004602031622486725
epoch 19 training time: 15.322
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc52630a90>
The learning rate scheduler starts at 10 epoch with decay rate of 0.738 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 03:54:58.692584
current #epochs=1, #steps=0
start validation
acc: 0.842105
AUC: 0.914285
Avg Precision: 0.385051
Avg Recall: 1.000000
d_prime: 1.934112
train_loss: 0.143843
valid_loss: 1.061423
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0019026108750591728
Epoch-1 lr: 0.005707832625177519
epoch 1 training time: 18.226
---------------
2023-09-24 03:55:16.918561
current #epochs=2, #steps=40
start validation
acc: 0.827751
AUC: 0.873820
Avg Precision: 0.350892
Avg Recall: 1.000000
d_prime: 1.618761
train_loss: 0.120022
valid_loss: 1.087043
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0019026108750591728
Epoch-2 lr: 0.005707832625177519
epoch 2 training time: 16.538
---------------
2023-09-24 03:55:33.456852
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00709	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00551	Train Loss 0.1371	
start validation
acc: 0.851675
AUC: 0.899602
Avg Precision: 0.375533
Avg Recall: 1.000000
d_prime: 1.809185
train_loss: 0.143854
valid_loss: 1.063166
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0019026108750591728
Epoch-3 lr: 0.005707832625177519
epoch 3 training time: 17.847
---------------
2023-09-24 03:55:51.304122
current #epochs=4, #steps=120
start validation
acc: 0.822967
AUC: 0.896079
Avg Precision: 0.361761
Avg Recall: 1.000000
d_prime: 1.781231
train_loss: 0.158305
valid_loss: 1.080849
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0019026108750591728
Epoch-4 lr: 0.005707832625177519
epoch 4 training time: 15.324
---------------
2023-09-24 03:56:06.628273
current #epochs=5, #steps=160
start validation
acc: 0.803828
AUC: 0.890556
Avg Precision: 0.362706
Avg Recall: 1.000000
d_prime: 1.738758
train_loss: 0.144386
valid_loss: 1.090981
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0019026108750591728
Epoch-5 lr: 0.005707832625177519
epoch 5 training time: 15.393
---------------
2023-09-24 03:56:22.021085
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03846	Per Sample Data Time 0.03054	Per Sample DNN Time 0.00792	Train Loss 0.0803	
start validation
acc: 0.861244
AUC: 0.922825
Avg Precision: 0.435299
Avg Recall: 1.000000
d_prime: 2.014314
train_loss: 0.120119
valid_loss: 1.045192
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0019026108750591728
Epoch-6 lr: 0.005707832625177519
epoch 6 training time: 17.631
---------------
2023-09-24 03:56:39.652259
current #epochs=7, #steps=240
start validation
acc: 0.827751
AUC: 0.886102
Avg Precision: 0.382513
Avg Recall: 1.000000
d_prime: 1.705617
train_loss: 0.152587
valid_loss: 1.085209
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0019026108750591728
Epoch-7 lr: 0.005707832625177519
epoch 7 training time: 15.359
---------------
2023-09-24 03:56:55.011636
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00713	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00557	Train Loss 0.1350	
start validation
acc: 0.842105
AUC: 0.904454
Avg Precision: 0.395744
Avg Recall: 1.000000
d_prime: 1.848876
train_loss: 0.120584
valid_loss: 1.079105
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0019026108750591728
Epoch-8 lr: 0.005707832625177519
epoch 8 training time: 15.241
---------------
2023-09-24 03:57:10.253020
current #epochs=9, #steps=320
start validation
acc: 0.803828
AUC: 0.873967
Avg Precision: 0.333425
Avg Recall: 1.000000
d_prime: 1.619763
train_loss: 0.149464
valid_loss: 1.115288
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0019026108750591728
Epoch-9 lr: 0.005707832625177519
epoch 9 training time: 15.281
---------------
2023-09-24 03:57:25.534681
current #epochs=10, #steps=360
start validation
acc: 0.799043
AUC: 0.900053
Avg Precision: 0.363128
Avg Recall: 1.000000
d_prime: 1.812814
train_loss: 0.159785
valid_loss: 1.084113
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.001404158804018187
Epoch-10 lr: 0.004212476412054561
epoch 10 training time: 15.424
---------------
2023-09-24 03:57:40.958971
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03971	Per Sample Data Time 0.02936	Per Sample DNN Time 0.01035	Train Loss 0.1271	
start validation
acc: 0.813397
AUC: 0.894029
Avg Precision: 0.391920
Avg Recall: 1.000000
d_prime: 1.765285
train_loss: 0.124909
valid_loss: 1.082109
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.001404158804018187
Epoch-11 lr: 0.004212476412054561
epoch 11 training time: 15.295
---------------
2023-09-24 03:57:56.253828
current #epochs=12, #steps=440
start validation
acc: 0.818182
AUC: 0.891921
Avg Precision: 0.369060
Avg Recall: 1.000000
d_prime: 1.749108
train_loss: 0.118596
valid_loss: 1.075564
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.001404158804018187
Epoch-12 lr: 0.004212476412054561
epoch 12 training time: 16.040
---------------
2023-09-24 03:58:12.293334
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00726	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00570	Train Loss 0.1158	
start validation
acc: 0.818182
AUC: 0.907075
Avg Precision: 0.357113
Avg Recall: 1.000000
d_prime: 1.870944
train_loss: 0.109084
valid_loss: 1.077081
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.001404158804018187
Epoch-13 lr: 0.004212476412054561
epoch 13 training time: 15.335
---------------
2023-09-24 03:58:27.628601
current #epochs=14, #steps=520
start validation
acc: 0.851675
AUC: 0.898555
Avg Precision: 0.358667
Avg Recall: 1.000000
d_prime: 1.800807
train_loss: 0.085654
valid_loss: 1.061211
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.001404158804018187
Epoch-14 lr: 0.004212476412054561
epoch 14 training time: 15.364
---------------
2023-09-24 03:58:42.992421
current #epochs=15, #steps=560
start validation
acc: 0.832536
AUC: 0.890064
Avg Precision: 0.348673
Avg Recall: 1.000000
d_prime: 1.735054
train_loss: 0.099966
valid_loss: 1.071208
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.001404158804018187
Epoch-15 lr: 0.004212476412054561
epoch 15 training time: 16.967
---------------
2023-09-24 03:58:59.959848
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04079	Per Sample Data Time 0.03072	Per Sample DNN Time 0.01007	Train Loss 0.0386	
start validation
acc: 0.813397
AUC: 0.897951
Avg Precision: 0.358595
Avg Recall: 1.000000
d_prime: 1.795999
train_loss: 0.094101
valid_loss: 1.092725
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.001404158804018187
Epoch-16 lr: 0.004212476412054561
epoch 16 training time: 15.392
---------------
2023-09-24 03:59:15.351790
current #epochs=17, #steps=640
start validation
[I 2023-09-24 03:59:30,787] Trial 91 finished with value: 0.3750928968227928 and parameters: {'warmup': 'True', 'num_epochs': 17, 'batch_size': 21, 'lr-adaptschedule': 'False', 'lr': 0.0019026108750591728, 'head-lr': 3, 'lr-scheduler-start': 10, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.7380168075484781}. Best is trial 87 with value: 0.45521598372193306.
acc: 0.837321
AUC: 0.906765
Avg Precision: 0.375093
Avg Recall: 1.000000
d_prime: 1.868312
train_loss: 0.115007
valid_loss: 1.054051
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.001404158804018187
Epoch-17 lr: 0.004212476412054561
epoch 17 training time: 15.423
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0a698b50>
The learning rate scheduler starts at 9 epoch with decay rate of 0.695 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 03:59:30.828629
current #epochs=1, #steps=0
start validation
acc: 0.832536
AUC: 0.888629
Avg Precision: 0.350757
Avg Recall: 1.000000
d_prime: 1.724306
train_loss: 0.165846
valid_loss: 1.099387
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0023391755437009417
Epoch-1 lr: 0.009356702174803767
epoch 1 training time: 17.776
---------------
2023-09-24 03:59:48.605011
current #epochs=2, #steps=40
start validation
acc: 0.837321
AUC: 0.897343
Avg Precision: 0.390013
Avg Recall: 1.000000
d_prime: 1.791182
train_loss: 0.140193
valid_loss: 1.080929
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0023391755437009417
Epoch-2 lr: 0.009356702174803767
epoch 2 training time: 17.911
---------------
2023-09-24 04:00:06.515909
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00718	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00556	Train Loss 0.1631	
start validation
acc: 0.842105
AUC: 0.899127
Avg Precision: 0.362182
Avg Recall: 1.000000
d_prime: 1.805372
train_loss: 0.154898
valid_loss: 1.084096
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0023391755437009417
Epoch-3 lr: 0.009356702174803767
epoch 3 training time: 17.658
---------------
2023-09-24 04:00:24.173759
current #epochs=4, #steps=120
start validation
acc: 0.784689
AUC: 0.883160
Avg Precision: 0.331230
Avg Recall: 1.000000
d_prime: 1.684232
train_loss: 0.159738
valid_loss: 1.115689
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0023391755437009417
Epoch-4 lr: 0.009356702174803767
epoch 4 training time: 16.958
---------------
2023-09-24 04:00:41.131647
current #epochs=5, #steps=160
start validation
acc: 0.779904
AUC: 0.866219
Avg Precision: 0.346970
Avg Recall: 1.000000
d_prime: 1.567933
train_loss: 0.170362
valid_loss: 1.087873
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0023391755437009417
Epoch-5 lr: 0.009356702174803767
epoch 5 training time: 16.268
---------------
2023-09-24 04:00:57.399278
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04068	Per Sample Data Time 0.03039	Per Sample DNN Time 0.01029	Train Loss 0.1125	
start validation
acc: 0.779904
AUC: 0.904549
Avg Precision: 0.396034
Avg Recall: 1.000000
d_prime: 1.849674
train_loss: 0.123969
valid_loss: 1.084794
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0023391755437009417
Epoch-6 lr: 0.009356702174803767
epoch 6 training time: 17.143
---------------
2023-09-24 04:01:14.542484
current #epochs=7, #steps=240
start validation
acc: 0.789474
AUC: 0.914550
Avg Precision: 0.384891
Avg Recall: 1.000000
d_prime: 1.936507
train_loss: 0.127037
valid_loss: 1.079886
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0023391755437009417
Epoch-7 lr: 0.009356702174803767
epoch 7 training time: 15.393
---------------
2023-09-24 04:01:29.935862
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00165	Per Sample DNN Time 0.00556	Train Loss 0.1332	
start validation
acc: 0.842105
AUC: 0.927024
Avg Precision: 0.411569
Avg Recall: 1.000000
d_prime: 2.056243
train_loss: 0.130396
valid_loss: 1.043153
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0023391755437009417
Epoch-8 lr: 0.009356702174803767
epoch 8 training time: 15.307
---------------
2023-09-24 04:01:45.243202
current #epochs=9, #steps=320
start validation
acc: 0.866029
AUC: 0.904859
Avg Precision: 0.374177
Avg Recall: 1.000000
d_prime: 1.852261
train_loss: 0.145535
valid_loss: 1.072351
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0016265211085530653
Epoch-9 lr: 0.006506084434212261
epoch 9 training time: 17.787
---------------
2023-09-24 04:02:03.030555
current #epochs=10, #steps=360
start validation
acc: 0.837321
AUC: 0.912843
Avg Precision: 0.422058
Avg Recall: 1.000000
d_prime: 1.921168
train_loss: 0.117346
valid_loss: 1.040262
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0016265211085530653
Epoch-10 lr: 0.006506084434212261
epoch 10 training time: 15.353
---------------
2023-09-24 04:02:18.383563
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04199	Per Sample Data Time 0.03160	Per Sample DNN Time 0.01039	Train Loss 0.0870	
start validation
acc: 0.784689
AUC: 0.911098
Avg Precision: 0.349319
Avg Recall: 1.000000
d_prime: 1.905721
train_loss: 0.106609
valid_loss: 1.066080
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0016265211085530653
Epoch-11 lr: 0.006506084434212261
epoch 11 training time: 15.339
---------------
2023-09-24 04:02:33.722863
current #epochs=12, #steps=440
start validation
acc: 0.842105
AUC: 0.922227
Avg Precision: 0.359060
Avg Recall: 1.000000
d_prime: 2.008485
train_loss: 0.088197
valid_loss: 1.031871
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0016265211085530653
Epoch-12 lr: 0.006506084434212261
epoch 12 training time: 17.106
---------------
2023-09-24 04:02:50.828544
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00712	Per Sample Data Time 0.00154	Per Sample DNN Time 0.00557	Train Loss 0.1149	
start validation
acc: 0.818182
AUC: 0.913941
Avg Precision: 0.359895
Avg Recall: 1.000000
d_prime: 1.931006
train_loss: 0.111915
valid_loss: 1.037170
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0016265211085530653
Epoch-13 lr: 0.006506084434212261
epoch 13 training time: 15.250
---------------
2023-09-24 04:03:06.078416
current #epochs=14, #steps=520
start validation
acc: 0.837321
AUC: 0.922825
Avg Precision: 0.405499
Avg Recall: 1.000000
d_prime: 2.014313
train_loss: 0.105125
valid_loss: 1.028822
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0016265211085530653
Epoch-14 lr: 0.006506084434212261
epoch 14 training time: 16.035
---------------
2023-09-24 04:03:22.113641
current #epochs=15, #steps=560
start validation
[I 2023-09-24 04:03:37,495] Trial 92 finished with value: 0.3693425818565005 and parameters: {'warmup': 'True', 'num_epochs': 15, 'batch_size': 31, 'lr-adaptschedule': 'False', 'lr': 0.0023391755437009417, 'head-lr': 4, 'lr-scheduler-start': 9, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.6953394810120384}. Best is trial 87 with value: 0.45521598372193306.
acc: 0.794258
AUC: 0.885524
Avg Precision: 0.369343
Avg Recall: 1.000000
d_prime: 1.701390
train_loss: 0.121517
valid_loss: 1.099112
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0016265211085530653
Epoch-15 lr: 0.006506084434212261
epoch 15 training time: 15.372
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc52645550>
The learning rate scheduler starts at 9 epoch with decay rate of 0.723 every 7 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 04:03:37.536484
current #epochs=1, #steps=0
start validation
acc: 0.803828
AUC: 0.910009
Avg Precision: 0.409961
Avg Recall: 1.000000
d_prime: 1.896189
train_loss: 0.165067
valid_loss: 1.060601
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0017691698137263564
Epoch-1 lr: 0.005307509441179069
epoch 1 training time: 17.861
---------------
2023-09-24 04:03:55.397456
current #epochs=2, #steps=40
start validation
acc: 0.851675
AUC: 0.912072
Avg Precision: 0.426833
Avg Recall: 1.000000
d_prime: 1.914312
train_loss: 0.123300
valid_loss: 1.034296
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0017691698137263564
Epoch-2 lr: 0.005307509441179069
epoch 2 training time: 17.777
---------------
2023-09-24 04:04:13.175084
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00715	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00559	Train Loss 0.0948	
start validation
acc: 0.803828
AUC: 0.889754
Avg Precision: 0.395496
Avg Recall: 1.000000
d_prime: 1.732727
train_loss: 0.090375
valid_loss: 1.062121
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0017691698137263564
Epoch-3 lr: 0.005307509441179069
epoch 3 training time: 15.258
---------------
2023-09-24 04:04:28.432546
current #epochs=4, #steps=120
start validation
acc: 0.856459
AUC: 0.916570
Avg Precision: 0.419169
Avg Recall: 1.000000
d_prime: 1.954957
train_loss: 0.075749
valid_loss: 1.047739
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0017691698137263564
Epoch-4 lr: 0.005307509441179069
epoch 4 training time: 17.817
---------------
2023-09-24 04:04:46.249318
current #epochs=5, #steps=160
start validation
acc: 0.813397
AUC: 0.884423
Avg Precision: 0.414207
Avg Recall: 1.000000
d_prime: 1.693369
train_loss: 0.107895
valid_loss: 1.087289
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0017691698137263564
Epoch-5 lr: 0.005307509441179069
epoch 5 training time: 18.323
---------------
2023-09-24 04:05:04.571833
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03908	Per Sample Data Time 0.02949	Per Sample DNN Time 0.00959	Train Loss 0.0724	
start validation
acc: 0.827751
AUC: 0.876902
Avg Precision: 0.393172
Avg Recall: 1.000000
d_prime: 1.639973
train_loss: 0.088552
valid_loss: 1.085457
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0017691698137263564
Epoch-6 lr: 0.005307509441179069
epoch 6 training time: 15.244
---------------
2023-09-24 04:05:19.815970
current #epochs=7, #steps=240
start validation
acc: 0.832536
AUC: 0.893285
Avg Precision: 0.442803
Avg Recall: 1.000000
d_prime: 1.759548
train_loss: 0.120434
valid_loss: 1.076587
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0017691698137263564
Epoch-7 lr: 0.005307509441179069
epoch 7 training time: 15.338
---------------
2023-09-24 04:05:35.153839
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00714	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00558	Train Loss 0.1092	
start validation
acc: 0.822967
AUC: 0.907560
Avg Precision: 0.361298
Avg Recall: 1.000000
d_prime: 1.875074
train_loss: 0.110475
valid_loss: 1.071102
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0017691698137263564
Epoch-8 lr: 0.005307509441179069
epoch 8 training time: 15.338
---------------
2023-09-24 04:05:50.492337
current #epochs=9, #steps=320
start validation
acc: 0.813397
AUC: 0.911903
Avg Precision: 0.336561
Avg Recall: 1.000000
d_prime: 1.912816
train_loss: 0.177451
valid_loss: 1.057418
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0012785814850180734
Epoch-9 lr: 0.0038357444550542207
epoch 9 training time: 15.232
---------------
2023-09-24 04:06:05.724259
current #epochs=10, #steps=360
start validation
acc: 0.775120
AUC: 0.885174
Avg Precision: 0.349713
Avg Recall: 1.000000
d_prime: 1.698835
train_loss: 0.170378
valid_loss: 1.098638
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0012785814850180734
Epoch-10 lr: 0.0038357444550542207
epoch 10 training time: 15.336
---------------
2023-09-24 04:06:21.060658
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03895	Per Sample Data Time 0.02887	Per Sample DNN Time 0.01008	Train Loss 0.1336	
start validation
acc: 0.813397
AUC: 0.874144
Avg Precision: 0.348727
Avg Recall: 1.000000
d_prime: 1.620972
train_loss: 0.156242
valid_loss: 1.111268
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0012785814850180734
Epoch-11 lr: 0.0038357444550542207
epoch 11 training time: 15.244
---------------
2023-09-24 04:06:36.304903
current #epochs=12, #steps=440
start validation
acc: 0.803828
AUC: 0.894658
Avg Precision: 0.336239
Avg Recall: 1.000000
d_prime: 1.770149
train_loss: 0.127665
valid_loss: 1.076205
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0012785814850180734
Epoch-12 lr: 0.0038357444550542207
epoch 12 training time: 15.318
---------------
2023-09-24 04:06:51.622905
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00563	Train Loss 0.1351	
start validation
acc: 0.784689
AUC: 0.907633
Avg Precision: 0.349148
Avg Recall: 1.000000
d_prime: 1.875696
train_loss: 0.127706
valid_loss: 1.078452
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0012785814850180734
Epoch-13 lr: 0.0038357444550542207
epoch 13 training time: 15.366
---------------
2023-09-24 04:07:06.988592
current #epochs=14, #steps=520
start validation
acc: 0.837321
AUC: 0.921594
Avg Precision: 0.414781
Avg Recall: 1.000000
d_prime: 2.002347
train_loss: 0.125103
valid_loss: 1.060583
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0012785814850180734
Epoch-14 lr: 0.0038357444550542207
epoch 14 training time: 15.285
---------------
2023-09-24 04:07:22.273056
current #epochs=15, #steps=560
start validation
acc: 0.851675
AUC: 0.909791
Avg Precision: 0.436867
Avg Recall: 1.000000
d_prime: 1.894295
train_loss: 0.172966
valid_loss: 1.073178
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0012785814850180734
Epoch-15 lr: 0.0038357444550542207
epoch 15 training time: 15.287
---------------
2023-09-24 04:07:37.559884
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04117	Per Sample Data Time 0.03073	Per Sample DNN Time 0.01044	Train Loss 0.1391	
start validation
acc: 0.842105
AUC: 0.914620
Avg Precision: 0.408381
Avg Recall: 1.000000
d_prime: 1.937142
train_loss: 0.172461
valid_loss: 1.066463
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0009240326175290925
Epoch-16 lr: 0.002772097852587278
epoch 16 training time: 15.341
---------------
2023-09-24 04:07:52.901006
current #epochs=17, #steps=640
start validation
acc: 0.837321
AUC: 0.909637
Avg Precision: 0.374735
Avg Recall: 1.000000
d_prime: 1.892956
train_loss: 0.140630
valid_loss: 1.062669
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0009240326175290925
Epoch-17 lr: 0.002772097852587278
epoch 17 training time: 15.317
---------------
2023-09-24 04:08:08.217684
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00563	Train Loss 0.1053	
start validation
acc: 0.818182
AUC: 0.909162
Avg Precision: 0.387021
Avg Recall: 1.000000
d_prime: 1.888844
train_loss: 0.110698
valid_loss: 1.067659
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0009240326175290925
Epoch-18 lr: 0.002772097852587278
epoch 18 training time: 15.294
---------------
2023-09-24 04:08:23.511877
current #epochs=19, #steps=720
start validation
acc: 0.846890
AUC: 0.902333
Avg Precision: 0.408103
Avg Recall: 1.000000
d_prime: 1.831348
train_loss: 0.102801
valid_loss: 1.057903
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0009240326175290925
Epoch-19 lr: 0.002772097852587278
epoch 19 training time: 15.387
---------------
2023-09-24 04:08:38.898856
current #epochs=20, #steps=760
start validation
acc: 0.765550
AUC: 0.913248
Avg Precision: 0.350435
Avg Recall: 1.000000
d_prime: 1.924791
train_loss: 0.225620
valid_loss: 1.065654
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0009240326175290925
Epoch-20 lr: 0.002772097852587278
epoch 20 training time: 17.017
---------------
2023-09-24 04:08:55.916209
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04084	Per Sample Data Time 0.03119	Per Sample DNN Time 0.00965	Train Loss 0.2075	
start validation
[I 2023-09-24 04:09:11,271] Trial 93 finished with value: 0.3871373407703701 and parameters: {'warmup': 'True', 'num_epochs': 21, 'batch_size': 25, 'lr-adaptschedule': 'False', 'lr': 0.0017691698137263564, 'head-lr': 3, 'lr-scheduler-start': 9, 'lr-scheduler-step': 7, 'lr-scheduler-decay': 0.7227013908433304}. Best is trial 87 with value: 0.45521598372193306.
acc: 0.765550
AUC: 0.910310
Avg Precision: 0.387137
Avg Recall: 1.000000
d_prime: 1.898813
train_loss: 0.300998
valid_loss: 1.083744
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0009240326175290925
Epoch-21 lr: 0.002772097852587278
epoch 21 training time: 15.343
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0a698520>
The learning rate scheduler starts at 10 epoch with decay rate of 0.705 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 04:09:11.312420
current #epochs=1, #steps=0
start validation
acc: 0.861244
AUC: 0.927089
Avg Precision: 0.401397
Avg Recall: 1.000000
d_prime: 2.056904
train_loss: 0.202362
valid_loss: 1.048048
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.001964519160206966
Epoch-1 lr: 0.007858076640827863
epoch 1 training time: 17.883
---------------
2023-09-24 04:09:29.195270
current #epochs=2, #steps=40
start validation
acc: 0.799043
AUC: 0.916976
Avg Precision: 0.341153
Avg Recall: 1.000000
d_prime: 1.958708
train_loss: 0.150882
valid_loss: 1.069187
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.001964519160206966
Epoch-2 lr: 0.007858076640827863
epoch 2 training time: 15.246
---------------
2023-09-24 04:09:44.440935
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00555	Train Loss 0.1391	
start validation
acc: 0.827751
AUC: 0.884722
Avg Precision: 0.342008
Avg Recall: 1.000000
d_prime: 1.695540
train_loss: 0.150532
valid_loss: 1.095051
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.001964519160206966
Epoch-3 lr: 0.007858076640827863
epoch 3 training time: 15.370
---------------
2023-09-24 04:09:59.810997
current #epochs=4, #steps=120
start validation
acc: 0.832536
AUC: 0.920137
Avg Precision: 0.371056
Avg Recall: 1.000000
d_prime: 1.988375
train_loss: 0.122356
valid_loss: 1.064797
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.001964519160206966
Epoch-4 lr: 0.007858076640827863
epoch 4 training time: 15.152
---------------
2023-09-24 04:10:14.962977
current #epochs=5, #steps=160
start validation
acc: 0.784689
AUC: 0.898676
Avg Precision: 0.341031
Avg Recall: 1.000000
d_prime: 1.801771
train_loss: 0.134774
valid_loss: 1.089900
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.001964519160206966
Epoch-5 lr: 0.007858076640827863
epoch 5 training time: 15.419
---------------
2023-09-24 04:10:30.381345
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04027	Per Sample Data Time 0.03011	Per Sample DNN Time 0.01016	Train Loss 0.0470	
start validation
acc: 0.803828
AUC: 0.881150
Avg Precision: 0.386684
Avg Recall: 1.000000
d_prime: 1.669840
train_loss: 0.148053
valid_loss: 1.108911
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.001964519160206966
Epoch-6 lr: 0.007858076640827863
epoch 6 training time: 15.306
---------------
2023-09-24 04:10:45.687387
current #epochs=7, #steps=240
start validation
acc: 0.827751
AUC: 0.914154
Avg Precision: 0.374226
Avg Recall: 1.000000
d_prime: 1.932932
train_loss: 0.182264
valid_loss: 1.084591
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.001964519160206966
Epoch-7 lr: 0.007858076640827863
epoch 7 training time: 15.429
---------------
2023-09-24 04:11:01.116699
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00561	Train Loss 0.1087	
start validation
acc: 0.746411
AUC: 0.874856
Avg Precision: 0.331091
Avg Recall: 1.000000
d_prime: 1.625848
train_loss: 0.153577
valid_loss: 1.105069
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.001964519160206966
Epoch-8 lr: 0.007858076640827863
epoch 8 training time: 15.302
---------------
2023-09-24 04:11:16.418713
current #epochs=9, #steps=320
start validation
acc: 0.818182
AUC: 0.912489
Avg Precision: 0.355943
Avg Recall: 1.000000
d_prime: 1.918018
train_loss: 0.117642
valid_loss: 1.054926
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.001964519160206966
Epoch-9 lr: 0.007858076640827863
epoch 9 training time: 15.357
---------------
2023-09-24 04:11:31.775122
current #epochs=10, #steps=360
start validation
acc: 0.799043
AUC: 0.879733
Avg Precision: 0.351990
Avg Recall: 1.000000
d_prime: 1.659798
train_loss: 0.106039
valid_loss: 1.088832
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0013848570762911975
Epoch-10 lr: 0.00553942830516479
epoch 10 training time: 15.409
---------------
2023-09-24 04:11:47.183717
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04045	Per Sample Data Time 0.03128	Per Sample DNN Time 0.00918	Train Loss 0.1221	
start validation
acc: 0.822967
AUC: 0.892616
Avg Precision: 0.389273
Avg Recall: 1.000000
d_prime: 1.754420
train_loss: 0.139540
valid_loss: 1.097170
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0013848570762911975
Epoch-11 lr: 0.00553942830516479
epoch 11 training time: 15.844
---------------
2023-09-24 04:12:03.027784
current #epochs=12, #steps=440
start validation
acc: 0.813397
AUC: 0.905924
Avg Precision: 0.360410
Avg Recall: 1.000000
d_prime: 1.861196
train_loss: 0.114654
valid_loss: 1.083058
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0013848570762911975
Epoch-12 lr: 0.00553942830516479
epoch 12 training time: 15.373
---------------
2023-09-24 04:12:18.400336
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00725	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00565	Train Loss 0.1086	
start validation
acc: 0.842105
AUC: 0.911501
Avg Precision: 0.391111
Avg Recall: 1.000000
d_prime: 1.909268
train_loss: 0.097618
valid_loss: 1.061969
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0013848570762911975
Epoch-13 lr: 0.00553942830516479
epoch 13 training time: 15.344
---------------
2023-09-24 04:12:33.744728
current #epochs=14, #steps=520
start validation
acc: 0.832536
AUC: 0.921955
Avg Precision: 0.388284
Avg Recall: 1.000000
d_prime: 2.005840
train_loss: 0.099152
valid_loss: 1.044912
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0013848570762911975
Epoch-14 lr: 0.00553942830516479
epoch 14 training time: 15.263
---------------
2023-09-24 04:12:49.008200
current #epochs=15, #steps=560
start validation
acc: 0.818182
AUC: 0.891792
Avg Precision: 0.347741
Avg Recall: 1.000000
d_prime: 1.748129
train_loss: 0.101915
valid_loss: 1.079677
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0013848570762911975
Epoch-15 lr: 0.00553942830516479
epoch 15 training time: 15.291
---------------
2023-09-24 04:13:04.298621
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04012	Per Sample Data Time 0.02924	Per Sample DNN Time 0.01088	Train Loss 0.0986	
start validation
acc: 0.813397
AUC: 0.894565
Avg Precision: 0.352839
Avg Recall: 1.000000
d_prime: 1.769432
train_loss: 0.110355
valid_loss: 1.085477
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0013848570762911975
Epoch-16 lr: 0.00553942830516479
epoch 16 training time: 15.284
---------------
2023-09-24 04:13:19.582809
current #epochs=17, #steps=640
start validation
acc: 0.799043
AUC: 0.884212
Avg Precision: 0.347912
Avg Recall: 1.000000
d_prime: 1.691834
train_loss: 0.089849
valid_loss: 1.085805
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0013848570762911975
Epoch-17 lr: 0.00553942830516479
epoch 17 training time: 15.376
---------------
2023-09-24 04:13:34.959031
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00564	Train Loss 0.0904	
start validation
acc: 0.813397
AUC: 0.910893
Avg Precision: 0.390849
Avg Recall: 1.000000
d_prime: 1.903922
train_loss: 0.089850
valid_loss: 1.054479
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.000976233350430523
Epoch-18 lr: 0.003904933401722092
epoch 18 training time: 15.369
---------------
2023-09-24 04:13:50.327638
current #epochs=19, #steps=720
start validation
acc: 0.827751
AUC: 0.922662
Avg Precision: 0.415657
Avg Recall: 1.000000
d_prime: 2.012722
train_loss: 0.100277
valid_loss: 1.057576
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.000976233350430523
Epoch-19 lr: 0.003904933401722092
epoch 19 training time: 15.219
---------------
2023-09-24 04:14:05.547138
current #epochs=20, #steps=760
start validation
acc: 0.818182
AUC: 0.907002
Avg Precision: 0.373317
Avg Recall: 1.000000
d_prime: 1.870323
train_loss: 0.083139
valid_loss: 1.072640
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.000976233350430523
Epoch-20 lr: 0.003904933401722092
epoch 20 training time: 15.412
---------------
2023-09-24 04:14:20.959149
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04172	Per Sample Data Time 0.03128	Per Sample DNN Time 0.01044	Train Loss 0.2208	
start validation
acc: 0.799043
AUC: 0.897941
Avg Precision: 0.358832
Avg Recall: 1.000000
d_prime: 1.795922
train_loss: 0.084888
valid_loss: 1.077373
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.000976233350430523
Epoch-21 lr: 0.003904933401722092
epoch 21 training time: 15.422
---------------
2023-09-24 04:14:36.380936
current #epochs=22, #steps=840
start validation
acc: 0.827751
AUC: 0.903576
Avg Precision: 0.386038
Avg Recall: 1.000000
d_prime: 1.841592
train_loss: 0.094437
valid_loss: 1.065825
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.000976233350430523
Epoch-22 lr: 0.003904933401722092
epoch 22 training time: 15.303
---------------
2023-09-24 04:14:51.684424
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00723	Per Sample Data Time 0.00159	Per Sample DNN Time 0.00565	Train Loss 0.0971	
start validation
acc: 0.837321
AUC: 0.899364
Avg Precision: 0.359851
Avg Recall: 1.000000
d_prime: 1.807277
train_loss: 0.096882
valid_loss: 1.073077
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.000976233350430523
Epoch-23 lr: 0.003904933401722092
epoch 23 training time: 15.364
---------------
2023-09-24 04:15:07.048130
current #epochs=24, #steps=920
start validation
acc: 0.832536
AUC: 0.899901
Avg Precision: 0.357746
Avg Recall: 1.000000
d_prime: 1.811587
train_loss: 0.103817
valid_loss: 1.073293
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.000976233350430523
Epoch-24 lr: 0.003904933401722092
epoch 24 training time: 15.304
---------------
2023-09-24 04:15:22.351877
current #epochs=25, #steps=960
start validation
acc: 0.803828
AUC: 0.875001
Avg Precision: 0.335976
Avg Recall: 1.000000
d_prime: 1.626849
train_loss: 0.110345
valid_loss: 1.089394
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.000976233350430523
Epoch-25 lr: 0.003904933401722092
epoch 25 training time: 15.402
---------------
2023-09-24 04:15:37.753681
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.04133	Per Sample Data Time 0.03127	Per Sample DNN Time 0.01006	Train Loss 0.1489	
start validation
acc: 0.822967
AUC: 0.881330
Avg Precision: 0.351655
Avg Recall: 1.000000
d_prime: 1.671125
train_loss: 0.079040
valid_loss: 1.079698
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.0006881804417284198
Epoch-26 lr: 0.0027527217669136793
epoch 26 training time: 15.382
---------------
2023-09-24 04:15:53.135544
current #epochs=27, #steps=1040
start validation
acc: 0.803828
AUC: 0.881035
Avg Precision: 0.345315
Avg Recall: 1.000000
d_prime: 1.669019
train_loss: 0.072678
valid_loss: 1.075549
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.0006881804417284198
Epoch-27 lr: 0.0027527217669136793
epoch 27 training time: 15.286
---------------
2023-09-24 04:16:08.421756
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00562	Train Loss 0.0790	
start validation
acc: 0.803828
AUC: 0.890544
Avg Precision: 0.340108
Avg Recall: 1.000000
d_prime: 1.738674
train_loss: 0.092305
valid_loss: 1.089499
validation finished
normal learning rate scheduler step
Epoch-28 lr: 0.0006881804417284198
Epoch-28 lr: 0.0027527217669136793
epoch 28 training time: 15.319
---------------
2023-09-24 04:16:23.741158
current #epochs=29, #steps=1120
start validation
acc: 0.832536
AUC: 0.894231
Avg Precision: 0.347450
Avg Recall: 1.000000
d_prime: 1.766842
train_loss: 0.098130
valid_loss: 1.085892
validation finished
normal learning rate scheduler step
Epoch-29 lr: 0.0006881804417284198
Epoch-29 lr: 0.0027527217669136793
epoch 29 training time: 15.366
---------------
2023-09-24 04:16:39.107673
current #epochs=30, #steps=1160
start validation
acc: 0.813397
AUC: 0.899611
Avg Precision: 0.336895
Avg Recall: 1.000000
d_prime: 1.809253
train_loss: 0.093946
valid_loss: 1.086801
validation finished
normal learning rate scheduler step
Epoch-30 lr: 0.0006881804417284198
Epoch-30 lr: 0.0027527217669136793
epoch 30 training time: 15.373
---------------
2023-09-24 04:16:54.480813
current #epochs=31, #steps=1200
Epoch: [31][0/40]	Per Sample Total Time 0.04057	Per Sample Data Time 0.02974	Per Sample DNN Time 0.01082	Train Loss 0.0835	
start validation
acc: 0.803828
AUC: 0.889768
Avg Precision: 0.333855
Avg Recall: 1.000000
d_prime: 1.732830
train_loss: 0.099013
valid_loss: 1.097119
validation finished
normal learning rate scheduler step
Epoch-31 lr: 0.0006881804417284198
Epoch-31 lr: 0.0027527217669136793
epoch 31 training time: 15.355
---------------
2023-09-24 04:17:09.835609
current #epochs=32, #steps=1240
start validation
acc: 0.794258
AUC: 0.895068
Avg Precision: 0.330858
Avg Recall: 1.000000
d_prime: 1.773341
train_loss: 0.085576
valid_loss: 1.092609
validation finished
normal learning rate scheduler step
Epoch-32 lr: 0.0006881804417284198
Epoch-32 lr: 0.0027527217669136793
epoch 32 training time: 15.984
---------------
2023-09-24 04:17:25.819412
current #epochs=33, #steps=1280
Epoch: [33][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00567	Train Loss 0.0873	
start validation
acc: 0.794258
AUC: 0.897052
Avg Precision: 0.330594
Avg Recall: 1.000000
d_prime: 1.788883
train_loss: 0.080738
valid_loss: 1.089324
validation finished
normal learning rate scheduler step
Epoch-33 lr: 0.0006881804417284198
Epoch-33 lr: 0.0027527217669136793
epoch 33 training time: 15.367
---------------
2023-09-24 04:17:41.186069
current #epochs=34, #steps=1320
start validation
acc: 0.818182
AUC: 0.894364
Avg Precision: 0.352684
Avg Recall: 1.000000
d_prime: 1.767876
train_loss: 0.087121
valid_loss: 1.083533
validation finished
normal learning rate scheduler step
Epoch-34 lr: 0.0004851220460442853
Epoch-34 lr: 0.0019404881841771412
epoch 34 training time: 17.124
---------------
2023-09-24 04:17:58.309718
current #epochs=35, #steps=1360
start validation
acc: 0.808612
AUC: 0.906464
Avg Precision: 0.379140
Avg Recall: 1.000000
d_prime: 1.865759
train_loss: 0.084822
valid_loss: 1.087737
validation finished
normal learning rate scheduler step
Epoch-35 lr: 0.0004851220460442853
Epoch-35 lr: 0.0019404881841771412
epoch 35 training time: 15.340
---------------
2023-09-24 04:18:13.650124
current #epochs=36, #steps=1400
Epoch: [36][0/40]	Per Sample Total Time 0.04234	Per Sample Data Time 0.03199	Per Sample DNN Time 0.01035	Train Loss 0.0877	
start validation
acc: 0.818182
AUC: 0.894001
Avg Precision: 0.359938
Avg Recall: 1.000000
d_prime: 1.765067
train_loss: 0.092920
valid_loss: 1.099694
validation finished
normal learning rate scheduler step
Epoch-36 lr: 0.0004851220460442853
Epoch-36 lr: 0.0019404881841771412
epoch 36 training time: 15.485
---------------
2023-09-24 04:18:29.135354
current #epochs=37, #steps=1440
start validation
acc: 0.813397
AUC: 0.893006
Avg Precision: 0.362477
Avg Recall: 1.000000
d_prime: 1.757406
train_loss: 0.087787
valid_loss: 1.088800
validation finished
normal learning rate scheduler step
Epoch-37 lr: 0.0004851220460442853
Epoch-37 lr: 0.0019404881841771412
epoch 37 training time: 15.514
---------------
2023-09-24 04:18:44.649640
current #epochs=38, #steps=1480
Epoch: [38][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00154	Per Sample DNN Time 0.00564	Train Loss 0.0798	
start validation
acc: 0.799043
AUC: 0.888102
Avg Precision: 0.372878
Avg Recall: 1.000000
d_prime: 1.720383
train_loss: 0.075070
valid_loss: 1.091709
validation finished
normal learning rate scheduler step
Epoch-38 lr: 0.0004851220460442853
Epoch-38 lr: 0.0019404881841771412
epoch 38 training time: 15.479
---------------
2023-09-24 04:19:00.128336
current #epochs=39, #steps=1520
start validation
acc: 0.784689
AUC: 0.882812
Avg Precision: 0.346512
Avg Recall: 1.000000
d_prime: 1.681732
train_loss: 0.095715
valid_loss: 1.086555
validation finished
normal learning rate scheduler step
Epoch-39 lr: 0.0004851220460442853
Epoch-39 lr: 0.0019404881841771412
epoch 39 training time: 15.256
---------------
2023-09-24 04:19:15.384102
current #epochs=40, #steps=1560
start validation
acc: 0.822967
AUC: 0.887594
Avg Precision: 0.368423
Avg Recall: 1.000000
d_prime: 1.716616
train_loss: 0.102616
valid_loss: 1.087223
validation finished
normal learning rate scheduler step
Epoch-40 lr: 0.0004851220460442853
Epoch-40 lr: 0.0019404881841771412
epoch 40 training time: 15.404
---------------
2023-09-24 04:19:30.787914
current #epochs=41, #steps=1600
Epoch: [41][0/40]	Per Sample Total Time 0.04086	Per Sample Data Time 0.03007	Per Sample DNN Time 0.01080	Train Loss 0.0248	
start validation
acc: 0.813397
AUC: 0.901069
Avg Precision: 0.368194
Avg Recall: 1.000000
d_prime: 1.821036
train_loss: 0.077752
valid_loss: 1.078228
validation finished
normal learning rate scheduler step
Epoch-41 lr: 0.0004851220460442853
Epoch-41 lr: 0.0019404881841771412
epoch 41 training time: 15.375
---------------
2023-09-24 04:19:46.162947
current #epochs=42, #steps=1640
start validation
acc: 0.813397
AUC: 0.903738
Avg Precision: 0.367934
Avg Recall: 1.000000
d_prime: 1.842932
train_loss: 0.072654
valid_loss: 1.064451
validation finished
normal learning rate scheduler step
Epoch-42 lr: 0.0003419792038365839
Epoch-42 lr: 0.0013679168153463356
epoch 42 training time: 15.316
---------------
2023-09-24 04:20:01.479067
current #epochs=43, #steps=1680
Epoch: [43][20/40]	Per Sample Total Time 0.00723	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00563	Train Loss 0.0839	
start validation
acc: 0.822967
AUC: 0.908124
Avg Precision: 0.390403
Avg Recall: 1.000000
d_prime: 1.879901
train_loss: 0.081185
valid_loss: 1.073349
validation finished
normal learning rate scheduler step
Epoch-43 lr: 0.0003419792038365839
Epoch-43 lr: 0.0013679168153463356
epoch 43 training time: 15.270
---------------
2023-09-24 04:20:16.749042
current #epochs=44, #steps=1720
start validation
acc: 0.822967
AUC: 0.913572
Avg Precision: 0.393899
Avg Recall: 1.000000
d_prime: 1.927695
train_loss: 0.078874
valid_loss: 1.054114
validation finished
normal learning rate scheduler step
Epoch-44 lr: 0.0003419792038365839
Epoch-44 lr: 0.0013679168153463356
epoch 44 training time: 16.281
---------------
2023-09-24 04:20:33.030265
current #epochs=45, #steps=1760
start validation
[I 2023-09-24 04:20:48,471] Trial 94 finished with value: 0.3973899330880444 and parameters: {'warmup': 'True', 'num_epochs': 45, 'batch_size': 18, 'lr-adaptschedule': 'False', 'lr': 0.001964519160206966, 'head-lr': 4, 'lr-scheduler-start': 10, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.7049343698665175}. Best is trial 87 with value: 0.45521598372193306.
acc: 0.861244
AUC: 0.909639
Avg Precision: 0.397390
Avg Recall: 1.000000
d_prime: 1.892975
train_loss: 0.085242
valid_loss: 1.046410
validation finished
normal learning rate scheduler step
Epoch-45 lr: 0.0003419792038365839
Epoch-45 lr: 0.0013679168153463356
epoch 45 training time: 15.430
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 3 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51d9a610>
The learning rate scheduler starts at 10 epoch with decay rate of 0.715 every 8 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 04:20:48.514003
current #epochs=1, #steps=0
start validation
acc: 0.784689
AUC: 0.894474
Avg Precision: 0.323527
Avg Recall: 1.000000
d_prime: 1.768728
train_loss: 0.171156
valid_loss: 1.115391
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.002196317528724911
Epoch-1 lr: 0.006588952586174732
epoch 1 training time: 18.260
---------------
2023-09-24 04:21:06.774365
current #epochs=2, #steps=40
start validation
acc: 0.856459
AUC: 0.915973
Avg Precision: 0.342798
Avg Recall: 1.000000
d_prime: 1.949475
train_loss: 0.152783
valid_loss: 1.059588
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.002196317528724911
Epoch-2 lr: 0.006588952586174732
epoch 2 training time: 18.410
---------------
2023-09-24 04:21:25.183976
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00561	Train Loss 0.1186	
start validation
acc: 0.827751
AUC: 0.897129
Avg Precision: 0.343306
Avg Recall: 1.000000
d_prime: 1.789493
train_loss: 0.138642
valid_loss: 1.081044
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.002196317528724911
Epoch-3 lr: 0.006588952586174732
epoch 3 training time: 15.404
---------------
2023-09-24 04:21:40.588269
current #epochs=4, #steps=120
start validation
acc: 0.789474
AUC: 0.898803
Avg Precision: 0.382501
Avg Recall: 1.000000
d_prime: 1.802782
train_loss: 0.135003
valid_loss: 1.096743
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.002196317528724911
Epoch-4 lr: 0.006588952586174732
epoch 4 training time: 15.385
---------------
2023-09-24 04:21:55.973009
current #epochs=5, #steps=160
start validation
acc: 0.746411
AUC: 0.876135
Avg Precision: 0.338047
Avg Recall: 1.000000
d_prime: 1.634664
train_loss: 0.161760
valid_loss: 1.100642
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.002196317528724911
Epoch-5 lr: 0.006588952586174732
epoch 5 training time: 15.317
---------------
2023-09-24 04:22:11.290152
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04099	Per Sample Data Time 0.03196	Per Sample DNN Time 0.00903	Train Loss 0.1008	
start validation
acc: 0.842105
AUC: 0.926268
Avg Precision: 0.377255
Avg Recall: 1.000000
d_prime: 2.048553
train_loss: 0.151032
valid_loss: 1.053058
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.002196317528724911
Epoch-6 lr: 0.006588952586174732
epoch 6 training time: 15.276
---------------
2023-09-24 04:22:26.566167
current #epochs=7, #steps=240
start validation
acc: 0.799043
AUC: 0.903665
Avg Precision: 0.333911
Avg Recall: 1.000000
d_prime: 1.842328
train_loss: 0.154357
valid_loss: 1.087505
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.002196317528724911
Epoch-7 lr: 0.006588952586174732
epoch 7 training time: 15.347
---------------
2023-09-24 04:22:41.913589
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00562	Train Loss 0.1445	
start validation
acc: 0.846890
AUC: 0.922240
Avg Precision: 0.416345
Avg Recall: 1.000000
d_prime: 2.008611
train_loss: 0.122777
valid_loss: 1.062437
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.002196317528724911
Epoch-8 lr: 0.006588952586174732
epoch 8 training time: 15.406
---------------
2023-09-24 04:22:57.320410
current #epochs=9, #steps=320
start validation
acc: 0.808612
AUC: 0.924926
Avg Precision: 0.423128
Avg Recall: 1.000000
d_prime: 2.035070
train_loss: 0.147781
valid_loss: 1.074351
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.002196317528724911
Epoch-9 lr: 0.006588952586174732
epoch 9 training time: 15.365
---------------
2023-09-24 04:23:12.685024
current #epochs=10, #steps=360
start validation
acc: 0.861244
AUC: 0.904764
Avg Precision: 0.369993
Avg Recall: 1.000000
d_prime: 1.851464
train_loss: 0.169079
valid_loss: 1.074524
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0015698858142003552
Epoch-10 lr: 0.004709657442601065
epoch 10 training time: 17.853
---------------
2023-09-24 04:23:30.538277
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03993	Per Sample Data Time 0.02905	Per Sample DNN Time 0.01088	Train Loss 0.1281	
start validation
acc: 0.808612
AUC: 0.916206
Avg Precision: 0.422099
Avg Recall: 1.000000
d_prime: 1.951612
train_loss: 0.136692
valid_loss: 1.108053
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0015698858142003552
Epoch-11 lr: 0.004709657442601065
epoch 11 training time: 15.234
---------------
2023-09-24 04:23:45.772533
current #epochs=12, #steps=440
start validation
acc: 0.846890
AUC: 0.909982
Avg Precision: 0.383639
Avg Recall: 1.000000
d_prime: 1.895953
train_loss: 0.147926
valid_loss: 1.104256
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0015698858142003552
Epoch-12 lr: 0.004709657442601065
epoch 12 training time: 15.314
---------------
2023-09-24 04:24:01.086265
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00720	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00562	Train Loss 0.1413	
start validation
[I 2023-09-24 04:24:16,361] Trial 95 finished with value: 0.36383831199620675 and parameters: {'warmup': 'True', 'num_epochs': 13, 'batch_size': 22, 'lr-adaptschedule': 'False', 'lr': 0.002196317528724911, 'head-lr': 3, 'lr-scheduler-start': 10, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.7147808974195842}. Best is trial 87 with value: 0.45521598372193306.
acc: 0.822967
AUC: 0.903549
Avg Precision: 0.363838
Avg Recall: 1.000000
d_prime: 1.841369
train_loss: 0.152645
valid_loss: 1.104926
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0015698858142003552
Epoch-13 lr: 0.004709657442601065
epoch 13 training time: 15.264
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc51d9abb0>
The learning rate scheduler starts at 9 epoch with decay rate of 0.754 every 2 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 04:24:16.402620
current #epochs=1, #steps=0
start validation
acc: 0.842105
AUC: 0.908321
Avg Precision: 0.367415
Avg Recall: 1.000000
d_prime: 1.881591
train_loss: 0.175178
valid_loss: 1.080918
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0016629645473827826
Epoch-1 lr: 0.0066518581895311304
epoch 1 training time: 18.160
---------------
2023-09-24 04:24:34.563610
current #epochs=2, #steps=40
start validation
acc: 0.827751
AUC: 0.925976
Avg Precision: 0.363056
Avg Recall: 1.000000
d_prime: 2.045604
train_loss: 0.155119
valid_loss: 1.089497
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0016629645473827826
Epoch-2 lr: 0.0066518581895311304
epoch 2 training time: 15.991
---------------
2023-09-24 04:24:50.554562
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00716	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00555	Train Loss 0.1262	
start validation
acc: 0.885167
AUC: 0.914776
Avg Precision: 0.421756
Avg Recall: 1.000000
d_prime: 1.938551
train_loss: 0.120126
valid_loss: 1.054270
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0016629645473827826
Epoch-3 lr: 0.0066518581895311304
epoch 3 training time: 18.152
---------------
2023-09-24 04:25:08.706429
current #epochs=4, #steps=120
start validation
acc: 0.789474
AUC: 0.872539
Avg Precision: 0.323073
Avg Recall: 1.000000
d_prime: 1.610050
train_loss: 0.129411
valid_loss: 1.091440
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0016629645473827826
Epoch-4 lr: 0.0066518581895311304
epoch 4 training time: 15.321
---------------
2023-09-24 04:25:24.027485
current #epochs=5, #steps=160
start validation
acc: 0.822967
AUC: 0.897487
Avg Precision: 0.348143
Avg Recall: 1.000000
d_prime: 1.792322
train_loss: 0.134543
valid_loss: 1.086077
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0016629645473827826
Epoch-5 lr: 0.0066518581895311304
epoch 5 training time: 15.194
---------------
2023-09-24 04:25:39.221870
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04051	Per Sample Data Time 0.03091	Per Sample DNN Time 0.00960	Train Loss 0.0787	
start validation
acc: 0.827751
AUC: 0.905686
Avg Precision: 0.372781
Avg Recall: 1.000000
d_prime: 1.859195
train_loss: 0.082936
valid_loss: 1.065028
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0016629645473827826
Epoch-6 lr: 0.0066518581895311304
epoch 6 training time: 15.362
---------------
2023-09-24 04:25:54.583960
current #epochs=7, #steps=240
start validation
acc: 0.851675
AUC: 0.891384
Avg Precision: 0.369061
Avg Recall: 1.000000
d_prime: 1.745027
train_loss: 0.112100
valid_loss: 1.080017
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0016629645473827826
Epoch-7 lr: 0.0066518581895311304
epoch 7 training time: 15.659
---------------
2023-09-24 04:26:10.243253
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00156	Per Sample DNN Time 0.00566	Train Loss 0.1588	
start validation
acc: 0.870813
AUC: 0.908028
Avg Precision: 0.394959
Avg Recall: 1.000000
d_prime: 1.879078
train_loss: 0.158743
valid_loss: 1.053099
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0016629645473827826
Epoch-8 lr: 0.0066518581895311304
epoch 8 training time: 15.317
---------------
2023-09-24 04:26:25.560483
current #epochs=9, #steps=320
start validation
acc: 0.837321
AUC: 0.910415
Avg Precision: 0.375419
Avg Recall: 1.000000
d_prime: 1.899738
train_loss: 0.113764
valid_loss: 1.053807
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0012532206545017614
Epoch-9 lr: 0.0050128826180070455
epoch 9 training time: 15.435
---------------
2023-09-24 04:26:40.995659
current #epochs=10, #steps=360
start validation
acc: 0.827751
AUC: 0.900220
Avg Precision: 0.374373
Avg Recall: 1.000000
d_prime: 1.814159
train_loss: 0.128745
valid_loss: 1.057960
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0012532206545017614
Epoch-10 lr: 0.0050128826180070455
epoch 10 training time: 15.279
---------------
2023-09-24 04:26:56.274675
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04090	Per Sample Data Time 0.03093	Per Sample DNN Time 0.00997	Train Loss 0.2372	
start validation
acc: 0.842105
AUC: 0.909099
Avg Precision: 0.408692
Avg Recall: 1.000000
d_prime: 1.888294
train_loss: 0.104545
valid_loss: 1.054969
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0009444350520530428
Epoch-11 lr: 0.0037777402082121714
epoch 11 training time: 15.390
---------------
2023-09-24 04:27:11.664654
current #epochs=12, #steps=440
start validation
acc: 0.813397
AUC: 0.907061
Avg Precision: 0.369770
Avg Recall: 1.000000
d_prime: 1.870827
train_loss: 0.100901
valid_loss: 1.060430
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0009444350520530428
Epoch-12 lr: 0.0037777402082121714
epoch 12 training time: 15.322
---------------
2023-09-24 04:27:26.986480
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00725	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00563	Train Loss 0.1130	
start validation
acc: 0.832536
AUC: 0.901945
Avg Precision: 0.354889
Avg Recall: 1.000000
d_prime: 1.828174
train_loss: 0.106328
valid_loss: 1.078278
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0007117322590737592
Epoch-13 lr: 0.0028469290362950366
epoch 13 training time: 15.390
---------------
2023-09-24 04:27:42.376004
current #epochs=14, #steps=520
start validation
acc: 0.837321
AUC: 0.899211
Avg Precision: 0.362686
Avg Recall: 1.000000
d_prime: 1.806044
train_loss: 0.090165
valid_loss: 1.059431
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0007117322590737592
Epoch-14 lr: 0.0028469290362950366
epoch 14 training time: 16.634
---------------
2023-09-24 04:27:59.010503
current #epochs=15, #steps=560
start validation
acc: 0.799043
AUC: 0.874521
Avg Precision: 0.348872
Avg Recall: 1.000000
d_prime: 1.623556
train_loss: 0.088370
valid_loss: 1.078501
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0005363659549749391
Epoch-15 lr: 0.0021454638198997564
epoch 15 training time: 15.381
---------------
2023-09-24 04:28:14.391503
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04084	Per Sample Data Time 0.03085	Per Sample DNN Time 0.00998	Train Loss 0.0405	
start validation
acc: 0.818182
AUC: 0.875444
Avg Precision: 0.349026
Avg Recall: 1.000000
d_prime: 1.629895
train_loss: 0.086602
valid_loss: 1.073930
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0005363659549749391
Epoch-16 lr: 0.0021454638198997564
epoch 16 training time: 15.343
---------------
2023-09-24 04:28:29.734349
current #epochs=17, #steps=640
start validation
acc: 0.818182
AUC: 0.900000
Avg Precision: 0.343325
Avg Recall: 1.000000
d_prime: 1.812388
train_loss: 0.095525
valid_loss: 1.069040
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0004042087933889256
Epoch-17 lr: 0.0016168351735557024
epoch 17 training time: 15.351
---------------
2023-09-24 04:28:45.084975
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00563	Train Loss 0.0994	
start validation
acc: 0.818182
AUC: 0.904045
Avg Precision: 0.345342
Avg Recall: 1.000000
d_prime: 1.845481
train_loss: 0.107938
valid_loss: 1.055259
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0004042087933889256
Epoch-18 lr: 0.0016168351735557024
epoch 18 training time: 15.381
---------------
2023-09-24 04:29:00.466314
current #epochs=19, #steps=720
start validation
acc: 0.808612
AUC: 0.907899
Avg Precision: 0.342215
Avg Recall: 1.000000
d_prime: 1.877976
train_loss: 0.098050
valid_loss: 1.056379
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.00030461431628442013
Epoch-19 lr: 0.0012184572651376805
epoch 19 training time: 15.355
---------------
2023-09-24 04:29:15.821763
current #epochs=20, #steps=760
start validation
acc: 0.822967
AUC: 0.908319
Avg Precision: 0.355757
Avg Recall: 1.000000
d_prime: 1.881572
train_loss: 0.089942
valid_loss: 1.040168
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.00030461431628442013
Epoch-20 lr: 0.0012184572651376805
epoch 20 training time: 15.444
---------------
2023-09-24 04:29:31.265883
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04264	Per Sample Data Time 0.03241	Per Sample DNN Time 0.01022	Train Loss 0.0121	
start validation
acc: 0.808612
AUC: 0.900363
Avg Precision: 0.341942
Avg Recall: 1.000000
d_prime: 1.815314
train_loss: 0.089512
valid_loss: 1.055840
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.00022955928520867992
Epoch-21 lr: 0.0009182371408347197
epoch 21 training time: 15.486
---------------
2023-09-24 04:29:46.751744
current #epochs=22, #steps=840
start validation
[I 2023-09-24 04:30:02,054] Trial 96 finished with value: 0.34718613239691204 and parameters: {'warmup': 'True', 'num_epochs': 22, 'batch_size': 19, 'lr-adaptschedule': 'False', 'lr': 0.0016629645473827826, 'head-lr': 4, 'lr-scheduler-start': 9, 'lr-scheduler-step': 2, 'lr-scheduler-decay': 0.7536063570772528}. Best is trial 87 with value: 0.45521598372193306.
acc: 0.808612
AUC: 0.907700
Avg Precision: 0.347186
Avg Recall: 1.000000
d_prime: 1.876270
train_loss: 0.093720
valid_loss: 1.057670
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.00022955928520867992
Epoch-22 lr: 0.0009182371408347197
epoch 22 training time: 15.290
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 5 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc52644eb0>
The learning rate scheduler starts at 10 epoch with decay rate of 0.671 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 04:30:02.094298
current #epochs=1, #steps=0
start validation
acc: 0.851675
AUC: 0.911363
Avg Precision: 0.358442
Avg Recall: 1.000000
d_prime: 1.908050
train_loss: 0.130788
valid_loss: 1.063629
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.002061053607977956
Epoch-1 lr: 0.01030526803988978
epoch 1 training time: 17.962
---------------
2023-09-24 04:30:20.056615
current #epochs=2, #steps=40
start validation
acc: 0.770335
AUC: 0.889131
Avg Precision: 0.332961
Avg Recall: 1.000000
d_prime: 1.728057
train_loss: 0.125789
valid_loss: 1.095144
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.002061053607977956
Epoch-2 lr: 0.01030526803988978
epoch 2 training time: 15.318
---------------
2023-09-24 04:30:35.374804
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00719	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00558	Train Loss 0.0922	
start validation
acc: 0.808612
AUC: 0.883060
Avg Precision: 0.355056
Avg Recall: 1.000000
d_prime: 1.683515
train_loss: 0.108155
valid_loss: 1.083929
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.002061053607977956
Epoch-3 lr: 0.01030526803988978
epoch 3 training time: 15.509
---------------
2023-09-24 04:30:50.883471
current #epochs=4, #steps=120
start validation
acc: 0.808612
AUC: 0.898194
Avg Precision: 0.320446
Avg Recall: 1.000000
d_prime: 1.797931
train_loss: 0.144886
valid_loss: 1.063102
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.002061053607977956
Epoch-4 lr: 0.01030526803988978
epoch 4 training time: 15.248
---------------
2023-09-24 04:31:06.131745
current #epochs=5, #steps=160
start validation
acc: 0.827751
AUC: 0.871269
Avg Precision: 0.326834
Avg Recall: 1.000000
d_prime: 1.601469
train_loss: 0.124816
valid_loss: 1.090003
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.002061053607977956
Epoch-5 lr: 0.01030526803988978
epoch 5 training time: 15.324
---------------
2023-09-24 04:31:21.455721
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04240	Per Sample Data Time 0.03235	Per Sample DNN Time 0.01005	Train Loss 0.1570	
start validation
acc: 0.808612
AUC: 0.883298
Avg Precision: 0.333345
Avg Recall: 1.000000
d_prime: 1.685229
train_loss: 0.121428
valid_loss: 1.090423
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.002061053607977956
Epoch-6 lr: 0.01030526803988978
epoch 6 training time: 16.745
---------------
2023-09-24 04:31:38.201154
current #epochs=7, #steps=240
start validation
acc: 0.794258
AUC: 0.911902
Avg Precision: 0.357900
Avg Recall: 1.000000
d_prime: 1.912811
train_loss: 0.141510
valid_loss: 1.052309
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.002061053607977956
Epoch-7 lr: 0.01030526803988978
epoch 7 training time: 15.449
---------------
2023-09-24 04:31:53.650631
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00717	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00560	Train Loss 0.1034	
start validation
acc: 0.818182
AUC: 0.897931
Avg Precision: 0.374265
Avg Recall: 1.000000
d_prime: 1.795836
train_loss: 0.094321
valid_loss: 1.068603
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.002061053607977956
Epoch-8 lr: 0.01030526803988978
epoch 8 training time: 15.294
---------------
2023-09-24 04:32:08.944483
current #epochs=9, #steps=320
start validation
acc: 0.861244
AUC: 0.906891
Avg Precision: 0.367238
Avg Recall: 1.000000
d_prime: 1.869375
train_loss: 0.122313
valid_loss: 1.057436
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.002061053607977956
Epoch-9 lr: 0.01030526803988978
epoch 9 training time: 18.961
---------------
2023-09-24 04:32:27.904997
current #epochs=10, #steps=360
start validation
acc: 0.846890
AUC: 0.928954
Avg Precision: 0.345921
Avg Recall: 1.000000
d_prime: 2.076125
train_loss: 0.167697
valid_loss: 1.059508
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.0013824926761339836
Epoch-10 lr: 0.006912463380669918
epoch 10 training time: 15.313
---------------
2023-09-24 04:32:43.217813
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.04082	Per Sample Data Time 0.03034	Per Sample DNN Time 0.01048	Train Loss 0.2336	
start validation
acc: 0.799043
AUC: 0.919080
Avg Precision: 0.340999
Avg Recall: 1.000000
d_prime: 1.978362
train_loss: 0.209889
valid_loss: 1.076121
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.0013824926761339836
Epoch-11 lr: 0.006912463380669918
epoch 11 training time: 15.401
---------------
2023-09-24 04:32:58.619044
current #epochs=12, #steps=440
start validation
acc: 0.822967
AUC: 0.883262
Avg Precision: 0.349064
Avg Recall: 1.000000
d_prime: 1.684972
train_loss: 0.149343
valid_loss: 1.083517
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.0013824926761339836
Epoch-12 lr: 0.006912463380669918
epoch 12 training time: 16.499
---------------
2023-09-24 04:33:15.117571
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00723	Per Sample Data Time 0.00169	Per Sample DNN Time 0.00554	Train Loss 0.1018	
start validation
acc: 0.789474
AUC: 0.889228
Avg Precision: 0.392074
Avg Recall: 1.000000
d_prime: 1.728784
train_loss: 0.101141
valid_loss: 1.094005
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.0013824926761339836
Epoch-13 lr: 0.006912463380669918
epoch 13 training time: 15.470
---------------
2023-09-24 04:33:30.587469
current #epochs=14, #steps=520
start validation
acc: 0.799043
AUC: 0.912153
Avg Precision: 0.392000
Avg Recall: 1.000000
d_prime: 1.915033
train_loss: 0.117712
valid_loss: 1.058812
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.0013824926761339836
Epoch-14 lr: 0.006912463380669918
epoch 14 training time: 15.349
---------------
2023-09-24 04:33:45.936418
current #epochs=15, #steps=560
start validation
acc: 0.861244
AUC: 0.900395
Avg Precision: 0.394713
Avg Recall: 1.000000
d_prime: 1.815575
train_loss: 0.117475
valid_loss: 1.057740
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0013824926761339836
Epoch-15 lr: 0.006912463380669918
epoch 15 training time: 15.330
---------------
2023-09-24 04:34:01.266174
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04074	Per Sample Data Time 0.03028	Per Sample DNN Time 0.01047	Train Loss 0.1053	
start validation
acc: 0.827751
AUC: 0.911785
Avg Precision: 0.336632
Avg Recall: 1.000000
d_prime: 1.911773
train_loss: 0.095823
valid_loss: 1.066675
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0013824926761339836
Epoch-16 lr: 0.006912463380669918
epoch 16 training time: 15.287
---------------
2023-09-24 04:34:16.552962
current #epochs=17, #steps=640
start validation
acc: 0.846890
AUC: 0.908251
Avg Precision: 0.376450
Avg Recall: 1.000000
d_prime: 1.880989
train_loss: 0.073624
valid_loss: 1.053793
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0013824926761339836
Epoch-17 lr: 0.006912463380669918
epoch 17 training time: 15.335
---------------
2023-09-24 04:34:31.888024
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00564	Train Loss 0.1164	
start validation
acc: 0.818182
AUC: 0.905206
Avg Precision: 0.384998
Avg Recall: 1.000000
d_prime: 1.855165
train_loss: 0.104232
valid_loss: 1.070203
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0013824926761339836
Epoch-18 lr: 0.006912463380669918
epoch 18 training time: 15.304
---------------
2023-09-24 04:34:47.192568
current #epochs=19, #steps=720
start validation
[I 2023-09-24 04:35:02,469] Trial 97 finished with value: 0.35739081107281534 and parameters: {'warmup': 'True', 'num_epochs': 19, 'batch_size': 16, 'lr-adaptschedule': 'False', 'lr': 0.002061053607977956, 'head-lr': 5, 'lr-scheduler-start': 10, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.6707698774949914}. Best is trial 87 with value: 0.45521598372193306.
acc: 0.760766
AUC: 0.872741
Avg Precision: 0.357391
Avg Recall: 1.000000
d_prime: 1.611420
train_loss: 0.105684
valid_loss: 1.101870
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0009273344430081149
Epoch-19 lr: 0.004636672215040575
epoch 19 training time: 15.265
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 2 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc0a698d30>
The learning rate scheduler starts at 8 epoch with decay rate of 0.739 every 7 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 04:35:02.509825
current #epochs=1, #steps=0
start validation
acc: 0.818182
AUC: 0.916600
Avg Precision: 0.372036
Avg Recall: 1.000000
d_prime: 1.955233
train_loss: 0.201467
valid_loss: 1.071819
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0013292528258133569
Epoch-1 lr: 0.0026585056516267138
epoch 1 training time: 17.803
---------------
2023-09-24 04:35:20.313294
current #epochs=2, #steps=40
start validation
acc: 0.789474
AUC: 0.928147
Avg Precision: 0.393013
Avg Recall: 1.000000
d_prime: 2.067760
train_loss: 0.131678
valid_loss: 1.052672
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0013292528258133569
Epoch-2 lr: 0.0026585056516267138
epoch 2 training time: 15.210
---------------
2023-09-24 04:35:35.523268
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00162	Per Sample DNN Time 0.00559	Train Loss 0.1384	
start validation
acc: 0.770335
AUC: 0.924040
Avg Precision: 0.370235
Avg Recall: 1.000000
d_prime: 2.026263
train_loss: 0.132685
valid_loss: 1.055352
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0013292528258133569
Epoch-3 lr: 0.0026585056516267138
epoch 3 training time: 15.432
---------------
2023-09-24 04:35:50.955796
current #epochs=4, #steps=120
start validation
acc: 0.789474
AUC: 0.890358
Avg Precision: 0.321705
Avg Recall: 1.000000
d_prime: 1.737270
train_loss: 0.094137
valid_loss: 1.090034
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0013292528258133569
Epoch-4 lr: 0.0026585056516267138
epoch 4 training time: 15.184
---------------
2023-09-24 04:36:06.140305
current #epochs=5, #steps=160
start validation
acc: 0.813397
AUC: 0.915131
Avg Precision: 0.368770
Avg Recall: 1.000000
d_prime: 1.941778
train_loss: 0.091865
valid_loss: 1.065756
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0013292528258133569
Epoch-5 lr: 0.0026585056516267138
epoch 5 training time: 15.467
---------------
2023-09-24 04:36:21.607130
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.04230	Per Sample Data Time 0.03223	Per Sample DNN Time 0.01006	Train Loss 0.0968	
start validation
acc: 0.794258
AUC: 0.896929
Avg Precision: 0.377899
Avg Recall: 1.000000
d_prime: 1.787915
train_loss: 0.122536
valid_loss: 1.091933
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0013292528258133569
Epoch-6 lr: 0.0026585056516267138
epoch 6 training time: 15.464
---------------
2023-09-24 04:36:37.071048
current #epochs=7, #steps=240
start validation
acc: 0.799043
AUC: 0.881528
Avg Precision: 0.345375
Avg Recall: 1.000000
d_prime: 1.672532
train_loss: 0.126716
valid_loss: 1.094690
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0013292528258133569
Epoch-7 lr: 0.0026585056516267138
epoch 7 training time: 15.429
---------------
2023-09-24 04:36:52.499684
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00725	Per Sample Data Time 0.00158	Per Sample DNN Time 0.00567	Train Loss 0.1323	
start validation
acc: 0.837321
AUC: 0.905996
Avg Precision: 0.383283
Avg Recall: 1.000000
d_prime: 1.861804
train_loss: 0.120640
valid_loss: 1.069080
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.000981997353860938
Epoch-8 lr: 0.001963994707721876
epoch 8 training time: 17.880
---------------
2023-09-24 04:37:10.379729
current #epochs=9, #steps=320
start validation
acc: 0.846890
AUC: 0.929628
Avg Precision: 0.391910
Avg Recall: 1.000000
d_prime: 2.083174
train_loss: 0.104326
valid_loss: 1.045309
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.000981997353860938
Epoch-9 lr: 0.001963994707721876
epoch 9 training time: 17.854
---------------
2023-09-24 04:37:28.234138
current #epochs=10, #steps=360
start validation
acc: 0.794258
AUC: 0.880110
Avg Precision: 0.319579
Avg Recall: 1.000000
d_prime: 1.662458
train_loss: 0.093504
valid_loss: 1.094260
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.000981997353860938
Epoch-10 lr: 0.001963994707721876
epoch 10 training time: 15.292
---------------
2023-09-24 04:37:43.526349
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03853	Per Sample Data Time 0.03039	Per Sample DNN Time 0.00815	Train Loss 0.0729	
start validation
acc: 0.832536
AUC: 0.906157
Avg Precision: 0.365249
Avg Recall: 1.000000
d_prime: 1.863160
train_loss: 0.095729
valid_loss: 1.073692
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.000981997353860938
Epoch-11 lr: 0.001963994707721876
epoch 11 training time: 15.287
---------------
2023-09-24 04:37:58.813312
current #epochs=12, #steps=440
start validation
acc: 0.827751
AUC: 0.908185
Avg Precision: 0.348623
Avg Recall: 1.000000
d_prime: 1.880421
train_loss: 0.091420
valid_loss: 1.069890
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.000981997353860938
Epoch-12 lr: 0.001963994707721876
epoch 12 training time: 15.291
---------------
2023-09-24 04:38:14.104314
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00724	Per Sample Data Time 0.00161	Per Sample DNN Time 0.00562	Train Loss 0.1063	
start validation
acc: 0.837321
AUC: 0.885965
Avg Precision: 0.380401
Avg Recall: 1.000000
d_prime: 1.704612
train_loss: 0.108258
valid_loss: 1.088389
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.000981997353860938
Epoch-13 lr: 0.001963994707721876
epoch 13 training time: 15.353
---------------
2023-09-24 04:38:29.456821
current #epochs=14, #steps=520
start validation
acc: 0.803828
AUC: 0.877479
Avg Precision: 0.376214
Avg Recall: 1.000000
d_prime: 1.643989
train_loss: 0.078910
valid_loss: 1.089023
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.000981997353860938
Epoch-14 lr: 0.001963994707721876
epoch 14 training time: 15.368
---------------
2023-09-24 04:38:44.825337
current #epochs=15, #steps=560
start validation
acc: 0.808612
AUC: 0.876689
Avg Precision: 0.355543
Avg Recall: 1.000000
d_prime: 1.638498
train_loss: 0.093464
valid_loss: 1.081068
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.0007254592837896185
Epoch-15 lr: 0.001450918567579237
epoch 15 training time: 15.454
---------------
2023-09-24 04:39:00.279987
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04104	Per Sample Data Time 0.03110	Per Sample DNN Time 0.00995	Train Loss 0.0036	
start validation
acc: 0.832536
AUC: 0.879830
Avg Precision: 0.365705
Avg Recall: 1.000000
d_prime: 1.660479
train_loss: 0.086631
valid_loss: 1.091765
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.0007254592837896185
Epoch-16 lr: 0.001450918567579237
epoch 16 training time: 15.400
---------------
2023-09-24 04:39:15.679498
current #epochs=17, #steps=640
start validation
acc: 0.818182
AUC: 0.878265
Avg Precision: 0.339652
Avg Recall: 1.000000
d_prime: 1.649481
train_loss: 0.090199
valid_loss: 1.095305
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.0007254592837896185
Epoch-17 lr: 0.001450918567579237
epoch 17 training time: 15.628
---------------
2023-09-24 04:39:31.307554
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00732	Per Sample Data Time 0.00165	Per Sample DNN Time 0.00568	Train Loss 0.0743	
start validation
acc: 0.846890
AUC: 0.898507
Avg Precision: 0.393349
Avg Recall: 1.000000
d_prime: 1.800423
train_loss: 0.088194
valid_loss: 1.062232
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0007254592837896185
Epoch-18 lr: 0.001450918567579237
epoch 18 training time: 15.460
---------------
2023-09-24 04:39:46.767777
current #epochs=19, #steps=720
start validation
acc: 0.822967
AUC: 0.900084
Avg Precision: 0.363726
Avg Recall: 1.000000
d_prime: 1.813061
train_loss: 0.076438
valid_loss: 1.074036
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0007254592837896185
Epoch-19 lr: 0.001450918567579237
epoch 19 training time: 15.340
---------------
2023-09-24 04:40:02.107848
current #epochs=20, #steps=760
start validation
acc: 0.818182
AUC: 0.885069
Avg Precision: 0.333465
Avg Recall: 1.000000
d_prime: 1.698065
train_loss: 0.086890
valid_loss: 1.081627
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0007254592837896185
Epoch-20 lr: 0.001450918567579237
epoch 20 training time: 15.297
---------------
2023-09-24 04:40:17.404767
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.04106	Per Sample Data Time 0.03048	Per Sample DNN Time 0.01058	Train Loss 0.1943	
start validation
acc: 0.813397
AUC: 0.887693
Avg Precision: 0.339266
Avg Recall: 1.000000
d_prime: 1.717352
train_loss: 0.075084
valid_loss: 1.083625
validation finished
normal learning rate scheduler step
Epoch-21 lr: 0.0007254592837896185
Epoch-21 lr: 0.001450918567579237
epoch 21 training time: 15.440
---------------
2023-09-24 04:40:32.844861
current #epochs=22, #steps=840
start validation
acc: 0.837321
AUC: 0.886600
Avg Precision: 0.370166
Avg Recall: 1.000000
d_prime: 1.709279
train_loss: 0.106257
valid_loss: 1.069066
validation finished
normal learning rate scheduler step
Epoch-22 lr: 0.0005359395016364524
Epoch-22 lr: 0.0010718790032729047
epoch 22 training time: 15.484
---------------
2023-09-24 04:40:48.328990
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00732	Per Sample Data Time 0.00166	Per Sample DNN Time 0.00566	Train Loss 0.0901	
start validation
acc: 0.813397
AUC: 0.888093
Avg Precision: 0.345376
Avg Recall: 1.000000
d_prime: 1.720316
train_loss: 0.078474
valid_loss: 1.068903
validation finished
normal learning rate scheduler step
Epoch-23 lr: 0.0005359395016364524
Epoch-23 lr: 0.0010718790032729047
epoch 23 training time: 15.496
---------------
2023-09-24 04:41:03.824988
current #epochs=24, #steps=920
start validation
acc: 0.803828
AUC: 0.885658
Avg Precision: 0.344071
Avg Recall: 1.000000
d_prime: 1.702366
train_loss: 0.089939
valid_loss: 1.071495
validation finished
normal learning rate scheduler step
Epoch-24 lr: 0.0005359395016364524
Epoch-24 lr: 0.0010718790032729047
epoch 24 training time: 15.339
---------------
2023-09-24 04:41:19.164188
current #epochs=25, #steps=960
start validation
acc: 0.822967
AUC: 0.885658
Avg Precision: 0.337540
Avg Recall: 1.000000
d_prime: 1.702370
train_loss: 0.092893
valid_loss: 1.075337
validation finished
normal learning rate scheduler step
Epoch-25 lr: 0.0005359395016364524
Epoch-25 lr: 0.0010718790032729047
epoch 25 training time: 15.371
---------------
2023-09-24 04:41:34.535073
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.04002	Per Sample Data Time 0.02979	Per Sample DNN Time 0.01023	Train Loss 0.0146	
start validation
acc: 0.818182
AUC: 0.905634
Avg Precision: 0.353134
Avg Recall: 1.000000
d_prime: 1.858755
train_loss: 0.068276
valid_loss: 1.063446
validation finished
normal learning rate scheduler step
Epoch-26 lr: 0.0005359395016364524
Epoch-26 lr: 0.0010718790032729047
epoch 26 training time: 15.363
---------------
2023-09-24 04:41:49.897935
current #epochs=27, #steps=1040
start validation
[I 2023-09-24 04:42:05,397] Trial 98 finished with value: 0.34650910583846944 and parameters: {'warmup': 'True', 'num_epochs': 27, 'batch_size': 12, 'lr-adaptschedule': 'False', 'lr': 0.0013292528258133569, 'head-lr': 2, 'lr-scheduler-start': 8, 'lr-scheduler-step': 7, 'lr-scheduler-decay': 0.7387588988272892}. Best is trial 87 with value: 0.45521598372193306.
acc: 0.832536
AUC: 0.903392
Avg Precision: 0.346509
Avg Recall: 1.000000
d_prime: 1.840071
train_loss: 0.076643
valid_loss: 1.062538
validation finished
normal learning rate scheduler step
Epoch-27 lr: 0.0005359395016364524
Epoch-27 lr: 0.0010718790032729047
epoch 27 training time: 15.487
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 4 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fcc52637580>
The learning rate scheduler starts at 9 epoch with decay rate of 0.769 every 9 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-24 04:42:05.437789
current #epochs=1, #steps=0
start validation
acc: 0.746411
AUC: 0.875838
Avg Precision: 0.316592
Avg Recall: 1.000000
d_prime: 1.632608
train_loss: 0.167756
valid_loss: 1.121654
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0018709175890916118
Epoch-1 lr: 0.007483670356366447
epoch 1 training time: 19.222
---------------
2023-09-24 04:42:24.660192
current #epochs=2, #steps=40
start validation
acc: 0.779904
AUC: 0.873359
Avg Precision: 0.350481
Avg Recall: 1.000000
d_prime: 1.615617
train_loss: 0.101012
valid_loss: 1.090594
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0018709175890916118
Epoch-2 lr: 0.007483670356366447
epoch 2 training time: 17.754
---------------
2023-09-24 04:42:42.413977
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00722	Per Sample Data Time 0.00160	Per Sample DNN Time 0.00562	Train Loss 0.0999	
start validation
acc: 0.827751
AUC: 0.904640
Avg Precision: 0.401238
Avg Recall: 1.000000
d_prime: 1.850429
train_loss: 0.104084
valid_loss: 1.081779
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0018709175890916118
Epoch-3 lr: 0.007483670356366447
epoch 3 training time: 17.959
---------------
2023-09-24 04:43:00.372876
current #epochs=4, #steps=120
start validation
acc: 0.775120
AUC: 0.894801
Avg Precision: 0.342676
Avg Recall: 1.000000
d_prime: 1.771266
train_loss: 0.104219
valid_loss: 1.094175
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0018709175890916118
Epoch-4 lr: 0.007483670356366447
epoch 4 training time: 15.229
---------------
2023-09-24 04:43:15.601944
current #epochs=5, #steps=160
start validation
acc: 0.813397
AUC: 0.896875
Avg Precision: 0.366741
Avg Recall: 1.000000
d_prime: 1.787491
train_loss: 0.077424
valid_loss: 1.086328
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0018709175890916118
Epoch-5 lr: 0.007483670356366447
epoch 5 training time: 15.348
---------------
2023-09-24 04:43:30.950125
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03950	Per Sample Data Time 0.02968	Per Sample DNN Time 0.00981	Train Loss 0.0969	
start validation
acc: 0.851675
AUC: 0.892252
Avg Precision: 0.377717
Avg Recall: 1.000000
d_prime: 1.751633
train_loss: 0.135331
valid_loss: 1.085646
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0018709175890916118
Epoch-6 lr: 0.007483670356366447
epoch 6 training time: 17.645
---------------
2023-09-24 04:43:48.595165
current #epochs=7, #steps=240
start validation
acc: 0.799043
AUC: 0.874638
Avg Precision: 0.392050
Avg Recall: 1.000000
d_prime: 1.624354
train_loss: 0.172504
valid_loss: 1.110858
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0018709175890916118
Epoch-7 lr: 0.007483670356366447
epoch 7 training time: 15.286
---------------
2023-09-24 04:44:03.880995
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00721	Per Sample Data Time 0.00157	Per Sample DNN Time 0.00563	Train Loss 0.1179	
start validation
acc: 0.779904
AUC: 0.891397
Avg Precision: 0.343651
Avg Recall: 1.000000
d_prime: 1.745126
train_loss: 0.114101
valid_loss: 1.089544
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0018709175890916118
Epoch-8 lr: 0.007483670356366447
epoch 8 training time: 15.355
---------------
2023-09-24 04:44:19.236442
current #epochs=9, #steps=320
start validation
acc: 0.851675
AUC: 0.914032
Avg Precision: 0.413206
Avg Recall: 1.000000
d_prime: 1.931833
train_loss: 0.109605
valid_loss: 1.067545
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.001438314770561216
Epoch-9 lr: 0.005753259082244864
epoch 9 training time: 15.396
---------------
2023-09-24 04:44:34.633159
current #epochs=10, #steps=360
start validation
acc: 0.851675
AUC: 0.920617
Avg Precision: 0.407781
Avg Recall: 1.000000
d_prime: 1.992955
train_loss: 0.099628
valid_loss: 1.074360
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.001438314770561216
Epoch-10 lr: 0.005753259082244864
epoch 10 training time: 15.285
---------------
2023-09-24 04:44:49.917859
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03976	Per Sample Data Time 0.03022	Per Sample DNN Time 0.00954	Train Loss 0.1879	
start validation
acc: 0.832536
AUC: 0.927371
Avg Precision: 0.395737
Avg Recall: 1.000000
d_prime: 2.059780
train_loss: 0.103113
valid_loss: 1.071577
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.001438314770561216
Epoch-11 lr: 0.005753259082244864
epoch 11 training time: 15.315
---------------
2023-09-24 04:45:05.233583
current #epochs=12, #steps=440
start validation
acc: 0.822967
AUC: 0.904883
Avg Precision: 0.337154
Avg Recall: 1.000000
d_prime: 1.852461
train_loss: 0.082608
valid_loss: 1.072778
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.001438314770561216
Epoch-12 lr: 0.005753259082244864
epoch 12 training time: 15.376
---------------
2023-09-24 04:45:20.609060
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00734	Per Sample Data Time 0.00167	Per Sample DNN Time 0.00567	Train Loss 0.1000	
start validation
acc: 0.803828
AUC: 0.891831
Avg Precision: 0.356511
Avg Recall: 1.000000
d_prime: 1.748430
train_loss: 0.106526
valid_loss: 1.085319
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.001438314770561216
Epoch-13 lr: 0.005753259082244864
epoch 13 training time: 15.399
---------------
2023-09-24 04:45:36.008407
current #epochs=14, #steps=520
start validation
acc: 0.851675
AUC: 0.885948
Avg Precision: 0.358692
Avg Recall: 1.000000
d_prime: 1.704489
train_loss: 0.130343
valid_loss: 1.078966
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.001438314770561216
Epoch-14 lr: 0.005753259082244864
epoch 14 training time: 15.317
---------------
2023-09-24 04:45:51.325058
current #epochs=15, #steps=560
start validation
acc: 0.784689
AUC: 0.875348
Avg Precision: 0.330603
Avg Recall: 1.000000
d_prime: 1.629234
train_loss: 0.119948
valid_loss: 1.104775
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.001438314770561216
Epoch-15 lr: 0.005753259082244864
epoch 15 training time: 15.309
---------------
2023-09-24 04:46:06.634118
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.04137	Per Sample Data Time 0.03059	Per Sample DNN Time 0.01078	Train Loss 0.0833	
start validation
acc: 0.822967
AUC: 0.888587
Avg Precision: 0.373478
Avg Recall: 1.000000
d_prime: 1.723997
train_loss: 0.097991
valid_loss: 1.080249
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.001438314770561216
Epoch-16 lr: 0.005753259082244864
epoch 16 training time: 15.275
---------------
2023-09-24 04:46:21.909073
current #epochs=17, #steps=640
start validation
acc: 0.808612
AUC: 0.885668
Avg Precision: 0.350619
Avg Recall: 1.000000
d_prime: 1.702442
train_loss: 0.091256
valid_loss: 1.094651
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.001438314770561216
Epoch-17 lr: 0.005753259082244864
epoch 17 training time: 15.412
---------------
2023-09-24 04:46:37.320549
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00727	Per Sample Data Time 0.00163	Per Sample DNN Time 0.00564	Train Loss 0.1059	
start validation
acc: 0.856459
AUC: 0.896158
Avg Precision: 0.374772
Avg Recall: 1.000000
d_prime: 1.781851
train_loss: 0.106872
valid_loss: 1.083245
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.0011057405153901006
Epoch-18 lr: 0.0044229620615604025
epoch 18 training time: 17.714
---------------
2023-09-24 04:46:55.034609
current #epochs=19, #steps=720
start validation
acc: 0.846890
AUC: 0.890285
Avg Precision: 0.347892
Avg Recall: 1.000000
d_prime: 1.736720
train_loss: 0.118326
valid_loss: 1.076233
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.0011057405153901006
Epoch-19 lr: 0.0044229620615604025
epoch 19 training time: 15.305
---------------
2023-09-24 04:47:10.340107
current #epochs=20, #steps=760
start validation
[I 2023-09-24 04:47:28,039] Trial 99 finished with value: 0.3799158718491439 and parameters: {'warmup': 'True', 'num_epochs': 20, 'batch_size': 29, 'lr-adaptschedule': 'False', 'lr': 0.0018709175890916118, 'head-lr': 4, 'lr-scheduler-start': 9, 'lr-scheduler-step': 9, 'lr-scheduler-decay': 0.768775053988114}. Best is trial 87 with value: 0.45521598372193306.
acc: 0.866029
AUC: 0.899624
Avg Precision: 0.379916
Avg Recall: 1.000000
d_prime: 1.809363
train_loss: 0.094138
valid_loss: 1.050081
validation finished
normal learning rate scheduler step
Epoch-20 lr: 0.0011057405153901006
Epoch-20 lr: 0.0044229620615604025
epoch 20 training time: 17.688
Best hyperparameters: {'warmup': 'True', 'num_epochs': 20, 'batch_size': 18, 'lr-adaptschedule': 'False', 'lr': 0.002290650550498399, 'head-lr': 3, 'lr-scheduler-start': 10, 'lr-scheduler-step': 8, 'lr-scheduler-decay': 0.7258506993606564}
