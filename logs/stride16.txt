I am process 1426248, running on amorgenstern-titanx8-25nlt: starting (Mon Sep  4 15:21:44 2023)
balanced sampler is not used
---------------the train dataloader---------------
now using following mask: 24 freq, 96 time
now using mix-up with rate 0.000000
now process ours
use dataset mean -6.627 and std 5.358 to normalize the input.
now use noise augmentation
number of classes is 4
---------------the evaluation dataloader---------------
now using following mask: 0 freq, 0 time
now using mix-up with rate 0.000000
now process ours
use dataset mean -6.627 and std 5.358 to normalize the input.
number of classes is 4
Now train with ours with 1921 training samples, evaluate with 211 samples
now load a SSL pretrained models from SSAST-Base-Patch-400.pth
pretraining patch split stride: frequency=16, time=16
pretraining patch shape: frequency=16, time=16
pretraining patch array dimension: frequency=8, time=64
pretraining number of patches=512
fine-tuning patch split stride: frequncey=16, time=16
fine-tuning number of patches=256

Creating experiment directory: stride16
Now starting fine-tuning for 30 epochs
running on cuda
Total parameter number is : 86.996 million
Total trainable parameter number is : 86.996 million
The mlp header uses 1 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 86.991 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fa67c844340>
The learning rate scheduler starts at 6 epoch with decay rate of 0.850 every 1 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-04 15:21:48.644747
current #epochs=1, #steps=0
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
[1693840923.673520] [amorgenstern-titanx8-25nlt:1426248:f]        vfs_fuse.c:281  UCX  ERROR inotify_add_watch(/tmp) failed: No space left on device
start validation
acc: 0.530806
AUC: 0.635679
Avg Precision: 0.266372
Avg Recall: 1.000000
d_prime: 0.490636
train_loss: 1.123381
valid_loss: 1.354055
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0001
Epoch-1 lr: 0.0001
epoch 1 training time: 33.952
---------------
2023-09-04 15:22:22.596981
current #epochs=2, #steps=40
start validation
acc: 0.530806
AUC: 0.665334
Avg Precision: 0.268937
Avg Recall: 1.000000
d_prime: 0.603960
train_loss: 1.096231
valid_loss: 1.352543
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0001
Epoch-2 lr: 0.0001
epoch 2 training time: 16.896
---------------
2023-09-04 15:22:39.492916
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.00812	Per Sample Data Time 0.00146	Per Sample DNN Time 0.00667	Train Loss 1.0857	
start validation
acc: 0.530806
AUC: 0.666795
Avg Precision: 0.258622
Avg Recall: 1.000000
d_prime: 0.609639
train_loss: 1.088904
valid_loss: 1.350844
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0001
Epoch-3 lr: 0.0001
epoch 3 training time: 16.966
---------------
2023-09-04 15:22:56.459325
current #epochs=4, #steps=120
start validation
acc: 0.530806
AUC: 0.661488
Avg Precision: 0.260830
Avg Recall: 1.000000
d_prime: 0.589060
train_loss: 1.074011
valid_loss: 1.343690
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0001
Epoch-4 lr: 0.0001
epoch 4 training time: 16.768
---------------
2023-09-04 15:23:13.227512
current #epochs=5, #steps=160
start validation
acc: 0.568720
AUC: 0.685161
Avg Precision: 0.267018
Avg Recall: 1.000000
d_prime: 0.681906
train_loss: 1.043381
valid_loss: 1.337724
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0001
Epoch-5 lr: 0.0001
epoch 5 training time: 19.438
---------------
2023-09-04 15:23:32.665289
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03564	Per Sample Data Time 0.02662	Per Sample DNN Time 0.00902	Train Loss 0.8433	
start validation
acc: 0.578199
AUC: 0.690399
Avg Precision: 0.265871
Avg Recall: 1.000000
d_prime: 0.702837
train_loss: 1.007409
valid_loss: 1.325475
validation finished
normal learning rate scheduler step
Epoch-6 lr: 8.5e-05
Epoch-6 lr: 8.5e-05
epoch 6 training time: 19.860
---------------
2023-09-04 15:23:52.525423
current #epochs=7, #steps=240
start validation
acc: 0.611374
AUC: 0.715995
Avg Precision: 0.270079
Avg Recall: 1.000000
d_prime: 0.807495
train_loss: 0.971244
valid_loss: 1.317093
validation finished
normal learning rate scheduler step
Epoch-7 lr: 7.225000000000001e-05
Epoch-7 lr: 7.225000000000001e-05
epoch 7 training time: 19.564
---------------
2023-09-04 15:24:12.089765
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.00800	Per Sample Data Time 0.00143	Per Sample DNN Time 0.00657	Train Loss 0.9304	
start validation
acc: 0.540284
AUC: 0.703034
Avg Precision: 0.270672
Avg Recall: 1.000000
d_prime: 0.753983
train_loss: 0.954249
valid_loss: 1.328246
validation finished
normal learning rate scheduler step
Epoch-8 lr: 6.141250000000001e-05
Epoch-8 lr: 6.141250000000001e-05
epoch 8 training time: 16.848
---------------
2023-09-04 15:24:28.937420
current #epochs=9, #steps=320
start validation
acc: 0.611374
AUC: 0.721997
Avg Precision: 0.274891
Avg Recall: 1.000000
d_prime: 0.832668
train_loss: 0.938607
valid_loss: 1.304136
validation finished
normal learning rate scheduler step
Epoch-9 lr: 5.2200625000000005e-05
Epoch-9 lr: 5.2200625000000005e-05
epoch 9 training time: 18.724
---------------
2023-09-04 15:24:47.661042
current #epochs=10, #steps=360
start validation
acc: 0.597156
AUC: 0.722303
Avg Precision: 0.278517
Avg Recall: 1.000000
d_prime: 0.833957
train_loss: 0.910378
valid_loss: 1.288905
validation finished
normal learning rate scheduler step
Epoch-10 lr: 4.437053125e-05
Epoch-10 lr: 4.437053125e-05
epoch 10 training time: 16.979
---------------
2023-09-04 15:25:04.640507
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03712	Per Sample Data Time 0.02746	Per Sample DNN Time 0.00966	Train Loss 0.8342	
start validation
acc: 0.587678
AUC: 0.744978
Avg Precision: 0.281927
Avg Recall: 1.000000
d_prime: 0.931640
train_loss: 0.897717
valid_loss: 1.292413
validation finished
normal learning rate scheduler step
Epoch-11 lr: 3.77149515625e-05
Epoch-11 lr: 3.77149515625e-05
epoch 11 training time: 16.895
---------------
2023-09-04 15:25:21.535338
current #epochs=12, #steps=440
start validation
acc: 0.554502
AUC: 0.746478
Avg Precision: 0.280059
Avg Recall: 1.000000
d_prime: 0.938255
train_loss: 0.880033
valid_loss: 1.292768
validation finished
normal learning rate scheduler step
Epoch-12 lr: 3.2057708828124995e-05
Epoch-12 lr: 3.2057708828124995e-05
epoch 12 training time: 17.150
---------------
2023-09-04 15:25:38.685253
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.00803	Per Sample Data Time 0.00143	Per Sample DNN Time 0.00660	Train Loss 0.8670	
start validation
acc: 0.663507
AUC: 0.761775
Avg Precision: 0.268765
Avg Recall: 1.000000
d_prime: 1.006953
train_loss: 0.860170
valid_loss: 1.267919
validation finished
normal learning rate scheduler step
Epoch-13 lr: 2.7249052503906245e-05
Epoch-13 lr: 2.7249052503906245e-05
epoch 13 training time: 19.513
---------------
2023-09-04 15:25:58.198601
current #epochs=14, #steps=520
start validation
acc: 0.616114
AUC: 0.757584
Avg Precision: 0.284572
Avg Recall: 1.000000
d_prime: 0.987902
train_loss: 0.850306
valid_loss: 1.290355
validation finished
normal learning rate scheduler step
Epoch-14 lr: 2.3161694628320308e-05
Epoch-14 lr: 2.3161694628320308e-05
epoch 14 training time: 16.862
---------------
2023-09-04 15:26:15.059897
current #epochs=15, #steps=560
start validation
acc: 0.682464
AUC: 0.766295
Avg Precision: 0.287774
Avg Recall: 1.000000
d_prime: 1.027707
train_loss: 0.833166
valid_loss: 1.275164
validation finished
normal learning rate scheduler step
Epoch-15 lr: 1.9687440434072263e-05
Epoch-15 lr: 1.9687440434072263e-05
epoch 15 training time: 19.222
---------------
2023-09-04 15:26:34.281690
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03559	Per Sample Data Time 0.02732	Per Sample DNN Time 0.00827	Train Loss 0.6727	
start validation
acc: 0.677725
AUC: 0.769714
Avg Precision: 0.288675
Avg Recall: 1.000000
d_prime: 1.043556
train_loss: 0.830775
valid_loss: 1.267032
validation finished
normal learning rate scheduler step
Epoch-16 lr: 1.673432436896142e-05
Epoch-16 lr: 1.673432436896142e-05
epoch 16 training time: 16.915
---------------
2023-09-04 15:26:51.196266
current #epochs=17, #steps=640
start validation
acc: 0.691943
AUC: 0.787483
Avg Precision: 0.288508
Avg Recall: 1.000000
d_prime: 1.128143
train_loss: 0.805217
valid_loss: 1.260049
validation finished
normal learning rate scheduler step
Epoch-17 lr: 1.4224175713617208e-05
Epoch-17 lr: 1.4224175713617208e-05
epoch 17 training time: 19.253
---------------
2023-09-04 15:27:10.449363
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.00797	Per Sample Data Time 0.00141	Per Sample DNN Time 0.00656	Train Loss 0.7821	
start validation
acc: 0.682464
AUC: 0.784506
Avg Precision: 0.289571
Avg Recall: 1.000000
d_prime: 1.113696
train_loss: 0.800275
valid_loss: 1.256528
validation finished
normal learning rate scheduler step
Epoch-18 lr: 1.2090549356574626e-05
Epoch-18 lr: 1.2090549356574626e-05
epoch 18 training time: 16.914
---------------
2023-09-04 15:27:27.363555
current #epochs=19, #steps=720
start validation
acc: 0.663507
AUC: 0.780811
Avg Precision: 0.291049
Avg Recall: 1.000000
d_prime: 1.095922
train_loss: 0.816291
valid_loss: 1.268862
validation finished
normal learning rate scheduler step
Epoch-19 lr: 1.0276966953088432e-05
Epoch-19 lr: 1.0276966953088432e-05
epoch 19 training time: 16.757
---------------
2023-09-04 15:27:44.120449
current #epochs=20, #steps=760
start validation
acc: 0.687204
AUC: 0.795926
Avg Precision: 0.289924
Avg Recall: 1.000000
d_prime: 1.169775
train_loss: 0.814499
valid_loss: 1.262829
validation finished
normal learning rate scheduler step
Epoch-20 lr: 8.735421910125167e-06
Epoch-20 lr: 8.735421910125167e-06
epoch 20 training time: 16.777
---------------
2023-09-04 15:28:00.897332
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03610	Per Sample Data Time 0.02693	Per Sample DNN Time 0.00917	Train Loss 0.8957	
start validation
acc: 0.701422
AUC: 0.797532
Avg Precision: 0.288983
Avg Recall: 1.000000
d_prime: 1.177812
train_loss: 0.794511
valid_loss: 1.253353
validation finished
normal learning rate scheduler step
Epoch-21 lr: 7.425108623606392e-06
Epoch-21 lr: 7.425108623606392e-06
epoch 21 training time: 19.435
---------------
2023-09-04 15:28:20.332561
current #epochs=22, #steps=840
start validation
acc: 0.701422
AUC: 0.802461
Avg Precision: 0.289734
Avg Recall: 1.000000
d_prime: 1.202708
train_loss: 0.786967
valid_loss: 1.246617
validation finished
normal learning rate scheduler step
Epoch-22 lr: 6.3113423300654325e-06
Epoch-22 lr: 6.3113423300654325e-06
epoch 22 training time: 16.814
---------------
2023-09-04 15:28:37.145898
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.00799	Per Sample Data Time 0.00143	Per Sample DNN Time 0.00656	Train Loss 0.7752	
start validation
acc: 0.706161
AUC: 0.809528
Avg Precision: 0.288887
Avg Recall: 1.000000
d_prime: 1.239073
train_loss: 0.760290
valid_loss: 1.240608
validation finished
normal learning rate scheduler step
Epoch-23 lr: 5.3646409805556175e-06
Epoch-23 lr: 5.3646409805556175e-06
epoch 23 training time: 19.468
---------------
2023-09-04 15:28:56.614326
current #epochs=24, #steps=920
start validation
acc: 0.715640
AUC: 0.804669
Avg Precision: 0.287990
Avg Recall: 1.000000
d_prime: 1.213985
train_loss: 0.762775
valid_loss: 1.244266
validation finished
normal learning rate scheduler step
Epoch-24 lr: 4.559944833472275e-06
Epoch-24 lr: 4.559944833472275e-06
epoch 24 training time: 19.490
---------------
2023-09-04 15:29:16.104133
current #epochs=25, #steps=960
start validation
acc: 0.715640
AUC: 0.816450
Avg Precision: 0.279801
Avg Recall: 1.000000
d_prime: 1.275507
train_loss: 0.757382
valid_loss: 1.240284
validation finished
normal learning rate scheduler step
Epoch-25 lr: 3.875953108451433e-06
Epoch-25 lr: 3.875953108451433e-06
epoch 25 training time: 17.136
---------------
2023-09-04 15:29:33.240245
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.03561	Per Sample Data Time 0.02697	Per Sample DNN Time 0.00863	Train Loss 0.7020	
start validation
acc: 0.715640
AUC: 0.815109
Avg Precision: 0.281533
Avg Recall: 1.000000
d_prime: 1.268381
train_loss: 0.750544
valid_loss: 1.233798
validation finished
normal learning rate scheduler step
Epoch-26 lr: 3.2945601421837183e-06
Epoch-26 lr: 3.2945601421837183e-06
epoch 26 training time: 16.929
---------------
2023-09-04 15:29:50.169507
current #epochs=27, #steps=1040
start validation
acc: 0.725118
AUC: 0.818519
Avg Precision: 0.280625
Avg Recall: 1.000000
d_prime: 1.286560
train_loss: 0.750302
valid_loss: 1.230744
validation finished
normal learning rate scheduler step
Epoch-27 lr: 2.8003761208561607e-06
Epoch-27 lr: 2.8003761208561607e-06
epoch 27 training time: 19.372
---------------
2023-09-04 15:30:09.541915
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.00791	Per Sample Data Time 0.00140	Per Sample DNN Time 0.00651	Train Loss 0.7676	
start validation
acc: 0.725118
AUC: 0.819749
Avg Precision: 0.281289
Avg Recall: 1.000000
d_prime: 1.293171
train_loss: 0.734446
valid_loss: 1.231395
validation finished
normal learning rate scheduler step
Epoch-28 lr: 2.3803197027277364e-06
Epoch-28 lr: 2.3803197027277364e-06
epoch 28 training time: 16.784
---------------
2023-09-04 15:30:26.326441
current #epochs=29, #steps=1120
start validation
acc: 0.710900
AUC: 0.825279
Avg Precision: 0.275196
Avg Recall: 1.000000
d_prime: 1.323238
train_loss: 0.729613
valid_loss: 1.226851
validation finished
normal learning rate scheduler step
Epoch-29 lr: 2.0232717473185757e-06
Epoch-29 lr: 2.0232717473185757e-06
epoch 29 training time: 16.712
---------------
2023-09-04 15:30:43.038107
current #epochs=30, #steps=1160
start validation
acc: 0.734597
AUC: 0.826706
Avg Precision: 0.278312
Avg Recall: 1.000000
d_prime: 1.331096
train_loss: 0.725068
valid_loss: 1.225619
validation finished
normal learning rate scheduler step
Epoch-30 lr: 1.7197809852207893e-06
Epoch-30 lr: 1.7197809852207893e-06
epoch 30 training time: 20.206
