I am process 1130019, running on amorgenstern-titanx8-25nlt: starting (Mon Sep  4 14:31:44 2023)
balanced sampler is not used
---------------the train dataloader---------------
now using following mask: 24 freq, 96 time
now using mix-up with rate 0.000000
now process ours
use dataset mean -6.627 and std 5.358 to normalize the input.
now use noise augmentation
number of classes is 4
---------------the evaluation dataloader---------------
now using following mask: 0 freq, 0 time
now using mix-up with rate 0.000000
now process ours
use dataset mean -6.627 and std 5.358 to normalize the input.
number of classes is 4
Now train with ours with 1921 training samples, evaluate with 211 samples
now load a SSL pretrained models from SSAST-Base-Patch-400.pth
pretraining patch split stride: frequency=16, time=16
pretraining patch shape: frequency=16, time=16
pretraining patch array dimension: frequency=8, time=64
pretraining number of patches=512
fine-tuning patch split stride: frequncey=10, time=10
fine-tuning number of patches=600

Creating experiment directory: baseline
Now starting fine-tuning for 30 epochs
running on cuda
Total parameter number is : 87.260 million
Total trainable parameter number is : 87.260 million
The mlp header uses 1 x larger lr
Total mlp parameter number is : 0.005 million
Total base parameter number is : 87.255 million
now training with ours, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7f51a2db6340>
The learning rate scheduler starts at 6 epoch with decay rate of 0.850 every 1 epoches
current #steps=0, #epochs=1
start training...
---------------
2023-09-04 14:31:50.994267
current #epochs=1, #steps=0
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
[1693837925.790486] [amorgenstern-titanx8-25nlt:1130019:f]        vfs_fuse.c:281  UCX  ERROR inotify_add_watch(/tmp) failed: No space left on device
start validation
acc: 0.530806
AUC: 0.620555
Avg Precision: 0.259841
Avg Recall: 1.000000
d_prime: 0.434075
train_loss: 1.116545
valid_loss: 1.349214
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0001
Epoch-1 lr: 0.0001
epoch 1 training time: 40.206
---------------
2023-09-04 14:32:31.200635
current #epochs=2, #steps=40
start validation
acc: 0.530806
AUC: 0.591694
Avg Precision: 0.260787
Avg Recall: 1.000000
d_prime: 0.327963
train_loss: 1.102174
valid_loss: 1.350781
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0001
Epoch-2 lr: 0.0001
epoch 2 training time: 22.792
---------------
2023-09-04 14:32:53.992906
current #epochs=3, #steps=80
Epoch: [3][20/40]	Per Sample Total Time 0.01095	Per Sample Data Time 0.00132	Per Sample DNN Time 0.00962	Train Loss 1.1056	
start validation
acc: 0.530806
AUC: 0.578362
Avg Precision: 0.261581
Avg Recall: 1.000000
d_prime: 0.279598
train_loss: 1.100599
valid_loss: 1.355132
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0001
Epoch-3 lr: 0.0001
epoch 3 training time: 22.744
---------------
2023-09-04 14:33:16.737315
current #epochs=4, #steps=120
start validation
acc: 0.530806
AUC: 0.637788
Avg Precision: 0.263411
Avg Recall: 1.000000
d_prime: 0.498583
train_loss: 1.098526
valid_loss: 1.355402
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0001
Epoch-4 lr: 0.0001
epoch 4 training time: 22.782
---------------
2023-09-04 14:33:39.518957
current #epochs=5, #steps=160
start validation
acc: 0.530806
AUC: 0.692398
Avg Precision: 0.267698
Avg Recall: 1.000000
d_prime: 0.710866
train_loss: 1.098264
valid_loss: 1.355075
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0001
Epoch-5 lr: 0.0001
epoch 5 training time: 23.866
---------------
2023-09-04 14:34:03.384832
current #epochs=6, #steps=200
Epoch: [6][0/40]	Per Sample Total Time 0.03635	Per Sample Data Time 0.02559	Per Sample DNN Time 0.01077	Train Loss 1.0005	
start validation
acc: 0.530806
AUC: 0.689768
Avg Precision: 0.264294
Avg Recall: 1.000000
d_prime: 0.700309
train_loss: 1.095007
valid_loss: 1.354363
validation finished
normal learning rate scheduler step
Epoch-6 lr: 8.5e-05
Epoch-6 lr: 8.5e-05
epoch 6 training time: 22.679
---------------
2023-09-04 14:34:26.064019
current #epochs=7, #steps=240
start validation
acc: 0.578199
AUC: 0.684775
Avg Precision: 0.259606
Avg Recall: 1.000000
d_prime: 0.680370
train_loss: 1.073417
valid_loss: 1.335343
validation finished
normal learning rate scheduler step
Epoch-7 lr: 7.225000000000001e-05
Epoch-7 lr: 7.225000000000001e-05
epoch 7 training time: 26.234
---------------
2023-09-04 14:34:52.297667
current #epochs=8, #steps=280
Epoch: [8][20/40]	Per Sample Total Time 0.01096	Per Sample Data Time 0.00144	Per Sample DNN Time 0.00952	Train Loss 1.0488	
start validation
acc: 0.578199
AUC: 0.682761
Avg Precision: 0.266047
Avg Recall: 1.000000
d_prime: 0.672364
train_loss: 1.047774
valid_loss: 1.325611
validation finished
normal learning rate scheduler step
Epoch-8 lr: 6.141250000000001e-05
Epoch-8 lr: 6.141250000000001e-05
epoch 8 training time: 23.830
---------------
2023-09-04 14:35:16.128076
current #epochs=9, #steps=320
start validation
acc: 0.573460
AUC: 0.711510
Avg Precision: 0.270980
Avg Recall: 1.000000
d_prime: 0.788849
train_loss: 1.008191
valid_loss: 1.304806
validation finished
normal learning rate scheduler step
Epoch-9 lr: 5.2200625000000005e-05
Epoch-9 lr: 5.2200625000000005e-05
epoch 9 training time: 22.892
---------------
2023-09-04 14:35:39.020128
current #epochs=10, #steps=360
start validation
acc: 0.545024
AUC: 0.650634
Avg Precision: 0.261927
Avg Recall: 1.000000
d_prime: 0.547346
train_loss: 1.017860
valid_loss: 1.331651
validation finished
normal learning rate scheduler step
Epoch-10 lr: 4.437053125e-05
Epoch-10 lr: 4.437053125e-05
epoch 10 training time: 22.762
---------------
2023-09-04 14:36:01.782477
current #epochs=11, #steps=400
Epoch: [11][0/40]	Per Sample Total Time 0.03624	Per Sample Data Time 0.02585	Per Sample DNN Time 0.01039	Train Loss 0.8970	
start validation
acc: 0.587678
AUC: 0.712630
Avg Precision: 0.268362
Avg Recall: 1.000000
d_prime: 0.793494
train_loss: 1.002194
valid_loss: 1.324354
validation finished
normal learning rate scheduler step
Epoch-11 lr: 3.77149515625e-05
Epoch-11 lr: 3.77149515625e-05
epoch 11 training time: 25.422
---------------
2023-09-04 14:36:27.204702
current #epochs=12, #steps=440
start validation
acc: 0.582938
AUC: 0.714780
Avg Precision: 0.271928
Avg Recall: 1.000000
d_prime: 0.802431
train_loss: 0.982307
valid_loss: 1.308298
validation finished
normal learning rate scheduler step
Epoch-12 lr: 3.2057708828124995e-05
Epoch-12 lr: 3.2057708828124995e-05
epoch 12 training time: 22.927
---------------
2023-09-04 14:36:50.131611
current #epochs=13, #steps=480
Epoch: [13][20/40]	Per Sample Total Time 0.01095	Per Sample Data Time 0.00134	Per Sample DNN Time 0.00961	Train Loss 0.9834	
start validation
acc: 0.639810
AUC: 0.711089
Avg Precision: 0.275517
Avg Recall: 1.000000
d_prime: 0.787109
train_loss: 0.957902
valid_loss: 1.296860
validation finished
normal learning rate scheduler step
Epoch-13 lr: 2.7249052503906245e-05
Epoch-13 lr: 2.7249052503906245e-05
epoch 13 training time: 25.249
---------------
2023-09-04 14:37:15.380810
current #epochs=14, #steps=520
start validation
acc: 0.601896
AUC: 0.719899
Avg Precision: 0.276225
Avg Recall: 1.000000
d_prime: 0.823840
train_loss: 0.972318
valid_loss: 1.296321
validation finished
normal learning rate scheduler step
Epoch-14 lr: 2.3161694628320308e-05
Epoch-14 lr: 2.3161694628320308e-05
epoch 14 training time: 23.318
---------------
2023-09-04 14:37:38.698491
current #epochs=15, #steps=560
start validation
acc: 0.654028
AUC: 0.729447
Avg Precision: 0.280397
Avg Recall: 1.000000
d_prime: 0.864284
train_loss: 0.952087
valid_loss: 1.287782
validation finished
normal learning rate scheduler step
Epoch-15 lr: 1.9687440434072263e-05
Epoch-15 lr: 1.9687440434072263e-05
epoch 15 training time: 25.821
---------------
2023-09-04 14:38:04.519329
current #epochs=16, #steps=600
Epoch: [16][0/40]	Per Sample Total Time 0.03486	Per Sample Data Time 0.02403	Per Sample DNN Time 0.01084	Train Loss 0.9465	
start validation
acc: 0.592417
AUC: 0.732638
Avg Precision: 0.272492
Avg Recall: 1.000000
d_prime: 0.877959
train_loss: 0.943321
valid_loss: 1.291183
validation finished
normal learning rate scheduler step
Epoch-16 lr: 1.673432436896142e-05
Epoch-16 lr: 1.673432436896142e-05
epoch 16 training time: 22.774
---------------
2023-09-04 14:38:27.293593
current #epochs=17, #steps=640
start validation
acc: 0.658768
AUC: 0.738388
Avg Precision: 0.278566
Avg Recall: 1.000000
d_prime: 0.902809
train_loss: 0.917401
valid_loss: 1.275426
validation finished
normal learning rate scheduler step
Epoch-17 lr: 1.4224175713617208e-05
Epoch-17 lr: 1.4224175713617208e-05
epoch 17 training time: 25.369
---------------
2023-09-04 14:38:52.662631
current #epochs=18, #steps=680
Epoch: [18][20/40]	Per Sample Total Time 0.01103	Per Sample Data Time 0.00136	Per Sample DNN Time 0.00967	Train Loss 0.9511	
start validation
acc: 0.649289
AUC: 0.736740
Avg Precision: 0.279891
Avg Recall: 1.000000
d_prime: 0.895660
train_loss: 0.918066
valid_loss: 1.279826
validation finished
normal learning rate scheduler step
Epoch-18 lr: 1.2090549356574626e-05
Epoch-18 lr: 1.2090549356574626e-05
epoch 18 training time: 23.021
---------------
2023-09-04 14:39:15.683597
current #epochs=19, #steps=720
start validation
acc: 0.635071
AUC: 0.751458
Avg Precision: 0.278414
Avg Recall: 1.000000
d_prime: 0.960373
train_loss: 0.916131
valid_loss: 1.273934
validation finished
normal learning rate scheduler step
Epoch-19 lr: 1.0276966953088432e-05
Epoch-19 lr: 1.0276966953088432e-05
epoch 19 training time: 22.866
---------------
2023-09-04 14:39:38.549142
current #epochs=20, #steps=760
start validation
acc: 0.644550
AUC: 0.740295
Avg Precision: 0.275861
Avg Recall: 1.000000
d_prime: 0.911115
train_loss: 0.913145
valid_loss: 1.279294
validation finished
normal learning rate scheduler step
Epoch-20 lr: 8.735421910125167e-06
Epoch-20 lr: 8.735421910125167e-06
epoch 20 training time: 22.848
---------------
2023-09-04 14:40:01.397657
current #epochs=21, #steps=800
Epoch: [21][0/40]	Per Sample Total Time 0.03468	Per Sample Data Time 0.02490	Per Sample DNN Time 0.00978	Train Loss 0.8039	
start validation
acc: 0.654028
AUC: 0.759160
Avg Precision: 0.281816
Avg Recall: 1.000000
d_prime: 0.995045
train_loss: 0.879399
valid_loss: 1.264045
validation finished
normal learning rate scheduler step
Epoch-21 lr: 7.425108623606392e-06
Epoch-21 lr: 7.425108623606392e-06
epoch 21 training time: 22.757
---------------
2023-09-04 14:40:24.154410
current #epochs=22, #steps=840
start validation
acc: 0.649289
AUC: 0.760008
Avg Precision: 0.272376
Avg Recall: 1.000000
d_prime: 0.998901
train_loss: 0.903058
valid_loss: 1.266231
validation finished
normal learning rate scheduler step
Epoch-22 lr: 6.3113423300654325e-06
Epoch-22 lr: 6.3113423300654325e-06
epoch 22 training time: 22.991
---------------
2023-09-04 14:40:47.145154
current #epochs=23, #steps=880
Epoch: [23][20/40]	Per Sample Total Time 0.01081	Per Sample Data Time 0.00129	Per Sample DNN Time 0.00952	Train Loss 0.8701	
start validation
acc: 0.644550
AUC: 0.753031
Avg Precision: 0.269893
Avg Recall: 1.000000
d_prime: 0.967407
train_loss: 0.875799
valid_loss: 1.269747
validation finished
normal learning rate scheduler step
Epoch-23 lr: 5.3646409805556175e-06
Epoch-23 lr: 5.3646409805556175e-06
epoch 23 training time: 22.810
---------------
2023-09-04 14:41:09.955174
current #epochs=24, #steps=920
start validation
acc: 0.668246
AUC: 0.762297
Avg Precision: 0.273536
Avg Recall: 1.000000
d_prime: 1.009341
train_loss: 0.873779
valid_loss: 1.261351
validation finished
normal learning rate scheduler step
Epoch-24 lr: 4.559944833472275e-06
Epoch-24 lr: 4.559944833472275e-06
epoch 24 training time: 25.427
---------------
2023-09-04 14:41:35.382340
current #epochs=25, #steps=960
start validation
acc: 0.654028
AUC: 0.761221
Avg Precision: 0.272776
Avg Recall: 1.000000
d_prime: 1.004427
train_loss: 0.890529
valid_loss: 1.262846
validation finished
normal learning rate scheduler step
Epoch-25 lr: 3.875953108451433e-06
Epoch-25 lr: 3.875953108451433e-06
epoch 25 training time: 22.875
---------------
2023-09-04 14:41:58.256786
current #epochs=26, #steps=1000
Epoch: [26][0/40]	Per Sample Total Time 0.03563	Per Sample Data Time 0.02535	Per Sample DNN Time 0.01028	Train Loss 0.8560	
start validation
acc: 0.663507
AUC: 0.758733
Avg Precision: 0.270608
Avg Recall: 1.000000
d_prime: 0.993106
train_loss: 0.885573
valid_loss: 1.260677
validation finished
normal learning rate scheduler step
Epoch-26 lr: 3.2945601421837183e-06
Epoch-26 lr: 3.2945601421837183e-06
epoch 26 training time: 22.828
---------------
2023-09-04 14:42:21.084973
current #epochs=27, #steps=1040
start validation
acc: 0.658768
AUC: 0.762701
Avg Precision: 0.273560
Avg Recall: 1.000000
d_prime: 1.011188
train_loss: 0.880827
valid_loss: 1.260202
validation finished
normal learning rate scheduler step
Epoch-27 lr: 2.8003761208561607e-06
Epoch-27 lr: 2.8003761208561607e-06
epoch 27 training time: 22.928
---------------
2023-09-04 14:42:44.012512
current #epochs=28, #steps=1080
Epoch: [28][20/40]	Per Sample Total Time 0.01091	Per Sample Data Time 0.00131	Per Sample DNN Time 0.00960	Train Loss 0.8842	
start validation
acc: 0.668246
AUC: 0.761890
Avg Precision: 0.268539
Avg Recall: 1.000000
d_prime: 1.007480
train_loss: 0.882985
valid_loss: 1.255610
validation finished
normal learning rate scheduler step
Epoch-28 lr: 2.3803197027277364e-06
Epoch-28 lr: 2.3803197027277364e-06
epoch 28 training time: 22.817
---------------
2023-09-04 14:43:06.829649
current #epochs=29, #steps=1120
start validation
acc: 0.668246
AUC: 0.762162
Avg Precision: 0.268754
Avg Recall: 1.000000
d_prime: 1.008724
train_loss: 0.879909
valid_loss: 1.257623
validation finished
normal learning rate scheduler step
Epoch-29 lr: 2.0232717473185757e-06
Epoch-29 lr: 2.0232717473185757e-06
epoch 29 training time: 22.789
---------------
2023-09-04 14:43:29.618499
current #epochs=30, #steps=1160
start validation
acc: 0.677725
AUC: 0.762837
Avg Precision: 0.268616
Avg Recall: 1.000000
d_prime: 1.011812
train_loss: 0.879082
valid_loss: 1.254194
validation finished
normal learning rate scheduler step
Epoch-30 lr: 1.7197809852207893e-06
Epoch-30 lr: 1.7197809852207893e-06
epoch 30 training time: 25.394
