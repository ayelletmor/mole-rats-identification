Blind Mole Rats (BMRs) communicate using seismic signaling by head-drumming in their tunnels. Yael Kimchi’s lab at Weizmann Institute of Science studies the BMRs communication. They conducted recorded experiments of BMRs communicating by head-drummings. Our project is to identify the “speaker” BMR by taking the recorded audio seismic signal using deep learning. We received a limited number of annotated raw audio files and conducted signal processing techniques which included cross-correlation, filtering and extraction to significantly increase the size of the dataset so it could be used for training a model to learn to classify the different BMR speakers. We used the pre-trained SSAST model, which is a pure self-attention transformer model used for audio classification, pre-trained in a self-supervised manner. We found that given our processed dataset, the model achieved high accuracy prediction of the BMR speaker. To the best of our knowledge, this is the first time a deep learning model successfully managed to achieve this, from which we can conclude that each BMR communicates in a pattern which can be learnt and recognized. This result opens up the opportunity of conducting further research on the communication of BMRs. 
